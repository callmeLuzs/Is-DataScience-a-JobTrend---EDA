Job Title,Job Description,Company Name,Location,Industry,Sector
Data Analyst,"Sapphire Digital seeks a dynamic and driven mid-level Data Analyst/QA to join our growing New Jersey team with experience in the healthcare domain. This role will perform in-depth analysis of our internal data management systems to identify, analyze, and interpret trends and/or patterns in order to provide actionable recommendations for data integrity. The Data Analyst/QA will work closely with multiple internal teams to collaborate on different stages of the data lifecycle and assist in developing data quality processes.
In this position, you'll be responsible for:
Preparing and conducting analyses and studies, needs assessment, and requirements analysis to align systems and solutions
Overseing data QA functions to ensure data integrity and accuracy
Monitoring all production data processes and validation systems
Performing data investigations, root cause analysis, data profiling, and data lineage activities
Performing research and provides recommendations for data processes and updates
Reviewing and analyzes specific data elements for accuracy and quality assurance
Driving the resolution of the identified data quality problems
Maintaining documentation as required
Partnering with BI in the development of reports and presentations
Maintaining data quality rules, data standards and data governance policies
Supporting special project work as assigned by the data managers
Collaborating effectively with cross functional teams including Data, Business Intelligence, Business Applications, and Engineering

You might be a good fit if you have:
Bachelor's degree (B. A. / B. S.) from four-year college or university; 4+ years related experience and/or training; or equivalent combination of education and experience
5+ years of experience as a data analyst or in a related field
Expertise with query languages (SQL) required
Experience working with large complex datasets including healthcare data such as medical claims, clinical information, demographic data and program activity results
Exposure with one or more of the following programming languages: SAS, Python, R
Prior experience working with Healthcare data, or in the Healthcare field preferred
Experience with data visualization tools and methodologies (Excel and PowerBI)
Demonstrated experience in analyzing large data sets and relational databases
Ability to manage time and priorities of multiple projects/tasks
Displays professionalism and ability to learn quickly
Extremely detail oriented
Strong oral and written communication skills
Ability to collaborate closely with multiple teams across with a wide range of technical backgrounds","Sapphire Digital
3.4","Lyndhurst, NJ",Internet,Information Technology
Data Scientist,"Job Brief

The ideal candidate will have previous Data Modeling experience. Strong preference will be given to candidates with an actuarial background in the property and casualty insurance space.

Overview

IFG Companies is in search of a Data Scientist to join its growing Predictive Modeling team.

The ideal candidate will have previous Data Modeling experience. Strong preference will be given to candidates with an actuarial background in the property and casualty insurance space.

Responsibilities
Build predictive and/or Machine Learning models in SAS
Research new statistical and mathematical techniques that are suitable and helpful for solving business related problems
Prepare data for modelling and make best/creative use of applicable and available internal or external data
Identifying and integrating new datasets that can be leveraged for modeling efforts
Support related processes around effectively deploying model to business
Effectively communicate results in written, oral and presentation formats to technical and non-technical audiences
Qualifications
Bachelor’s degree in statistics, applied mathematics, or related discipline
3+ years of Data Modeling or similar experience.
Experience with predictive modeling (classification, regression, parameter tuning, optimization criteria, feature selection), preferably with multiple techniques
Experience in model validation techniques, model testing and continuous monitoring of model performance
Experience in Property & Casualty Insurance is strongly preferred.
Demonstrated experience working with large relational data sets.
Working knowledge in SAS, R, Python or another platform to develop and implement predictive models.
Ability and willingness to quickly gain knowledge of SAS enterprise guide and enterprise miner.
Ability to communicate complex technical information in common language to foster teaching and analytics guidance to internal customers.
Advanced experience in analytics, data cleaning, and predictive modeling.
Ability to write queries in SQL.
Detail-oriented and ability to work collaboratively
Physical Demands
Physical demands are considered to be that of an office environment, climate controlled, with minimal physical exertion. This position requires prolonged sitting, ability to utilize a computer and interactions with others in meetings or via phone.
Benefits
We offer a competitive compensation and benefits package including medical, dental, vision, 401(k), flexible spending, short-term and long-term disability insurance, life insurance, long-term care, education assistance and paid time off.
IFG Companies is an equal opportunity employer committed to a diverse workforce. M/F/D/V","IFG Companies
2.9","New York, NY",Insurance Carriers,Insurance
Data Scientist,"Company Description:

Quartet is a pioneering healthcare technology company striving to improve the lives of people with mental health conditions. We connect people to a personalized care team to get them the right care at the right time. Our collaborative technology platform and range of services brings together physicians, mental health providers, and insurance companies to effectively improve patient outcomes and drive down healthcare costs. Backed by $153MM in venture funding from top investors like Oak HC/FT, GV (formerly Google Ventures), F-Prime Capital Partners, Polaris Partners, Centene Corporation and Echo Ventures. Quartet is headquartered in NYC and is currently operating in several markets across the United States Pennsylvania, Washington, Northern California, New Jersey, North Carolina, Louisiana, and Illinois.

About the team & opportunity:

As a Data Scientist at Quartet, you will work on a range of projects -- developing statistical analyses to study impact of Quartet interventions; predicting mental health needs among populations; building machine learning models to suggest timely and appropriate behavioral health care interventions for patients. You'll develop a deep understanding of Quartet interventions and the predictive models and algorithms.

You will design and develop effective models, features, and algorithms involving multiple datasets, including user activity, Electronic Health Records (EHR), admissions, discharges and transfers (ADT), medical claims, pharmacy claims, and lab test claims. Leverages knowledge of computer science, machine learning, data mining and software architecture to build high-quality data products. Supports the design of Quartet products, including: an entity resolution and de-duplication library for linking patients and providers data, which is collected from multiple sources; a machine learning application for the detection of opioid use disorder in patients using supervised learning and deep learning; and an optical mark recognition (OMR) computer vision application for transcribing paper assessments.

Accountabilities:
Research and develop machine-learning and statistical models in Quartet Health's platform to improve software personalization and recommendations for users
Drives a data-informed process for experimenting with new products to improve patient outcomes and operational efficiency.
Performing ML research, exploratory data analysis, and computer-vision modeling; developing model evaluation and online maintenance methodologies, including confidence estimation, calibration, and concept drift
Develop general-purpose frameworks to support machine learning applications in production.
Minimum Qualifications:
2-3 years experience as a data scientist.
Formal training in statistics and computer science.
Knowledge of mathematical fundamentals: probability theory, linear algebra and statistics.
Strong data transformation and extraction skills with SQL databases.
Strong statistical programming skills in both Python and R.
Comfort/self-sufficiency with Amazon Web Services infrastructure.
Comfort/self-sufficiency with Linux command line.
Comfort/self-sufficiency with git for version control.
Ability to work on projects from initial to final phase- beginning by defining a problem, developing an implementation plan, and overseeing deployment and maintenance.
Ability to clearly communicate across disciplines and work collaboratively.
Experience with any of the following: Docker, TensorFlow, Keras, Numpy, Scipy, Pandas, Gensim, Scikit-learn, NLKT, Jupyter
Employee Benefits for Quartet include: Unlimited vacation, volunteer opportunities, catered lunches, snacks, team events and outings, mental healthcare coverage of 15 free therapy sessions + unlimited copay reimbursements, medical, dental + vision coverage, generous parental leave, commuter benefits, 401K, stock option grants, gym benefits.

Want to know what Quartet life is like? Click here to meet our team.

Quartet is committed to building a diverse team and fostering an inclusive culture, and is proud to be an equal opportunity employer. We embrace and encourage our employees' differences in race, religion, color, national origin, gender, family status, sexual orientation, gender identity, gender expression, age, veteran status, disability, pregnancy, medical conditions, and other characteristics. Headhunters and recruitment agencies may not submit resumes/CVs through this Web site or directly to managers. Quartet does not accept unsolicited headhunter and agency resumes. Quartet will not pay fees to any third-party agency or company that does not have a signed agreement with Quartet.

Please note: Quartet interview requests and job offers only originate from quartethealth.com email addresses (e.g. jsmith@quartethealth.com). Quartet will also never ask for bank information (e.g. account and routing number), social security numbers, passwords, or other sensitive information to be delivered via email. If you receive a scam email or wish to report a security issue involving Quartet, please notify us at: security@quartethealth.com.

Have someone to refer? Email talent@quartethealth.com to submit their details to us.","Quartet Health
3.9","New York, NY",Enterprise Software & Network Solutions,Information Technology
Data Scientist,"A Career with Point72’s MI Data team
At Point72 MI Data, our Data Scientists sift through petabytes of unstructured data from diverse sources to discover trends and insights that help Point72’s Portfolio Managers create new investment theses. We combine an experiment-based approach with the strongest possible management support and the freedom to innovate unencumbered by bureaucracy. We encourage our Data Scientists to imagine the impossible, and provide the structure to bring those ideas to market in months, not years.
What you’ll do
Our Data Scientists conduct research through data mining and statistical modeling to discover insights from Big Data that are used by our investment professionals to make investment decisions. You will have the opportunity to work in a highly collegial environment that emphasizes teaching and learning as a team. In this role, you will:
Tackle the challenges of featurizing and modeling large and unstructured data using machine learning and statistical techniques
Manage all aspects of the research and execution process including methodology selection, data collection and quality, modeling and analysis, and performance monitoring
Deliver research findings to investment teams, portfolio managers, and other internal clients
Work within a team to help drive technical innovation through a collaborative R&D process

What’s required
We look for candidates with extensive knowledge in machine learning, statistical models, and data mining tools, and a proven track record of working with large structured and unstructured data sets to extract timely, actionable insights. Other requirements include:
MS or PhD degree in a quantitative discipline
3+ years of industry working experience in a role that requires advanced statistical analysis
3+ years of hands-on working experience with varied and complex data sets
Strong programming skills in the following languages: SQL, Python (preferred), R, Scala, Spark
Ability to think creatively and see the big picture as well as finer details

We take care of our people
We invest in our people, their careers, their health, and their well-being. We want you to concentrate on success and leave the rest to us. When you work here, we provide:
Fully-paid health care benefits
Generous parental and family leave policies
Mental and physical wellness programs
Tuition assistance
A 401(k) savings program with an employer match and more

About Point72
Point72 Asset Management is a global firm led by Steven Cohen that invests in multiple asset classes and strategies worldwide. Resting on more than a quarter-century of investing experience, we seek to be the industry’s premier asset manager through delivering superior risk-adjusted returns, adhering to the highest ethical standards, and offering the greatest opportunities to the industry’s brightest talent. We’re inventing the future of finance by revolutionizing how we develop our people and how we use data to shape our thinking.","Point72
3.9","New York, NY",Investment Banking & Asset Management,Finance
Data Scientist,"Data Scientist
Affinity Solutions / Marketing Cloud seeks smart, curious, technically savvy candidates to join our cutting-edge data science team. We hire the best and brightest and give them the opportunity to work on industry-leading technologies.
The data sciences team at AFS/Marketing Cloud build models, machine learning algorithms that power all our ad-tech/mar-tech products at scale, develop methodology and tools to precisely and effectively measure market campaign effects, and research in-house and public data sources for consumer spend behavior insights. In this role, you'll have the opportunity to come up with new ideas and solutions that will lead to improvement of our ability to target the right audience, derive insights and provide better measurement methodology for marketing campaigns. You'll access our core data asset and machine learning infrastructure to power your ideas.
Duties and Responsibilities
· Support all clients model building needs, including maintaining and improving current modeling/scoring methodology and processes,
· Provide innovative solutions to customized modeling/scoring/targeting with appropriate ML/statistical tools,
· Provide analytical/statistical support such as marketing test design, projection, campaign measurement, market insights to clients and stakeholders.
· Mine large consumer datasets in the cloud environment to support ad hoc business and statistical analysis,
· Develop and Improve automation capabilities to enable customized delivery of the analytical products to clients,
· Communicate the methodologies and the results to the management, clients and none technical stakeholders.
Basic Qualifications
· Advanced degree in Statistics/Mathematics/Computer Science/Economics or other fields that requires advanced training in data analytics.
· Being able to apply basic statistical/ML concepts and reasoning to address and solve business problems such as targeting, test design, KPI projection and performance measurement.
· Entrepreneurial, highly self-motivated, collaborative, keen attention to detail, willingness and capable learn quickly, and ability to effectively prioritize and execute tasks in a high pressure environment.
· Being flexible to accept different task assignments and able to work on a tight time schedule.
· Excellent command of one or more programming languages; preferably Python, SAS or R
· Familiar with one of the database technologies such as PostgreSQL, MySQL, can write basic SQL queries
· Great communication skills (verbal, written and presentation)
Preferred Qualifications
· Experience or exposure to large consumer and/or demographic data sets.
· Familiarity with data manipulation and cleaning routines and techniques.","Affinity Solutions
3.0","New York, NY",Advertising & Marketing,Business Services
Data Scientist,"Job Description
Company Description

As an Etsy employee, you can do the work you love, be yourself, and make an impact in the lives of millions. Our commitments to diversity and inclusion, team culture and the spaces where we work all reflect our mission to keep commerce human.Job Description

Data scientists at Etsy use rigorous methods to generate insights that inform product, engineering, and business decisions across the company. We collaborate with partner teams through all stages of development: actively uncovering opportunity areas, crafting experiments to test hypotheses, analyzing the impact of our efforts, and highlighting takeaways.

Learning new skills and techniques is not only a requirement but a perk of the job! We are always looking for opportunities to grow. Our mission is to guide our partner teams with data and insights and tell the story of how we attract and retain our users — to teams, to senior management, and to the community.

We're hiring partners for a few key Product teams, including the search experience and fulfillment teams. These groups are focused are enhancing their areas of the core shopping experience to connect more buyers with sellers offering just the items they need.

This role is located in Brooklyn, NY and is part of our Analytics and Strategic Finance team.

About the Role
Transform raw data into impactful analysis characterized by strong data governance/documentation, rigorous techniques, and actionable recommendations.
Partner with product, engineering, design teams; use behavioral and transactional data to shed light on our users and our product experience, identify areas for improvement, and drive decision-making.
Identify actionable metrics to understand the performance of products, develop reporting dashboards to track progress, and ingrain these metrics into teams’ day-to-day decision-making.
Lead experimentation, help teams set strong hypotheses, and deliver robust analysis of experiment results.
Continually evaluate and refine your technical toolkit; teach what you learn to the team.
Qualifications

About You
2-3 years experience as an analyst or in a quantitative role in which you extracted meaning from big data sets with little engineering support.
Understand the principles of A/B testing, and love crafting and analyzing experiments.
Proficient in SQL and have familiarity with either R or Python. Bonus points for experience with the Hadoop ecosystem or additional scripting languages (Scala, PHP, Ruby, etc.).
Experience with Looker, Tableau, or other data visualization software a plus.
You look for ways to advance your technical skill set and to apply new methods to impactful questions.
You can communicate your insights verbally, visually, and in writing and care deeply about the quality and integrity of your work.
You want to play a key role on a cross-functional team.
You are passionate about subjects such as experimental design, data visualization, and statistical analysis techniques.
Additional Information

At Etsy, we believe that a diverse, equitable and inclusive workplace makes us a more relevant, more competitive, and more resilient company. We welcome people from all backgrounds, ethnicities, cultures, and experiences. Etsy is an equal opportunity employer. We do not discriminate on the basis of race, color, ancestry, religion, national origin, sexual orientation, age, citizenship, marital or family status, disability, gender identity or expression, veteran status, or any other legally protected status. We will ensure that individuals with disabilities are provided a reasonable accommodation to participate in the job application or interview process, to perform essential job functions, and to receive other benefits and privileges of employment. While Etsy supports visa sponsorship, sponsorship opportunities may be limited to certain roles and skillsets.","Etsy
3.6","New York, NY",Other Retail Stores,Retail
Data Scientist,"Job Description
What does WITHIN do?

We are Performance Branding experts. WITHIN works with some of the coolest brands and hottest startups, including Nike, AB InBev, Spanx and Shake Shack. We leverage digital channels and inspiring creative to fuel clients' growth using data every step of the way to drive our decision making.

What you will build as a Data Scientist at WITHIN...
You will cross-functionally collaborate with the Performance and Creative teams to understand our business then build machine-learning models to uncover trends and optimize performance
You will build scalable clustering, customer lifetime value, and churn models to help clients maximize long-term profitability
You will build and maintain data pipelines internal and external teams rely on for making key decisions
You will build and improve our underlying data infrastructure (we currently use Fivetran, GCP/BigQuery, and dbt as our analytics stack)
Requirements

You might be a fit for this role if...
You have professional SQL experience and understand the benefits of columnar storage
You have familiarity with git and the command line
You know how to write object-oriented Python
You have experience building machine learning models for both structured (decision-trees, linear regression, etc) and unstructured data (Computer Vision, NLP)
You understand the benefits of dbt for data transformations
You have the desire to learn Microservice Architecture (Docker and Kubernetes)
You are naturally curious and embrace failure as you learn new technologies
You have an obsession with accuracy
You have excellent listening and collaboration skills
Benefits

We offer competitive salary and benefits based on ability level including:
Competitive salary dependent on experience
Unlimited vacation policy
Anniversary vacation bonus
401k with match
Fully paid health insurance premiums
Monthly transportation and phone stipends
In-house massages, manicures, and haircuts
Daily lunch
Fully stocked kitchen
Dog-friendly office","WITHIN
4.4","New York, NY",Advertising & Marketing,Business Services
Data Scientist,"About Datadog:We're on a mission to build the best platform in the world for engineers to understand and scale their systems, applications, and teams. We operate at high scale-trillions of data points per day-providing always-on alerting, metrics visualization, logs, and application tracing for tens of thousands of companies. Our engineering culture values pragmatism, honesty, and simplicity to solve hard problems the right way. The opportunity:You will have a fantastic team of data engineers to support you, a collaborative environment to encourage your work, and the best technologies for performing data science at high scale in your toolkit. You will:* Present the latest academic research papers to your team.* Research and benchmark the latest algorithms that can be used for our particular use-cases.* Apply machine learning algorithms and statistical techniques to build new product features.* Deploy a new feature to production, instantly affecting customers with your work.* Mentor other data scientists on your team.* Explore and find meaning in extremely high volumes of data.* Investigate and fix a production issue from a service your team owns. Requirements:* You have 2 + years professional experience* You are fluent with SQL / relational algebra.* You have mastered working with data in a language such as Python, R, or Julia.* You've done data science at high scale with tools like Hadoop and Spark.* You have backend programming experience in one or more languages.* You have significant experience applying machine learning to real business problems.* You want to work in a fast, high-growth startup environment and thrive on autonomy.* You care about code simplicity and performance.* You have a BS/MS/PhD in a scientific field or equivalent experience.* You can explain complex ideas and algorithms in understandable ways. Bonus points:* You've written production data pipelines.* You're familiar with time series analysis.","Datadog
4.1","New York, NY",Computer Hardware & Software,Information Technology
Data Scientist,"Caserta is a best-in-class Data Analytics consulting and implementation firm known for its bold solutions to the toughest data challenges. Leading organizations including world-class Financial Services, Healthcare, Media, Ad-tech and Universities, turn to Caserta for the right answer to effect change and realize business goals. We specialize in transformative strategic consulting in the areas of business intelligence, data intelligence, and artificial intelligence. Renowned for our advanced technical implementation of data architecture, data engineering, and data science, Caserta provides meticulous customer service and is dedicated to solving our clients' toughest data challenges with the right answers.Experience & Qualifications:* Experience building complex Data Pipelines, Algorithms and Models with the latest technology stacks:? Python, R, Scala, PySpark? AWS, S3, EC2, EMR? Hadoop, Hive, MapR, Spark? AWS, Google Cloud(GCP), Azure* Experience developing commercial data science solutions leveraging one or more of the following: operations research, Natural Language Processing(NLP), Machine Learning(ML), Deep Learning, video/image/text analysis, or time-series analysis.* Experience with Structured and Unstructured Data* Experience building recommendation engines - Multi-Algorithm/Multi-ModelDisciplines:? NumPy, Pandas, SciPy, Scikit-learn? TensorFlow, Keras, Neural Networks, Deep Learning, NLP, Text Analytics","Caserta
4.3","New York, NY",IT Services,Information Technology
Data Scientist,"Job Description
Join the INTERACTIVE BROKERS Team!
Interactive Brokers has been at the forefront of the Fintech space for over 40 years and we pride ourselves on being a technology company. We continue to challenge the status quo and push boundaries to offer the best trading platform with the most sophisticated features all for the lowest cost to our customers.

Job Description:

Interactive Brokers Group (IBG) is looking for a junior Data Scientist. We are looking for someone to execute analytical tasks on large data sets to support decision makers and provide insight and reports about our platforms. The data scientist role will use data to help us better understand who our clients are, how they engage with our products and services and how we can better serve them by identifying interesting and useful trends in our data. You will make an impact by using your passion for data and analysis to generate actionable insights that we will use to improve the experience for our clients.

**For this position, the company is not sponsoring applicants for work visas**

You will be expected to:
Collect and analyze various telemetry and behavioral data
Produce daily metrics and reports
Clean and prepare data for Machine Learning and A.I.
Assist with designing and running A/B tests
Automate frequently used reporting and data analysis workflows
Work closely with software engineers and architects to extract, transform and standardize data for optimal use for analytic tools
You will need to have:
Bachelor's in computer science, Mathematics, Statistics, or related fields
2+ years' experience in a data science or data analysis role
2+ years of Java coding experience
2+ years mining and analyzing data sets to extract meaningful trends, producing meaningful and actionable reports
Experience using statistical programming languages, machine learning and other toolkits and techniques for analyzing large, complex datasets
Technical proficiency with transforming structured and unstructured data sets
Strong analytical skills, attention to detail and accuracy
Expert problem-solving skills and creative thinking ability
What we'd also love to see:
Master's degree in previously listed fields (strongly preferred)
An ambitious and diligent individual
An innovative mindset with a drive to improve upon existing systems
A desire to solve challenging problems
Company Perks:
Competitive salary, annual performance-based bonuses, and annual stock grants.
Daily company paid lunch.
401k with company match.
Excellent medical, dental, and vision benefits.
Newly renovated offices with sit/stand desks and multi-monitor setups.
Team outings and dinners.
Education reimbursement and learning opportunities.
Company Overview

Interactive Brokers (""IBKR""), a subsidiary of publicly-traded Interactive Brokers Group, Inc., based in Greenwich, Connecticut (NASDAQ: IBKR) is a low-cost provider of trade execution and clearing services for active traders, institutional investors, financial advisors and introducing brokers. IBKR's premier technology provides electronic access to stocks, options, futures, forex, bonds, and funds worldwide from a single IBKR Integrated Investment account. IBKR is one of the largest online brokers by trade volume and is consistently ranked at the top of its field.

Our employees are part of a dynamic, multinational, fast-paced, results-oriented team working to provide our customers with state-of-the-art trading technology, superior execution capabilities, worldwide electronic access, and sophisticated risk management tools.

Our headquarters are in Greenwich, CT, USA. IBKR has offices in the United States, Canada, the United Kingdom, Switzerland, Hungary, Estonia, Russia, India, Hong Kong, China, Japan and Australia.

IBKR is a member of NYSE, FINRA, and SIPC. Interactive Brokers Group brokerage affiliates are regulated by securities and commodities agencies around the world.

Click HERE to view a short video with a few words from current Interactive Brokers employees.

For more information, please visit www.ibkr.com/info","IBG LLC
4.3","New York, NY",Brokerage Services,Finance
Data Scientist,"CLEAR's mission is to strengthen security and create frictionless experiences for consumers. We believe you are you and by using your biometrics - your fingerprints, eyes, and face - we keep you moving. Imagine a world where you can do virtually everything you need to - breeze through the airport, buy a beer at the game, check-in at the doctor's office, access your office building, and more - without ever pulling out your wallet or phone. Now in 60+ airports and other venues nationwide, you are your ID, credit card, ticket, reservation and more with CLEAR.We're defining and leading an entirely new industry, obsessing over our customers, and investing in great people to lead the way. Recently named on CNBC's Disruptor 50 List and winner of the SXSW Interactive Innovation Award, we're working tirelessly to create frictionless customer experiences for our 4+ million members across the country.We're seeking an innovative and results-oriented Data Scientist to identify actionable insights within our New Vertical business unit. As a critical member of the team, you will have a prominent voice in the future of the product from conception to launch, and in some cases IP creation. You're a deep thinker who is intellectually curious and enjoys solving critical problems. You are a self starter who can own a solution from end to end.You are technically proficient and have the ability to access and wrangle large amounts of structured and unstructured data, a great business sense, the desire to influence strategic decisions with data-driven analysis. You think deep, you happily prove your assumptions and you work fast. Lastly, you have strong written and verbal communication skills to translate the complex to the organization as a whole.This role requires you to have unrestricted work authorization to work in the United States.What You Will Do:* In house subject matter expert for a machine learning related product line, including the creation of algorithms.* Understand ground truth, create training models, devise new statistical models, using machine learning techniques within the context of domain specific and domain independent data.* Work collaboratively with the data science and product management teams to evolve current and build new quantitative product features.Who You Are:* Experience taking quantitative features to market.* Experience modeling risk related problems, particularly those with class imbalances is highly preferred.* Experience conceiving of new metrics based on synthesis of new and existing data is highly preferred.* You have a strong desire to work in a highly collaborative, team oriented, intellectually curious environment.* Comfortable scoping and structuring your work in the face of a variety of different problems types such as deterministic problems, amorphous, ambiguous, and otherwise heuristic ones as well.* Have at least an M.S. (preferred) or Bachelors (required) in Computer Science, Operations Research, Computational Economics, Statistics, Applied Mathematics, Data Science, or related major.* Demonstrable hands-on experience in Machine learning (Bayesian Analysis, Decision Trees, Random Forests, Boosted Trees, Support Vector Machines, Neural Networks, etc.) and Advanced mathematics to create product features.* 5+ years experience leveraging the Python Data Science stack (scikit-learn, Numpy, Pandas, etc.) to drive prototyping of large data sets. Experience with auto model building tools such as DataRobot, AutoML, et al. is highly desired.* Skilled in cleaning, transforming and otherwise statistically describing data for the purpose of feature engineering. Experience with Feature Tools or similar is highly preferred.* Proficient in leveraging a variety of visualization packages and applications such as Tableau, Looker, matplotlib, Python dash, plotly, et al. to expose meaningful insights in data.* Experience working with data warehouses and/or relational databases and SQL in a real-world context.","CLEAR
3.0","New York, NY",Security Services,Business Services
Data Scientist,"Our client is the leading freight marketplace that's transforming the $700 billion trucking industry, connecting shippers to a national network of reliable carriers. Fortune 500 companies such as Anheuser-Busch, Unilever, and Target rely on Our client to handle their most important FTL freight needs. With instant pricing tools, guaranteed capacity, data-driven insights, and reliable service, Our client is changing the world of transportation one load at a time. Come leave a positive impact on the environment as we help reduce the carbon footprint caused by the 65 billion wasted miles on the road.

Our client was named one of Forbes' ""Next Billion-Dollar Company"" in 2018.

Based in New York City, Our client is backed by top VC firms including New Enterprise Associates (NEA), Canvas Ventures, and Lerer Hippeau. The company has raised more than $78.5 million in funding.

The problems we solve everyday are real and require creativity, grit, and determination. We are building a culture that challenges norms while fostering experimentation and personal growth. We're hiring team members who are passionate and are energized by the vision to simplify and transform one of the largest and most complex industries through technology, data and a strong commitment to customers.

As a Data Scientist, you will implement machine learning models into critical business processes, forecast industry trends, and build data pipelines. The Data Science team works closely with engineers, pricing analysts, and the business intelligence team to complement qualitative knowledge of the freight industry with rigor and quantitative insights. We're currently living in AWS infrastructure including SageMaker and Redshift. You will be expected to autonomously run your own projects, drive business impact, and be a domain expert for teams across the company.

If you are excited about tackling challenges to improve the lives of truckers and shippers across the country and reinventing an industry from the inside out, send us your resume.

What you'll do:
Develop and implement pricing strategies into our automated bidding processes
Build forecasting models for freight market pricing changes using industry indicators
Collaborate with our Sales, Operations, and Tech teams to provide analytic and machine learning support
Execute long-term modeling initiatives
Drive adoption of improved, innovative technologies and tools
Act as a mentor for the data science teamHelp drive strategic data-driven analyses, insights, and report on KPIs
Partner with data engineering for system design and infrastructure
About you:
You have a Bachelor's degree in a STEM or quantitative field
You love data and have at least 2+ years experience with conducting in-depth data analyses, building machine learning models, and presenting results to business stakeholders
You have a solid grasp on both theory and application, and you know how to balance methodological purity with practical implementation
You are fluent with programming languages (Python, R)
You are comfortable working in high-paced, impact-driven environments
Price optimization and financial forecasting knowledge is a plus
Andiamo is an Equal Opportunity Employer

Andiamo provides equal employment opportunities to all employees and applicants for employment without regard to race, color, religion, sex, national origin, age, disability or genetics. In addition to federal law requirements, Andiamo complies with applicable state and local laws governing nondiscrimination in employment in every location in which the company has facilities. This policy applies to all terms and conditions of employment, including recruiting, hiring, placement, promotion, termination, layoff, recall, transfer, leaves of absence, compensation and training.

All qualified candidates are encouraged to apply by submitting their resume as an MS word document including a cover letter with a summary of relevant qualifications, highlighting clearly any special or relevant experience.","Andiamo
3.5","New York, NY",Casual Restaurants,"Restaurants, Bars & Food Services"
Data Scientist,"Passionate to eat better, Infarm was founded in Berlin in 2013 by Osnat Michaeli and the brothers Erez and Guy Galonska. With the aim to share the goodness of own-grown produce with everyone, they developed a smart modular farming system, that allows distribution of farms throughout the urban environment, growing fresh produce in any available space and fulfilling any market demand.

Today, with cutting edge R&D, patented technologies, and a leading multi-disciplinary team, Infarm is growing a global farming network helping cities become self-sufficient in their food production while significantly improving the safety, quality, and environmental footprint of our food.

Be part of the Infarm (r)evolution and help people to take back ownership of their food.

Who you are


At Infarm we grow a smart worldwide Infarm network that brings farming to the people. As the Data Scientist, you contribute to that mission by searching for patterns in financial data that can provide solutions to business problems or create new business opportunities. In this role, you will communicate clearly and effectively with both clients and multi-disciplinary teams and use advanced mathematical and computer science skills to analyze vast pools of data.

You appreciate diversity. You love to be challenged. You are passionate.

Responsibilities
Work with stakeholders throughout the organization to identify opportunities for leveraging company, customer, and market data to drive business solutions
Mine and analyze data from company databases to drive optimization and improvement of product development, marketing techniques, and business strategies
Analyze customer store data to evaluate key KPIs, understand trends, risks and opportunities; Propose solutions for identified risks/opportunities
Assist the management team with the development of expansion strategies including product offerings and regional market analysis
Gather and analyze market research data for various growth initiatives
Assist teams in analyzing data for efficiency/cost saving projects
Assess the effectiveness and accuracy of new data sources and data gathering techniques
Develop custom data models and algorithms to apply to data sets
Use predictive modeling to increase and optimize customer experiences, revenue generation, ad targeting, and other business outcomes
Develop company A/B testing framework and test model quality
Coordinate with different functional teams to implement models and monitor outcomes
Develop processes and tools to monitor and analyze model performance and data accuracy
Requirements
3+ years of experience manipulating data sets and building statistical models along with a Bachelor's degree (B. A. / B. S.) from four-year college or university in Statistics, Mathematics, Computer Science, or another quantitative field
Experience using statistical computer languages (R, Python, SLQ, etc.) to manipulate data and draw insights from large data sets preferred
Strong MS Excel skills (data analysis, modeling, and functions) with SQL querying experience preferred
Knowledge of advanced statistical techniques and concepts (regression, properties of distributions, regression, simulations, scenario analysis, modeling, clustering, decision trees, statistical tests, and proper usage, etc.) and experience with applications
Strong problem-solving skills with an emphasis on product development
Experience analyzing data from 3rd party providers as needed and visualizing/presenting data for stakeholders
A drive to learn and master new technologies and techniques
Excellent written and verbal communication skills for coordinating across teams
What we offer
The opportunity to join Infarm as we expand across the globe and help change the future of farming
The ability to drive impact and be a true partner to the business, working closely with top-level managers
A friendly work environment with a diverse group of motivated, talented, and visionary colleagues
Comprehensive healthcare benefits
19 days of vacation plus an extra day off on your birthday
Infarm is an equal opportunity employer. We strive to grow an inclusive environment, where everyone can thrive, regardless of your background and circumstances. We nurture diversity because we appreciate the uniqueness and differences between people. Each employee's distinctive experiences, perspectives, and viewpoints helps us build a resilient environment, where we can all learn, grow, and create great things together. All applicants are given equal opportunity regardless of age, gender identity or expression, language, disability, ethnic origin, national origin, religion, belief, culture, socio-economic status, or sexual orientation.","infarm
4.2","New York, NY",Food & Beverage Stores,Retail
Data Scientist,We make small businesses more successful through better banking.Our company is looking for a Data Scientist to join our growing team as we enter a new phase of expansion,"NorthOne
4.3","New York, NY",-1,-1
Data Scientist,"Looking for a job to get you out of bed?Casper is looking to add a Data Scientist to our Data and Analytics team. The Data Scientist will touch all aspects of the organization including marketing, retail, operations, product, customer experience, wholesale and engineering to increase the organization's sophistication leveraging data and modelling to drive decision-making and optimize profit generating activities.Casper (casper.com) was created to re-imagine sleep from the ground up, beginning with its obsessively engineered, outrageously comfortable mattress. All of Casper's sleep products - including its pillow, bedding, and furniture - are developed in-house by the company's award-winning R&D team in San Francisco. Casper was named one of Fast Company's Most Innovative Companies in the World and its eponymous mattress was crowned one of TIME Magazine's Best Inventions.We are deeply committed to building a diverse and inclusive workforce so that we represent all those who dream big equally.When you're not catching zzz's, this is what you'll do...You have the statistical and technical firepower to take advantage of our rich data, translate business problems into data science products and solutions, and accelerate our data-driven approach to decisioning. The Data Scientist will focus on areas within Marketing Analytics, with responsibilities including:* Refine, evolve and take ownership of our media mix model to drive increased understanding of marketing spend impact and a full spectrum of factors on revenue and collaborate with analytics to enhance scenario planning capabilities* Develop and continue enhancing our media mix optimization process, drive marketing strategy and budget allocation through statistical modeling and analysis* Improve customer acquisition efficiency and drive profitable growth by enhancing Casper's data driven revenue prediction models* Carry out customer path analysis and predictive modeling to understand customer journey and customer behaviors* Develop customer segmentation models to uncover opportunities for CRM and drive more personalized experiences to increase customer value and profitability* Build comprehensive testing frameworks to empower and champion a testing culture that rapidly tests, measures, and iterates, executing in conjunction with the Digital Product, Acquisition and Customer Marketing teams to continually measure new tactics and strategies and drive strategic learningsOur dream candidate...* 4+ years of experience working in data and analytics, with an emphasis on marketing analytics and /or product development, preferably at an omni-channel e-commerce brand, and working with teams to successfully implement spend recommendations to drive business growth* Bachelor's degree with a quantitative focus in Economics, Computer Science, Statistics, Engineering, other technical field or equivalent practical experience. MS/MBA or PhD in a quantitative field is preferred.* Proficient knowledge in statistical modeling and machine learning methodologies, bonus points for experience with generalized linear models, time-series, state space, and econometric modeling* Strong data modeling skills including writing complex SQL queries, experience with dbt a plus.* Python expertise, with a solid understanding of open source data mining / data visualization software packages (e.g., scipy, pandas, numpy).* Experience of using data visualization platforms such as Looker, and web analytics platforms like Heap, Google Analytics is preferred* Experience of implementing modeling algorithms for business applications* Strong communication skills and able to influence others to achieve buy-in for recommendations and translate business challenges into data science applications that meaningfully drive results* Highly motivated self-learner. Flexible, adaptable, able to work in a fast-paced agile environment* Excited by the prospect of developing and building a data science competency at Casper from the ground up and finding new applications for data science partnerships with senior leaders. Lots of latitude to identify new area for impact and implement proof of concept work to drive impact and adoptionThe syrup on your waffles...* Participation in our HQ bonus program for some splurging and equity so that you're part of the Casper family.* Medical, vision, and dental insurance to help you with those coughs or cavities (too many waffles...)* Wellness programs like cash incentives for tracking sleep and fitness, credits for your favorite studios and in-office activities* Unlimited vacation policy. If you need time off just take it; we trust you!* Catered lunches twice a week to give you time to catch up with your teammate* Free snacks and coffee, including a huge breakfast selection (10 types of cereal anyone?)* A full gifted bed set when you join and product discounts for friends and family!If you dream about this stuff this job is probably right for you. We look forward to learning more about you!","Casper
3.4","New York, NY",Home Furniture & Housewares Stores,Retail
Data Analyst,"About Cubist
Cubist Systematic Strategies is one of the world’s premier investment firms. The firm deploys systematic, computer-driven trading strategies across multiple liquid asset classes, including equities, futures and foreign exchange. The core of our effort is rigorous research into a wide range of market anomalies, fueled by our unparalleled access to a wide range of publicly available data sources.
Job Description
We are passionate about data. We collaborate to build elegant, effective, scalable and highly reliable solutions to empower predictive modelling in finance.
Cubist’s Data Services group is looking for a Data Analyst to join our dedicated team. Our group is responsible for the timely delivery of comprehensive and error-free data to some of the most demanding and successful systematic Portfolio Managers in the world.
This exceptional individual will be a member of a small team of Data Scientists/Analysts who play a vital role in ensuring the smooth day-to-day implementation of a large research infrastructure, and the live production trading of billions of dollars of capital across global capital markets, including equities, futures, options and other financial instruments.
Job Responsibilities
Identifying potential data sources
Coordinating with compliance team and legal team on new vendor trial/subscription process
Assisting with collecting and maintaining vendor overviews and content offerings
Assisting with data questions and requests from investment teams
Setting up feed downloads and monitor check-in database
Monitoring the automated data collection and cleansing infrastructure
Assisting with scheduling meetings and conference calls between data users and experts
Assisting Data team with interoffice travel arrangements, expenses, etc.
Assisting in organizing presentations
Managing data trial repository permissions
Downloading trial datasets from vendor FTP sites or other delivery mechanism
Assisting Data Team with manual data processing as required
Maintaining Cubist Data Wiki contents
Desirable Candidates
Bachelor degree required
Basic understanding of SQL.
Programming skills in Python and at least one of C#, C++, or Java are a plus
Proficient knowledge of Microsoft Outlook, Excel, and Word
Financial industry experience is preferred but not required
Strong organization, communication and interpersonal skills
Attention to detail and a love of process
Strong oral and written communication skills
Ability to exercise sound judgment in assessing and determining how to handle queries, calls and issues
Ability to multitask and prioritize assignments","Point72
3.9","New York, NY",Investment Banking & Asset Management,Finance
Data Scientist,"viagogo is an industry-leading entertainment marketplace dedicated to helping people attend their favorite live events. We are expecting rapid growth after acquiring Stubhub.

Our team of data scientists uses data to automate manual processes and human decisions. This function is crucial to scaling our business across all geographies, languages, and currencies. You'll mine rich data sets and find insights that will drive the decisions that power our platform. Every piece of work you complete will tie directly into a business goal so you can measure the impact you have on viagogo.

About You:
Love to have an impact, learn from the best, and help people access unforgettable experiences
Currently pursuing or recently completed a degree in a quantitative field like statistics, mathematics, computer sciences, or engineering
Have familiarity with using tools like Python, SQL, or R
Initially, you'll learn:
How to present findings and make decisions with a real commercial impact
How to explore and find meaning in extremely high volumes of data
How we use tools like Python, SQL, and R to analyze, visualize, and present data
How to optimize coverage and ef?ciency of ad campaigns through search engines and social media platforms
Best practices for designing, running, and analyzing feature experiments (A/B tests)
What your team's goals are and how to achieve them
Your Growth Path:
Receive mentorship and a clear path for growing your technical and leadership skills
Be given autonomy to make decisions regarding experiments and tests
Demonstrated results and increasing ownership are rewarded
What we offer:
An environment where you can quickly grow your skills, autonomy, and knowledge
A+ Compensation Package, including stock incentives
Paid Time Off, 401k, Health, Vision, and Dental Insurance
Dog friendly office, weekly lunches, office snacks, and team events
About Data Science at viagogo:

Rather than having a compartmentalized team of data scientists, our data scientists are embedded into cross-functional groups. viagogo's agile teams consist of data scientists, engineers, analysts, and product managers who achieve success through their collaborative culture and entrepreneurial mindset.

We are a multicultural, diverse team that values a coactive approach to making data-driven decisions.

About viagogo:

viagogo is the leading global marketplace for music, sports, and entertainment tickets. We have acquired StubHub and look forward to our continued market leadership.

Despite our rapid growth while revolutionizing a 100-billion-dollar industry, we maintain our start-up ethos and data-driven, collaborative culture. We believe that small, cross-functional teams can achieve extraordinary results. Fans from nearly every country in the world can find millions of tickets to their favorite events in the language, currency, and with the device of their choice.

We provide the widest possible choice of tickets to events around the world and help ticket sellers reach a global audience. viagogo has partnered with many of the world's leading brands in sports and entertainment while helping fans access unforgettable experiences.

We are an equal opportunity employer and value diversity on our team. We do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status.","viagogo
3.2","New York, NY",Internet,Information Technology
Data Scientist,"YOUR ROLE

CompIQ is building a future where predicting your career path and potential earnings is easy and fun. To do this, we use artificial intelligence and machine learning to help companies and industry professionals make informed decisions in their career. To solve such a large problem, we’ve put together an incredible team and are selectively adding to it.

You will play a mission-critical role in helping advance the intelligence machine that powers CompIQ's products.

You will have the opportunity to constantly learn new things, take on responsibilities and help propel a successful startup to even further success. Companies and consumers alike will rely heavily on what you build! If challenges excite you, and you are ready for a large one, let us know.

SKILLS AND EXPERIENCE

4+ years of experience or 2+ years of experience if you hold a graduate degree in a relevant field (statistics, mathematics, (astro)physics, computer science, etc) of hands on data science using Python including:

• Data wrangling: acquire, clean, analyze and present data

• Text mining and Natural Language Processing including regular expressions, packages TM, NLTK, etc.

• Machine Learning: clustering, regression/classification

• Statistics

DESIRED SKILLS/EXPERIENCES

Experience with databases, APIs, web scraping, financial modelling, economics, software engineering standards (git, collaboration and project management software, software development lifecycle understanding, general computer science principles), science background

Located in or willing to relocate to New York City",CompIQ,"New York, NY",Enterprise Software & Network Solutions,Information Technology
Data Scientist,"You are key to helping global clients make better decisions based on data analytics.

As a data scientist at Gallup, you will apply your knowledge of statistical and machine-learning techniques to a wide variety of challenging projects customized to our clients’ complex global research. Working on the biggest stage for researchers, you’ll explain and predict large-scale social behavior (e.g., consumer spending, lifestyle trends, political stability, election outcomes, and employee performance and retention) using data from Gallup, the web, third parties (e.g., governments, IGOs and NGOs) and our clients. We will count on your expertise with parametric, nonparametric, linear, and nonlinear methods as well as feature selection and variable transformation. And we will depend on your ability to translate data for clients in a comprehensible way.

Gallup’s unique data give you an unparalleled opportunity to use your creativity to explore new avenues of social research. If you are passionate about using data to solve the world’s most pressing problems, join Gallup — the company that established the gold standard in survey research methodology.

Who we want:
Analytical thinkers who use their research talents to provide critical insights in advanced analytics for the growing needs of global organizations
Curious researchers who apply their instincts and expertise to discover breakthroughs that are key to clients’ growth
Sophisticated communicators who can easily explain complex technical material to nontechnical audiences
Self-motivated professionals who can manage multiple projects, set a standard of excellence, and consistently deliver exceptional results
Data experts who excel at building predictive models using various data sources and techniques to inform business decisions
Mission-driven scientists who are motivated to solve the world’s most pressing problems
What you need:
Master’s degree required. Degree from a statistics, engineering, mathematics, computer science, computational social science, physics, or operations research program preferred. Ph.D. a plus.
At least six years of professional work experience conducting analysis and writing code in Python and R required.
A deep understanding of the mathematical fundamentals of machine learning and statistics, with an emphasis on nonparametric and nonlinear methods (e.g., random forests, support vector machines, neural networks) required
Previous work experience with survey design, sampling, weighting, item nonresponse, imputation and other survey research concepts and challenges preferred
Must be currently authorized to work in the United States on a full-time basis
What we offer:
A strengths-based, engagement-focused, and performance-oriented culture
A flexible work environment
World-class managers who support, empower, and engage you
Ongoing learning and development opportunities
Mission-driven work that changes the lives of people around the world
Gallup is an equal opportunity/affirmative action employer that celebrates, supports, and promotes diversity and inclusion. We will consider all qualified applicants without regard to race, color, religion, sex, national origin, disability, protected veteran status, sexual orientation or gender identity, or any other legally protected basis, in accordance with applicable law.","Gallup
4.2","New York, NY",Consulting,Business Services
Data Scientist,"Amazon is building a world class advertising business and defining and delivering a collection of self-service performance advertising products that drive discovery and sales of merchandise. Our products are strategically important to our Retail and Marketplace businesses driving long term growth. We deliver billions of ad impressions and millions of clicks daily and are breaking fresh ground to create world-class products.

Our team's mandate is to accelerate advertising in the Books category as it requires a differentiated customer and advertiser experience. We own end-to-end the advertising experience including placements, ad relevance, creative, ad serving, advertiser experience, and marketing. We are looking for entrepreneurial, innovative individuals who thrive on solving tough problems. We are investing in a deep science and technical team to pursue a transformation opportunity.

About this role:
We are seeking a talented, energetic, entrepreneurial, and self-driven Data Scientist to join our team. Our team works on complex science, engineering, optimization, econometric, and user-experience problems in order to deliver relevant product ads on Amazon search and detail pages world-wide. Leveraging Amazon's massive data repository, our data scientists develop experiments, insights and optimizations that enable the monetization of Amazon online and mobile search properties while enhancing the experience of Amazon shoppers.

In this role, you will:
· Solve new and challenging problems using statistical, Machine Learning, or optimization approaches to create measurable customer facing impact.
· Translate prototype models to production quality, scaling to millions of customers and across different languages.
· Design experiments leveraging your models to measure effectiveness.
· Work closely with product, business and engineering teams to execute on your project plans.
· Communicate verbally and in writing to senior leaders with various levels of technical knowledge, educating them about your approach, as well as sharing insights and recommendations.
· Drive best practices on the team; mentor and guide junior members to achieve their career growth potential.



Basic Qualifications

· Bachelor's Degree
· 3+ years of experience with data scripting languages (e.g SQL, Python, R etc.) or statistical/mathematical software (e.g. R, SAS, or Matlab)
· 2 years working as a Data Scientist

Preferred Qualifications

· Masters or PhD Degree in Statistics, Applied Mathematics, Computer Science, Operations Research, Economics or a related quantitative field.
· Experience in the Ad-Tech industry
· Experience building content based recommendation models
· Experience in NLP techniques
· Excellent verbal and written communication skills with the ability to effectively advocate technical solutions to research scientists, engineering teams and business audiences.



Amazon is committed to a diverse and inclusive workplace. Amazon is an equal opportunity employer and does not discriminate on the basis of race, national origin, gender, gender identity, sexual orientation, protected veteran status, disability, age, or other legally protected status. For individuals with disabilities who would like to request an accommodation, please visit https://www.amazon.jobs/en/disability/us.



#sspajobs #sspasv #adsto #booksvert","Amazon
3.9","New York, NY",Internet,Information Technology
Data Scientist,#NAME?,Pierce Technology Corp,"New York, NY",-1,-1
Data Scientist,"About Known

Known is a modern marketing company engineered for the unprecedented challenges and opportunities facing marketers today. Known pairs PhD data scientists with award-winning creatives, expert research teams and strategists. Known is anchored by two decades of groundbreaking market research and data science capabilities, which uniquely empower our marketing strategy and acclaimed creative groups, who produce some of the most innovative, cutting-edge creative work in culture. The result? Marketing that is predisposed to succeed and be persistently optimized, directly impacting clients' bottom lines. Our clients span the leading brands in finance, technology, media, CPG, real estate and many other categories. Known has over 200 employees in 6 US cities including Seattle, San Francisco, Los Angeles, Austin, Boston and New York. Our teams have won multiple Emmys, Clios, Effies, Cannes Lions Awards and ProMax Agency of the Year three times.

Known’s Media Science team uses advanced analytics, machine learning, statistics, and algorithms to plan and optimize advertising dollars. We partner with our clients to translate their business goals into meaningful metrics, and buy media across all channels to drive those target outcomes. We are looking for a Data Scientist to join the team and work alongside other data analysts, data scientists, and software engineers.

The ideal candidate will have:
A Masters or PhD from a well-regarded college or university. STEM degrees are preferred.
3+ years of hands-on experience doing quantitative analysis, modeling, optimization and/or statistics. Experience utilizing Python (or similar language) and SQL.
Superb communication and presentation skills
A desire to work on advertising challenges that require flexibility in approach -- everything from on-the-fly analytics to statistics, big data, machine learning, and mathematical algorithms
An ability to translate business challenges into quantitative problems, and solve them by whatever means necessary, which may not always be strict machine learning
A willingness to learn foundational knowledge and skills rapidly
An ability to think strategically, analytically, and proactively about diverse business problems
A commitment to managing the quality & accuracy of analytics, ensuring high standards with your and others’ work
Experience in advertising or advertising technology is a plus
Experience multi-tasking in a fast-paced environment is a plus
Experience working directly with clients is a plus
Experience working on a tech team is a plus, with experience in cloud technologies, version control, etc.
Your responsibilities would include:
Driving performance for our media campaigns and amazing our clients
Day-to-day management of advertising spend you’re responsible for, including ideation on quantitative approaches for driving value, monitoring metrics, and troubleshooting issues
Developing new techniques (e.g., ML models, optimization algorithms, and automation) to optimize KPIs and improve Known IP
Building analyses, stories and slides for client reports
Interfacing directly with clients to communicate results
Productionalizing workflows and contributing your code to our Known repos
Operating existing software infrastructure to traffic, evaluate performance, and analyze media","Known
3.0","New York, NY",Advertising & Marketing,Business Services
Data Scientist,"Job: Data Scientist

Reports to: Director, Data & Insights

Start Date: ASAP

At its core, DoSomething.org is a data-driven organization. Data leads every strategy and goal-setting conversation. The Data & Insights teams job is to analyze large and rapidly evolving data sets to detect changes in our member's behavior and the global youth population.

The Data Scientists role at DoSomething.org is to be the analytical powerhouse that fuels and informs decision making across the organization enabling us to create the most socially and civically engaged generation of young people, ever. You will deliver analyses and products that advance our understanding of drivers of growth and impact.

A successful candidate will possess strong analytical and programming skills alongside a steadfast sense of curiosity, ability to communicate to technical and non-technical stakeholders and a solutions-oriented mindset.

What you'll do:
Data Analysis and Model Building (50%)
Mine and synthesize large data sets to enhance the organizations understanding of membership segments, propensities, outcomes and decision points.
Build models and analyses that uncover the key drivers of acquisition, engagement and retention within the context of the DoSomething campaign mix and product feature development.
Build statistical models to predict various outcomes of interest and forecast KPIs
Deliver findings & recommendations to non-technical, cross-functional stakeholders via various visualization methods (Google Analytics, Slides, Docs, Looker, notebooks etc.)
Assist in sizing impact of new growth opportunities
Contribute to the development DoSomething.orgs long term analytics strategy
Data Infrastructure Strategy & Design (20%)
Collaborate with product management and engineering departments to understand company needs and devise possible data product solutions that scale
Inform requirements for derived tables that enable analysis; Optimize these joint development efforts through appropriate database use and project design
Inform requirements for monitoring to ensure our data pipelines are functional, scalable and working as expected
BI/ Operational support (30%)
Support ad hoc requests for data & insights from business stakeholders across product, marketing, campaign and business development teams
Support top level Looker reports/dashboards for non-technical staff
What we're looking for:
Strong sense of curiosity. You have the desire to learn new skills and understand complex problems fast.
Ability to explain analytical outcomes in basic terms. You understand why making data accessible to the larger organization is important, and don't want to be a gatekeeper to this pertinent information.
High degree of technical proficiency:
2-3 years of experience with SQL (any variant is fine, though we use PostgreSQL)
1-3 years of experience with R or Python
Ability to write scalable, portable scripts that automate querying or generate reproducible analysis
Experience with the following:
BI tool (Tableau/Looker/PowerBI)
Working with non-relational data
Data warehousing technology and environments (a plus, not a non-negotiable)
Team oriented with the ability to work cross-functionally and collaboratively at all levels of the organization.
Well-rounded individual. You are currently learning a new skill or adopting a new hobby that has nothing to do with data science.
Other Notes:
Data is everywhere. If youve worked with it at scale, apply, even if you dont meet every single qualification, please apply! Past successful candidates have come with backgrounds in CS, statistics, mathematics, and economics, although these are not required.
Application Instructions.

Here at DoSomething, we are committed to cultivating an equitable and inclusive environment where a diverse group of people can do their best work, and that starts with how we hire. We ask that you please remove all identifying information from your resume before you upload your application in an effort to help us remove unconscious bias from our resume review process.

Identifying information includes your name, photos, LinkedIn URL, email and physical address.

The Perks.
3 weeks vacation plus the week between Christmas and New Years (plus Summer Fridays from Memorial Day to Labor Day!). And your birthday, Valentines day, and a half-day on Halloween. If youre in costume. Seriously.
An inclusive office environment, a gong, brownie bake-offs, and the best coworkers you could ask for.
Medical and dental premiums fully covered by us. Mhmm. You read that right.
Five (or six? Were losing count.) different ways of making coffee.
An incredibly compelling reason to wake up and make it to work every day.
DoSomething.org is an equal opportunity employer.
Please, no calls.

------------------------------------------------

DoSomething.org and DoSomething Strategic (we, us) are committed to protecting and respecting your privacy. This policy explains when and why we collect personal information on candidates, and how we keep it secure.

Who are we?
DoSomething.org is one of the largest organizations in the world focused on young people and social change. DoSomething Strategic is the consulting arm of DoSomething.org. Our 6 million+ members take action, online and offline, to better their communities by participating in one of our 250+ cause campaigns.
How and why we collect data from you.
We collect and retain data that is included in your job application. This includes your full name, contact information, and any personal information disclosed in your resume, cover letter, and other supplemental application materials.
Data is collected for evaluation criteria when seeking employment at DoSomething
We will only use your data for what was originally intended -- for purposes of seeking and gaining employment at DoSomething. Your data will not be recycled for marketing emails or to sell to third parties.
How long do we retain this data?
DoSomething will retain candidate profiles for 3 years.
Annually on August 1, candidate profiles from 3+ years prior will be entirely deleted from our system.
Is your data secure?
JazzHR maintains secure job board pages. Job boards will default to HTTPS. Additionally, if we were to terminate our contract with JazzHR our candidate data is deleted from JazzHRs systems in accordance with JazzHRs Terms of Service.
Powered by JazzHR","DoSomething.org
3.6","New York, NY",Social Assistance,Non-Profit
Data Scientist,"We are building a new kind of financial company. You would be leading a team of data engineers responsible for data acquisition from multiple vendors, transforming it, and making it usable across the entire organization. You will work closely with research and operations in order to ensure they have access to the information they need. You will have a major influence on the design of the systems and processes. You will work with the latest cloud-based technologies. Responsibilities Lead major initiatives successfully Implement the hardest parts of the system Play a critical role in technical direction for the team Produce high-quality work and improve others by thoughtful code reviews Influence engineering culture Lead and coordinate releases across multiple teams Provide high-quality feedback on teammates and collaborators from other teams Help with recruiting of senior engineers Preferred Qualifications B.S. in Computer Science 5+ years of experience Working knowledge of big data, streaming and queuing tools Strong oral and written communication Bonus Qualifications Knowledge of Airflow and Python","ApTask
3.9","New York, NY",IT Services,Information Technology
Data Scientist,"Hinge is seeking a versatile data scientist to work on product development initiatives. From assessing opportunities and results through analytical techniques to curating personalized experiences with machine learning, you will take on a central and multi-faceted role in the product development process. In turn, your work will deeply influence how millions of Hinge members connect with each other.
Responsibilities
Collaborate with a cross-functional team of product managers, researchers, and engineers to develop and iterate on product features
Translate product objectives to data science problems and vice versa
Apply statistical inference to draw rigorous conclusions from data
Identify and execute on opportunities to apply machine learning to improve user experience
Perform ad hoc exploratory analysis as needed
Requirements:
2+ years of experience as data scientist
Strong knowledge of statistics and machine learning
Experience with A/B testing
Proficiency in SQL and Python
Exposure to engineering best practices
Superb communication skills
Deep sense of intellectual curiosity
Comfort with ambiguity
Our Company:
Hinge is the dating app for people who want to get off dating apps. In today’s digital world, singles are so busy matching that they’re not actually connecting, in person, where it counts. Hinge is on a mission to change that. So we built an app that’s designed to be deleted. On Hinge, there are no rules, timers, or games. Instead, you’ll meet your most compatible matches and you’ll have unique conversations over what you’ve shared on your detailed profile. It’s a natural way to find a great first date. Currently, 3 out of 4 first dates lead to second dates, we’re the #1 mobile-first dating app mentioned in the New York Times wedding section, and we’re the fastest growing dating app in the US, UK, Canada, and Australia.

Our Culture:
- Authenticity: Share your genuine thoughts and opinions directly.
- Courage: Invite and deeply consider challenges and criticism.
- Empathy: Be empathetic, communitarian and trustworthy.

We are an equal opportunity employer and value diversity at our company. We do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status.","Match Group
2.8","New York, NY",Advertising & Marketing,Business Services
Data Scientist,"Data Scientist Join the INTERACTIVE BROKERS Team! Interactive Brokers has been at the forefront of the Fintech space for over 40 years and we pride ourselves on being a technology company. We continue to challenge the status quo and push boundaries to offer the best trading platform with the most sophisticated features all for the lowest cost to our customers. Job Description Interactive Brokers Group (IBG) is looking for a junior Data Scientist. We are looking for someone to execute analytical tasks on large data sets to support decision makers and provide insight and reports about our platforms. The data scientist role will use data to help us better understand who our clients are, how they engage with our products and services and how we can better serve them by identifying interesting and useful trends in our data. You will make an impact by using your passion for data and analysis to generate actionable insights that we will use to improve the experience for our clients. For this position, the company is not sponsoring applicants for work visas You will be expected to Collect and analyze various telemetry and behavioral data Produce daily metrics and reports Clean and prepare data for Machine Learning and A.I. Assist with designing and running AB tests Automate frequently used reporting and data analysis workflows Work closely with software engineers and architects to extract, transform and standardize data for optimal use for analytic tools You will need to have Bacheloraposs in computer science, Mathematics, Statistics, or related fields 2+ yearsapos experience in a data science or data analysis role 2+ years of Java coding experience 2+ years mining and analyzing data sets to extract meaningful trends, producing meaningful and actionable reports Experience using statistical programming languages, machine learning and other toolkits and techniques for analyzing large, complex datasets Technical proficiency with transforming structured and unstructured data sets Strong analytical skills, attention to detail and accuracy Expert problem-solving skills and creative thinking ability What weaposd also love to see Masteraposs degree in previously listed fields (strongly preferred) An ambitious and diligent individual An innovative mindset with a drive to improve upon existing systems A desire to solve challenging problems Company Perks Competitive salary, annual performance-based bonuses, and annual stock grants. Daily company paid lunch. 401k with company match. Excellent medical, dental, and vision benefits. Newly renovated offices with sitstand desks and multi-monitor setups. Team outings and dinners. Education reimbursement and learning opportunities. Company Overview Interactive Brokers (""IBKR""), a subsidiary of publicly-traded Interactive Brokers Group, Inc., based in Greenwich, Connecticut (NASDAQ IBKR) is a low-cost provider of trade execution and clearing services for active traders, institutional investors, financial advisors and introducing brokers. IBKRaposs premier technology provides electronic access to stocks, options, futures, forex, bonds, and funds worldwide from a single IBKR Integrated Investment account. IBKR is one of the largest online brokers by trade volume and is consistently ranked at the top of its field. Our employees are part of a dynamic, multinational, fast-paced, results-oriented team working to provide our customers with state-of-the-art trading technology, superior execution capabilities, worldwide electronic access, and sophisticated risk management tools. Our headquarters are in Greenwich, CT, USA. IBKR has offices in the United States, Canada, the United Kingdom, Switzerland, Hungary, Estonia, Russia, India, Hong Kong, China, Japan and Australia. IBKR is a member of NYSE, FINRA, and SIPC. Interactive Brokers Group brokerage affiliates are regulated by securities and commodities agencies around the world. Click HERE to view a short video with a few words from current Interactive Brokers employees. For more information, please visit www.ibkr.cominfo","Interactive Brokers
2.9","New York, NY",Brokerage Services,Finance
Data Scientist,"A retail energy provider in New York is looking for several Data Scientists to join their growing team. Here, you'll have the opportunity to be a part of one of the state's biggest initiatives in the clean energy space. As a part of a small but hungry team, you will work on exciting projects, and get the hands on experience required to thrive in the Data Science field while interfacing with key stake holders and senior leadership regularly. About You - 3-5 years experience in industry as a Data Scientist or Machine Learning Engineer - Masters Degree or PhD in a Quantitative field - Working experience with Python, AWS, SQL - Strong written and oral communication skills - Experience in Energy, Finance, or Digital Retail space - Experience with customer lifetime value, churn propensity, segmentation, cash flow models etc.. If this sounds like you, please apply! Sthree US is acting as an Employment Agency in relation to this vacancy.",Huxley Banking & Financial Services,"New York, NY",-1,-1
Data Scientist,"We’re seeing a passionate Data Scientist to join the team at One Drop. Data Science is all about providing startlingly novel and refreshingly useful decision support directly to One Drop’s end users. For example, One Drop is the first company to make blood glucose prediction available to the majority of people with diabetes. Working with One Drop’s behavioral and health science, diabetes education, engineering, and product teams, we invent new ways to convert over 11 billion health data points into daily support and suggestions for over 2 million users through the One Drop app.

We look at a wide variety of health and lifestyle data provided by users both actively, through logging, and passively, from phones and wearables. Our job is to help inform the hundreds of decisions that people with chronic conditions have to make every day, to empower users to take the actions that will help them get healthier. There are a lot of directions to explore, and each team member is expected and encouraged to help set the development agenda.
You'll make an impact by
Developing machine learning, deep learning, or dynamic simulation models for forecasting and classification
Creating new model features by intelligently combining multiple data sources
Adding to One Drop’s inventory of tools and routines to accelerate experimentation
Creatively applying additional techniques to develop and test new data products
Envisioning new and useful data-driven applications to help people manage chronic conditions
You'll bring
Several years of experience in machine learning or simulation modeling
Strong skills with a scripting language such as Python, and data-related libraries
Expertise in any of deep learning, time series forecasting, pattern identification, recommendation systems, natural language processing, or other data science subdomains with application to helping transform the lives of people living with diabetes
Ability and motivation to absorb new, complex domain knowledge quickly
Evident verbal and written communication skills ranging from documentation of experiments and results to explaining project goals, plans, and progress
Demonstrated ability to set and follow a productive agenda independently, while keeping coordinated with the team
Bonus Points:
Experience with data related to diabetes or other chronic conditions
Experience with tracking data from mobiles and wearables
A personal connection to, or passion for empowering people living with chronic conditions
You'll get
Deeply impact the lives of people with chronic conditions
Work at an early stage startup and help develop the future of healthcare
Competitive salary and equity commensurate with experience and performance
Medical, Dental, and Vision insurance and 401k plan
Yearly Professional Development Budget
Unlimited Vacation Days
Weekly Catered Lunches, Company Swag, company outings, and other surprises when you start
One Drop is the future of healthcare. Our mission is to develop technology that ensures all people living with diabetes and other chronic conditions can thrive. We harness the power of data science and mobile computing to make healthcare more affordable, accessible, and effective.

Our clinically proven mobile platform combines AI-powered predictive insights, personalized health coaching, and FDA-approved connected devices to simplify self-care. And it works. People using the One Drop platform have seen significant improvements in their health in just a few weeks.

Today, the rate of people living with chronic conditions is increasing dramatically, and traditional approaches to healthcare cannot possibly scale to reach them all. We exist to serve those people and help them lead their best lives. www.onedrop.today

One Drop provides equal employment opportunities (EEO) to all employees and applicants for employment without regard to race, color, religion, sex, national origin, age, disability or genetics.

To all recruitment agencies: One Drop does not accept unsolicited agency resumes. Please do not forward resumes to our jobs alias or One Drop employees. One Drop is not responsible for any fees related to unsolicited resumes.",One Drop,"New York, NY",Computer Hardware & Software,Information Technology
Data Scientist,"Job Description


Data Scientist will be responsible for researching and building machine learning and natural language processing applications. You will work as part of our client highly collaborative R&D team, and your solutions will directly and rapidly impact our client business. This includes researching and developing models, algorithms, and applications; analyzing raw source data and derived data; presenting findings; and building tools.

Job Responsibilities:
Develop an understanding of our client platform
Use your machine learning expertise to research and recommend the best approaches to solving our technology and business problems
Design, implement, and validate your solutions using Scala or Python on a large state-of-the-art cluster
Work with our Engineering teams to integrate your solutions into client platform
Requirements & Preferred Skills:
A Ph.D., (or Master’s degree plus at least 5 years’ relevant experience), in Computer Science, Statistics, Linguistics, Mathematics, Economics, Physics, or a related scientific discipline.
At least 2+ years of experience working with large datasets for drawing business insights. Work experience at leading high tech companies such as Google, Amazon, and Facebook etc. is highly desirable.
Research experience and coursework in Machine Learning
Fluency in Python programming
Experience with large data sets
Strong understanding of statistics and modeling techniques
Desire to work in a highly collaborative environment
Experience with Natural Language Processing, Information Retrieval, or Recommender Systems.
Experience with distributed computing, such as Hadoop, Spark, or related technologies would also be an added advantage.
Experience with mathematical optimization, control theory, time-series analysis would also be an added advantage.",Microagility,"New York, NY",Consulting,Business Services
Data Scientist,"OnPoint is a connected solutions business within Koch Engineered Solutions, a unit of Koch Industries, Inc., that leverages unique engineering capabilities and expertise in combination with digital technology. The OnPoint solutions portfolio drives advanced, actionable insights to help customers identify root causes, analyze performance, and optimize equipment as well as plant operations to improve efficiency, yield, reliability, environmental performance, and safety.

OnPoint Digital Solutions is looking for a Data Scientist to join our competitive data analytics and software development team. OnPoint is a new Koch engineered digital solutions company, focused to provide actionable insights for our customers to enable real time monitoring and optimization of their operations. OnPoint combines our deep subject matter expertise in combustion, distillation, separation, filtration with digital technology to deliver new solutions and technology which will create value for our customers. The Data Scientist will work with a dynamic team and be responsible for delivering A.I. algorithms to solve problem in industrial arena and expand the capability of our analytics platform to deploy the developed solutions at scale.

A Day In The Life Typically Includes:
Research, design and develop machine learning algorithms as part of the product development team
Perform Root Cause Analysis leveraging data science on large industrial problems related to process control, process engineering, and discrete manufacturing environments
Collaborate with our process engineering teams as the expert in applied data science and machine learning techniques
Use industry technologies, tools, and data mining frameworks for data analytics including data visualization for analyzing, optimizing, developing hypotheses, and drawing conclusions
What You Will Need:

Basic Qualifications:
3+ years of industry experience analyzing data sets and applying machine learning to assist decision making and solve industrial problems
3+ years of experience building and deploying scalable A.I. models using state of the art learning algorithms.
3+ years of experience on building models from ground up using python and packages like sklearn, pandas, xgboost, tensorflow and keras as well as tools such as Jupyter notebook
Bachelor's Degree in Mathematics, Computer Science, Computer Engineering, Physics, Data Science, Engineering, or Statistics from an accredited institution
What Will Put You Ahead?

Preferred Qualifications:
Master’s degree or PhD in Mathematics, Computer Science, Computer Engineering, Physics, Data Science or Statistics from an accredited institution
Ability to comprehend research papers and implement it
2+ years of experience working with web services like AWS, Azure or Google cloud.
Experience deploying models to production and maintain models in a commercial setup
The ability to communicate results clearly and a focus on driving impact
Salary and benefits commensurate with experience.
We are an equal opportunity employer. Minority/Female/Disabled/Veteran
Except where prohibited by state law, all offers of employment are conditioned upon successfully passing a drug test.

This employer uses E-Verify. Please visit the following website for additional information: www.kochcareers.com/doc/Everify.pdf","Koch Industries
3.6","New York, NY",Oil & Gas Exploration & Production,"Oil, Gas, Energy & Utilities"
Data Analyst,"NYU Grossman School of Medicine is one of the nation’s top-ranked medical schools. For 175 years, NYU Grossman School of Medicine has trained thousands of physicians and scientists who have helped to shape the course of medical history and enrich the lives of countless people. An integral part of NYU Langone Health, the Grossman School of Medicine at its core is committed to improving the human condition through medical education, scientific research, and direct patient care. For more information, go to med.nyu.edu, and interact with us on Facebook, Twitter and Instagram.

Position Summary:

We have an exciting opportunity to join our team as a Data Analyst.

The Data Analyst will work directly with Dr. Horwitz, the Director of the Division of Healthcare Delivery Science and the Center for Healthcare Innovations and Delivery Science, as well as the Rapid RCT Lab. We are seeking a qualified Data Analyst to provide support for data management and analyses across the Rapid RCT portfolio of projects. The Data Analyst will be responsible for planning, designing, and implementing statistical analyses. A successful applicant will be able to work autonomously and comfortably in an academic medical center environment.

Job Responsibilities:
Maintain existing data collection and analysis systems in support of the research protocol
Under direct supervision by the Division Director and with the guidance of the team’s lead biostatistician, conduct basic statistical analyses and present them to the team
Support the development of publications and conference presentations, including drafting academic and nonacademic publications, writing conference abstracts, conducting lit reviews and creating tables and other data visualizations for presentations
Work with staff and others to facilitate automation of standard, recurrent data acquisition, management, analysis and reporting
Design and conduct analyses pertaining to data acquired thorough various data sources
Create descriptive data summaries including visualizations and written descriptions of data findings for a wide range of audiences
Provide technical assistance to analysts and researchers in accessing and analyzing datasets, as needed
Minimum Qualifications:
To qualify you must have a Masters degree in health care economics, health care policy, applied statistics, data science, biostatistics or a Bachelors degree with relevant work experience
Strong quantitative skills and advanced programming skills in Stata, SAS, and/or R
At least 2 years of work experience and/or research experience in a relevant setting
Ability to select and apply appropriate statistical methods for collecting and summarizing varied data
Excellent organization, time management, and communication skills and the ability to work both independently and as part of a collaborative research team
Preferred Qualifications:
Knowledge of principles and methods of biostatistics; principles, theories, and procedures of epidemiology, including study design, statistical analysis, and causal inference
Appropriate computer processing methods used to generate, organize and display statistical and research data; and standard English grammar, spelling, and usage
Strong attention to detail
Problem-solving and critical thinking skills
Planning/organizational skills
Personal motivation
Qualified candidates must be able to effectively communicate with all levels of the organization.

NYU Grossman School of Medicine provides its staff with far more than just a place to work. Rather, we are an institution you can be proud of, an institution where you’ll feel good about devoting your time and your talents.

NYU Grossman School of Medicine is an equal opportunity and affirmative action employer committed to diversity and inclusion in all aspects of recruiting and employment. All qualified individuals are encouraged to apply and will receive consideration without regard to race, color, gender, gender identity or expression, sex, sexual orientation, transgender status, gender dysphoria, national origin, age, religion, disability, military and veteran status, marital or parental status, citizenship status, genetic information or any other factor which cannot lawfully be used as a basis for an employment decision. We require applications to be completed online.

If you wish to view NYU Grossman School of Medicine’s EEO policies, please click here. Please click here to view the Federal “EEO is the law” poster or visit https://www.dol.gov/ofccp/regs/compliance/posters/ofccpost.htm for more information. To view the Pay Transparency Notice, please click here.","NYU Langone Health
4.1","New York, NY",Health Care Services & Hospitals,Health Care
Data Scientist,"Job Description
Personalize the experience for millions of customers using advanced machine learning algorithms to improve adherence and our customer experience.

Use advanced optimization and machine learning techniques to increase the relevance and customer value of our industry-leading loyalty program.

Improve operational efficiency and effectiveness within our supply chain, pharmacy operations, marketing with an integrated team of data engineers, data scientists, and solution strategists.

Partner with business leaders and opportunities to use data science to improve our customer experience and business results.

An Ideal Candidate will have the following Technical experience and background:
Experience within advanced analytics function of a corporation, tech startup or a consulting firm
Deep expertise in modern machine learning and artificial intelligence techniques
Expert level proficiency with common modeling tools and frameworks, e.g. Python, R, Scala, TensorFlow, etc.
Ability to understand data management and model productionalization best practices Ability to write scalable, production level code
Proficiency with tools to automate CI/CD pipelines (e.g., Jenkins, GIT, Control-M)
Design and implement end-to-end solutions using Machine Learning, Optimization, and other advanced technologies, and own live deployments
Experience with frameworks for either Machine Learning or NLP (Scikit-Learn, SpaCy, Pytorch, Spark NLP)
Experience with cloud computing environment (ideally Microsoft Azure)
Experience working on a large scale Spark implementation Productionalized one or more ML application on a big data platform
Additionally, we would like this individual to have the following Analytics & Leadership Skills
Must be able to translate business problem into modeling approach taking into account business requirements, data availability, development time / complexity and ability to scale.
Experience leading project management activities including communications within project teams, stakeholder management, leadership updates, etc.
Must be able to extract actionable insights from the analysis and interpred outcomes of complex models for business audience
Experience with preparing data for the analysis, work with data engineering team to create modeling dataset, assess completeness and quality of data and perform feature engineering
Knowledge of the healthcare landscape including patient and payer concerns, as well as the operational considerations in support of the business objectives and analytics experience within the retail and/or healthcare industries is highly preferred
Experience working with data and have a strong understanding of analytics and how it is leveraged within the healthcare/retail industry
Creative problem solver, flexible, proactive and ability to work in a fast paced, ever changing environment
Experience presenting to audiences including technical, non-technical and senior leaders (both verbally and through Microsoft Office products - Excel, Word, and PowerPoint)
Experience in managing cross functional initiatives communicating effectively and confidently with business partners, project team members and senior management
Excellent written and oral communication skills, ability to interact with and influence decision-making by non-analytical business audiences
Bachelor's Degree in Economics, Statistics, Mathematics, Computer Science, Engineering or related field
Minimum 3 years of healthcare industry experience or Master's Degree with coursework focused on advanced algorithms, mathematics in computing, data structures etc.
Background Experience

Masters degree in Mathematics, Engineering, Health Informatics or a related field.

Minimum 3 years of healthcare industry experience in an analytical role working with health care data, systems and standards. Must have experience utilizing R or Python to manipulate large datasets and develop statistical models; performing mathematical analysis, machine learning, and experimental design and evaluation; utilizing data visualization techniques and business intelligence tools, including Tableau or RShiny; and writing SQL queries to extract, transform and load large datasets.","Gate Staffing LLC
2.8","New York, NY",IT Services,Information Technology
Data Scientist,"About ConcertAI

ConcertAI is the leading provider of precision oncology solutions for biopharma and healthcare, leveraging the largest collection of research-grade Real-world Data and the only broadly deployed oncology-specific AI solutions. Our mission is to improve translational sciences; accelerate therapeutic clinical development; and provide new capabilities for post-approval studies to accelerate needed new medical innovations to patients and to improve patient outcomes.
ConcertAI has emerged as one of the highest growth technology companies in Real-world Data and AI, backed by industry leading private equity companies: SymphonyAI, Declaration Partners, Maverick Ventures, and Alliance|Bernstein.

Role Summary

As a Data Scientist at ConcertAI you will be responsible for data exploration, analysis, and predictive/descriptive modeling on patient data for various stakeholders in the oncology and healthcare domain. You will report to the Vice President of Data Products. You should have a good mix of programming/CS, visualization, stats/math, and ML skills (with a particular strength in at least 2 of those areas), and ideally, you have been applying those skills in in healthcare. You will design methods and models around client driven needs and you will collaborate with various subject matter experts to inform those methods. You will assist the client delivery team with insights, dashboards, and ad-hoc analytics. You will also work with the engineering team to build prototypes and models for new product development.

Responsibilities
Understand client / product needs and translate them into tactical R&D initiatives with defined goals and timelines.
Reason about healthcare specific problems to analyze visualize, interpret, and contextualize results.
Run a variety of analytics from data QA to complex models.
Understand the differences and tradeoffs between various ML/Stats techniques and be able to select them appropriately, and apply them in a meaningful way.
Implement models using high level software packages (SKlearn, R, TensorFlow, Spark).
Collaborate on software projects with engineers, providing analytical guidance and contributing to codebase.
Requirements
B.sc or higher in a STEM field, with formal training in CS, stats, and math.
Strong programming abilities in at least one high level language (python, stata, R).
Knowledge of statistical methods- regression, ANOVA, EDA, PCA, etc.
Knowledge of machine learning methods- un/supervised, non/parametric, ensemble.
Basic visualization skills- matplotlib/seaborn/plotly/etc, tableau.
Experience with big data – Cloud data warehouses, cluster computing, Spark, MapReduce/Hadoop.
Intimate familiarity with the python data science stack (pandas, sklearn, numpy/scipy, pyspark).
Knowledge of advanced computational techniques and AI: neural networks, bayesian networks, mixture models, NLP, stochastic. optimization, HMMs, MCMC, search, NLP, image processing.
Advanced visualization skills- interactive custom visualizations in d3.js, plotly, etc.
Learn More About ConcertAI

ConcertAI is transforming how healthcare is delivered and dedicated to improving patient outcomes in oncology by offering innovative solutions on how data and intelligence is used to solve healthcare problems. We are creating something special in our culture, by building a collaborative, engaged, patient focused, team approach to our mission. Our high-performance teams are looking to add great talent to the mix and we are hiring for the right mix of new skills and diverse mindset. Learn more about ConcertAI at www.concertai.com or on LinkedIn .",ConcertAI,"New York, NY",-1,-1
Data Scientist,"Data Scientist


New York, NY | Full Time

We’re seeking Data Scientists who will help solve critical business problems and derive valuable insights for our clients. Our teams apply business intuition along with a diverse set of methods and algorithms, including but not limited to, advanced analytics, machine learning, text mining, process mining, network analysis, and data visualization to improve operations. The ideal candidate is capable of ingesting, processing and interpreting data sets that vary widely in size, structure, complexity, and dimensionality. They are quick to adapt to new technology, and passionate about data-driven business problem solving for business operations. They also thrive in cross-functional teams and can clearly communicate technical concepts to non-technical individuals.

CKM is on the forefront of leveraging data analytics to inform strategic decision-making and drive operational improvement for clients. Our number one asset is our people, who shape the uniquely creative and energetic culture at CKM. Because we’re passionate about knowledge sharing and professional development, we give our employees ample opportunity to satisfy natural curiosity, access to the firm’s expertise, plus the autonomy and authority to design and execute their own analyses.

Why we’ll love you:
Bachelors, Masters, or Ph.D.
Passion for quantitative problem solving and developing data driven solutions to difficult business questions
Demonstrated proficiency in Python, in an academic or professional environment
Skills in or familiarity with data cleaning, natural language processing, machine learning, artificial intelligence, visualization, network analysis, and distributed computing are a plus
Familiarity with database concepts and structures
Ability to communicate complex quantitative analyses clearly
Fluent oral and written English communication skills
Self-starter and team player
Ability and willingness to travel from time to time (domestic and international)
Authorized to work in the US
Why you’ll love us:


Our team is diverse and intellectually curious, made up of people that you’ll genuinely enjoy spending time with
We’re fanatical about helping clients derive value from data and work on solving challenging problems within some of the world’s largest companies
We are a meritocracy and consistently promote from within
We move fast and are not afraid of evolving our tools, technology and thinking
Compensation is competitive and commensurate with your degree and experience. At CKM, we celebrate our differences – they help our business thrive and our employees have fun. CKM Analytix is proud to be an equal opportunity workplace. We are dedicated to equal employment opportunities regardless of race, color, ancestry, religion, sex, national orientation, sexual orientation, age, citizenship, marital status, disability, gender identity/expression, or veteran status.","CKM Advisors
2.9","New York, NY",Consulting,Business Services
Data Scientist,"We are the most sought after hedge fund in New York City, and we are hiring a Senior Data Scientist to join a new role of ours. If you are excited about new challenges and becoming a leader in our new space, then this is the place for you.

What Is The job?

This is a new role as a Senior Data Scientist in one of our fund's most important divisions. You will be using your Machine Learning and Quantitative experience to apply data science analysis to our private equity portfolio for the first time. Your analysis will help us both expand out our portfolio to help in acquisitions, as well as to help implement advanced analytics for use with our investments to aid in their profitability.

You will be helping to build out a new team in this effort. Since this is a new role, there is no team in place currently, so you will help to build it going forward.

This role will involve ""customer"" interaction since you will be working closely with our portfolio companies to gather data, implement data science solutions, and guide them to maximize profitability. You should be comfortable and excited about working with these external stakeholders.

Who Are We?

We are one of the largest and most well-known hedge funds in the world with over $50 Billion in assets. We use cutting-edge technology towards trading and investment strategies. We recognize the role that data plays in the world of finance, and explore every possible avenue of harnessing it to its fullest potential.

What Skills Do You Need?

• You should have advanced experience with building Machine Learning models.

• Master's or Ph.D. in a quantitative or computational field.

• It's a ""plus"" if you have management experience or experience building a data science team.

Compensation

• $275,000 - $325,000 total compensation

• Medical, Dental, and Vision Coverage

• In-office gym, great culture, and amazing learning environment

What's In It For You?

This is a phenomenal opportunity for an experienced Data Scientist to join a great organization and make an impact immediately. If you are someone who thrives wearing multiple hats and never turns down a challenge, we would love to hear from you!","Averity
5.0","New York, NY",Staffing & Outsourcing,Business Services
Data Scientist,"Data Scientist


The data scientist will advocate, evangelize and build data-fueled products that help our customers improve their Capital Project Delivery. You'll dig in and become an expert on our energy sector datasets. You will provide insight into leading analytic practices, design and lead iterative learning and development cycles, and ultimately produce new and creative analytic solutions that will become part of our core deliverables.

The data scientist will work with cross-functional team members to identify and prioritize actionable, high-impact insights across a variety of core business areas. You will lead applied analytics initiatives that are leveraged across the breadth of our solutions for the technology sector. You will research, design, implement and validate cutting-edge algorithms to analyze diverse sources of data to achieve targeted outcomes.

You will provide expertise on mathematical concepts for the broader applied analytics team and inspire the adoption of advanced analytics and data science across the entire breadth of our organization.

Candidate Requirements:
Posses a Ph.D. (strongly preferred) or Master's Degree in operations research, applied statistics, data mining, machine learning, physics or a related quantitative discipline.
Deep understanding of statistical and predictive modeling concepts, machine-learning approaches, clustering and classification techniques, and recommendation and optimization algorithms.
3+ years of experience delivering world-class data science outcomes, the data scientist will solve complex analytical problems using quantitative approaches with their unique blend of analytical, mathematical and technical skills.
Passionate about asking and answering questions in large datasets, and will be to communicate that passion to product managers and engineers.
Keen desire to solve business problems, and live to find patterns and insights within structured and unstructured data.
Propose analytics strategies and solutions that challenge and expand the thinking of everyone around you.
Expert in analyzing large, complex, multi-dimensional datasets with a variety of tools.
Expert in the use of statistical analysis environments such as R, MATLAB, SPSS or SAS.
Experienced with BI tools.
Experience with relational databases as you are with Hadoop-based data mining frameworks.
Experience with SQL, Python, Java and C/C++.

Education:


Master's Degree or higher","The CARIAN Group
4.2","New York, NY",Consulting,Business Services
Data Scientist,"The Business

GradTests.com is a leading provider of practice psychometric tests to graduates, students and young professionals.

The Role

A data science all rounder role. The core purpose of the role is to build models to improve the product, the customer experience and ultimately the business. We're looking for someone with a nice blend of technical skills, and softer skills like business acumen, decision making and communication skills.

You'll do things like:
Conceive, devise, create, implement and fine tune data science models to solve a range of business problems, from customer churn through to
Set up, run and analyse A/B experiments for the website and email marketing campaigns
Help devise and layout a high quality infrastructure, upon which future data science can flourish
Help up skill other analytical team members into advanced data science techniques
Produce ad hoc analyses
And let's be honest, a whole load of data wrangling!
Skills and experience

Non negotiables:
SQL
Python or R
Data science models (K-means, random Forrest, neural nets etc.)
Strong foundational knowledge in stats and maths
Experience in actually productionising models and exposing to real customers
Business acumen
Strong communication skills, both written and verbal
Nice to haves:
Experience in working with developers, especially on experimentation
Some kind of cloud based experience (AWS preferred)
Some basic knowledge of source control with Git
Our application process consists of some online testing with Alooba, video call interview and then a case study. We expect the process to take about 10 business days end to end.

Job Types: Full-time, Contract

Salary: $120,000.00 /year

Experience:
Analytics: 1 year (Preferred)
Work Remotely:
Yes",GradTests (gradtests.com),"New York, NY",-1,-1
Data Scientist,"Job Description
The Committee of 100 (C100) is seeking a Data Scientist for a full time position. The Data Scientist will work with the President to use data and informational metrics to measure the impact of C100, to help further build a brand identity, to help improve internal decision-making processes, and to raise our public profile. This position will be responsible for proactively gathering data and producing data-driven insights and developing visualizations to advance the strategic position of C100.

The ideal candidatefor this position has an exceptional eye for detail, expertise as a data scientist, and a solid understanding of popular data analysis tools. He/she will work closely across C100's programs and datasets to understand objectives and identify trends in various studies.

Responsibilities:
Responsible for researching, collecting, analyzing, storing and creating data related to C100’s programs and its dual missions
Responsible for overseeing data presented across surveys, studies in order to identify meaningful results
Lead and build data architecture processes and databases
Perform quantitative and qualitative data analysis
Audit data on a regular basis to ensure data integrity and quality
Assist in preparation of data reports, board presentations, publications, marketing collaterals, and other educational materials
Responsible for the maintenance, back up and security of organizational data
Must have experience working with software development teams and have strong communication skills including capability to explain complex technical topics
Must have experience with relevant data analysis software programs
Qualifications
Bachelor’s degree in computer science, information technology or related field; PhD degree preferred
Commitment to the mission and values of C100
3-5+ years of experience as a data scientist or analyst; experience with a data/technology firm is
preferred
Extensive knowledge of data analysis software programs
Good problem-solving and analytical skills, ability to resolve issues
Exceptional writing, proofreading and copy editing skills
Strong interpersonal and presentation skills
Attention to detail, and a propensity to approach problems from creative angles
Outstanding prioritization and project management skills
Powered by JazzHR

PR2XEtXlzi","Committee of 100
2.8","New York, NY",Social Assistance,Non-Profit
Statistician,"Job title: Data Scientist / Statistician
Job type: Permanent
Emp type: Full-time
Salary:
Negotiable
Location: New York, United States
Job published: 2019-08-05
Job ID: 41456

Job Description


Our client is looking for a Data Scientist/ Statistician to join their New York office.

Responsibilities:
Serve as expert statistician/data scientist on discretionary investment team
Test research hypotheses and assumptions of portfolio manager and investment analysts by designing methodology and writing necessary code to perform backtesting, cross-validation, event studies, Bayesian data analysis, etc.
Test and identify the most predictive and robust statistical, machine learning, and deep learning methods to forecast factors, features, metrics, drivers, etc. relevant to portfolio manager and investment analysts in making investment decisions
With guidance from and in collaboration with portfolio manager and investment analysts help select relevant data sets
Work closely with team’s data engineer/systems developer to help specify best sources, format, and delivery mechanism of data
Write efficient, modular, and dependable code, packages, libraries, and scripts
Ensure code is written so it is easily understood by teammates when reviewing
Document all work extensively and train teammates on use of work products (e.g., custom Python libraries or R packages)
Work closely with team’s data engineer/systems developer and portfolio manager to design research (e.g., backtesting software) and production (e.g., trade file creation) processes
Collaborate regularly with firm’s Big Data group (Aperio) and other firm resources
Stay abreast of new research in statistics, machine learning, and deep learning


Requirements:
3+ years of working experience in a role that requires advanced statistical analysis
Be an expert in statistics (e.g., doctoral level) including time-series analysis
Have strong programming skills in SQL/NoSQL and at least one of the following Python, R, or C++
Good communication skills
Education:
Advanced degree in quantitative discipline (or 6+ years of full-time work experience using advanced statistical analysis)
If you would like to be considered for the position of Data Scientist / Statistician or wish to discuss the role further then please leave your details below. Your resume will be held in confidence until you connect with a member of our team","NJF Global Holdings
4.2","New York, NY",Staffing & Outsourcing,Business Services
Data Analyst,"The Data Analyst is an integral member of the global commercial data and analytics team driving commercial insights and opportunities for the world's largest English language newspaper website, DailyMail.com. This is a unique opportunity to work in a fast-paced entrepreneurial environment, with wide exposure to ad-tech and big data platforms.

The Data Analyst will be responsible for maintaining and optimizing the global commercial data systems, identifying methods to maximize commercial performance and providing business insights to internal stakeholders. This individual will have a genuine passion for digital media and data technology.

DailyMail.com is a division of UK-based DMGT, an international portfolio of digital, information, media and events businesses, which employs over 12,000 people and is listed on the London Stock Exchange (LSE:DMGT.L).

Specific Responsibilities
Participate in cross-functional projects using advanced data modeling and analysis techniques to discover insights that will guide strategic decisions and uncover optimization opportunities.
Develop and maintain big data infrastructure, reporting systems and data models that support key business decisions.
Develop and maintain data visualization dashboards to allow data access to necessary stakeholders.
Evaluate the configuration and performance of commercial practices against key indicators.
Continuously monitor yield across platforms and offer innovative recommendations to internal teams to boost performance and generate new revenue.
Work cross-functionally with teams including Operations, Sales, Marketing, Finance and Analytics to provide excellent customer service in support of DailyMail.com clients and revenue goals.
Desired Experience and Skills

Required:
B.A. or B.S. in a quantitative or technical field (e.g., math, engineering, statistics, computer science).
High proficiency in Excel, SQL, Python
Possess quantitative skills with a creative problem-solving mindset.
Ability to work collaboratively in a team environment.
Strong project management skills and ability to meet deadlines
Preferred:
Digital media and ad-tech experience is a plus
Familiarity with R, Scala, Spark, Airflow
Google Cloud (Storage, BigQuery, Compute Engine, Kubernetes Engine)
About MailOnline


MailOnline is one of the world's leading newspaper websites with more than 12 million daily unique visitors spending an average of 145 million minutes consuming its content each day across the globe, of which 77% is from direct traffic. MailOnline offers a unique amalgam of fresh, sensational, breaking and reliable news with over 1,600 stories, 800 videos and more than 12,800 photos posted daily. With newsrooms in New York, Los Angeles, London, and Sydney, Dailymail.com uses its massive homepage to deliver the exclusive content people need and want to know.

DailyMailTV brings the best of DailyMail.com, the world's most read English-language newspaper website, to life on television, with an edgy, fast-paced daily show featuring the hottest headlines, trending topics and celebrity breaking news from around the world.

Daily Mail North America is a division of UK-based DMGT, an international portfolio of digital, information, media and events businesses, which employs over 12,000 people and is listed on the London Stock Exchange (LSE:DMGT.L).","DMGT
4.0","New York, NY",Venture Capital & Private Equity,Finance
Data Scientist,"Description

We are looking for several of the best and brightest Data Scientists to participate in a confidential marketplace called Matchbook that will connect you with the most prestigious investment and asset management firms / hedge funds in New York City.

Here's how it works:
Apply to this job by creating an account on OneWire and uploading your resume;
Upon acceptance into the marketplace, a recruiter will reach out and schedule brief 1 on 1 phone interview with you;
If you qualify, your profile will be featured and then listed in front of the best investment management firms seeking individuals like you;
Receive interview requests, field offers and get hired;
And here's the best part - we will pay you a $500 signing bonus on the first day of your new role!
If you want the hard to find job opportunities in the marketplace to directly choose you, as opposed to endless job searching across different sites and recruiters, then please apply to be included in the marketplace. Space will be limited.
Requirements

Here's what we are looking for:
Must have a Bachelors of Science in Computer Science, Statistics, Engineering, Physics, or related quantitative field with strong record of academic achievement
Experience using machine learning and specifically natural language processing to mine unstructured data, extracting information from documents such as electronic filings, contracts, news, patents etc.
Knowledge of a variety of machine learning techniques (clustering, decision tree learning, artificial neural networks, etc.) and their real-world advantages/drawbacks.
Knowledge of advanced statistical techniques and concepts (regression, properties of distributions, statistical tests and proper usage, etc.) and experience with applications.
Professional experience with one or more of Java, Hibernate, Python, Scala, C/C++.
Experience with Numerical / Scientific Python (NumPy, SciPy, Pandas)
Knowledge of machine learning pipelines using Scala / Spark or Python / scikit-learn
Possess intellectual curiosity and a strong passion for investing and financial markets
Bonus Points:
Masters degree or higher in Computer Science or related quantitative field with specialization in natural language processing and/or machine learning
Over two years of work experience (outside of internships)
Work experience in the financial services industry (ie hedge fund, research firm, bank or alternative asset manager)
Experience with distributed computing architectures
Experience with tools for statistical computing (e.g. R, NumPy, SciPy).
Experience with big data technologies like Apache Spark, Hadoop, Cassandra, etc.
If this sounds like you, please apply to this opportunity and someone from our team will be in touch with you if you are the right fit.

Posted 06/17/2020
Full Time position
Compensation will be Market Rate","OneWire
4.0","New York, NY",Staffing & Outsourcing,Business Services
Data Scientist,"Thomas is looking for a Data Scientist to help build a world-class data team that will support and guide Thomas’ business strategy and operations. The right candidate will be a problem solver who is obsessive about all things data, and is enthusiastic about working with cutting-edge techniques, technologies and applications.

The Thomas Data Analytics team uses data-driven insights to fuel strategic growth for clients. You will apply your knowledge and skills in driving insights across our product platforms to come up with data powered solutions for our clients. We believe that our data should be put to work to bring the best ideas and stories to our clients!

You’ll solve complex marketing and business challenges – from cross-channel media and customer experience optimization, targeting and business strategy – by accessing, integrating, manipulating, mining, modeling a wide array of data sources.

This is an opportunity to work with a newly assembled team of data analysts, engineers and architects to establish best practices and processes as we transition to a data-focused organization, and will involve working with petabyte-scale data across a diverse set of data platforms. A key goal in the near future is creation of a data lake across our industry platforms to facilitate deeper analysis and bring sophisticated data tools and methods to bear in order to more effectively anticipate industry trends and events.

Requirements:


Technical
Bachelor’s or Master’s Degree preferably in Computer Science, Information Systems, Statistical Analysis or Economics
Familiarity with statistical analysis/modeling, data science and/or data design and development of actionable advanced analytical solutions that provide insights to decision makers
Hands-on experience mining data for decision focused insights
Ability to design complex systems and translate user requirements into business solutions
Background in predictive modeling and machine learning
2 years of experience with open source machine learning or statistical analysis tools
Experienced in at least one programming language (Java, Python, Scala, R)
Guru level experience with query tools and languages including SQL
Experience with NoSQL databases and related tools
Experience with Amazon AWS big data and machine learning technologies a plus (RedShift, Sagemaker, Comprehend etc.)
Non-technical
Strong communication skills – oral and written
Ability to guide and lead a data analytics team of 5 – collaborate with both technical and non-technical colleagues in product management and executive leadership groups
Ability to gauge the complexity of machine learning problems and a willingness to execute simple approaches for quick effective solutions as appropriate
Sharing knowledge, debating techniques, and conducting research to advance collective knowledge and skills of our practices
Demonstrated self-starter who thrives in a fast paced environment","Thomas
3.4","New York, NY",Advertising & Marketing,Business Services
Data Scientist,"As a data scientist at TBWA\Chiat\Day New York, you will join a close-knit and innovative data science team that is pioneering the use of data as a core component of creative storytelling.

This is not just another data wrangling job. As part of one of the world's leading creative agencies, the TBWA Data Team works closely with strategy across global clients and new business. Every day is a little bit different and you will be challenged to evolve the role of data in the creative process.

The ideal candidate believes in the creativity of data. Having a curious-minded approach to research, problem solving and supporting multiple client work streams will lead to success on this team and in this agency.

On a day to day level, the Data Scientist is responsible for collecting data from disparate sources, merging datasets, performing exploratory analyses, and extracting key insights. We often develop custom approaches and tools, so expertise with R or Python and ownership of a project will be essential

Impact will be your goal.

RESPONSIBILITIES
Big picture thinking and attention to detail to solve problems/help teams make decisions/find insights
Perform extraction and interrogation of data sets from multiple platforms and perform hygiene and quality control steps. Data sources will include: web analytic tools, media analytics, customer databases, social listening tools, search tools, syndicated data, research & survey tools, etc.
Derive key findings and observations from analyzing various data sources, and together with more senior analytics staff, communicate those findings orally or in writing, primarily to internal agency team.
Develop a picture of the customer leveraging data from 3rd party data sources.
Stay abreast of industry trends, best practices, and the evolving analytics landscape.
Put together slides with findings and insights that are communicated to cross functional teams.
REQUIREMENTS
3-5 years experience with programming languages such as R, Python, SQL, etc.
Advanced skills in Excel functions: Pivots, advanced formulas/macros, multi-spreadsheet links.
Competency in analytic techniques such as: time series data analysis, segmentation, univariate & multivariate statistical analysis, various metrics and key performance indicators, research & test design, significance testing, variance and growth calculations, forecasting, return on investment.
Working knowledge of data visualization tools, such as Shiny, Tableau or Power BI.
Strong written and verbal communication skills.
Preferred:
2-4 years of work experience in marketing analytics or related fields such as advertising, direct marketing, online marketing, loyalty marketing, using data to solve complex Marketing problems.
Basic knowledge of marketing/advertising/research principles.\
Alignment with TBWA\Chiat\Day Values

Our ambition is to create ideas for our clients that lift their businesses and brands. Ideas are our business. We believe that great ideas can come from anywhere.

Certain attitudes define how we work and are important in what we seek for our culture.

Key TBWA\Chiat\Day Attitudes

Curiosity: Be open-minded to ideas wherever they come; curious people are often unafraid of change;

Collaboration: Self-confidence without a big ego; work with all types of people;

Integrity: What we say is what we do; it is honesty and respect in our dealings with people;

Resourcefulness: To find ways to do whatever we have to do for our clients, and our people.","TBWA\Chiat\Day
2.7","New York, NY",Advertising & Marketing,Business Services
Statistician,"The U.S. Department of the Treasury has a distinguished history dating back to the founding of our nation. As the steward of U.S. economic and financial systems, Treasury is a major and influential leader in today's global economy. We have over 100,000 employees across the country and around the world. Come Join the Department of the Treasury and Invest in Tomorrow.
See Other Information for Locations
Positions are to be filled in the Large Business & International (LB&I), Data Solutions division.
Eight (8) positions are to be filled in any of the following locations:
Birmingham, AL
Fayetteville, AR
Little Rock, AR
Phoenix, AZ
El Monte, CA
Glendale, CA
Laguna Niguel, CA
Los Angeles, CA
Long Beach, CA
Oakland, CA
Sacramento, CA
San Diego, CA
San Francisco, CA
San Jose, CA
Santa Ana, CA
Lakewood, CO
Hartford, CT
New Haven, CT
Norwalk, CT
Washington, DC
Newark, DE
Miami, FL
Ft. Myers, FL
Jacksonville, FL
Maitland, FL
Plantation, FL
Tampa, FL
West Palm Beach, FL
Atlanta, GA
Honolulu, HI
Des Moines, IA
Chicago, IL
Downers Grove, IL
Schiller Park, IL
Springfield, IL
Indianapolis, IN
Wichita, KS
Louisville, KY
New Orleans, LA
Boston, MA
Brockton, MA
Stoneham, MA
Southborough, MA
Baltimore, MD
Lanham-Seabrook, MD
Rockville, MD
Ann Arbor, MI
Clinton Township, MI
Detroit, MI
Farmington Hills, MI
Flint, MI
Grand Rapids, MI
Pontiac, MI
Bloomington, MN
Chesterfield, MO
Lee's Summit, MO
Charlotte, NC
Greensboro, NC
Raleigh, NC
Omaha, NE
Edison, NJ
Iselin, NJ
Mountainside, NJ
Paterson, NJ
Las Vegas, NV
Albany, NY
Bethpage, NY
Buffalo, NY
New York, NY
Rochester, NY
Cincinnati, OH
Columbus, OH
Independence, OH
Oklahoma City, OK
Tulsa, OK
Portland, OR
Philadelphia, PA
Pittsburgh, PA
King Of Prussia, PA
Guaynabo, PR
Warwick, RI
Franklin, TN
Memphis, TN
Nashville, TN
Austin, TX
Farmers Branch, TX
Fort Worth, TX
Houston, TX
San Antonio, TX
Ogden, UT
Salt Lake City, UT
Norfolk, VA
Richmond, VA
Vienna, VA
Seattle, WA
Milwaukee, WI
Waukesha, WI
Kearneysville, WV
Martinsburg, WV
WHAT DOES A DATA SCIENTIST DO? The Data Scientist utilizes advanced analytical, statistical, and computer programming skills to develop data- driven solutions to difficult business challenges. As a data scientist, you are responsible for conducting data-centric projects to provide insight and informed decisions for mission- oriented programs of the Internal Revenue Service (IRS), which may impact multiple program segments, divisions, the Service, or segments of the taxpayer population. This is accomplished by utilizing a wide range of technical competencies such as statistics and machine learning, coding languages, data wrangling, and reporting and visualization techniques. The Data Scientist may lead team or cross functional projects, and will apply critical thinking, problem solving and ability to communicate complex analysis to advance the use of data-driven decision making in IRS operations.

WHAT IS THE LARGE BUSINESS AND INTERNATIONAL (LB&I) DIVISION OF THE INTERNAL REVENUE SERVICE? The Large Business and International (LB&I) business unit provides service and enforcement activities to support tax compliance of businesses and related entities with assets of $10 million or more, as well as small U.S. businesses engaged in international, U.S. citizens abroad, and foreign persons and businesses with a U.S. tax requirement.
As a Data Scientist, you will:
Serve as a technical expert with responsibility for the initiation, planning, implementation, controlling, modifying and executing of all or part of an entire project, including such tasks as formulation of workload estimates for program segments, specification of the methodology to be used, preparation of appropriate specifications and procedures, and review of computer systems specifications and materials and instructions needed for assuring the adequacy of the project’s design and objectives.
Explore novel methods of retrieving data and develop innovative recommendations to management and senior leadership as a means for making data driven decisions such as modification of processes and policies. Review, evaluate, validate, and document the results of the findings.
Assist the supervisor in determining the scope, goals and schedules for future programs in the Office. Collaborate with business or technology partners to understand business needs, identify opportunities, and develop and implement analytical solutions.
Identify and assess relevant data sources’ validity and reliability to meet project needs. Collate, clean, transform, analyze, and integrate structured and unstructured data from various sources in preparation for analysis.
Apply statistical methods and concepts including data mining, statistical theory and research procedures to test hypotheses using structured and unstructured data. Develop data product solutions to improve customer experiences, anomaly detection, and business outcomes. Develop proofs of concept or demonstrations to evaluate feasibility of project solutions and recommend visualization strategies.
Document project work and review deliverables for validity, reliability and timeliness. Communicate analytic solutions to technical and non-technical stakeholders, including during executive- level and/or cross-agency meetings, in a clear and effective manner using oral and written communications.
Maintain knowledge of state-of-the-art innovations in data science from both academic and industry sources and identify opportunities for implementation. Engage in general professional development to improve knowledge of IRS processes/programs.
Apply computer based mathematical/statistical techniques using software. Lead or participate in statistical projects or studies in survey sampling (design and estimation), modeling, or statistical research. Apply knowledge of programming/coding language (i.e., SQL, SAS, SPSS, RStudio) to develop scripts or applications.
Act as a troubleshooter in resolving bottlenecks at any step in a project by identifying and proposing solutions; this may include coordination with other project team members or stakeholders to mitigate issues.

WHERE CAN I FIND OUT MORE ABOUT OTHER IRS CAREERS? If you want to find out more about IRS careers, visit us on the web at www.jobs.irs.gov
#LI-POST
You must meet the following requirements by the closing date of this announcement
BASIC QUALIFICATION REQUIREMENTS:

GS-1530 Statistician All Grades:
You must have a Bachelor's degree that included 15 semester hours in statistics (or in mathematics and statistics, provided at least 6 semester hours were in statistics), and 9 additional semester hours in one or more of the following: physical or biological sciences, medicine, education, or engineering; or in the social sciences including demography, history, economics, social welfare, geography, international relations, social or cultural anthropology, health sociology, political science, public administration, psychology, etc. Credit toward meeting statistical course requirements should be given for courses in which 50 percent of the course content appears to be statistical methods, e.g., courses that included studies in research methods in psychology or economics such as tests and measurements or business cycles, or courses in methods of processing mass statistical data such as tabulating methods or electronic data processing. OR
Combination of education and experience -- courses as shown above, plus appropriate experience or additional education. The experience should have included a full range of professional statistical work such as (a) sampling, (b) collecting, computing, and analyzing statistical data, and (c) applying statistical techniques such as measurement of central tendency, dispersion, skewness, sampling error, simple and multiple correlation, analysis of variance, and tests of significance.
GS-13 LEVEL: You must have one year of specialized experience at a level of difficulty and responsibility equivalent to the GS-12 grade level in the Federal service. Specialized experience for this position includes all of the following:
Experience applying project management principles on a data science project
Experience planning and executing a variety of data science and/or analytics projects.
Experience using data mining process models (such as CRISP-DM, SEMMA, etc.,) to design and execute data science project.
Experience preparing and analyzing structured and unstructured datasets to explorations and evaluating data science centric models.
Experience working with multiple data types and formats as a part of a data science project.
Experience applying a range of analytic approaches, including (but not limited to) machine learning, text analytics, and natural language processing; graph theory, link analysis and optimization models; complex adaptive systems; and/or deep learning neural networks that are part of the exploration.
Experience coding in various programming languages (such as R, Python, SQL, or JAVA) to conduct various phases of data science projects.
Experience creating and querying different datastores and architectures (such as Sybase, Oracle, and open-source databases) to work with various types of data as part of the data science project.
Experience using tools for data visualization (graphs, tables, charts, etc.,) and end-user business intelligence.
-The experience may have been gained in the public sector, private sector or Volunteer Service. One year of experience refers to full-time work; part-time work is considered on a prorated basis.
-To ensure full credit for your work experience, please indicate dates of employment by month/year, and indicate number of hours worked per week, on your resume.","Internal Revenue Service
3.5","New York, NY",Federal Agencies,Government
Data Scientist,"Key Competencies:* Strong analytical mind, problem-solving skills and foundation in Statistics* Ability to collaborate well with individuals on-site and in remote offices* Intermediate to advanced level of expertise using SAS, SQL, Tableau, Python* Outstanding analytical skill set: a clear expert in the Analytics/ Data Science field* Experience working with large volumes of data, combining and reconciling data from different sources* Experience in MS Office applications with very strong Excel skillsRequirements:* Minimum B.S. in Mathematics, Statistics, Data Analytics or related quant field* 5+ years in a similar analytical role generating insights through data analytics* Strong communication skills: both written and verbal* Ability to work independently on multiple concurrent assignments* Self-driven for continual learning and ongoing training/development* Highly organized, detail-oriented","Harry and David, LLC
3.4","Carle Place, NY",Food & Beverage Stores,Retail
Data Scientist,"ABOUT GLEAN (currently in stealth mode)

After managing vendor expenses, wrangling budgets, and feeling the pain of wasted money due to poor visibility + manual processes at previous companies, we started dreaming about a better way to manage spend.

Welcome to Glean - a data-powered spend intelligence
solution that saves companies money by providing complete up-to-date visibility, line-item level insights, anomaly detection, and the tools you need to action on them: approvals, payments, forecasting, benchmarking, and more.

We are a data-first startup, well funded by leading VCs, with an ambitious mission and a growing waitlist! Our culture is rooted in experimentation, intellectual curiosity, and openness — providing the ownership and opportunity needed to learn, to grow, and to make something awesome together.

Join us!

ABOUT THIS ROLE (REMOTE APPLICANTS OK)
We are building the next billion-dollar business in enterprise SAAS. We have an amazing founding team, with experts in product, engineering, data science, and machine learning, and we just launched our MVP. We are now searching for a data scientist that will own the core data science work, build NLP applications, and generate insights from the very rich data we collect.

Here are some of the major items you will own at Glean:
Data science code to clean and prepare the data extracted from invoices, including handling nulls, addressing exceptions, imputing data (when possible), and enriching data using third-party APIs
Data science code to validate the goodness of extractions performed by the ML models + human in the loop
Collaborate with vendors to perform OCR and text classification
Develop NLP models to map the extracted data to our canonical taxonomy of vendors and line items (e.g., using word embeddings, etc.) at scale
Once the data has been mapped to the canonical taxonomy, perform feature engineering, generate insights, detect anomalies, and surface the intelligence in a digestible format to the end user
You will work closely with the data engineers to productionize the data science and machine learning code that is developed, and you will work closely with the engineering team to make sure the data science and machine learning pipelines are performant in production.

PERFECT FIT

You're a perfect fit for the Glean Team if…
You want to join an early-stage startup or you are extremely anxious to be challenged at your first startup
You are passionate about building / leading data science teams and rapidly developing data pipelines at various stages of growth
You pride yourself in communicating complex concepts, including the ability to distill intricate workflows and systems into clear processes and decisions with measurable company-wide impact
You ask “why” a lot and use critical thinking and data to back up your intuitions. You hate when a customer struggles through your product experience
Qualifications
3+ years of experience in Python, Data Science, Machine Learning, and NLP
2+ years of experience with Spark, coding in either PySpark or Scala
Have built and deployed deep learning models using TensorFlow and/or PyTorch
Are well versed in NLP
Experience with Unsupervised Learning is a bonus",Glean Analytics Inc.,"New York, NY",-1,-1
Data Scientist,"Hi,

Greetings of the Day!!!

Looking for Data Scientist for below requirement.

Job Title: Data Scientist with SQL, Python, R, Tableau.

Location: Manhattan, NY

Duration: 12 Months Plus

Interview Mode: F2F Mandatory.

Description:

Experience requirements
5+ years as a data scientist leading efforts to identify relevant questions, collect data from a multitude of different data sources, organize the information, translate results into solutions, and communicate findings in a way that positively affects decisions
5+ years working with SQL, Python, R, Tableau and other data science programing languages and tools
Strong quantitative and problem-solving skills
Experience and passion for data wrangling, data cleaning, and ETL
Experience working with administrative data sets
Experience with statistical modelling and machine leaning analysis
Experience with Bayesian analysis
Proficiency in GIS concepts and software (ArcGIS, Google Maps, QGIS, Carto)
Attention to detail for documenting work processes and writing clear instructions for technical tasks
Ability to distill complex material into actionable recommendations
Excellent written and oral communication skills
JOB Duties

Â Develop SQL and Python queries to analyze the completeness and quality of key data elements in StreetSmart, including demographics, caseload history, mental illness diagnoses, and substance abuse details

Â Develop and monitor a data cleaning prioritization plan, working with a data analyst dedicated to data cleaning

Â Manipulate and analyze administrative data in order to predict outcomes and make data-driven recommendations

Â Apply statistical and data mining techniques to conduct performance audits, trend analysis, and predictive analytics using StreetSmart data

Â Collaborate with team members to develop novel strategies for technical analysis

Â Evaluate ethical implications of design choices for predictive analytics models and automated decision support systems

Â Create and present compelling reports to stakeholders based upon project findings and methods

Â

If interested, kindly do share profiles to madhavi(at)impetususa(dot)com","TechProjects
4.8","New York, NY",IT Services,Information Technology
Data Scientist,"***Please note: All hiring and recruitment at Spring Health is handled with a valid '@springhealth.com' email address only or from recruitment firms @hays.com, @oxeonpartners.com, @neptunepeople.com, @rivierapartners.com, or @swingtalent.com. If you receive a message from a sender whose domain is not @springhealth.com, please beware that those communications are not authorized or coming from Spring Health. ***

Our mission: helping individuals and organizations thrive by eliminating every barrier to mental health.

Spring Health is a comprehensive mental health benefit for employers. We help employees understand their mental health issues and connect with best-in-class providers to get the right treatment at the right time.

We are an award-winning, passionate, and mission-driven team with the support of leaders in psychiatry, and backed by prominent VCs including Northzone, Rethink, RRE, and General Catalyst. From early detection to full recovery, Spring Health is the only clinically validated solution proven to be more effective than traditional mental healthcare. By combining the latest technology with vetted providers, we engage 1 in 3 employees, reduce recovery times, and reduce healthcare costs.

We are looking for a Data Scientist to join our R&D team. You will be responsible for designing, developing, and implementing data products throughout our organization. You will collaborate with a team of engineers, designers, product managers, social workers, psychologists, and scientists.

We are creating the future of mental healthcare: within your first year, you’ll discover something no human ever knew before about mental health.
What you’ll do at Spring Health:
Develop analytics and secure reporting approaches for a high-performing network of mental health providers
Work with product and engineering teams to improve user acquisition, patient adherence, and clinical outcomes
Develop data infrastructure to ingest and integrate multiple data sources, ETL, validate, and create automated reports for clients
Design and build data deliverables across multiple contexts, such as: claims analyses/financial ROI, longitudinal treatment outcomes, provider quality, and risk stratification algorithms
What we expect from you:
BA/BS in Psychology, Economics, Biology, Biochemistry, or other STEM-related field.
Fluency in R
Strong presentation skills — fluently tell a compelling clinical or business story with data
Strong written communication skills — quickly compose client-facing communications or publications for peer-review
Experience with Git, Python, SQL, parallel/distributed computing, cloud computing, and other data science toolkits
Experience or knowledge of traditional statistics, e.g. measures of central tendency, descriptive statistics, and inferential statistics
Possess the initiative and ability to self-direct projects and solve unconventional problems
Proximity to NYC: minimum 2 days per week in our NY HQ, max 3 days remote
What we’d love to see:
STEM PhD— especially in Applied Sciences (e.g. Biostatistics, Psychiatry, Psychology, Biological Sciences), or 3-4 years of equivalent data analysis experience
Experience using any of the following data: EMR, clinical trials, claims data, longitudinal
Demonstrated passion for, and understanding of, mental illness and broader U.S. healthcare system
Experience programming and testing statistical/machine learning models
Experience using data visualization techniques to present key findings
Ability to quickly and independently pick up concepts and skills
Experience working cross-functionally with operations, product, engineering, and design teams
Why you’ll love working at Spring Health:
Competitive compensation plan, including equity in the company: we want you to own a piece of what you’re building.
Comprehensive benefits: we offer 401k, health, dental and vision benefits as well as free mental healthcare!
World-leading science: we’re shaping the future of mental healthcare, and are at the forefront of peer-reviewed science. You’ll be the first human to discover something about how to treat mental illness.
Flexible vacation plan: our open vacation-policy allows you to take the time off you need when you need it.
Great people: make an impact on something that truly helps people alongside an incredible team.
We care about diversity: diversity allows us to build an excellent patient experience. We are an equal opportunity employer and we do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status.
We value: humility, entrepreneurship, passion for mental health, honesty and candor/directness
If you're interested in the role, please submit your CV/Resume via email to careers@springhealth.com, along with one code sample and one writing sample.

The code samples can be in any language, and the writing sample should either be 250 words, or include a 250 word abstract. Communication skills are really important to us, and we are particularly looking for a simple, direct writing style and the ability to articulate a question and research methodology clearly.","Spring Health
3.6","New York, NY",Health Care Services & Hospitals,Health Care
Data Scientist,"Job Description
Client JD below:

We need a technical contractor to assist on building out data cleaning and manipulation tools for our machine learning system. The contractor will sit along side our data scientists to productionize and optimize the code that we have for data ingestion and optimization, and if necessary help to build out the machine learning tools that we are using. A strong background in Python and SQL is a must as that is what our systems are built upon. Additional experience with working with Google compute and cloud services is a plus as our algorithms are being calculated on those systems. We are located in the Flatiron district.
Company Description
SkillSoniq hires great talent for projects within SkillSoniq or with our Clients. Below is the hiring process we follow:
We review applications and resumes for relevant skills and experience
Profiles that get short-listed are contacted by SkillSoniq on next steps
You then go through a few rounds of interviews for the project
If you get selected, you are advised on next steps and paid by SkillSoniq","SkillSoniq
5.0","New York, NY",-1,-1
Data Scientist,"Use statistical analysis, machine learning, pattern recognition, and data visualization along with domain knowledge and subject-specific models to solve science, engineering, and commercial problems
Solve challenging data science problems by developing novel and/or adapting existing computational methods
Debugging and performance tweaking in Python
Taking ownership over parts of an application and collaborating on global issues Understand and enjoy working in a micro services based architecture
Hands-on experience in PostgreSQL, SQL Server, Oracle, RESTFul,GIT, API, JSON, Statistical Analysis, Machine Learning, Pattern Recognition,
Knowledge in Data Visualization, Numpy, Pandas, Scipy, Matplotlib, Soup, Scrapy, Teradata,NoSQL, Redis, Elastic Search, Mongo, Django, Flask, Pyramid, SVN, Mercurial,Linear Algebra and Optimization
Knowledge in Hypothesis Testing, Monte Carlo Simulation, Clustering","Lorven Technologies Inc
4.0","New York, NY",Accounting,Accounting & Legal
Data Scientist,"Do you love numbers and finding the story in the numbers? Does the thought of tackling a complex data issue make you smile? Have you got a knack for solving problems? Do you want to help drive the results of a multi-million dollar business? If you have answered ""yes"" to these questions, the Data Scientist position at Strategic Financial Solutions may be the right fit for you.
Strategic is looking for an experienced Data Scientist with statistical and machine learning experience to join our Data Science Team, which produces models for prescriptive and predictive analytics. The person in this role would be responsible for conducting data analysis and developing predictive models by leveraging data science and machine learning to solve various business use cases, including marketing intelligence, customer segmentation, and predictive models for operations.
This is a great opportunity for someone who wants to learn all aspects of business as s/he will support our product, sales, leadership and marketing teams with insights gained from analyzing company and external data.
Candidates must have strong experience in a variety of data manipulation tools, data analysis/ mining methods to build and implement models and should be able to develop algorithms and simulation methods. A successful candidate will have the proven ability to drive business results with their data-based insights.

Research and develop statistical and machine learning methodologies to solve complicated business problems
Work with stakeholders to identify opportunities by leveraging large data sets to drive business decisions. Collaborate with sales, marketing and senior executive teams for model development
Strong communication skills and ability to clearly present ideas and technical findings to key decision makers

Knowledge of statistical and machine learning techniques in regressions and classifications such as generalized linear models, classification trees, Random Forest, XGBoost, SVMs etc. Industry experience in such areas a definite plus.
Knowledge of stochastic process in terms of transaction matrix and equilibrium distribution, etc.
Experience in R, Python, and SQL, etc. and in variable selection and dimension reduction skills such as LASSO and PCA
Strong problem-solving skills with an emphasis on financial risk management in sales and marketing predictive analytics
Unsupervised learning experience such as k-means, hierarchical clustering, Bayesian network etc.
Excellent written and verbal communication skills for coordinating across teams
Graduate degree in Statistics, Data Science, Applied Math, Operations Research, Computer Science or other areas in STEM. Exceptional candidates with undergraduate degree will be also be seriously considered.
About Strategic:
Strategic Financial Solutions is a leading consumer finance company that specializes in helping people that have too much credit card debt. We were recently named the 21st Best Company to Work for in New York by Best Companies to Work For and have been certified as a Great Place to Work 4 times. Additional honors include being named, two times, as one of the 50 fastest growing companies in New York City and to the prestigious Inc. 500 list as one of the 500 fastest growing companies in the United States.
Please mark @talent.icims.com as a safe sender to ensure recruiter emails don't go to spam","Strategic Financial Solutions
3.6","New York, NY",Consumer Product Rental,Consumer Services
Data Scientist,"Are you excited about an opportunity to apply your experience and passion for experimental design, statistical modeling and optimization techniques to improve customer product experience? Are you a data scientist who dreams of building scalable solutions and innovations that enhances and enriches millions of customers lives every day? If so, this may be a great fit for you!

Audible Product Data Science team partners with technology and product leaders to solve business and technology problems using scientific approaches to build product and services that surprise and delight our customers. Improving Search and Content discovery experience is our key focus. We employ cutting-edge machine learning (ML), deep learning (DL) techniques and Natural Language Processing (NLP) knowledge to improve the relevance of search results, query intents understanding, and recommendation system, etc. We operate in an agile environment in which we own and collaborate the life cycle of research, design, and model development of relevant projects.

As a data scientist, you will be responsible for making experimentation methods recommendations by researching state-of-art methods, examining and tuning the current methods with simulations. You will be working on projects through their entire lifecycle from idea creation through implementation, experimentation and finally, deployment. You will be a key driver in improving our experimentation best practices to accelerate our rate of learning. You will be working with other data scientists, ML experts, engineers as well as product teams locally and abroad, and on cross-disciplinary efforts with other scientists within Amazon.

We are looking for a motivated, results-oriented Data Scientist with strong rigor and demonstrable skills in Experimentation, ML, DL, NLP, data mining and/or large-scale distributed computation.","Audible
3.7","Newark, NJ",Motion Picture Production & Distribution,Media
Data Scientist,"Get To Know Voice

At Voice, we are on a mission to take social media back from big tech. Voice is the first social media platform that empowers communities to self-govern, champions realness and respects user data.

Description

We're seeking an experienced data scientist to deliver data insight to us on a daily basis. Our ideal team member will have the mathematical and statistical expertise you'd expect, but a natural curiosity and creative mind that's not so easy to find. As you mine, interpret, and clean our data, we will rely on you to ask questions, connect the dots, and uncover opportunities that lie hidden within.

This is an exciting opportunity to join a thriving, well-funded startup with big ambitions. In addition to doing ground breaking work, this role will be pivotal in establishing a culture of openness, positive communication, and continuous learning. We are looking for the best and brightest to take our platform to the next level. Are you that person? Let's talk.

Responsibilities:
Identify and integrate new datasets, working closely with the engineering team to strategize and execute the development of data products.
Implement analytical models into production by collaborating with software developers and machine learning engineers.
Execute analytical experiments methodically to help solve various problems and make a true impact across various domains and industries.
Communicate analytic solutions and implement improvements as needed to operational systems.
Other duties as assigned.
Qualifications
Bachelor's degree in Statistics, Applied Mathematics, or related discipline
3 to 6 years of practical experience in data science (compensation scales accordingly)
Proficiency with data mining, mathematics, and statistical analysis
Advanced pattern recognition and predictive modeling experience
Experience with data visualization, analytics platforms and basic programming languages (i.e., Java/Python, SAS)
Comfort working in a dynamic, research-oriented group with several ongoing concurrent projects","Voice
3.4","Brooklyn, NY",-1,-1
Data Engineer,"Us and the role

Seated is an app that rewards you for dining out. Users can browse restaurants based on their location, preferences or mood and book either as walk-in or reservation. The seated mobile app, powered by robust microservices architecture, provides a convenient way to upload receipts, verify spend and reward users. The Seated platform further allows users to spend rewards on in-person experiences such as wine tasting & cooking classes or redeem rewards for gift cards from a wide variety of brands such as Uber, Amazon, Target or SoulCycle.

We are fast-paced, innovative & metric-driven, with a team who are passionate about delighting our customers. We are looking for a Data Engineer with proven experience in producing reporting, dashboards, visualizing insights and expertise in data analytics to join this newly data analytics team. The role requires both a broad knowledge of existing data modeling and processing along with the creativity to invent and customize when necessary using programming and technology platforms.

You will work with data scientists, engineers & product managers hand in hand to build insightful and efficient reporting solutions & data analysis. In your role, you will be a key player in a multi-functional team that delivers insights, having direct and measurable impact on Seated's platforms & consumer applications.

What you'll do
Work with product, engineering & business teams to deliver complex data analysis requests
Visualize datasets across multiple databases & warehouses using tools such as Tableau, D3, Looker, etc.
Build financial models & growth projections for new products and business initiatives
Build ETL pipelines for regular reporting on business and operational KPIs
Help business understand key trends by executing complex analysis via Tableau or ad-hoc SQL queries
Coordinate within cross-functional teams such as engineering, product, marketing, customer experience for various data analysis needs
Proactively build data and event-driven dashboard for real-time business operations and consumer insights
What you'll bring
Bachelors in CS, Statistics, Economics or Engineering, Masters preferred
3+ years of hands-on SQL experience
2+ years of experience in using data visualization tools such as Tableau, Looker, PowerBI
2+ years of experience in building financial models, growth projections & ETL data pipelines
experience either in R or Python and working with data warehousing solution such as AWS Redshift or Google BigQuery
What you'll get
Comprehensive Healthcare, Dental, and Vision
Generous 401(k) Matching
Stock options
Unlimited PTO
Pre-Tax Flexible healthcare spending account (FSA), Dependent Care FSA and Commuter Benefits
Paid Family Leave
$100 monthly Seated allowance (dine on us)
Stocked fridges, coffee, soda, and lots of treats
Collaborative, dynamic work environment within a fast-paced, mission-driven company
At Seated we welcome passionate people from all backgrounds, helping us make dining experiences more accessible & rewarding. If you have the curiosity & passion to drive our mission together, we would love to hear from you.","Seated
4.7","New York, NY",Internet,Information Technology
Data Scientist,"Duties Provides advanced professional input to complex Data Science assignmentsprojects. Responsible for the research, extraction and analysis of data. Evaluates and writes reports. May research and analyze algorithms. Provides statistical data trends to business partners such as medical management and underwriting. May also assist in the designing and implementation of systems to analyze and report findings. Combines IT capabilities with advanced clinical knowledge to determine trends, costbenefit ratios, and forecasting of health care costs, medical management, and health economics. Supports and provides direction to more junior professionals. Works autonomously, only requiring expert level technical support from others. Exercises judgment in the evaluation, selection, and adaptation of both standard and complex techniques and procedures. Utilizes in-depth professional knowledge and acumen to develop models and procedures, and monitor trends, within Data Science","Digital Intelligence Systems, LLC
3.4","Franklin Lakes, NJ",IT Services,Information Technology
Data Scientist,"Job Title: Data Scientist

Location: New Jersey

Duration: Long (Contract)

Rate: $60/hr.

Client: DXC

Â

Who are we looking for?

Looking for Data Scientist resource - Who has Sound knowledge in the product support and implementation

Â

Technical Skills:

5+ years of hands-on experience as a Data Scientist with â

â Undertaking data collection, preprocessing and analysis

â Building models to address business problems

â Presenting information using data visualization techniques

â Experience in data mining, business intelligence tools, data frameworks

â Understanding of machine-learning and operations research

â Knowledge of R, SQL and Python; familiarity with languages such Scala, Java or C++ would be an advantage","InvenTech Info
4.8","Jersey City, NJ",IT Services,Information Technology
Data Analyst,"Whip Media Group's products, including Mediamorph, TV Time and TheTVDB, offer a data-driven integrated cloud solution that empowers the world's leading entertainment organizations to efficiently acquire, distribute and monetize their content. Together, our companies track billions of consumer actions and financial transactions that accelerate innovation for buyers and sellers of content. Whip Media Group has offices in Los Angeles, New York City and London.


We're looking for a data analyst to join our Business Operations team in New York City! To be successful in this role, you should be detail oriented and highly attentive when working with data sets of varying sizes and kinds. This role will encompass using both our in-house built tools as well as Microsoft Excel for data input, Q/A, and management.

How you will contribute:
Data tracking, maintenance and QA
Data and contract analysis
Data and contract input
Internal and external communication on key statuses, deliverables, and metrics
Ownership of all assigned tasks, with time management and diligence to hit deadlines given
Consistent support to the team and clients through excelling data management
To be successful in this role you'll need:
Bachelor's degree
Strong communication skills and attention to detail
Favorable but not required relevant experience in accounting and or/financial reporting, contract management, or paralegal experience, preferably in the media, broadcast or entertainment industry.
Candidates must have strong computer skills, including strong data entry skills (with an emphasis on accuracy) and strong proficiency using Microsoft Office's Excel, Word and PowerPoint applications
Ability to work within deadlines, exercise good judgment, and maintain client confidentiality
Good pop culture IQ","Whip Media Group
5.0","New York, NY",-1,-1
Data Scientist,"Learn and work on meaningful initiatives with some of the best and brightest in the market research industry. The NPD Group provides the world’s most successful brands with leading market research, combining consumer and retail point-of-sale data with analytic solutions to interpret today’s market trends while anticipating tomorrow’s. In addition, we offer a career filled with innovation and growth to the forward-thinking problem solvers who join our team. Position Overview NPD group is looking for a data scientist with significant statistical modeling and programming experience. This position exists within the Methodology team, a core function in Research Science that is responsible for building models and code that help achieve quality outcomes. Sampling of issues we might tackle: Differential non response Selection bias Differential use of scales Differential recruitment Data imputation Ecological inference Quantifying uncertainty Choosing between alternate methodologies Identifying spurious drivers / sources of bias Sampling of techniques we might use: Multilevel regression and post stratification (MRP) Multilevel modeling / hierarchical modeling Propensity-adjustments Matching Raking Post-stratification Causal modeling Generative models Optimization Artificial intelligence Although modeling expertise is central to this role, candidates will also benefit from experience modifying model-based approaches to be used at production scale. Also helpful is experience triangulating estimates from disparate data sources with different sample frames, levels of measurement, and frequency of collection. The ideal candidate will be an experienced statistical programmer using R who also has experience working with survey and sales data, refining and developing methodological improvements, and familiarity with or willingness to learn Agile or Lean approaches to developing new product improvements. Responsibilities: Use various modeling approaches to design enhancements to NPD methodologies Quantify improvements to data due to modeling Carry out tests of alternative implementations of these enhancements Making sure code to implement models on an ongoing basis is robust by creating unit tests Investigating unexpected results and brainstorming alternative methodological solutions. Provide peer mentoring of other team members via code reviews, pair programming, unit test/acceptance test reviews, and brainstorming sessions. Adopt and continue to improve usage of development practices and patterns, such as test-driven development, version control, and use of agile management tools. Conduct original research-on-research (e.g., through simulations and/or evaluations of historical data) to improve methodologies, processes, and data integrity for both survey and scanner (point-of-sale) data. Promote consistency in implementation of designed enhancements across different businesses Maintain relationships with Research Science client teams to understand what is working well with NPD methodology and what could be improved Listen to internal customers and build an understanding of their needs before building solutions Communicate results and procedures in a concise and polished manner to diverse internal stakeholders Back up assertions with facts, and design experiments to quantify or reduce uncertainty when dealing with the unknown Qualifications: Degree in statistics, quantitative social science, computer science, mathematics, or related fields is required. Graduate-level experience preferred. 6+ years of work experience, with solid breadth and depth of knowledge of statistical and analytic techniques. Excellent time management and creative problem solving skills. Experience with data analysis in R is required. Experience with additional languages and/or more extensive proficiency in R preferred. Excellent written and oral communication skills, with the ability to communicate effectively to both technical and non-technical audiences. Experience with one or more development methodologies (Agile, Lean, Scrum) is preferred. Experience with tools for managing software development is preferred (tools such as JIRA, Confluence, Github/Gitlab issue tracker, Trello, Team Foundation Server/DevOps Server, etc). Location: We would prefer to find a candidate who can work from either our corporate headquarters in Port Washington, NY, or one of our other largest offices, in Rosemont, IL. However, we are committed to finding the right candidate across all US locations. We have offices in many US cities, including: Chicago, IL; New York, NY; Los Angeles, CA; San Diego, CA; Cincinnati, OH; Boulder, CO; Bentonville, AR; Greensboro, NC; Houston, TX. The NPD Group, Inc. is an Affirmative Action/Equal Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability or protected veteran status or any other characteristic protected by law.","NPD
3.8","Port Washington, NY",Research & Development,Business Services
Data Scientist,"Description

The Data Scientist will be part of the Enterprise BI team at , Inc. This individual will manage one or more analysts and focus on customer-level advanced analytics for the direct-to-consumer and business-to-business channels.

Responsibilities include, but are not limited to:

As a hands-on analytics leader, deliver actionable insights while prioritizing and managing the workload of junior analysts

Collaborate with business owners and propose appropriate analytics solutions to address critical business questions

Create Tableau dashboards to empower business owners

Develop advanced analytics solutions to address some open business questions, e.g.,

Multi-Brand Customer Segmentation

Next Best Offer/ Next Best Brand

Channel Attribution

Customer Retention

Requirements

Key Competencies:

Strong analytical mind, problem-solving skills and foundation in Statistics

Ability to collaborate well with individuals on-site and in remote offices

Intermediate to advanced level of expertise using SAS, SQL, Tableau, Python

Outstanding analytical skill set: a clear expert in the Analytics/ Data Science field

Experience working with large volumes of data, combining and reconciling data from different sources

Experience in MS Office applications with very strong Excel skills

Requirements:

Minimum B.S. in Mathematics, Statistics, Data Analytics or related quant field

5+ years in a similar analytical role generating insights through data analytics

Strong communication skills: both written and verbal

Ability to work independently on multiple concurrent assignments

Self-driven for continual learning and ongoing training/development

Highly organized, detail-oriented

About Us
, Inc. is a leading provider of gifts for all celebratory occasions. For the past 40 years, has been helping deliver smiles to customers with a 100% Smile Guarantee backing every gift. The , Inc. family of brands also includes everyday gifting and entertaining products from Harry & David, The Popcorn Factory, Cheryl's Cookies, , Wolferman's, Moose Munch premium popcorn, Personalization Universe, Simply ChocolateSM, and SM. The Company also offers top-quality steaks and chops from Stock Yards and gift baskets and towers from its DesignPac Gifts, LLC division. Loyalty programs, such as Celebrations Passport, Celebrations Rewards and Celebrations Reminders are designed to deepen relationships with customers across all brands. The Company's BloomNet international floral wire service and Napco SM floral gifts and seasonal dcor division provide a broad-range of products and services designed to help professional florists grow their businesses profitably. , Inc. was named to the Stores 2017 Hot 100 Retailers List by the National Retail Federation and also received the Gold award in the Best Artificial Intelligence category at the Data & Marketing Association's 2017 International ECHO Awards. Shares in , Inc. are traded on the NASDAQ Global Select Market, ticker symbol: FLWS.","1-800-Flowers
2.8","New York, NY",Wholesale,Business Services
Data Scientist,"Job Description
Job Responsibilities
Develop reliable systems that are scalable, and maintain current software to ensure its effectiveness and efficiency.
Optimize user effectiveness, and seek and process feedback to determine areas of improvement and other changes that could further enhance the user experience.
Research and evaluate new types of technology to assess their feasibility and implementation in accordance with company objectives.
Create organized and accessible ways to document code and track changes in software including updates for future reference and use.
Perform regular unit tests to determine the effectiveness of current software and to catch glitches that could slow or hamper organizational growth.
Implement new types of software and introduce innovative technological advancements to maintain a competitive edge in the industry.
Educate and update staff and executive management about how to use various software, while ensuring their understanding and accessibility.
Job Skills & Qualifications

Required
Masters in Computer Science, Mathematics, Statistics or related fields
5+ years' experience in a data science or data analysis role
TOR157",The Organic Recruiter,"New York, NY",-1,-1
Data Scientist,"As a Data Scientist, you'll utilize advanced quantitative & statistical analysis techniques to drive business model innovation for Via, and work closely with our senior management to help drive decisions.

What You'll Do
Adeptly interpret and utilize mass quantities of data to generate innovative hypotheses & insights, and present these insights to the different stakeholders
Use sophisticated statistical methods to solve problems, leveraging up-to-date academic research and tools
Quantitatively test hypotheses about customer and driver behavior using large sets of proprietary data; leverage results to increase conversion and retention at every touch point
Design and implement novel experiments to better understand current operation as well as expansion to new markets
Who You Are
Obsessed with data; analytical and rigorous, with a thorough understanding of statistics and machine learning
Extraordinary communicator with demonstrated writing and editing skills.
Passionate about elegant visualization; you understand the importance of graphic techniques in communicating a quantitative idea effectively
Have a deep understanding of business concepts within strategy, operations, and marketing
Have a PhD in statistics, machine learning, physics, math, systems biology, or highly quantitative fields in social sciences, including 2+ years of graduate-level research experience (or the equivalent).
Have experience with predictive modeling and statistical analysis techniques in a business environment
Demonstrate mastery in some or all of the following: SQL, Python, R, and Tableau
We're Via, and we build technology that changes the way the world moves. Our guiding principle is simple: we know that the future of transportation is safe, dynamic, shared public mobility the kind that reduces carbon emissions across congested cities, compliments existing transit infrastructure, and provides everyone with accessible, efficient, and affordable ways of getting around. Through intelligently designed operating systems and sophisticated routing algorithms, we build localized and customizable solutions for each and every one of our global partners (100 and counting, last we checked)

Long story short: we're very proud to be championing the transportation evolution of cities around the world and modernizing mobility. Ready to join the ride?

Via offers above market compensation packages and benefits, including equity, health insurance, and relocation assistance.

Via is an equal opportunity employer.","Via Transportation
3.7","New York, NY",Internet,Information Technology
Data Scientist,"Job Description
Build Data Pipelines for AI/ML Solutions using Python
KEY ACCOUNTABILITIES KEY DUTIES
Build Data Pipelines deployed at the edge (customer locations)
Programming skills:- SPSS Modeler (with working experience in most of common libraries like Scikit , numpy, pandas, mathplotlib, keras, tensorflow, nltk, genism, spacy etc)
Good to have working exposure in common cloud environments and understanding of robust on premise data science infrastructure.
Nice to have understanding of big data related technologies and DevOps(Dockers, Singularity)
Good communication and presentation skill
Good knowledge in statistics and deep understanding on ML algorithms and their usage
Working experience in end to end data science project life cycles from use case framing, data collection, data exploration, model building, deployment
Working experience in most of the common Machine Learning techniques related to Time series, Regression, Classification,
Clustering, NLP, working with IoT data
Proven ability be creative and analytical in trouble shooting issues
Ability to work in a fast-paced and high-pressure environment to manage competing priorities",Biotenico Research and Development Company,"New York, NY",-1,-1
Data Scientist,"Building Service 32BJ Benefit Funds
Job Description Posting

Health Fund
Job Title: Data Scientist
Grade: 11
Department: Executive Office
Reports To: Director of Operations
FLSA Status: Non-Union/Non-Management - Exempt
Posting Date: June 30, 2020

Summary: The Data Scientist is responsible for exploring, examining, analyzing and visualizing data from multiple disparate sources to develop new products based on the data gathered; has strong business acumen, along with an effective ability to communicate findings to both business and technology leaders.
The prime candidate will have the ability to analyze incoming data from multiple business domains and build a data platform upon which to build multiple data-driven applications. The person will be responsible for designing and implementing processes and layouts for complex, large-scale data sets used for aggregation, statistical and research purposes.

Essential Duties and Responsibilities:

 Selecting features, building and optimizing classifiers using machine learning techniques

 Data mining using state-of-the-art methods

 Identify valuable data sources and automate collection processes. Extending company’s data with third party sources of information when needed

 Enhancing data collection procedures to include information that is relevant for building analytic systems

 Processing, cleansing, and verifying the integrity of data used for analysis

 Doing ad-hoc analysis and presenting results in a clear manner

 Creating automated anomaly detection systems and constant tracking of its performance

 Undertake preprocessing of structured and unstructured data

 Analyze large amounts of information to discover trends and patterns

 Build predictive models and machine-learning algorithms

 Combine models through ensemble modeling

 Present information using data visualization techniques

 All other duties as assigned by management

Qualifications and Core Competencies:

 Practical ability to visualize data, communicate the data, and utilize it effectively

 Extensive experience solving analytics problems using quantitative approaches

 A proven passion for generating insights from data

 Strong knowledge of statistical methods generally, and particularly in the areas of modeling and business analytics

 Comfort manipulating and analyzing complex, high-volume, high-dimensionality data from varying sources

 Ability to communicate complex quantitative analysis in a clear, precise, and actionable manner

 Strong problem solving and logical skills.

Technical Skills:

 Expert level proficiency in Python, R, or Julia languages for the development of data science applications

 Expertise with SQL databases and unstructured data stores

 Experience working with complex and/or large data sets

 Excellent understanding of machine learning techniques and algorithms, such as k-NN, Naive
Bayes, SVM, Random Forests, etc.

 Expertise in testing and validating models and assessing the trade-offs between different modeling techniques and specifications

 Experience with deep learning utilities such as Tensor Flow, PyTorch, or Flux

 Experience with Qlikview or KNIME a plus

Interpersonal Skills:

 Effective written and verbal communication with all levels of the organization, including both business and IT partners

 Ability to think creatively and to work well both as part of a team and as an individual contributor

Education and/or Experience:

 Degree in Applied Math, Economics, Statistics, Computer Science or other quantitative field. MS preferred

Language Skills: Speak, read, write and understand English
Reasoning Ability: High
Certificates, Licenses, Registrations: None

Physical Demands: The physical demands described here are representative of those that must be met by an employee to successfully perform the essential functions of this job. Reasonable accommodations may be made to enable individuals to perform the essential functions.

 Under 1/3 of the time: Standing, Walking, Climbing or Balancing, Stooping, Kneeling, Crouching, or Crawling

 1/2 to 2/3 of the time: Sitting, Reaching with Hands & Arms

 Over 2/3 of the time: Talking or Hearing

 100% of the time: Using Hands

Job Type: Full-time

Benefits:
401(k)
Dental Insurance
Disability Insurance
Health Insurance
Paid Time Off
Parental Leave
Retirement Plan
Tuition Reimbursement
Vision Insurance
Schedule:
Monday to Friday
Experience:
computer science: 1 year (Preferred)
Education:
Master's (Preferred)
Work authorization:
United States (Required)
Application Question:
education in economics
Work Location:
One location
Benefit Conditions:
Only full-time employees eligible
Work Remotely:
Temporarily due to COVID-19","Building Service 32BJ Benefit Funds
1.9","New York, NY",Health Care Services & Hospitals,Health Care
Data Analyst,"Undertone stands alone among AdTech and ad network businesses in its ability to address marketing objectives through Synchronized Digital Branding and extraordinarily creative treatments. We drive best in class results for clients through Undertones expansive rich media and video capabilities that are expressed across multiple channels and platforms, matching the consumer journey.

Undertones Data Management Service (UDMS) is a big data, cloud-based data-warehouse, dashboard and reporting environment. Do you want to help enable a data-driven organization? This is your opportunity to join a mission critical team, at an innovative company in an industry just beginning to harness the power of data.

As member of the Undertones UDMS Team, the Data Analyst drives value by providing provocative, differentiating analytics and insights. This position will support a wide variety of business intelligence efforts across Undertone while working in a highly collaborative manner within multiple large, cloud-based data sources to identify insights and spearhead our next generation product offerings. Most importantly, you should love the data, working with data, finding the nuance that leads to key differentiation for the business and our customers. This is a high visibility analytics and consulting position requiring daily interaction with business users, data scientists, engineers and key stakeholders.

Job Responsibilities:
Work with business teams to understand their analytical needs, including identifying critical metrics and KPIs
Use analytical and problem-solving skills to deliver actionable insights to relevant decision makers
Develop rich interactive visualizations integrating various reporting components from multiple data sources
Use SQL, Tableau and other technologies to pull data from different backend systems and product meaningful information and visualizations
Take complicated problems and build simple frameworks
Work directly with users and management to gather requirements, provide status updates, and build good relationships and rapport
Profile and Experience:
A minimum of 1 year of a full-time data analytics experience, ideally in an Ad-tech company
A minimum of a Bachelors degree in Engineering, Mathematics, Business, or related field
Expert SQL coding skills against large data sets
Strong analytical skills, including the ability to mine data in order to draw meaningful conclusions
Strong oral and written communications skills
Knowledge of Business Intelligence tools such as Tableau
Powered by JazzHR","Undertone
3.8","New York, NY",Advertising & Marketing,Business Services
Data Analyst,"Job Description
The New York City Department of Investigation (DOI) is one of the oldest law enforcement agencies in the country with a mission of combating municipal corruption. It serves the people of New York City by acting as an independent and nonpartisan watchdog for New York City government, City agencies, and City employees, vendors with City contracts, individuals and entities that receive City funds.

DOI seeks a Data Analyst who will support the criminal and policy-driven investigations of the Inspectors General. The Data Analyst will assist DOI investigators with building and enhancing complex investigations through large scale data collection and analysis.
The Data Analyst is expected to:
• Develop and enhance practices for identifying patterns and trends related to fraudulent financial activity.
• Ensure the collection, management, and analysis of quality data from external sources.
• Conduct quality assurance of data.
• Maintain, summarize, and report on outcomes of data searches.
• Work collaboratively with DOI investigators to generate investigative leads, create reports, and interpret data.
• Present findings in a cogent manner through detailed and accessible reports to key decision-makers.

If selected, the candidate will be fingerprinted and undergo a background investigation. In addition, for positions that have a law enforcement and/or investigative function, the candidate's consumer credit history will be reviewed during the background investigation, and as otherwise permitted by NYC Administrative Code § 8-107(24)(b)(2)(A).
Minimum Qual Requirements
1. A four-year high school diploma or its educational equivalent approved by a State's Department of Education or a recognized accrediting organization and four years of satisfactory full-time experience in an industrial or governmental agency in the field of investigation, auditing, law enforcement, security, inspections, or in a major operational area of the agency in which the appointment is to be made; or
A baccalaureate degree from an accredited college or university; or
Education and/or experience equivalent to ""1"" or ""2"" above.
Preferred Skills
• Experience working with data analytics.
• Bachelor's degree in Finance, Accounting, or Information Technology, Computer Science, or Information Systems.
• Advance knowledge in MS Excel: VBA, Data Models, and ability to create Pivot Tables and complex nested formulas.
• Strong written and verbal communication skills.
• Knowledge in SQL and experience with any RDBMS: MS SQL Server (T-SQL), Oracle (PL/SQL), MySQL (SQL/PSM), and PostgreSQL (PL/pgSQL).
• Knowledge in Python, R, C++ ,and/or Java.
• Knowledge in analytics software (i2 Analyst Notebook, Palantir, Cognos, etc.).
• Database related certifications from Oracle or Microsoft.
• Demonstrated interest in law enforcement, criminal justice, or social service.
To Apply
All current City Employees may apply by going to Employee Self Service (ESS) http://cityshare/ess then click on Recruiting Activities/Careers and Search for the specific Job ID# 435571.

All other applicants please go to www.nyc.gov/career/search and search for the specific Job ID# 435571.

Please do not email, mail or fax your resume to DOI directly. Submissions of resumes does not guarantee an interview. Due to the high volume of resumes DOI receives for positions, only selected candidates will be contacted.

Appointments are subject to Office of Management & Budget approval for budgeted headcount.

The City of New York is an equal opportunity employer and is strongly committed to a policy of non-discrimination. We are committed to recruiting a diverse and inclusive talent pool.
Residency Requirement
New York City residency is generally required within 90 days of appointment. However, City Employees in certain titles who have worked for the City for 2 continuous years may also be eligible to reside in Nassau, Suffolk, Putnam, Westchester, Rockland, or Orange County. To determine if the residency requirement applies to you, please discuss with the agency representative at the time of interview.","City of New York
3.4","New York, NY",Municipal Governments,Government
Data Scientist,"Requisition Number
6027006

Department
Enterprise Reporting

Location
Melville
992 North Village Avenue Rockville Centre, NY 11570

Schedule
Full Time

Shift
Day shift

Hours
8:00am - 4:00pm

Job Details
POSITION SUMMARY:

The Data Scientist will be responsible for the creation of advanced static models, dynamic models and algorithms, through data science, numerical methods and statistics.

DUTIES/RESPONSIBILITIES:
Perform Data discovery, profiling and analysis of real-time and historical clinical healthcare data
Drive Data management, classification and taxonomy development
Hypothesis development and testing
Data model and algorithm development and training
Collaborate with the multi-disciplined business analysts, technical analysts, data scientists and software engineers
Creation of support tools, documentation and designs of algorithms for implementation in healthcare big data ecosystem
Works collaboratively to design, implement and maintain data science models and applications.
Establish programs to apply data science methodologies, including predictive modeling and machine learning, data analytics and visualization, and usability and design, to departmental, service line, and enterprise applications and functions.
Synthesizes complex data-related problems into actionable business and/or clinical strategy, and communicate findings to appropriate end-users and stakeholders.
Assists with the development of specifications to support the design of new or modified data science projects, with a focus on data-driven optimization, enhancement, and development.
Assists in the evaluation of projects, systems, and initiatives at the department, service line, and enterprise level. Ensures projects and their outputs enhance clinical quality, patient safety, and institutional efficiency, focusing on all aspects of data science, including data gathering and wrangling, exploratory data analysis, data modeling and machine learning, and model implementation and evaluation. Ensures high quality execution of all proposed projects.
Knowledgeable in present and planned data science projects and maintains voice of the customer in all project initiatives.
Serves as the link between the clinical staff (customer) requirements and IS capabilities.
Assists in ensuring that systems are implemented to support Health System initiatives and goals to improve the quality of patient care, to maximize patient safety, and to provide operational efficiencies
POSITION REQUIREMENTS AND QUALIFICATIONS:

Education:
PhD in Computer Science, Biomedical Informatics or related field
Experience:
Experience with predictive modeling in healthcare, is preferred
Experience with healthcare data, including HL7, EMR and claims data, is preferred
Experience with natural language processing, is preferred
Experience with using languages like R, Scala and Java, is preferred
Understanding of Hadoop environment, is preferred
Experience with big data cluster computing tools like Spark, is highly-desirable
Experience with machine learning (supervised and unsupervised), is preferred
Experience with statistical analysis, is essential
Experience with hypothesis testing, is essential
Knowledge/Skills:
Proficient with statistical software packages (R, Python, MATLAB, SAS or related programs)
Highly proficient with Excel, Microsoft Office and using data visualization tools (e.g., Tableau, Qlik, PowerBI) to present data in clear, concise formats
Solid creative thinking, learning agility, decision making, problem solving, reasoning, and visualization skills and abilities.
Interest in becoming a content expert in healthcare reporting databases and warehouses.
Communicate effectively with excellent verbal/written communication skills.
Collaborating with developers for customized development.
Able to manage multiple tasks, often with competing deadlines.
Possess the ability to contribute to an environment that motivates individuals to work collaboratively as a team
Reasonable accommodation will be made to enable individuals with disabilities to perform the essential physical demands.

Expectation for All Employees:
Demonstrate knowledge of and conduct himself/herself in conformity with the CHS Compliance Assurance Program and Standards of Conduct. Employee shall receive a copy of the CHS Compliance Program Handbook and be aware of the CHS Helpline. Employee will perform all work activities according to the highest ethical and legal standards.
Conduct himself/herself in conformity with the HIPAA Compliance Program and applicable institutional policies and procedures for patient privacy.
Play an active role in the CHS Information Security Awareness Program by following and supporting all CHS information security policies and procedures to the best of their ability. This will include reporting any suspected fraud, abuse, or violation of policy to the appropriate management or reporting mechanism.
Support the organizations mission, vision, and values by exhibiting the following behaviors: excellence and competence, collaboration, innovation, respect personalization, commitment to our community, and accountability and ownership.","Catholic Health Services of Long Island
3.1","Rockville Centre, NY",Health Care Services & Hospitals,Health Care
Data Analyst,"Job Description:
Legal experience is required.
Managing several different data sets - including creation, updates, and deletion.
Provide quality assurance of imported data, working with quality assurance analyst if necessary.
Troubleshooting data issues with IT/ Review Team.
Supporting initiatives for data integrity and normalization.
Generating reports from single or multiple systems.
Evaluating changes and updates to source production systems.
UAT Testing.","Pozent
3.5","New York, NY",-1,-1
Data Scientist,"Job Description
Data Scientist

Base: $160,000 - $220,000

Company Overview:

Our Client is looking for a Data Scientists from a variety of backgrounds to help propel and enhance its data-driven investment initiatives. As a Data Scientist, you will explore a breadth of challenges: identifying timely and unique data sets, diving deep into a diverse set of data domains, visualizing and exploring and visualizing underlying data drivers, and developing data set features and forecasts.

Responsibilities:
Apply statistical analysis & modeling techniques with finance intuition to datasets large and small, advance existing initiatives and open opportunities to pursue new and previously unexplored research topics across a wide variety of industries and domains
Operate and extend the data science platform to deliver production-grade data curation and analysis services
Own end-to-end data workflows and develop deep domain expertise on the underlying actors and behaviors manifested through data
Visualize and explore data sets to enable the ideation and generation of new, predictive feature
Qualifications and Experience:
Advanced degree in Computer Science is preferred
3+ years of experience in data analysis or similar role
Experience applying statistical methods (distribution analysis, classification, clustering, etc.)
Strong coding skills with data-frames are a prerequisite, example platforms include Pandas, R, Matlab, and Apache Spark Demonstrated experience highlighting innovation, creativity, and intuition, e.g the ability to laterally identify other sources of useful information and think 'outside the box'
Prior Experience in finance is not required",Amber People,"New York, NY",-1,-1
Data Scientist,"CompuForce is seeking an experienced and highly motivated data scientist to join our clients growing data science team. This individual will support enterprise initiatives on segmentation, personalization, and forecasting through in-depth, statistical & quantitative analyses of consumer data, and integration of high-quality prediction systems into our brands & products. Discover the information hidden in vast amounts of data, and help us make smarter decisions to deliver even better products. Your primary focus will be in applying data mining techniques, doing statistical analysis, and building high quality prediction systems integrated with our products.

Responsibilities:

Conduct statistical analysis of our audience web, demographic and transactional data in support of strategic initiatives. Project work covers all phases conceptualization, planning, data acquisition, modeling, documentation, and presentation of findings/recommendations.

Design tests, benchmark and track performance of predictive models over time.

Improve business results, by applying machine learning to ongoing business activities, and develop recommendations to guide future activities.

Work with partners in Data Engineering, Marketing, Product and Programmatic teams, to operationalize integration of analytic models into production environment(s).

Stay current on relevant academic and industry developments to identify best-in-class algorithms, techniques, libraries, etc.

Partner with other team members to evolve existing capabilities.

Perform ad hoc analytic tasks and reporting as needed.

Select features, building and optimizing classifiers using machine learning techniques

Mine data using state-of-the-art methods

Extend companys data with third party sources of information when needed

Enhance data collection procedures to include information that is relevant for building analytic systems

Process, cleanse, and verify the integrity of data used for analysis

Create automated anomaly detection systems and constant tracking of its performance

Skills:

Excellent understanding of machine learning techniques and algorithms, such as k-NN, Naive Bayes, SVM, Decision Forests, etc.

Exceptional quantitative analytics/applied statistics skills, including regression, clustering and classification, forecasting and machine learning, and other techniques appropriate for large scale data analysis.

Experience with common data science toolkits, such as R, Weka, NumPy, MatLab, etc. Excellence in at least one of these is highly desirable

Exceptional programming skills in a modern-stack Linux environment. This includes knowledge of approaches to automate workflows and data pipelines.

Experience with big data technologies: Hadoop, AWS/EMR, Spark, Hive.

Two or more years of business/marketing analytics experience, preferably in a media organization.

Exceptional communication skills, particularly in communicating and visualizing quantitative findings in a compelling and actionable manner for management.

Strong set of professional skills: attention to detail; analytic, logical and creative problem solving; critical thinking; ability to work independently and within a cross-functional team.

Advanced degree with an emphasis in a quantitative discipline such as statistics, engineering or mathematics. PhD preferred.",CompuForce,"New York, NY",-1,-1
Data Scientist,"Company Description

Wisestep is the fastest growing talent sourcing network of Recruitment Agencies and Freelance Recruiters. We have strong relationships with IT services companies focussed on Europe and the US. Hence, we have a large ongoing pool of IT job positions ranging from entry level to executive. We allocate these positions to our recruitment partners based on a lucrative fee sharing model. See what some of our successful partners say: https://youtu.be/QzKe9iZszD0

Job Description
Data Scientist / Machine Learning Engineer
Seeking a Azure Big Data Machine Learning Engineer where you will help leverage data to make informed decisions. You will be knowledgeable of cloud based architectures and Azure technologies. You will be passionate about Machine Learning, Deep Learning, and be an expert with Azure ML with knowledge of AutoML, MLOps, and data science on ML platform.
Well versed with Data Science, Machine learning and Deep Learning based solutions and frameworks. Apply technical knowledge to architect solutions that meet business and IT needs, create enterprise development roadmaps, and ensure long term technical viability of new deployments, infusing key analytics and AI technologies where appropriate (e.g. Azure Machine Learning, Machine Learning Server, BOT framework, Cognitive Services, Azure Databricks, etc.)
Ability to Interpret the logical side of the data, demonstrate leadership in advanced Analytics, support leading project tasks, experience with ETL tools, Python coding required-At least 2 years preferred, Hands-on with Spark, SQL highly preferred.",Wisestep,"Queens Village, NY",-1,-1
Data Scientist,"Job Description
As a Data Scientist, you will apply the latest data mining techniques, using statistical analysis to integrate prediction systems with products and present findings to the business. As a data scientist you will work closely with architects, engineers, account managers and data scientists within and outside the company. You will be involved from pre-sales to support. You will work on next generation algorithms development and help measure, maintain and upgrade current business.

Responsibilities:
Building algorithms and designing experiments to merge, manage, analyze, and extract data for tailored reports to colleagues, clients or management.
Gathering, standardizing, and analyzing voluminous electronic data, such as records, general ledgers, sales and inventory data, etc.
Creating and monitoring anomaly detection systems.
Own complete life cycle from problem formulation to solution deployment and maintenance
Must be able to collaborate with architects, engineers, and data scientists within and outside the company
Building predictive models and presenting information using data visualization tools and techniques.
Develop proven methods and strategies for the larger Data Scientist team.
Collaborating with engineering and product development teams.
Querying and mining large data sets to discover transaction patterns, examining financial data and filtering for targeted information that utilize both traditional and predictive/advanced analytic methodologies.
Keeping the company current with the latest technology, techniques, and methods.
Act as a technical thought leader in collaboration with the analytics team, helping to set the strategy and standards for data science and advanced analytics.
Excellent interpersonal skills with ability to communicate clearly and concisely with executives, engineers, account managers, sales, business partners and data scientists.
Qualifications
0-10+ years of work experience in a Data Scientist role (or related field).
3+ years of outstanding technical abilities with Java, or C/C++ development experience with statistical machine learning models
Bachelor’s degree or higher in data relevant fields: Computer Science, Mathematics, Physics, Engineering, Statistics, etc.
Experience with common data science toolkits, such as Python, R etc., with expert proficiency in at least one
Experience creating, managing, and utilizing high performance relational and NoSQL databases, such as Microsoft SQL Server, Oracle, Microsoft Access, OLAP and other software.
Experience with a business intelligence tool such as Tableau, Adobe Analytics or Google Analytics
Experience with Spark, Kaplan, Breeze, MapReduce models a plus
You can describe and speak in an approachable way about complex analyses and concepts within a cross-functional team. You are a great “analytic translator”. You know how to simplify technical concepts when explaining things to non-technical business leaders.
Selecting and implementing data mining methods most relevant to company projects and desired outcomes.
Experience with at least two of Social Network Analysis, Knowledge Graphs, Predictive Modeling, Language Processing (including NLP) is a plus
Excellent understanding of computer science fundamentals, data structures, and algorithms
Rounded business skills with the ability to understand customer and/or stakeholder needs
Have a strong mathematical background and have experience with modeling complex high dimensional problems
Experience performing petabyte scale data analysis and developing meaningful visualizations
Must be organized, have an eye for detail, and be able to identify trends within the data and tell that story to business leaders",HireAi,"New York, NY",-1,-1
Data Analyst,"Vettery is changing the way people hire and get hired. We use machine learning and real-time data to match talented job-seekers with inspiring companies. Our goal is to enrich and automate the recruiting process, make hiring more rewarding for everyone, and create a happier and more accountable working world.

Since launching in 2015, we've made thousands of matches on our marketplace. We're currently working with over 80,000 job-seekers and 20,000 companies, from Fortune 500 giants to startups based out of co-working spaces. We've built powerful machine learning capabilities, and our matching algorithm is becoming more intelligent with each passing day. With an eye on the future, we're expanding our reach across major cities in the US, and around the globe.

As Vettery undergoes growth and changes, our Analytics team delivers the data and insights needed across all departments for a data-driven approach to scalability. As a Data Analyst at Vettery, you will work directly with our Director of Analytics to get the right data to the right people, and figure out what 'right' is.

Key responsibilities and expectations:
Collaborate with key stakeholders across the company to understand their needs and how we can leverage data to improve their processes
Create reports and dashboards that will give insight into areas previously unexplored, including Product Analytics, Finance Metrics, Marketing Attribution, and more
Support the Director of Analytics in developing data-driven strategic proposals that have far-reaching impacts on the company's growth
Learn! Quickly learn new skills, technologies, and business context. There's nothing you can't do… there's only what you can't do yet
Candidate Qualifications:
0-1+ years of experience in analytics (or related field)
Willingness to be hands-on with data and a capacity to build processes
Strong communication skills and a desire to collaborate with others
A passion for improving the recruiting experience
A growth mindset, willingness to learn as you go, and a strong tendency to Google stuff you don't already know!
Experience with Microsoft Excel, including data manipulation, charting, and advanced functions
Experience with SQL and relational database management
Experience working with data visualization is a plus
Knowledge of data analytics environments (python, R) is a plus
With the above said, we understand that no candidate is perfectly qualified for any job and believe that diversity of background and thought makes for better problem solving and creative thinking, which is why we're dedicated to adding new perspectives to the team. Even more important than your resume is a positive attitude, passion for the work, personal drive for growth, and the ability to thrive in a fluid and collaborative environment. We want you to learn new things in this role, and we encourage you to apply even if your experience doesn't align perfectly to what is listed here.

Vettery has five key values that are the foundation of our company culture, which every employee embodies:
Positivity - We're positive when things get difficult so we can stay motivated and lift each other up. We're very team focused in everything we do so contagious positive energy is extremely impactful.
Ownership - We take pride in our work and take on a lot of responsibility from day one. All of us have the ability to see how our work and performance impact the success of the business.
Grit - We love getting in the trenches and building from the ground up. Even though we've significantly grown since our tiny startup days, we still have that scrappy mentality and love that there's still a lot to accomplish.
Awareness - We're focused, strategic, and constantly learning from our experiences. Each of us knows what's expected of us as a corporate citizen and within our teams.
Collaboration - We learn from one another and are constantly working with each other, within and across teams. Every team has an impact on others and we take pride in clear lines of communication.
Why you'll love working at Vettery:

We love coming to work on Monday. It's easy to love the work you do when you see the positive impact it has, and helping someone find their dream job can change their life forever. We believe in our mission, love the work, and have fun doing it together. Plus, coming to work in our sunny Flatiron office is easy when there are so many things to look forward to: Flag Football games, Thursday Game Night, Cross-Team lunches, company happy hours, volunteer events, adorable pups, ping-pong, and your favorite snacks.

We know life is about more than just work. We have an open vacation policy so you can take the time you need to relax and rejuvenate, contribute to the cost of insurance coverage (health, vision, and dental), and offer a fully paid 12-week parental leave, 401k, commuter benefits, and gym membership discounts.

We invest in your development. A company is only as strong as its team, and we want to help strengthen every member of our team. We give everyone the opportunities and support they need to reach that next professional level through company-sponsored General Assembly classes and conferences, in-house training, a culture of continuous feedback, and the chance to run with projects.

We're consistently recognized for our culture. We're listed #5 on Fortune's 60 Best Companies to Work for in New York City, included in Fortune's Best Workplaces in Technology for 2020, and have been previously honored at Crain's Best Places to Work Awards and included in Inc Best Workplaces.

Equal Opportunity Employer/Veterans/Disabled

Vettery values the multitude of talents and perspectives that a diverse workforce brings. All qualified applicants will receive consideration for employment without regard to race, national origin, religion, age, color, sex, sexual orientation, gender identity, disability, or protected veteran status.","Vettery
3.1","New York, NY",Internet,Information Technology
Data Scientist,"Job Description
Data Scientist & Senior Data Scientist
Location: New York, NY

Have the opportunity to join a fast growing Biotech Analytics firm located in New York City as a Data Scientist or Senior Data Scientist to join their statistical / machine learning team. This firm is a research-driven natural science and precision medicine company focused on maximizing reproductive medicine through fertility analytics. You will need to have a deep expertise in data science with a desire to work with large clinical datasets. This is a great opportunity for an individual to leverage their experience and skills in data analytics to make a meaningful impact on reproductive medicine.

Responsibilities:
• Working with large scale structured and unstructured clinical data.
• Applying standard statistical analysis and machine learning techniques in an R&D setting.
• Developing standardized and automated processing pipelines to prepare data for analytic activities.
• Planning and executing analytic solutions for scientific audits, reviews, and reports with minimal supervision.
• Designing, developing, and maintaining databases for scientific and commercial applications.
• Setting up and working on compute clusters and parallel computing.

An ideal candidate would have the following academic background and concrete skills (Required Skills):
• Master’s or PhD in biostatistics, computer science or a similar discipline is required.
• Minimum of 2+ years of professional Data Science, Statistical Analysis and/or Machine Learning experience.
• You should have an understanding of Bayesian decision theory, Support Vector Machines (SVM), Markov modeling, clustering, survival analysis, and other standard analytical methods used for regression and classification problems.
• Proficiency in SQL, NoSQL, or MongoDB programing.
• Proficiency in modeling and programming with R, Matlab, or Python. Any C/C++ would be a plus.
• A proven publication record, along with strong organizational, writing, and communication skills.

The ideal candidate will have the following characteristics (Desired Skills):
• Enjoys working in a highly collaborative environment with a diverse team to tackle complex problems
• Is disciplined and driven to deliver ongoing research results
• Has a positive attitude with a willingness to roll up their sleeves and do what it takes to get the job done
• Is highly organized
• Is a strong written and verbal communicator
• Has a hard work ethic with emphasis on execution

More about our Bio-Tech client:
Our client is leveraging proprietary access to large clinical datasets to drive data-driven decision-making through our SaaS data fusion platform. They are also generating whole genome datasets that expand their understanding of how a woman’s personal genetic signature relates to her fertility potential. These genetic feature sets, together with the clinical metrics, will power the next generation release of their SaaS platform. The firm’s leadership team includes a diverse group of world-class scientists and professionals.","TEKREQS, Inc.
1.0","New York, NY",-1,-1
Data Engineer,"Mark43's mission is to empower communities and their governments with new technologies that improve the safety and quality of life for all. We build powerful, scalable, and elegant software that sets a new standard for the tools upon which our first responders rely. Our users are diverse, and we are therefore committed to embracing diversity of thought and experience within our team.

Mark43 is looking for a Data Engineer to help us build a next generation real-time crime analysis platform. Our Analytics product helps police departments draw better insights from their data, detectives to solve cases, and agency leadership to allocate department resources more efficiently. Working at Mark43, you'll be helping first responders save lives!

We are looking for someone passionate about data - best ways to collect, organize, transform and present it. You have extensive experience architecting complex, highly available and optimized real-time data pipelines, know the pros and cons of different tools, and when to build your own vs use an off-the-shelf solution.

What you can expect to work on
Plan, design and build distributed, real time data pipelines for the next generation of our Analytics product
Work with analytics product engineers to ensure performance, stability and availability of our MS SQL Server analytics databases
Evangelize best data practices among the engineering team, help internal education
Work together with DevOps engineers to improve our AWS data infrastructure
What we expect from you
BA/BS degree in Computer Science or a related technical field or equivalent practical experience
Knowledge and at least a year of production experience working with streaming platforms such as AWS Kinesis, Kafka, and/or Kafka Connect
Experience working with both MySQL and Microsoft SQL Server databases
Data warehouse design and implementation experience
Good knowledge of at least one scripting language
Excellent communication skills, verbal and written
Experience in a fast paced, agile startup environment
What you can expect from us:


Opportunities to learn and grow personally and professionally
Building mission critical and socially responsible software to enable first responders to better serve their communities
A workplace dedicated to supporting and bettering law enforcement, first responders, and other government agencies via mission critical software products
Working towards a worthwhile mission with a team of friendly and intelligent coworkers","Mark43
4.4","New York, NY",Enterprise Software & Network Solutions,Information Technology
Data Analyst,"MediaMath is a leading global independent advertising technology company, working with brands and agencies. We created the first software for real-time media buying in 2007 and today work with over two-thirds of the Fortune 500 and more than 3,500 brands and their agency partners to grow and deepen direct customer relationships.

We have recently launched SOURCE by MediaMath which provides our clients with the most trusted, efficient, and effective way to connect their brands with consumers: real impressions on real media properties with policies and practices that respect the humans behind billions of screens and speakers every day.

We need talent like you to fuel this next-generation ecosystem.

Key Responsibilities:
MediaMath's Account Analytics team is currently seeking a Data Analyst with the knowledge, passion and capability to mine complex datasets, discover and deliver insights that drive value for our clients. The Analytics team fulfills customers' advanced analytics and reporting needs through custom reports and analyses, advanced statistical applications, predictive modelling and interactive web dashboards to help clients effectively manage campaigns and optimize performance. This role, on the Account Analytics team within the Analytics team, will extend that value proposition to more custom, client-specific initiatives. The ideal candidate has the appropriate blend of technical capabilities, business acumen and analytical skills to manage a team of analysts that focus on the challenges of our biggest clients and uncover actionable insights that drive revenue.

You will:
Develop a deep understanding of the MediaMath databases collection process and architecture of databases
Partner with the account and sales team to identify client's analytical and reporting needs and present solutions
Create materials (client facing and internal) that package and promote Analytics offerings.
Design innovative, new and exciting reports and analyses and fully own projects from scope to execution
Articulate results of data analysis to clients, stakeholders and internal groups; translate technical results to a non-technical audience.
Be fully autonomous and self-motivated in making processes as efficient as possible
QA all of their own work in addition to reviewing their team member's code to promote knowledge sharing
Maintain a high level of pride in their own work, always looking to improve current processes and widen scope

You are:
An excellent problem-solver and have superior analytical skills
Good with multi-tasking, time management and prioritizing projects and deliverables
A strong communicator ability to distill key ideas for a non-mathematical audience
Comfortable working in a fast-paced, fun, and entrepreneurial environment
Collaborative and team focused
Experienced in working with disparate reporting systems within an organization
Experienced in working with Analytics contacts at agencies/brands directly
You have:
Bachelor Degree or higher, preferably with a concentration in a computational field such as Computer Science, Mathematics, Statistics, Physics, Engineering; Masters Degree preferred
1 - 2 years of experience working with large data sets or relational databases; Marketing experience a plus
Strong SQL and Python programming; experience of at least one big data technology, e.g. MapReduce, Hadoop, Hive, Spark, Pig, AWS/S3 a plus
Excellent problem-solving capabilities and superior analytical skills

Why We Work at MediaMath

We are restless innovators, smart, passionate and kind. At the heart of our culture are six values that provide a framework for how we approach our work and the world: Teams Win, Scale + Innovation, Obsess Over Learning & Growth, Align then Execute, Do Good Better and Embrace the Journey. These values inform how we energize one another and engage with our clients. They get us amped to come to work. And, let's face it, so do the free snacks, great benefits, and unlimited vacation.

We were named a Leader in both the 2018 and 2019 Gartner Magic Quadrants for Ad Tech, won four awards from the IAB for Sales, Service and Education Excellence, and received Best DMP in the 2019 Digiday Technology Awards. We have offices in 16 cities worldwide and are headquartered in New York City.

MediaMath is committed to equal employment opportunity. It is a fundamental principle at MediaMath not to discriminate against employees or applicants for employment on any legally-recognized basis including, but not limited to: age, race, creed, color, religion, national origin, sexual orientation, sex, disability, predisposing genetic characteristics, genetic information, military or veteran status, marital status, gender identity/transgender status, pregnancy, childbirth or related medical condition, and other protected characteristic as established by law.","MediaMath
3.6","New York, NY",Advertising & Marketing,Business Services
Machine Learning Engineer,"Machine Learning Engineer

At Temboo, we build software that people are using to fundamentally change the world around us. Our no-code platform for environmental engagement empowers organizations, cities, and residents to achieve sustainability goals, advance green infrastructure projects, and build more engaged and informed communities. We want you to join us as we grow and scale Temboo. A few highlights:
Our customers are building a wide range of environmental monitoring applications, from tracking soil moisture in city tree beds to assessing pH levels in octopus farms!
As reported by the New York Times, the software we build helps nonprofits promote policy changes, businesses assess their environmental impact, governments maintain green infrastructure, and citizens become more involved. Regardless of background or experience, we give people all the tools they need to measure, engage, inform, and advocate—for the future of their neighborhood, their city, their country, and the planet.
Temboo's software comes pre-shipped in hardware development platforms for millions of devices from companies like Texas Instruments, Samsung, and Arduino.
Temboo integrates with over 100 internal and external APIs and cloud services, and we work closely with API providers such as Amazon and Microsoft to make their APIs more accessible.
Temboo has been adopted as a teaching tool by over 150 universities worldwide, in courses ranging from traditional CS and engineering, to digital art and urban data mining, and is a New York State approved provider of IoT instruction for professional licensed engineers.
We’re looking for a curious, skillful engineer to employ machine learning techniques to develop new features and products at Temboo. You will be responsible for leveraging and advancing existing machine learning systems as you apply them to Temboo’s increasingly rich sensor data and device activity dataset. You will lead the design, prototyping and productization of machine learning-based features, and take responsibility for introducing other Temboo developers to machine learning projects.

Your specific technical skill-set is less important to us than your all-around intelligence, problem-solving ability, and eagerness for new challenges. It will be your responsibility to identify and introduce new languages and tools to support your machine learning initiatives.

What You'll Be Doing
Identifying opportunities to apply machine learning techniques to develop new Temboo features, particularly those based on sequence mining
Working with other Temboo engineers to implement machine learning algorithms in an efficient manner
Shipping new features based on your research
Continually observing and refining these features in production to improve behavior over time
Taking responsibility for maintaining our data collection, storage and processing infrastructure

What We're Looking For In You
Proven experience with developing machine learning systems in a professional or academic environment
A deep understanding of the mathematical foundations of machine learning algorithms
Strong computer science fundamentals (notably algorithms and data structures, distributed systems and information retrieval)
Experience with relational database technology e.g., MySQL, and distributed data storage and processing systems e.g., Hadoop
You’re a strong programmer, with experience in both scripting languages and strongly typed programming languages
A willingness to learn and use new technologies, strategies, tools, and components
Strong written and verbal skills, with an ability to explain complex concepts to a varied audience
Experience in a startup environment

Why You Should Apply
You’ll have a high-impact role working with transformative technologies like IoT and Machine Learning
You'll work on exciting technical challenges like designing secure, optimized protocols for communicating with internet-connected hardware, iterating on our data models and supporting architecture to scale to masses of connected devices, and implementing predictive algorithms for generating insights on sensor data sets
You’ll be writing software that people use to make a positive impact on the world
You’ll get wide-ranging exposure to different aspects of the technology and business worlds since Temboo touches hardware & software, multiple layers of the technology stack, and a variety of industries
You’ll be part of a committed, smart, respectful, and fun team
We offer competitive compensation, a casual office environment, and respect for autonomy
Our users are our customers, and they control their own data. We're not selling ads or user data.

2019-08-01
104 Franklin St.
New York,
NY
10013

Full-time

Does this sound like you? If so, send us your resume and a note about why you're interested in working at Temboo. We're looking for people who have passionate interests outside of work as well, so please mention a few of yours in your cover letter.

Check out a customer story that combines community activism and emerging technology to deal with climate change at the hyper-local level.

How To Apply


Email us at jobs@temboo.com, including your resume and a note about yourself (please use “Machine Learning Engineer” in the subject line).","Temboo
3.9","New York, NY",IT Services,Information Technology
Data Scientist,"A leading global diversified mass media company in looking to hire a Data Scientist to join their team! They have over 3,000 employees across the nation and publishes dozens of daily and weekly newspaper, print and digital. This media company is looking to build out their Data team in the Newspaper division to create the next generation of data products and capabilities. The Data Scientist will be taking ownership of their code and help implement machine learning predictive models with modern ML tools.Ideally, this Data Scientist will have experience working with Python and SQL. Any experience with cloud & big data tools will be a plus.This is the perfect chance to growth technically with a leader in the industry!Required Skills & Experience* 3-5 years professional experience* Experience with working in Python and SQL* Experience with ML tools such as SciLearn and Pandas* Comfortable working with GCP* Excellent communicationDesired Skills & Experience* Previous experience working in a data intensive environment* Familiarity with Spark or Hadoop is a plus* Exposure to any cloud platform is also a plusWhat You Will Be Doing* You would be working on a variety of data science projects, specifically focusing on implementing ML-based predictive models and writing production worth codeTech Breakdown* 100% Data ScienceRole Breakdown* 90% Hands on development* 10% Working cross-functionally with the Digital Marketing & Business Intelligence team.The Offer* Competitive annual salary up to $155,000Your benefits will include:* Full health benefit including medical, dental, and vision* 401(k) options* PTO & vacation policies* Defined pension plan optionsApplicants must be currently authorized to work in the United States on a full-time basis now and in the future.Jobspring Partners, part of the Motion Recruitment network, provides IT Staffing Solutions (Contract, Contract-to-Hire, and Direct Hire) in major North American markets. Our unique expertise in today's highest demand tech skill sets, paired with our deep networks and knowledge of our local technology markets, results in an exemplary track record with candidates and clients.","Management Decisions, Inc.
1.6","New York, NY",Advertising & Marketing,Business Services
Data Analyst,"The Ombudsman’s Office (OMB) is a neutral and confidential resource for member firms and their employees, public investors, and any other business or individual who interacts with FINRA to voice their concerns about operations, enforcement, or other FINRA activities or staff. The Analyst is responsible for collecting and analyzing ombudsman and other secondary data to identify patterns, trends and problematic issues. This is professional position, developing and refining skills and receives moderate supervision and regular direction from a manager.

Essential Job Functions:
Maintains strict confidence and neutrality while performing duties and responsibilities and strictly adheres to the ombudsman Standards of Practice.
Utilizing data analytics, gather and analyze Ombudsman and other FINRA data to determine significant patterns, trends, and areas that may require additional focus by Ombudsman case managers.
Partners with Ombudsman case managers to conduct research to detect underlying causes of problematic issues and trends, and develop recommendations for improvement.
Responsible for the production of management-level quarterly and annual statistical and other ad-hoc reports that identify trends, risks, recommendations, and ongoing work status.
Supports the development of recommendations where other departments’ policies, procedures, and practices should be created or improved.
Develops case documentation guidelines and the development/maintenance of a knowledge management (FAQs, topical dictionary) tool.
Acts as a point of contact in the development of the Ombudsman office case tracking and reporting system, a system used to track all inquiries and complaints received by the Office, including complaint details, progress notes, report of findings, and resolution summaries.
Acts as the lead in testing of system requirements and in system maintenance.
Other Responsibilities:
Works with the Ombudsman team on the development of departmental processes and procedures that guide the ongoing activities of the Office and primarily responsible for developing and maintaining written procedures.
Receives and manages inquiries from FINRA constituents to determine the appropriate referral department or resolution and captures detailed records of inquiries in the department’s case tracking and reporting system.
Support Ombudsman case managers by assisting with research for complex cases as needed.
Ensure all records are retained in accordance with FINRA and the office’s Information Privacy and Protection Policy and Record Retention Requirements.
Special Projects as assigned.
Education/Experience Requirements:
Bachelors in Computer Science, Engineering, Business, Finance, Economics, or Statistics and 2+ years of cumulative relevant experience; or equivalent combination of training and/or work experience.
1 - 3 years of securities, compliance or financial regulatory experience preferred.
Quantitative and qualitative analysis experience and strong analytical and critical thinking skills required.
Experience with SQL and relational database design.
Experience generating, improving and automating statistical and graphical charts.
Advanced skills utilizing Microsoft Excel, Access, and PowerPoint
Microsoft 365, and Visual Basic experience helpful.
Excellent written and verbal communication skills, including interactions with both internal and external constituents.
Strong organizational skills and excellent detail orientation are essential.
Working Conditions:
Professional office environment
Occasional travel may be required.
To be considered for this position, please submit an application.

The information provided above has been designed to indicate the general nature and level of work of the position. It is not a comprehensive inventory of all duties, responsibilities and qualifications required.

Please note: If the “Apply Now” button on a job board posting does not take you directly to the FINRA Careers site, enter www.finra.org/careers into your browser to reach our site directly.

FINRA strives to make our career site accessible to all users. If you need a disability-related accommodation for completing the application process, please contact FINRA’s accommodation help line at 240.386.4865. Please note that this number is exclusively for inquiries regarding application accommodations.

In addition to a competitive salary, comprehensive health and welfare benefits, and incentive compensation, FINRA offers immediate participation and vesting in a 401(k) plan with company match. You will also be eligible for participation in an additional FINRA-funded retirement contribution, our tuition reimbursement program and many other benefits. If you would like to contribute to our important mission and work collegially in a professional organization that values intelligence, integrity and initiative, consider a career with FINRA.

Important Information

FINRA’s Code of Conduct imposes restrictions on employees’ investments and requires financial disclosures that are uniquely related to our role as a securities regulator. FINRA employees are required to disclose to FINRA all brokerage accounts that they maintain, and those in which they control trading or have a financial interest (including any trust account of which they are a trustee or beneficiary and all accounts of a spouse, domestic partner or minor child who lives with the employee) and to authorize their broker-dealers to provide FINRA with duplicate statements for all of those accounts. All of those accounts are subject to the Code’s investment and securities account restrictions, and new employees must comply with those investment restrictions—including disposing of any security issued by a company on FINRA’s Prohibited Company List or obtaining a written waiver from their Executive Vice President—by the date they begin employment with FINRA. Employees may only maintain securities accounts that must be disclosed to FINRA at one or more securities firms that provide an electronic feed (e-feed) of data to FINRA, and must move securities accounts from other securities firms to a firm that provides an e-feed within three months of beginning employment.

You can read more about these restrictions here.

As standard practice, employees must also execute FINRA’s Employee Confidentiality and Invention Assignment Agreement without qualification or modification and comply with the company’s policy on nepotism.

Search Firm Representatives

Please be advised that FINRA is not seeking assistance or accepting unsolicited resumes from search firms for this employment opportunity. Regardless of past practice, a valid written agreement and task order must be in place before any resumes are submitted to FINRA. All resumes submitted by search firms to any employee at FINRA without a valid written agreement and task order in place will be deemed the sole property of FINRA and no fee will be paid in the event that person is hired by FINRA.

FINRA is an Equal Opportunity and Affirmative Action Employer

All qualified applicants will receive consideration for employment without regard to age, citizenship status, color, disability, marital status, national origin, race, religion, sex, sexual orientation, gender identity, veteran status or any other classification protected by federal state or local laws as appropriate, or upon the protected status of the person’s relatives, friends or associates.

FINRA abides by the requirements of 41 CFR 60-741.5(a). This regulation prohibits discrimination against qualified individuals on the basis of disability, and requires affirmative action by covered prime contractors and subcontractors to employ and advance in employment qualified individuals with disabilities.

FINRA abides by the requirements of 41 CFR 60-300.5(a). This regulation prohibits discrimination against qualified protected veterans, and requires affirmative action by covered prime contractors and subcontractors to employ and advance in employment qualified protected veterans.

©2020 FINRA. All rights reserved. FINRA is a registered trademark of the Financial Industry Regulatory Authority, Inc.","FINRA
3.5","New York, NY",Brokerage Services,Finance
Data Scientist,"One of the world’s leading financial consultative service providers are looking for Data Sceintists to join their team. The Company provides financial advisory and consultations to more than 4,500 clients in more than 35 countries, worldwide.

Job Description

Maintaining business excellence for us means the acquisition of new talent that are experts in new technologies and sciences.

We are looking for an experienced Data Scientist to join our team of technologists and data scientists to help us deliver data-driven solutions to our clients.

We are looking for someone with experience in using machine learning and natural language processing technologies to isolate, identify and utilize relevant data and help in designing and implementing new technologies and solutions to both simple and complex financial problems.

Roles & Responsibilities
Liaise with clients and our senior management team to understand client needs
Identify and process various sources of client/third-party financial data
Analyse sets of data to identify structures, patterns and trends
Use patterns in data to propose solutions and strategies for client problems
Create and present findings to senior management team and other stakeholders, as and when required
Collaborate with our technical team to design and implement automated data collection tools/processes, using predictive analytics and machine learning algorithms
Collaborate with our product development team to make recommendations for service improvements
Essential Requirements
5+ years of relevant experience (e.g. Data Scientist, Data Analyst, Statistician, Economist, etc.)
Working knowledge of machine learning algorithms and technologies
A great knowledge and/or experience of business intelligence tools (e.g. VBA, SQL, Tableau, etc.)
MSc or higher in Data Science, Statistics, Economics or a related field
Experience delivering agile solutions to various small and large clients
Strong problem-solving skills
Excellent attention to detail
Impeccable listening skills
Excellent verbal and written communication skills
Able to create and maintain strong working relationships with both internal and external colleagues and clients
Great planning and organisational skills
A desire for continuous learning and professional improvement
Desirable Skills
Experience working within the financial services (or similar) sector
Knowledge of cloud computing technologies (MS Azure, Amazon AWS, etc.)
A working knowledge of Python programming
Experience providing advisory or consultation services to client
Benefits
Competitive salary
Work-from-home Scheme
Fully funded training courses available
Apply directly at: https://prolancer.com/jobs/send-proposal/298

Job Types: Full-time, Contract

Salary: $60,000.00 to $75,000.00 /year

Work Remotely:
Yes","Prolancer
5.0","New York, NY",-1,-1
Software Engineer,"As a member of our Data Engineering team, you’ll sit with a diverse team of software engineers, data scientists and business analysts, working closely with your team to turn complex sources into understandable data. The data sets, pipelines and tools that you build will be involved in pivotal, company-level decisions for years to come. Not only that, but you’ll work on a team where constant learning and team-wide knowledge sharing is a core part of our culture. You will report to our Team Lead, Data Engineering in our NYC Headquarters.

RESPONSIBILITIES
Build and maintain data processing services
Write, test, and review primarily microbatch or streaming ETL
Continuously improve of our system, tests, and data quality indicators
Guide our technical decisions
Keep yourself up-to-date and informed about new technologies
Encourage the technical growth of your teammates
QUALIFICATIONS
Experience working with SQL
Experience working with financial systems is a plus
You love working directly with the people whose problems you're solving
You are experienced at data modeling, storage, security, and retrieval
You enjoy working with dynamic programming languages, relational databases, and distributed systems. Our platform is ever-evolving, but currently is a combination of Python, Java, Postgres, Kubernetes, Spark, Presto, Kafka, and Mongo
You gain a deep understanding of the products and tools you work with
2+ years of industry experience
About Squarespace

Squarespace makes beautiful products to help people with creative ideas succeed. By blending elegant design and sophisticated engineering, we empower millions of people — from individuals and local artists to entrepreneurs shaping the world’s most iconic businesses — to share their stories with the world. Squarespace’s team of more than 1,100 is headquartered in downtown New York City, with offices in Dublin and Portland. For more information, visit www.squarespace.com/about.

Benefits & Perks
Health insurance with 100% premium covered for you and your dependent children
Flexible vacation & paid time off
Up to 20 weeks of paid family leave
Equity plan for all employees
Retirement benefits with employer match
Fertility and adoption benefits
Free lunch and snacks at all offices
Education reimbursement
Dog-friendly workplace in New York office
Commuter benefit in the form of reduced tax (Ireland) and pretax (US)
Today, more than a million people around the globe use Squarespace to share different perspectives and experiences with the world. Not only do we embrace and celebrate the diversity of our customer base, but we also strive for the same in our employees. At Squarespace, we are committed to equal employment opportunity regardless of race, color, ethnicity, ancestry, religion, national origin, gender, sex, gender identity or expression, sexual orientation, age, citizenship, marital or parental status, disability, veteran status, or other class protected by applicable law. We are proud to be an equal opportunity workplace.","Squarespace
3.4","New York, NY",Internet,Information Technology
Data Engineer,"Data Engineering at B12

B12's engineering team views software as a craft, but improving the world as the reason to practice it. Our engineers are responsible for prioritizing, conceptualizing, co-designing, building, testing, and engaging users for any concept we are building out. We're generalists in encouraging each other to experience the full stack, but we're also aware of each other's preferences in the stack. We mentor and teach where we can, both inside and outside of the company.

We value sharing our work with the outside world. Our team has published papers on forming expert flash teams and machine-mediated worker hierarchies. We've baked our research into Orchestra, the system that coordinates our expert and machine teams, and released Orchestra into open source to contribute our software back to the community.

We're looking for a Data Engineer to help us answer critical questions our business faces while improving our data systems and architecture to support greater variety, volume, and velocity of data and data sources. We hope our engineers have more longevity than any one tool we use, but here is a sampling of our current thoughts about technology:
We build our product on Python/Django and JavaScript/React.
We store blobs in Amazon's S3, munch on them in Amazon's EC2, develop in Docker, and deploy containers to Amazon's Elastic Beanstalk.
We believe Postgres should be the first system you consider when you think about persisting structured data.
We religiously clean and centralize data in Amazon's Redshift, and are able to answer most any question in SQL. We recently wrote our 1000th query in Metabase!
Before building complex statistical machine learning models, we build simple ones we can understand. Rarely, we build complex models.
We have near-full test coverage on the backend, and are making progress on our frontend and integration tests.
We set up continuous integration and deployment because, while this model comes with its own pains, we've disliked being on fixed release schedules on previous projects.
We like to move fast and support point-in-time recovery :).
As a Data Engineer, you will
Collaborate with operational teams including sales, marketing, and customer success.
Contribute to infrastructure that enables and informs B12's analytical efforts.
Write SQL queries and reusable views that enable various analyses including funnel, retention, and performance reporting.
Use Python to clean data, send it to various systems including our data warehouse and operational services, and perform feature engineering to power the creation of predictive models.
Build rules-based models and statistical machine learning models in Python using packages like scikit-learn.
You'd be a good fit if
You are fluent in SQL and Python.
You have experience building and using data infrastructure, including systems like Postgres and Redshift.
You've used reporting tools like Metabase, Tableau, or Looker in the past.
You know that no dataset is ever pristine, but love to interrogate, structure, and clean data.
You've contributed to extract-transform-load pipelines to collect data from disparate sources and centralize them in a data warehouse.
You feel comfortable managing your time and deciding amongst competing priorities.
You have worked with non-engineering teams and are comfortable explaining technical solutions to them.
You are passionate about the future of work.
You enjoy learning and teaching.
You have strong written and verbal communication skills in English.
You care about and want to contribute to our mission of helping people do meaningful work.
Don't fear
We don't have a minimum number of years of experience for this role. We highly favor talent and interest.
Some candidates may see this list and feel discouraged because they don't match all the items. Please apply anyway: there's a good chance you're more wonderful than you think you are.
B12 is a safe place for human beings. We are dedicated to building a diverse and inclusive team with a wide range of backgrounds and experiences, each helping us understand our customers better, and strengthen our team. We particularly encourage you to apply if you identify as a woman, are a person of color or other underrepresented minority, or are a member of the LGBTQIA community.
How to apply


Please provide:
A pointer to your CV, resume, LinkedIn profile, or any other summary of your career so far.
Some informal text introducing yourself and what you are excited about.
If you have a profile on websites like GitHub or other repositories of open source software, you can provide that as well. If you don't have one, it's still very possible for us to get along just fine!","B12
4.7","New York, NY",Internet,Information Technology
Data Scientist,"The Data Scientist shall have at least a Masterrsquos degree in data science, statistical analysis, machine learning, or related fields and seven (7) years relevant experience in research, organizational and business analyses, predictive analysis, and deep learning development with preference for experience running big data projects for the federal government or at least 24 semester hours in a combination of operations research, mathematics, probability, statistics, mathematical logic, science, or subject-matter courses requiring substantial competence in college level mathematics or statistics.Education may be a substitute for years of experience. oDemonstrate applying appropriate methods in order to mathematically formulate and examine statistical associations between variables within a data set using R or Python oConceptualize, plan, design, and develop deep learningartificial intelligence algorithms for multi-objective optimization and decision-making tools focused on solving resource allocationprioritization problems. oExperience implementing the following libraries in R h2o, Keras and mlr andor the following libraries in Python TensorFlow, PyTorch and mpi4py. oExperience implementing the Data Analysis Epicycle and skilled in performing multiple correspondence analysis (MCA), principal component analysis (PCA), and association rule mining. oAbility to develop algorithms in a High-Performance Computing (HPC) environment using custom multi-core desktop computers and Microsoft MPI oProduce executive level summary reportsbriefings of algorithm results using R Markdown or Jupyter Notebook. oUtilizeMS Access to perform queries and analyses oUtilizeMS Excel to perform analyses to produce reports oUtilizeMS PowerPoint to produce reports oUtilizeMS Word to produce reports oUtilizeR(COT statistical analysis program)to perform analyses",Simatree,"Middletown, NJ",Commercial Equipment Rental,Business Services
Data Engineer,"Data Engineer

Job Details
Level
Experienced
Job Location
New York (Home Office) - New York, NY
Position Type
Full Time
Education Level
4 Year Degree
Salary Range
Undisclosed
Travel Percentage
Undisclosed
Job Shift
Day
Job Category
Information Technology
Description
Greater New York Mutual Insurance Company (""GNY"") is an A+ rated, financially stable and growing property casualty insurance company with locations throughout the Northeast. We are currently looking for a dynamic and highly motivated Data Engineer for our New York office.

Responsibilities:
Develop, construct, test, and maintain architectures, such as databases and analytic environments and platform required for structured, semi-structured and unstructured data
Design and develop data pipelines that deliver accurate, consistent, and traceable datasets for data science projects
Support regular and ad-hoc data needs for data scientists
Provide recommendations and implement ways to improve data reliability, efficiency, and quality
Qualifications
Bachelor’s or Master’s degree obtained from an accredited institution preferably in Computer Science, Computer Engineering, and Software Engineering, Data Science, or a related field
3-5 years of professional experience in data science or related field
Experience in database deployment and management and proficient in SQL
Experience in data warehousing and ETL (Extract, Transform, and Load)
Proficient in R, Python, VBA, Excel and Word
Excellent oral and written communication skills","GNY Insurance Companies
3.7","New York, NY",Insurance Carriers,Insurance
Data Scientist,"Responsibilities

About Our Team:

The Data Science Team provides advanced analytical support across VNSNYs family of corporations. We leverage big data to develop insights and to support strategic decisions for the agency. Meaningful, appropriate use of data is central to the success of our organization. We are looking for an ambitious data scientist to join our team.

About the Role:

The Data Scientist will join a core group of analysts who play an important role in generating strategic insights across the VNSNY organization in these four applications of data science:
Clinical - Who is going to get sick? What can we do to prevent or mitigate these health events? When is the best time to implement these actions? This application of data science examines the drivers of clinical outcomes; analyzes opportunities for managing risk-based populations; evaluates programs and interventions that aim to improve patient outcomes.
Quality How is quality of care measured and how is it related to patient outcomes? Where are opportunities to improve the quality of care to our patients and members? Our data scientists serve as subject matter experts on healthcare quality measurement and risk adjustment; use predictive modeling to identify patient populations in need of clinical interventions; identify opportunities for improvement in clinical processes that can lead to improved quality of care.
Operational How can we optimize our business operations in order to be more efficient? How do we deliver our services in order to improve the coordination of care for our patients and members? This application of data science focuses on efficiency and optimization of business practices in order to improve patient care; uses techniques including time series forecasting and geospatial analysis to address business problems such as staffing and scheduling; analyzes opportunities for business growth within the organization and predicts and forecasts expenses.
Policy What is the impact of health care policy on our patient population? On our most vulnerable patients and members? How will changes in reimbursement policy affect the way we deliver patient care? What partnerships can we develop in order to ensure that our patients and members continue receiving optimal care? Our data scientists are well-versed in healthcare policy; analyze areas for meaningful value investments that focus on improving health outcomes while saving money; use predictive modeling to identify high cost and high need patient populations who may be impacted most by changes in health policy.
You Are:
Looking for an opportunity to perform hands-on data analysis and modeling to solve a wide variety of business problems while working alongside clinical/business stakeholders
Driven by curiosity and a passion to learn, you thrive in situations where you can bring clarity to ambiguous and multi-faceted problems
A logical thinker who is comfortable learning new programming languages and computing applications independently
Obsessive about streamlining data and modeling processes; if you find you or your colleagues doing something several times, you create a standard reproducible workflow
Love the challenge of exploring new data sources while practicing a healthy skepticism about data; when you find data that looks wrong, you are emotionally compelled to figure out why
Have a desire to use your analytical skills to make measurable impacts on the lives of patients
Requirements:
MS in statistics, biostatistics, mathematics, econometrics, epidemiology, computer science, or other quantitative field
2+ years of professional experience in applied data analysis, interpretation, and prediction
Experience with statistical/mathematical software (e.g. R, SAS, Matlab) and data querying languages (e.g. SQL, PLSQL) with demonstrated ability to learn and wield multiple analytical tools
Solid understanding of relational databases
Expertise in supervised and unsupervised data mining and predictive modeling techniques
Demonstrated experience executing reproducible and rigorous analyses in a timely manner
Strong written and verbal communication and presentation skills, with experience communicating results of complex data analyses to non-technical stakeholders
Expertise in translating business needs into relevant data-driven deliverables and analyses
Experience managing multiple projects independently, sometimes on tight deadlines
Excellent interpersonal communication skills and ability to work collaboratively across different teams
Nice to Have:
Experience with building and deploying predictive models, especially via API, and building tools and processes to track and monitor the performance of models
Solid understanding of data structures, algorithms, software architecture, functional coding
Software engineering experience (e.g. Java, C++, Python) and knowledge of best practices across the development lifecycle (e.g. coding standards, testing)
Experience with version control, shell scripting, and the Unix filesystem
Experience with operational analytics and applying operational research techniques to support strategic and operational decisions
Experience in quasi-experimental methods such as propensity score matching or instrumental variable analysis
Experience with medical claims, electronic medical records, and health assessment data (e.g. OASIS, UAS-NY)
Knowledge of Medicare and Medicaid payment policy and alternative payment models (e.g. PDGM, Value Based Payment, dual-risk models, Hospice Final Rule)
Knowledge of risk adjustment strategies and application of risk adjustment to quality measurement programs such as CMS Home Health Quality Measures, CMS Home Health Value-Based Purchasing Model, CMS Hospice Quality Reporting Program, New York State MLTC Quality Incentive, HEDIS","Visiting Nurse Service of New York
3.8","New York, NY",Health Care Services & Hospitals,Health Care
Machine Learning Engineer,"Who_We_Are

The Personalization & ML Engineering team is responsible for building features
powered by machine learning such as personalized content recommendations.

Responsibilities
Build and improve machine learning pipeline that power Peloton s
content recommendations.
Evaluate, implement, and improve machine learning models.
Productionize, deploy and monitor machine learning based services.
Qualifications
Passion for building scalable backend framework that supports a rapid
growing user base
4+ years of software development experience
Strong understanding of software engineering principles and fundamentals
including data structures and algorithms.
Proficient in at least one programming language, e.g., Python, Java,
Kotlin, Go, C++, C.
Experience with relational and non-relational databases such as Postgres,
MySQL, Cassandra, or DynamoDB.
Experience with both machine learning and developing services with
production quality deployment and monitoring.
Strong machine learning knowledge, including neural networks, RNNs and
CNNs. Good understanding of the practical aspects of ML such as train/
dev/test sets, bias, variance, overfitting, hyperparameter tuning, etc.
Experience using machine learning libraries and tools, such as PyTorch,
Tensorflow, Keras, Caffe, Theano, or scikit-learn.
Familiar with monitoring and deployment tools and platforms, for
instance, DataDog, Jenkins, Docker, Kubernetes, Terraform and AWS
services.
Self directed and detail oriented with ability to come up with good
design proposals or thorough analysis of production issues.
About_Peloton
Founded in 2012, Peloton is a global interactive fitness platform that brings
the energy and benefits of studio-style workouts to the convenience and comfort
of home. We use technology and design to bring our Members immersive content
through the Peloton Bike, the Peloton Tread, and Peloton Digital, which provide
comprehensive, socially-connected fitness offerings anytime, anywhere. We
believe in taking risks and challenging the status quo by continuously
innovating and improving. Our team is made up of passionate brand ambassadors,
and we know that together, we go far.

Headquartered in New York City, with offices, warehouses and retail showrooms
in the US, UK and Canada, Peloton is changing the way people get fit. Peloton
has been named to many prestigious industry lists, including Fast Company's
Most Innovative Companies, CNBC's Disruptor 50, Crain's New York Business'
Tech25 and Fast50, as well as TIME's Genius Companies. Visit
to learn more about joining our team.
Show moreShow less","Peloton Interactive
3.8","New York, NY","Health, Beauty, & Fitness",Consumer Services
Data Analyst,"Data AnalystOur client is seeking an experienced data analyst to join our Analytics practice and help advance our business intelligence capabilities. Successful candidates will work with analytics and product leadership to assure that the most relevant real-time and historical data is identified, tracked, analyzed, and made actionable across all of our titles.RESPONSIBILITIES* Analyze, synthesize, and interpret product and player data to determine observations and trends.* Partner with data scientists and live producers to identify strategic business questions, key metrics, and actionable insights.* Drive needle moving improvements via hands-on exploration of data and dashboards.* Determine the telemetric needs of the business units and translate these needs into elements that are compatible with the data collection technology.* Follow up on data collection system integration with internal teams.* Collaborate with game and development teams to ensure that the implementation of metrics corresponds to the observed values.* Contribute to the development and enhancement of the data collection systems.* Drive requirements for data collection and for data modeling with data engineers.* Document new and modified data sources, tables, and fields.* Work within a team of data analysts and engineers.QUALIFICATIONS* 2+ years in a similar position or a position requiring data preparation, creation of reports and dashboards, and deep dive analysis.* Bachelor's degree in a related field.* Fluency in SQL (or a SQL-like language) required, other programming experience highly preferred.* Experience with Hadoop an asset.* Game industry experience strongly desired.SKILLS* Ability to develop and maintain good relations and communicate with people at all hierarchical levels.* Strong problem-solving skills.* Ability to reconcile technical and business perspectives.* Autonomy and entrepreneurship.* Strong team spirit.* Passion for our client and their titles.Andiamo is an Equal Opportunity EmployerAndiamo provides equal employment opportunities to all employees and applicants for employment without regard to race, color, religion, sex, national origin, age, disability or genetics. In addition to federal law requirements, Andiamo complies with applicable state and local laws governing nondiscrimination in employment in every location in which the company has facilities. This policy applies to all terms and conditions of employment, including recruiting, hiring, placement, promotion, termination, layoff, recall, transfer, leaves of absence, compensation and training.All qualified candidates are encouraged to apply by submitting their resume as an MS word document including a cover letter with a summary of relevant qualifications, highlighting clearly any special or relevant experience.","Andiamo
3.5","New York, NY",Casual Restaurants,"Restaurants, Bars & Food Services"
Machine Learning Engineer,"Role: Machine Learning Engineer

Location: Los Angeles, New York, Flexible*

Hours: Full time

About Trevor

The Trevor Project is the world’s largest suicide prevention and crisis intervention organization for LGBTQ young people. We are a non-profit that provides 24/7 life-saving support via phone, text, and chat. We also operate the world’s largest safe space social networking site for LGBTQ youth and run innovative research, education, and advocacy programs. We’ve been saving lives every day for over 20 years.

On May 7th 2019, Google announced that The Trevor Project is one of 20 organizations that will share $25 million in grants from Google.org, credit and consulting from Google Cloud, and coaching by Google’s AI experts as a grantee of the Google AI Impact Challenge. The Google AI Impact Challenge was an open call to nonprofits, social enterprises, and research institutions from around the world to submit their ideas to use AI to help address societal challenges. Over 2,600 organizations applied. And on June 15, 2020, Google announced that a new cohort of Google.org engineering fellows will be joining our team full-time in 2020.

Overview of the Role

Our Machine Learning Engineer will contribute to The Trevor Project’s life-saving work by developing machine learning and natural language processing models that drive significant increases in quality of care and scalability for our crisis services and other internal processes. This individual will help the team to contribute to the development of the machine learning models from concept to productionization, and integrate them across our platforms and services. The successful candidate will work closely with domain experts across The Trevor Project and will leverage advice and expertise from external partners and advisors.

Who you are
Experienced.You have at least 2 years of machine learning, using one of these libraries: TensorFlow, PyTorch, Keras; and natural language processing experience in a high-tech environment. You have developed high-performing models from concept to web production. You understand fundamental statistical methodologies
Perpetual Learner.You are energized by learning about new topics and can quickly get up to speed and contribute to initiatives
Collaborative.People love how you can explain complex concepts in a way that everyone can understand
Innovative.You stay up-to-date on the latest research in AI, but always approach the problem-solving process first with practical, simple, and proven methods
Organized and efficient.You know how to manage multiple projects and prioritize appropriately. You create clear and logical systems and processes to support your work and that of the organization
Inspirational.You love working with people and know how to excite them about the opportunities to use data and technology to improve the work that we do
Empathetic.You care about the wellbeing of LGBTQ youth and respect those around you regardless of race, ethnic origin, gender, age, sexual orientation, gender identity and physical ability
User Experience.You can put yourself in the shoes of the audience and oversee operations that prioritize their experience
Fun.The work we do is very serious, but that doesn’t mean we don’t have fun. We know how to have a good time and you should too
What you’ll do
Train and test machine learning and natural language processing models (e.g. BERT, GPT-2, etc.) in accordance with internally defined best practices
Deploy machine learning solutions and monitor for system reliability and fairness in accordance with internally defined standards for fairness, accountability, and transparency
Develop new approaches to sourcing and labeling data for machine learning models
Develop automated tools to process and evaluate data privacy protection
Evaluate and select machine learning model architectures using appropriate statistical methods
Develop optimization techniques for machine learning models
Learn the latest techniques and stay apprised of the latest research in machine learning and natural language processing
Work closely with the product team to prototype new features
Work with domain experts to understand our external and internal processes
Benefits
Generous vacation and holidays (like a full day off to celebrate Harvey Milk Day!), including Summer Fridays
Comprehensive health insurance (we pay 100% of your premiums for medical, dental, and life), including gender affirmation surgery
Fun office environment and passionate team. It’s NBD around here if Daniel Radcliffe or Imagine Dragons drops into our office
The Trevor Project is an equal opportunity employer
Meaningful work at an organization that is saving the lives of LGBTQ young people every day
Your Application:

We’re excited to hear from you! To join Team Trevor, please upload a resume and cover letter. Applications without cover letters will not be considered.

If this sounds like you, we are open to hiring in the following states: California, Colorado, D.C., Hawaii, Illinois, Maryland, Michigan, Minnesota, Nebraska, Nevada, New Jersey, New York, Oregon, Pennsylvania, Texas, Utah, and Virginia.","The Trevor Project
4.6","New York, NY",Social Assistance,Non-Profit
Data Engineer,"Company Description

Pinto is building the world’s smartest food data platform, with a mission of making food data fully personalized, transparent, and easily accessible for both consumers and businesses alike. Over 40% of Americans now follow a specific dietary eating pattern, and our data platform is organizing the world of food at scale across every dimension that matters to these modern consumers (diets, health conditions, ingredients, allergies/intolerances, personalized health needs, etc.). The era of personalization is here and we’re building Pinto to power it .

We’re now looking for a Data Engineer to join our growing engineering team. In this role you’ll envision and build critical features for our data platform, design and implement API methods, and improve the overall performance and reliability of our data processing platform as we scale.

This is an amazing opportunity for someone looking to join in the early stages of a rapidly growing technology startup solving a meaningful problem in food and the broader world of personalization in nutrition and consumer products.

Job Description

What you will be doing
You’ll make key decisions on the architecture and implementation of scalable data processing and analytics structure
You’ll help build data processes and pipelines, and craft the tools to make them efficient
You’ll work on the backend of the Pinto stack using Javascript, Node.js, MongoDB, GraphQL
You’ll work with our Research, Nutrition & Data Analyst teams to gain a deep knowledge of underlying use cases in food data and nutrition
You’ll design systems that improve the accessibility and scalability of our data platform
You’ll automate and handle the life-cycle of systems and platforms that process our data
You’ll build and scale data infrastructure that powers batch and real-time data processing across our data platform
You’ll evolve the maturity of our monitoring systems and processes to improve visibility and failure detection in our infrastructure
You’ll use your skills to help solve real-word problems, while learning about the food, nutrition, and consumer product goods (CPG) ecosystem
Qualifications
4+ years of software engineering and/or Big Data Engineering experience
Degree in Computer Science, Computer Engineering, or Statistics (or commensurate experience)
Experience working with large, complex data sets from a variety of sources
Proven track record of building and shipping large-scale engineering products
3+ years experience with Node.js and the related ecosystem
Experience with MongoDB, GraphQL, Redis, REST APIs in general
Ability to collaborate cross-team with engineers, data analysts, product managers and business analysts
You are a strong communicator. Explaining complex technical concepts to designers, support, and other engineers is no problem for you.
Self-awareness and a desire to continually learn and improve
Bonus points for
An open GitHub profile to showcase some of your work (or code samples)
Have built a deployment pipeline
Have built a full stack application
Experience with or strong interest in data science and/or machine learning
Additional Information

About Us

Pinto is a smarter food data platform, designed for the needs of today's consumers in the world of personalized diet. To do this, we're rapidly bringing the world of food online and mapping it across every dietary need and preference — everything from general diets like Vegan, Paleo, and Keto, to health conditions like Diabetes Management, Heart Health, and Kidney health, to the long tail of ingredient and allergen considerations like Lactose Free, Gluten Free, Nut Free, and No Added Sugars. Over 40% of Americans now follow a specific dietary eating pattern, and our data platform is organizing the world of food at scale with partners that include Whole Foods and Kroger.

Current retail partners include Whole Foods, Kroger, and more. Learn more about Pinto and the technologies we power: http://business.pinto.co

See some examples searches:

-- Vegan meat substitutes: https://bit.ly/2m14P0P

-- Paleo snack bars: https://bit.ly/2lCOcYS

-- Gluten-free cereals that are also kosher: https://bit.ly/2m1510

Come join us on our mission as we build the future of smart, personalized product data!

All your information will be kept confidential according to EEO guidelines.",Pinto,"New York, NY",-1,-1
Data Analyst,"Data Analyst (Decision Science)

Hearst is an American mass media and business information conglomerate. It owns a wide variety of newspapers, magazines, television channels, and television stations, including the San Francisco Chronicle, the Houston Chronicle, Cosmopolitan, Esquire, 50% of cable network A+E, and 20% of the sports broadcaster ESPN.

Are you looking for a great opportunity to grow in your profession as a decision scientist?

Do you want to be part of a lean team that is helping lead the evolution of local news?

At Hearst you will have the chance to make a data driven impact by forming strong partnerships with marketing, editorial, product, ad operation and executive leadership teams.

You will be working with traffic, subscriptions, advertising, and email data and have the opportunity to work in Python, R, Big Query SQL, Looker, PowerBI and more!

Role
Clean, prepare and explain datasets, use advanced analytics to identify key trends, size up opportunities, and then work closely with business leaders to turn those opportunities into action.
Work with the latest analytic tools to perform advanced analysis and discover insights.
Create iterative and highly reproducible analytic scripting to show ongoing improvement in data visuals and analytical techniques.
Partner closely with data scientist to extract learnings from latest prediction models.
Streamline automation to help us scale and ensure ongoing data integrity.
Qualifications
Demonstrated comfort working autonomously in Python/R, particularly working with dataframes.
2+ years' experience in a data analytics role.
Degree/Advanced degree in a technical/mathematical program preferred.
Strong interpersonal and communication skills, experience building presentations.
Passion for problem solving and data exploration.
Experience in statistical methods a huge plus.
SQL knowledge
Must be hungry to take on a highly technical role and make a clear business impact.
NA","Hearst Communications
4.0","New York, NY",Advertising & Marketing,Business Services
Data Engineer,"A Career with Point72’s Platform Engineering Team

Point72’s Market Intelligence Data (MI Data) group drives high quality fundamental research powered by advanced data analytics to help inform investment decisions at Point72. Our Platform Engineering team manages the technology infrastructure used to ingest, process, and visualize the large and unstructured data sets behind our alternative data investment signals. Our engineering team is nimble and maintains a start-up culture – it is backed by the full support of Point72 management who recognizes that our work is essential to the success of the business.

What you’ll do

Our Data Engineers tackle the complex technical challenges associated with processing big and unstructured data sets. In this role, you will:
Partner with portfolio managers and data scientists to understand the potential business value of data sets and build data processing pipelines to help deliver that value
Find innovative solutions to ingest and process new data sources using open source technologies, agile-based development processes, and cloud computing
Maintain best in class infrastructure through evaluations and proof of concepts with cutting-edge of technology and frameworks
Take on a number of new initiatives as an individual contributor that have the potential to grow into more sizable engineering efforts in the future.
A commitment to the highest ethical standards
A degree in Computer Science and strong programming experience in Python or Java
Experience working with data at scale using Hadoop, Spark or other large-scale data platforms
Ability to devise novel and innovative solutions to challenges in a collaborative environment
Fully-paid health care benefits
Generous parental and family leave policies
Mental and physical wellness programs
Tuition assistance
A 401(k) savings program with an employer match and more
About Point72

Point72 Asset Management is a global firm led by Steven Cohen that invests in multiple asset classes and strategies worldwide. Resting on more than a quarter-century of investing experience, we seek to be the industry’s premier asset manager through delivering superior risk-adjusted returns, adhering to the highest ethical standards, and offering the greatest opportunities to the industry’s brightest talent. We’re inventing the future of finance by revolutionizing how we develop our people and how we use data to shape our thinking.","Point72
3.9","New York, NY",Investment Banking & Asset Management,Finance
Machine Learning Engineer,"Excited by using massive amounts of data to develop Machine Learning (ML) and Deep Learning (DL) models? Want to help the largest global enterprises derive business value through the adoption of Artificial Intelligence (AI)? Eager to learn from many different enterprises use cases of AWS ML and DL? Thrilled to be key part of Amazon, who has been investing in Machine Learning for decades, pioneering and shaping the worlds AI technology?

At Amazon Web Services (AWS), we are helping large enterprises build ML and DL models on the AWS Cloud. We are applying predictive technology to large volumes of data and against a wide spectrum of problems. Our Professional Services organization works together with our AWS customers to address their business needs using AI.

AWS Professional Services is a unique consulting team. We pride ourselves on being customer obsessed and highly focused on the AI enablement of our customers. If you have experience with AI, including building ML or DL models, wed like to have you join our team. You will get to work with an innovative company, with great teammates, and have a lot of fun helping our customers.

In our Global Specialist Practice, you will also have the opportunity to create white papers, write blog posts, build demos and other reusable collateral that can be used by our customers, and you will work closely with our Solution Architects and Service Engineering teams.

A successful candidate will be a person who enjoys diving deep into data, doing analysis, discovering root causes, and designing long-term solutions. It will be a person who likes to have fun, loves to learn, and wants to innovate in the world of AI. Major responsibilities include:

· Understand the customers business need and guide them to a solution using our AWS AI Services, AWS AI Platforms, AWS AI Frameworks, and AWS AI EC2 Instances .
· Assist customers by being able to deliver a ML / DL project from beginning to end, including understanding the business need, aggregating data, exploring data, building & validating predictive models, and deploying completed models to deliver business impact to the organization.
· Work with our Professional Services Big Data/Analytics consultants to analyze, extract, normalize, and label relevant data.
· Work with our Professional Services consultants and customer teams to help our customers operationalize models after they are built.
· Assist customers with identifying model drift and retraining models.
· Research and implement novel ML and DL approaches, including using FPGA.


This is a customer facing role. You will be required to travel to client locations and deliver professional services when needed.


Basic Qualifications

· B.S. degree in mathematics, statistics, computer science or a similar quantitative field
· 5+ years work experience in relevant field
· Experience in using SQL to analyze data in a database or data warehouse and be able to use a major programming (e.g. Java/C) and/or a scripting language (Perl, Unix shell, Python) to process data for modeling
· Experience working with a wide range of predictive and decision models and data mining techniques, as well as tools for developing such models

Preferred Qualifications

· Experience in data modeling, ETL development, and Data warehousing.
· Experience building/operating highly available, distributed systems of data extraction, ingestion, and processing of large data sets
· Data Warehousing Experience with Oracle, Redshift, etc
· Experience with software coding practices is a strong plus.
· Experience using Linux/UNIX to process large data sets
· Meets/exceeds Amazons functional/technical depth and complexity for this role
· Experience with AWS technologies like Redshift, S3, EC2, Data Pipeline, & EMR
· Combination of deep technical skills and business savvy enough to interface with all levels and disciplines within our customers organization
· Demonstrable track record of dealing well with ambiguity, prioritizing needs, and delivering results in a dynamic environment

Amazon is committed to a diverse and inclusive workplace. Amazon is an equal opportunity employer and does not discriminate on the basis of race, national origin, gender, gender identity, sexual orientation, protected veteran status, disability, age, or other legally protected status. For individuals with disabilities who would like to request an accommodation, please visit https://www.amazon.jobs/en/disability/us.","Amazon
3.9","New York, NY",Internet,Information Technology
Data Analyst,"About Us

At Teachers Pay Teachers (TpT), we're unlocking the power of educator-created content. More than 85% of U.S. teachers come to TpT every year to get teacher-tested, engaging, and rigorous materials. What began as a humble exchange for teachers looking to share lesson plans has since exploded into a massive online marketplace where teachers have created 4 million resources for all aspects of PreK-12 education. More than six million educators worldwide (including teachers, administrators, and parents) have downloaded TpT resources more than a billion times. According to Fast Company, in 2019, Teachers Pay Teachers is one of the top 50 Most Innovative Companies in the world! If you haven't heard of TpT yet and want to learn more, just ask a teacher.

Who we are looking for

We're a team of good people doing great things. We listen first. We love our work. And we are all teachers and learners in whatever we do. We believe that productivity is never an accident. It's the result of a commitment to excellence, intelligent planning, passionate teamwork, and focused effort. We want every day to be fun and to matter.

Role Description

As a Data Analyst, you will support the adoption of business intelligence tools across teams, foster a culture of insightful analysis and crisp reporting, and become a trusted business partner within the organization.

You know and love working with data and analytics tools and can use your technical skills, business acumen, and creativity to solve unique business problems. Reporting to the Analytics Manager, you'll work closely with business, marketing, data science, engineering, and product teams to develop a deep understanding of TpT's business and drive strategy and action through high quality, timely analysis.

Responsibilities
Analyze: surface actionable insights and opportunities from complex data; leverage quantitative and qualitative data to understand ecosystems, user behaviors, and long-term trends
Collaborate: partner with marketing, product, customer experience, and engineering to translate business issues into testable hypotheses with defined KPIs; ensure metrics used to track the business and measure results are consistent and the most relevant to inform decision-making across the organization
Communicate: report on the state of the business and make data accessible through objective data-driven stories that influence and enable stakeholders; establish shared vision across the company for data-driven practices
Enable: build dynamic and rich dashboards and reporting solutions to support company initiatives and strategic planning; educate other teams at TpT on analysis best practices and how to self-serve data needs; leverage Jira to prioritize projects and requests
Requirements
2+ years of analytics experience at a software technology company
Experience designing, leading and executing analysis
Ability to visualize data in additive ways
Comfortable with large, complex relational databases (both transactional and clickstream)
Excellent communication skills
Experience in creating, optimizing, and automating reports and dashboards
Highly organized & able to prioritize effectively
Experience working cross-functionally
Experience with SQL
Extra Credit
Experience with an online marketplace
Experience with attribution modeling
Experience with aspects of our BI tech stack: BigQuery, Looker, Heap, Optimizely
Experience with Python and/or R
Statistical skills (e.g., confidence intervals and forecasting)
Experience with ML
Extracurriculars
Parental leave for both mothers and fathers to be able to take some quality time in bonding with their new addition to their family
Comprehensive Medical & Dental Benefits
Mother's Room
Quiet Room
Company Events (Bring Your Child to Work Day, Field Day, Camp TpT, Hackathons, etc.,)
Here at TpT we value Diversity & Inclusion and encourage people to bring their most authentic selves to work. We cultivate an environment where people are recognized and celebrated for their individuality.

Any TpT applicant who requires reasonable accommodations during the interview process should contact the TpT People Ops Team (accommodations@teacherspayteachers.com) to make the need for an accommodation known.

Finally, if you're a California resident, California law requires that we provide you notice about the collection and use of your personal information. We encourage you to read it carefully. You can find our full notice here.","Teachers Pay Teachers
4.9","New York, NY",Internet,Information Technology
Data Analyst,"Medly is a patient-first digital pharmacy that delivers free, same-day prescription medication to patients throughout the nation. At Medly, our mission is to elevate the healthcare journey for all patients - regardless of income, lifestyle, or diagnosis.

We are looking for a Data Analyst with a strong understanding of data acquisition, management, analysis, and reporting. Together, we will uncover and share the story behind Medly’s business metrics.

What you’ll do:
Design and conduct analyses pertaining to data acquired through various sources
Develop, extract and automate reports from multiple data sources
Collaborate with cross-functional teams to facilitate the automation of standard, recurrent data acquisition, management, analysis and reporting
Create descriptive data summaries including visualizations and written descriptions of data findings for a wide range of audiences
Provide technical assistance to stakeholders in accessing and analyzing datasets
What you’ll gain:
Competitive compensation and benefits
Unlimited room for growth and development
The ability to make a noticeable impact and improve lives
What you’ll need:
1 or more years of data analytics experience, preferably in a healthcare environment
Bachelor’s degree in Computer Science, Information Technologies or a related field
Experience using databases with large-scale data sets
Advanced knowledge of Microsoft Excel
Ability to effectively organize and project-manage multiple priorities
Effective problem-solver with strong critical thinking skills
Prior pharmacy experience is a plus!
Strong sense of urgency
Attention to detail
Composure
Integrity
Medly Pharmacy is an equal opportunity employer. We proudly celebrate diversity and are devoted to creating an inclusive environment for all employees regardless of race, color, religion, national origin, sex, sexual orientation, age, disability, military service, or any other non-merit factor.

Job Type: Full-time

Pay: $60,000.00 per year

Benefits:
401(k)
Dental Insurance
Flexible Schedule
Health Insurance
Paid Time Off
Vision Insurance
Schedule:
Monday to Friday
Company's website:
https://www.medlypharmacy.com/","Medly Pharmacy
4.8","Brooklyn, NY",Health Care Services & Hospitals,Health Care
Data Analyst,"About Tachyon Technologies:

Tachyon TechnologiesÂis a Digital Transformation consulting firm that partners with businesses to implement customer-focused business transformation. Aligned with SAP's digital core, Tachyon Technologies collaborates with its clients to transform their business by leveraging existing IT investments and leading-edge digital solutions to positively impact their customers' experience. From initiation through realization, Tachyon Technologies understands what it takes for a consulting partner to be effective and strives to deliver a meaningful solution that exceeds its clients' expectations.

Â

Role: Data Analyst

Location: NYC, NY

Duration: Longterm

Description

Â
Expertise on SQL (Snowflake or any other MPP databases such as Redshift)<b> 2. Very good knowledge in data visualization tools such as Tableau and Looker( development and maintenance of LookerML).
Good experience on working with business stake holders such as Marking, Sales and Finance to understand the requirements and delivering the projects upon their sign-off
Working experience on Media subscriptions domain is highly preferred.
Basic understanding of Python programming will be added advantage(To work with Data Eng Team on roll-up Tables)
Â

Tachyon'sÂfull-time employees receive complete and competitive benefits. We offer a collaborative work environment, competitive compensation, generous work/life opportunities, and an outstanding benefits package that includes paid time off plus holidays. In addition, all colleagues are eligible for a number of rewards and recognition programs. Encouraging a healthy work/life balance and providing our colleagues great benefits are just part of what makesÂTachyonÂa great place to work.

Disclaimer:ÂThe above statements are not intended to be a complete statement of job content, rather act as a guide to the essential functions performed by the employee assigned to this classification. Management retains the discretion to add or change the duties of the position at any time.

Â

Â","Tachyon Technologies
4.4","New York, NY",IT Services,Information Technology
Machine Learning Engineer,"Job Description:

Responsible for developing, enhancing, modifying and/or maintaining applications in the Global Markets environment. Software developers design, code, test, debug and document programs as well as support activities for the corporate systems architecture. Employees work closely with business partners in defining requirements for system applications. Employees are expected to have in-depth capital markets product knowledge, and manage a high level of risk. Employees typically have in-depth knowledge of development tools and languages. Is clearly recognized as a content expert by peers. Individual contributor role. Typically requires 5-7 years of applicable experience. This job code is only to be used for associates supporting Global Markets.

JOB DESCRIPTION

Machine Learning Engineer

Responsibilities
Design and develop scalable ML/AI solutions to solve diverse business challenges by deriving features from rich data sources, training, evaluating and deploying models to production using cutting edge technologies
Gather and analyze data to perform statistical analysis, identify key factors and build comprehensive visualizations to report findings
Utilize statistical methods to process, clean and validate data for uniformity and accuracy
Create and maintain end-to-end data pipelines and APIs according to business requirements
Communicate analytic solutions to stakeholders and implement improvements as needed to operational systems
Requirements
5+ years in a data science role with proven record of implementing end-to-end ML/AI solutions into production
5+ years of experience using statistical computer languages, such as R or Python (preferred)
2+ years of experience working with large data sets (> 1TB) and using big data solutions such as Hadoop, Hive, Spark, Storm, MongoDB etc.
1+ year of experience specifically with deep learning (e.g., CNN, RNN, LSTM) and NLP frameworks
Excellent understanding of machine learning techniques and algorithms, such as k-NN, Naive Bayes, SVM, etc. and their real-world advantages/drawbacks
Rigorous understanding of statistics and ability to discern appropriate statistical techniques to problem-solve
Proficiency with writing SQL queries
Master’s degree or PhD in computer science, applied mathematics, or related technical/scientific field preferred
Experience with data visualization tools, such as Tableau, is a plus
Prior work experience in the financial industry is a plus
Bank of America's Global Banking and Markets Technology Organization....
Believes diversity makes us stronger so we can reflect, connect and meet the diverse needs of our clients and employees around the world.
Is committed to building a workplace where every employee is welcomed and given the support and resources to perform their jobs successfully.
Wants to be a great place for people to work and strives to create an environment where all employees have the opportunity to achieve their goals.
Provides continuous training and development opportunities to help employees achieve their career goals, whatever their background or experience.
Is committed to advancing our tools, technology, and ways of working to better serve our clients and their evolving business needs.
Believes in responsible growth and is dedicated to supporting our communities by connecting them to the lending, investing and giving them what they need to remain vibrant and vital.
Shift:

1st shift (United States of America)

Hours Per Week:

40

Learn more about this role","Bank of America
3.7","New York, NY",Banks & Credit Unions,Finance
Machine Learning Engineer,"Machine Learning Engineer
Our client, one of the largest banks in the US with wealth management, investment banking, and international business, is seeking a Machine Learning Engineer

Location: New York, NY
Position Type: Contract

Responsibilities:

-Design and develop scalable ML/AI solutions to solve diverse business challenges by deriving features from rich data sources, training, evaluating and deploying models to production using cutting edge technologies
-Gather and analyze data to perform statistical analysis, identify key factors and build comprehensive visualizations to report findings
-Utilize statistical methods to process, clean and validate data for uniformity and accuracy
-Create and maintain end-to-end data pipelines and APIs according to business requirements
-Communicate analytic solutions to stakeholders and implement improvements as needed to operational systems

Requirements:

-5+ years in a data science role with proven record of implementing end-to-end ML/AI solutions into production
-5+ years of experience using statistical computer languages, such as R or Python (preferred)
-2+ years of experience working with large data sets (> 1TB) and using big data solutions such as Hadoop, Hive, Spark, Storm, MongoDB etc.
-1+ year of experience specifically with deep learning (e.g., CNN, RNN, LSTM) and NLP frameworks
-Excellent understanding of machine learning techniques and algorithms, such as k-NN, Naive Bayes, SVM, etc. and their real-world advantages/drawbacks
-Rigorous understanding of statistics and ability to discern appropriate statistical techniques to problem-solve
-Proficiency with writing SQL queries
-Master’s degree or PhD in computer science, applied mathematics, or related technical/scientific field preferred
-Experience with data visualization tools, such as Tableau, is a plus
-Prior work experience in the financial industry is a plus","Mitchell Martin
4.1","New York, NY",Staffing & Outsourcing,Business Services
Data Engineer,"FanDuel Group is an innovative sports-tech entertainment company that is changing the way consumers engage with their favorite sports, teams, and leagues. The premier gaming destination in the United States, FanDuel Group consists of a portfolio of leading brands across gaming, sports betting, daily fantasy sports, advance-deposit wagering, and TV/media, including FanDuel, Betfair US,and TVG. FanDuel Group has a presence across 45 states and 8 million customers. The company is based in New York with offices in California, New Jersey, Florida, Oregon, and Scotland.

Our competitive edge comes from making decisions based on accurate and timely data. As a Data Engineer, you will help us build scalable systems to provide access to that data across the company.

What we're looking for

We are looking for an experienced Data Engineer, ideally well versed in Python, with a deep understanding of large scale data handling and processing best practices in a cloud environment. You should be comfortable building complex yet performant SQL queries on large data sets. Our current stack is built on AWS with Spark and Hive on Amazon EMR for batch processing and Redshift for the data warehouse. Experience working with and tuning these for large scale workloads would be a plus.

Data is a key component of the business used by almost every facet of the company including product development, marketing, operations and finance. It is vital that we deliver robust solutions that ensure reliable access to data with a focus on quality and availability. We operate a rigorous code review process, so you need to be able to continuously give and take feedback and act on it.

As our data is always growing it is important that we have a cost effective data warehouse with data that is modelled to suit our users needs.

Looking ahead to the next phase of our data platform we are keen to do more more with real time data processing and working with our data scientists to create machine learning pipelines. We would love to hear how you have tackled these before.

What you get in return

Beyond working with such a great team?
An exciting environment with real growth
Contribute to exciting products used by a highly passionate user base
Personal learning and development opportunities
Flexible holiday allowance
401K plan with company match
Attractive health insurance premiums
There's more, but we don't want to go on and on.

FanDuel is an equal opportunities employer. Diversity and inclusion in FanDuel means that we respect and value everyone as individuals. We don't tolerate bias, judgment or harassment. Our focus is on developing employees so that they reach their full potential.","FanDuel
3.9","New York, NY",Sports & Recreation,"Arts, Entertainment & Recreation"
Data Engineer,"Work from Home (East Coast) or NYC

About us

Nasdaq (Nasdaq:NDAQ) is a leading global provider of trading, clearing, exchange technology, listing, information and public company services. Through its diverse portfolio of solutions, Nasdaq enables customers to plan, optimize and execute their business vision with confidence, using proven technologies that provide transparency and insight for navigating today's global capital markets. As the creator of the world's first electronic stock market, its technology powers more than 100 marketplaces in 50 countries, and 1 in 10 of the world's securities transactions. Nasdaq is home to approximately 4,000 total listings with a market value of approximately $15 trillion. To learn more, visit: http://www.nasdaq.com

The Team

The financial risk management team utilizes automated processes to manage workflow, risk monitoring, risk evaluation, and risk alerting functions. You will be part of a small, multi-disciplinary team which is united by our goal to utilize the latest technology tools to help us assess financial risks across Nasdaq. We focus on clearing and trading operations, investments, and trade receivables counterparty risk.

Business Unit

The Risk Management group at Nasdaq is tasked with surveillance and risk controls across the company.

Your role and responsibilities

You will be managing the data management platform for counterparty risk, which consists of an automated system of data flows with external and internal data source transformations which occur on a daily basis, and form the backbone of the team. You will work with risk managers, quantitative analysts, data scientists, Finance, and full suite of IT support teams to maintain and develop new features and functionality to our risk management technologies.

You will need the following skills and experience
Data integration software experience such as Informatica, Talend, or Adeptia
Extensive database experience, especially MS SQL
Project management
Good communication skills and time management
And it would be great if you have experience with
Big data platforms such as Apache Spark
Unstructured and specialty databases such as MongoDB & InfluxDB.
AWS resources for data management such as Redshift & Glue.
Business intelligence software such as Tableau, Power BI, or Grafana.
Sounds like you? Please follow through by clicking the “Apply” link and submitting your application. If your skills and experience are a match, we will be in touch soon, and in the meantime please visit our website and social media channels to learn more about our innovative business, inclusive culture and where a career at Nasdaq can take you.

Nasdaq is an equal opportunity employer. We positively encourage applications from suitably qualified and eligible candidates regardless of age, color, disability, national origin, ancestry, race, religion, gender, sexual orientation, gender identity and/or expression, veteran status, genetic information or any other status protected by applicable law.","Nasdaq
3.6","New York, NY",Stock Exchanges,Finance
Data Analyst,"Gainful is changing the way people shop for nutrition products to support their active lifestyle and help them achieve their fitness goals. Launched in 2017, Gainful is backed by some of the world's best venture investors (including Y Combinator, Dorm Room Fund, BrandProject, and Courtside VC). Gainful combines personalization with the highest quality ingredients to make sports nutrition accessible for every body.

Gainful is positioned to become the category leader in personalized nutrition, with personalized protein powder the first of many products. We are excited to find incredible team members to join us on this journey.

Job Description:

Gainful is hiring a data analyst to work with engineering and growth teams in order to quickly iterate our product (both physical and digital) in order to successfully meet our customers' needs. You will be responsible for utilizing large data sets in order to uncover insights that will serve as hypotheses for future tests and initiatives. You will then manage these initiatives and measure their effectiveness and provide suggestions for continuous improvement.

Responsibilities include:
Working with the CTO and COO to discover insights in the data.
Plan ways to test and measure the insights from above.
Provide suggestions for how to meet our customers needs, keeping in mind business constraints.
Support backend and frontend engineers in their data needs
Support growth marketing team to help efficiently test and evaluate different initiatives
Be an owner of the Looker platform in order to allow other team members to access the data they need
Required:
Bachelor's Degree or equivalent
Basic understanding of SQL
Expert in Excel or another data analysis tool
Relentless attitude toward continuous improvement
Preferred:
Interest or experience in nutrition, wellness, or food/bev
Desire to work on a small team and self-starter to quickly iterate on initiatives
Experience in data science tools such as pandas (Python library)
Background in financial and/or subscription modeling
Location: New York City (100% remote during COVID-19 outbreak)

Hours: Full time, unlimited PTO

Pay: competitive salary + equity

Health Insurance: Choice between Blue Shield Gold Full PPO 750 or Blue Shield Platinum Full PPO 0
Gainful will cover 99% of the monthly cost of the Gold plan, or 85% of Platinum
If you opt out of group healthcare coverage, Gainful will add $250/month to your salary as a wellness stipend
Dental: Guardian EM Dental 10
Vision: CA Beam VSP Choice Plan 2
Pre-tax benefits
Health FSA
Dependent Care FSA
Commuter
Perks:
Lunch every other Friday
Free snacks/beverages of every kind
Unlimited Gainful product & swag
Macbook Pro and whatever tools you need to do your job
Visa sponsorship: Not Available

Start Date: ASAP",Gainful Health,"New York, NY",Food & Beverage Stores,Retail
Data Analyst,"Job Description
Role: Data Analyst
Project duration: 12+ months
Location: New York, USA

Requirements:
Assist with project issues log to initiate, track and record the resolution of project issues
Must be able to document business and technology process flows clearly using standard tools
Follow and update structured data collection procedures
Develop and execute SQL/Oracle/SAS/Documentum queries based on business application EDD requirements.
Ability to write SQL/DQL queries and coordinate creation of queries with other technical resources
Work closely with business and IT resources to define collection requirements
Collection, Processing, and delivery of data for processing
Work with IT and business resources to update and or develop new collection procedures
Assist in testing and QA of collection and processing tools for system implementation and upgrades.
Qualification and skills:
BS in Computer Science, Computer Information Systems or equivalent experience.
Business Analyst Experience.
1-2 years of experience extracting data from the MS SQL server.
Experience using Microsoft Operating System and MS Office 365.
Strong analytical and problem-solving abilities.
Good interpersonal skills, i.e., Strong verbal, and written communication, work well in a team environment.","SoftStandard Solutions
4.8","New York, NY",-1,-1
Data Analyst,"Job Description
Mulberry is disrupting a $40B insurance industry by providing omnichannel merchants a seamless plug-and-play platform from which to offer product insurance. Our backers have invested in companies such as Uber (IPO'd in 2019), Venmo (acquired by PayPal), Pill Pack (acquired by Amazon), Optimizely, and Kaggle (acquired by Alphabet/Google).We call NYC home and are founded by a team of executives who are passionate about e-commerce and building efficiencies through a customer-first outlook. Our platform not only drives revenue for brands, but also improves customer experience and trust in warranty programs.

Mulberry has an open position for a Data Analyst on the Data Science and Analytics team.

What You’ll Do:
Design, implement and maintain reporting dashboards that track key business metrics and provide actionable insights.
Conduct research to aid competitive price analyses.
Improve internal data dissemination processes and strategies.
Develop processes and systems to democratize data within the company.
Conduct data analysis to make business recommendations (e.g. cost-benefit, forecasting, impact analysis).
Develop and automate reports, iteratively build and prototype dashboards to provide insights at scale, solving for business priorities.
Improve analytics practices and documentation.
Suggest improvements in the tools and techniques to help scale the team and make it more efficient.
What We’re Seeking:
Minimum of 2-3 years of experience
Experience extracting data from a diverse set of data sources, including but not limited to PostgresQL, Mongo, Redis, etc.
Experience with analytics and dashboarding solutions such as Tableau, Looker, Domo, etc.
Familiarity with solving analytical problems using quantitative approaches.
Standard Python analytics frameworks and libraries: pandas, numpy, scipy, matplotlib/seaborn/altair, jupyter.
Bachelors in computer science, physics, economics, mathematics, operations research, or related quantitative field.
Nice-to-haves:
A Masters or PhD in computer science, physics, economics, mathematics, operations research, or related quantitative field.
Experience with the data storage, analytics, ETL and data science stack on AWS.
Web crawling + scraping experience.
Experience with scripting, extracting large sets of data, and design of ETL flows.
Excellent written and verbal communication skills.
Passion for adding useful features and building new products.
Ability to function independently with minimal oversight but also effectively on a team.
Benefits and Perks:
Competitive Salary
1:1 ongoing training and career development with the Co-Founder, and all team members
Equity
Full Benefits
Unlimited Paid Time off
Gym on-site
Strong, vibrant, and fun culture, with lots of outings!
Unlimited snacks, pool table, and an awesome rooftop deck!","Mulberry Technology
5.0","New York, NY",-1,-1
Data Analyst,"Data Analyst (Decision Science)

Hearst is an American mass media and business information conglomerate. It owns a wide variety of newspapers, magazines, television channels, and television stations, including the San Francisco Chronicle, the Houston Chronicle, Cosmopolitan, Esquire, 50& of cable network A E, and 20& of the sports broadcaster ESPN.

Are you looking for a great opportunity to grow in your profession as a decision scientist?

Do you want to be part of a lean team that is helping lead the evolution of local news?

At Hearst you will have the chance to make a data driven impact by forming strong partnerships with marketing, editorial, product, ad operation and executive leadership teams.

You will be working with traffic, subscriptions, advertising, and email data and have the opportunity to work in Python, R, Big Query SQL, Looker, PowerBI and more!
Role
Clean, prepare and explain datasets, use advanced analytics to identify key trends, size up opportunities, and then work closely with business leaders to turn those opportunities into action.
Work with the latest analytic tools to perform advanced analysis and discover insights.
Create iterative and highly reproducible analytic scripting to show ongoing improvement in data visuals and analytical techniques.
Partner closely with data scientist to extract learnings from latest prediction models.
Streamline automation to help us scale and ensure ongoing data integrity.
Qualifications
Demonstrated comfort working autonomously in Python/R, particularly working with dataframes.
2 years’ experience in a data analytics role.
Degree/Advanced degree in a technical/mathematical program preferred.
Strong interpersonal and communication skills, experience building presentations.
Passion for problem solving and data exploration.
Experience in statistical methods a huge plus.
SQL knowledge
Must be hungry to take on a highly technical role and make a clear business impact.
NA",Newspaper Administration,"New York, NY",-1,-1
Data Analyst,"Data Analyst

Teaching at Hyde Leadership Charter School-Brooklyn

Our mission at Hyde-Brooklyn is to develop the deeper character and unique potential of each student. Hyde maintains a student-centered culture that motivates character development and emphasizes curiosity, courage, concern, integrity and leadership. Our goal is to prepare children for college and beyond, and to live their lives according to standards of personal excellence. We believe in order to provide the best possible education for our young leaders, we as educators need to be in a continuous growth process. Teaching at Hyde-Brooklyn is a unique and rewarding experience because our teachers receive both professional development and participate in their own self-discovery process through the Hyde process of journaling, facilitated discussion, workshops and seminars.

Character Development Expectations
Believe the purpose of education is both academic achievement AND character development
Provide whatever is necessary to ensure ALL students are successful and are developing strong character
Use data and assessments to inform and drive instruction
Involve families in their students’ education and in the Hyde process
Value feedback and evaluation on teaching practices and set SMART goals
Support and challenge colleagues and hold each other to his or her best
Voice thoughts, opinions and suggestions and embody an entrepreneurial spirit by taking on leadership in a multitude of ways
Pursue self-discovery and growth through reflective practices and team building experiences
Essential Duties and Responsibilities:
Maintain and verify critical school data in Hyde-Brooklyn's Student Information System, PowerSchool
Respond to all data requests and manage data reporting for all compliance-related reports
Support the Operations and Data team in the tracking of school-based data related to student information, culture and special education.
Assist with GradeBook, Progress Reports, Report Cards, ongoing student achievement data collection, and reporting and analysis
Support the Instructional Leadership Team with assessment logistics and data entry as needed
Provide training as needed for school-based Data Management
Support the Director of Operations with additional projects as required
The ideal candidate will have:
A Bachelor's degree from an accredited college or university
Demonstrated success working in an urban school setting
Strong data tracking and analysis skills
An ability to communicate and collaborate effectively with colleagues, families and students
A belief that everyone is gifted with a unique potential
A commitment to character development and family partnerships",Hyde Leadership Brooklyn,"Brooklyn, NY",-1,-1
Data Engineer,"About Freestar:

Freestar engineers cutting-edge monetization solutions for websites. By combining industry-leading technology, data, and massive scale, we enable busy site owners to seamlessly maximize revenue while freeing themselves of the hassles of ad operations. Publishers then have more time to do what they do best: create content.

Data Engineer Job Responsibilities:

Joining our data team, you will have an opportunity to learn and work with modern tools like Airflow and Druid to ensure a seamless stream of data where we need it. As we are a startup environment, you'll likely pick up some software engineering skills too, however the primary focus on the role is on data engineering. We're looking for someone who:
Develops and maintains scalable data pipelines and builds out new API integrations to support continuing increases in data volume and complexity.
Collaborates with analytics and business teams to improve data models that feed business intelligence tools, increasing data accessibility and fostering data-driven decision making across the organization.
Implements processes and systems to monitor data quality, ensuring production data is always accurate and available for key stakeholders and business processes that depend on it.
Writes unit/integration tests, contributes to engineering wiki, and documents work.
Performs data analysis required to troubleshoot data related issues and assist in the resolution of data issues.
Works closely with a team of frontend and backend engineers, product managers, and analysts.
Defines company data assets (data models), SQL, Airflow to populate data models.
Designs data integrations and data quality framework.
Build dashboards that concisely and succinctly convey business metrics.
Designs and evaluates open source and vendor tools for data lineage.
Works closely with all business units and engineering teams to develop strategy for long term data platform architecture.
Data Engineer Qualifications / Skills:
Knowledge of best practices and IT operations in an always-up, always-available service
Experience with or knowledge of Agile Software Development methodologies
Excellent problem solving and troubleshooting skills
Process oriented with great documentation skills
Excellent oral and written communication skills with a keen sense of customer service
Education, Experience
Ample relevant knowledge and experience. You either have a BS or MS degree in Computer Science or a related technical field, OR certification from a data science bootcamp + 2 years of experience in a role as a data engineer
Proficiency in Python and Java, Scala, or Go development experience
4+ years of SQL experience (Strong SQL required)
Familiarity with BI reporting tools like Tableau, Looker.
4+ years of experience with schema design and dimensional data modeling
Ability in managing and communicating data warehouse plans to internal clients
Experience designing, building, and maintaining data processing systems
Experience working with either a Map Reduce or an MPP system on any size/scale
Experience/knowledge of cloud computing platforms like AWS/GCP would be a plus
We'd also like to see:
Excellent interpersonal and problem solving skills with the ability to communicate with team members to deliver actionable results
Comfortable interacting across multiple teams and management levels within the organization
Previous background in the ad tech or media landscape (linear, digital, or social) is a plus
What you can expect in return:
Full-Time, Salaried Position
Medical, Dental, and Vision benefits
401K with company match, vested immediately
The opportunity to be part of something BIG
Freestar is an Equal Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, age, protected veteran or disabled status, or genetic information.

This role is not eligible for visa sponsorship","Freestar
4.9","New York, NY",Advertising & Marketing,Business Services
Data Engineer,"PulsePoint Data Engineering team plays a key role in our technology company that's experiencing exponential growth. Our data pipeline processes over 80 billion impressions a day (> 20TB of data, 220 TB uncompressed). This data is used to generate reports, update budgets, and drive our optimization engines. We do all this while running against extremely tight SLAs and provide stats and reports as close to real-time as possible.

The most exciting part about working at PulsePoint is the enormous potential for personal and professional growth. We are always seeking new and better tools to help us meet challenges such as adopting proven open-source technologies to make our data infrastructure more nimble, scalable and robust. Some of the cutting edge technologies we have recently implemented are Kafka, Spark Streaming, Presto, Airflow, and Kubernetes.

What you'll be doing:
Design, build and maintain reliable and scalable enterprise level distributed transactional data processing systems for scaling the existing business and supporting new business initiatives
Optimize jobs to utilize Kafka, Hadoop, Presto, Spark Streaming and Kubernetes resources in the most efficient way
Monitor and provide transparency into data quality across systems (accuracy, consistency, completeness, etc)
Increase accessibility and effectiveness of data (work with analysts, data scientists, and developers to build/deploy tools and datasets that fit their use cases)
Collaborate within a small team with diverse technology backgrounds
Provide mentorship and guidance to junior team members
Team Responsibilities:
Installation, upkeep, maintenance and monitoring of Kafka, Hadoop, Presto, RDBMS
Ingest, validate and process internal & third party data
Create, maintain and monitor data flows in Hive, SQL and Presto for consistency, accuracy and lag time
Maintain and enhance framework for jobs(primarily aggregate jobs in Hive)
Create different consumers for data in Kafka using Spark Streaming for near time aggregation
Train Developers/Analysts on tools to pull data
Tool evaluation/selection/implementation
Backups/Retention/High Availability/Capacity Planning
Review/Approval - DDL for database, Hive Framework jobs and Spark Streaming to make sure they meet our standards
24*7 On call rotation for Production support
Technologies We Use:
Airflow - for job scheduling
Docker - Packaged container image with all dependencies
Graphite/Beacon - for monitoring data flows
Hive - SQL data warehouse layer for data in HDFS
Impala- faster SQL layer on top of Hive
Kafka- distributed commit log storage
Kubernetes - Distributed cluster resource manager
Presto - fast parallel data warehouse and data federation layer
Spark Streaming - Near time aggregation
SQL Server - Reliable OLTP RDBMS
Sqoop - Import/Export data to RDBMS
Required Skills:
BA/BS degree in Computer science or related field
5+ years of software engineering experience
Knowledge and exposure to distributed production systems i.e Hadoop is a huge plus
Knowledge and exposure to Cloud migration is a plus
Proficiency in Linux
Fluency in Python, Experience in Scala/Java is a huge plus
Strong understanding of RDBMS, SQL;
Passion for engineering and computer science around data
Willingness to participate in 24x7 on-call rotation
What we offer:
401(k) Match and free access to a financial advisor
Generous paid vacation/company holidays
Vacation reimbursement (we give you $500 to take vacation), sabbatical, pawternity leave, marriage leave, honeymoon bonus
Comprehensive healthcare with 100%-paid medical, vision, life & disability insurance
$2,000 annual training and development budget
Complimentary annual memberships to One Medical, NY Citi Bike and SF Ford GoBike
Monthly chair massages
Free fitness classes (spin, yoga, boxing)
Gym reimbursement, local gym membership discounts
Onsite flu shots, dental cleanings and vision exams
Annual company retreat
Paid parental leave and a lot of new parent perks
Emergency childcare credits
Volunteer Time Off and Donation Matching, ongoing group volunteer opportunities
Team lunches, Sip & Social Thursdays, Game Nights, Movie Nights
Healthy snacks and drinks
And there's a lot more!","PulsePoint
4.4","New York, NY",Internet,Information Technology
Data Analyst,"NYU Grossman School of Medicine is one of the nation's top-ranked medical schools. For 175 years, NYU Grossman School of Medicine has trained thousands of physicians and scientists who have helped to shape the course of medical history and enrich the lives of countless people. An integral part of NYU Langone Health, the Grossman School of Medicine at its core is committed to improving the human condition through medical education, scientific research, and direct patient care. For more information, go to med.nyu.edu, and interact with us on Facebook, Twitter and Instagram.

Position Summary:

We have an exciting opportunity to join our team as a Data Analyst.

In this role, the successful candidate The Ophthalmic Imaging Research Laboratory in the Department of Ophthalmology is seeking a Data Analyst. Responsibilities will include management of all historical and on-going research data, including databases, images, patient health record information, etc. The individual will be responsible for all data collection and organization. The individual must have at least an undergraduate degree in data or computer science. A background in database programming, data cleaning and query creation is advantageous but not required. Must be able to work independently as well as with a group and have excellent interpersonal skills. Must be extremely organized and pay close attention to detail.

Job Responsibilities:
Image analysis including the processing of the images captured using state of the art prototype imaging software.
Export of clinical images and raw image data for further processing.
Production of new tools and methods to streamline laboratory productivity.
Creation of custom data sets for students and researchers on an ad hoc basis.
Aggregation of data from multiple sources.
Management, clean up, and optimization of a database containing large data sets.
Extraction of information from patient medical records. This will require discrete handling of sensitive patient related information including the de-identification of datasets.
Responsible for all research data collection and organization from historical and on-going studies. This responsibility will be done following a strict timeline.
Minimum Qualifications:

To qualify you must have a 2 years experience or an equivalent combination of education and experience with at least an undergraduate degree in physical sciences or computer science. A background in database programming, data cleaning and query creation is advantageous. The incumbent must be willing to work with minimal supervision or independently under a strict timeline. Some analytical skills will be required. The incumbent must proficient with regards to data collection and analysis. Will not involve any financial responsibility/accountability.

Qualified candidates must be able to effectively communicate with all levels of the organization.

NYU Grossman School of Medicine provides its staff with far more than just a place to work. Rather, we are an institution you can be proud of, an institution where you'll feel good about devoting your time and your talents.

NYU Grossman School of Medicine is an equal opportunity and affirmative action employer committed to diversity and inclusion in all aspects of recruiting and employment. All qualified individuals are encouraged to apply and will receive consideration without regard to race, color, gender, gender identity or expression, sex, sexual orientation, transgender status, gender dysphoria, national origin, age, religion, disability, military and veteran status, marital or parental status, citizenship status, genetic information or any other factor which cannot lawfully be used as a basis for an employment decision. We require applications to be completed online.

If you wish to view NYU Grossman School of Medicine's EEO policies, please click here. Please click here to view the Federal ""EEO is the law"" poster or visit https://www.dol.gov/ofccp/regs/compliance/posters/ofccpost.htm for more information. To view the Pay Transparency Notice, please click here.",NYU Langone Medical Center,"New York, NY",-1,-1
Data Analyst,"Los Angeles, CA | New York, NY

Email careers@edo.com for more information about EDO and the application process.

Who We Are

EDO is a data science software firm that develops analytics tools to make data accessible and actionable for the media and entertainment industry. Currently focused on film and TV, we work with many major movie studios and TV networks to help them forecast, market and distribute their content more effectively. Building from this strong base, we are growing into adjacent verticals.

We are a team of world-class engineers and data scientists backed by top leaders in entertainment and technology. Our co-founders and executive leadership have a strong track record with other successful ventures.

What You Will Do

In addition to standard client engagement responsibilities, you'll get to
Perform advanced statistical analyses for our clients, who will use the insights and opinions you generate to make key decisions
Understand our clients’ needs and figure out how to present our data in compelling ways that match those needs
Create client deliverables that showcase our products and present our data
Work closely with our engineers and data scientists to plan and prioritize new features
Understand industry dynamics and the competitive landscape
Help our executive leadership with strategic planning, investor pitches, strategic partnership development, and corporate finance activities

What We Are Looking For

At least 1-2 years of professional experience in a role involving on quantitative analysis
Comfort with advanced statistical analysis and ability to translate into layman’s terms
Experience in SQL and with a programming language commonly used for statistical analysis such as R or Python
Ability to write well and create slide decks and reports that present our information in a succinct and efficient manner
Strong presence in meetings with senior executives
Passion for movies, TV and advertising
The ability and willingness to wear multiple hats and switch gears frequently

Benefits

Early-stage equity and competitive salary
Medical, dental, & vision insurance
Meals and snacks during work
Movie tickets + concessions, fitness discounts, and Apple hardware","EDO, Inc.
5.0","New York, NY",Internet,Information Technology
Data Analyst,"Data Analyst Data Scanning team

Client: Perficient, Inc.; End Client BNY Mellon

Location: 240 Greenwich St, New York, NY (Initially Remote with onsite starting around late September/early October)

Duration: 12 months contract with possibility for extension/conversion.

Description:

Data Scanning Team

Responsible for determining systems requirements for new or modified database application programs, creates the system specifications and is responsible for the development, testing and implementation of efficient, cost effective application solutions.

Will receive general direction from the Manager, work closely with business analysts to identify and specify complex business requirements and processes.

May co-ordinate the activities of the section with the client area and other IT sections (e.g., data base, operations, technical support). Work in conjunction with the data architect/modeler on the data warehouse reporting solution.

Possess expertise in writing and tuning, view, stored procedures, and functions. Strong problem-solving, interpersonal, written and oral communications skills with demonstrated ability to simultaneously adjust to changing priorities, successfully completing multiple tasks.

Prepares deliverables such as source-to-target mappings; transformation rules documentation.

7-10 Years of relevant work experience required.

Data cataloging/data profiling

SQL Server, DB2, Oracle

Must have knowledge of lineage and financial industry, technical metadata layer

Skills needed for DB Analyst specific: Data Scanning, Data Profiling

Data Analyst Data Scanning team

Client: Perficient, Inc.; End Client BNY Mellon

Location: 240 Greenwich St, New York, NY (Initially Remote with onsite starting around late September/early October)

Duration: 12 months contract with possibility for extension/conversion.

Description:

Data Scanning Team

Responsible for determining systems requirements for new or modified database application programs, creates the system specifications and is responsible for the development, testing and implementation of efficient, cost effective application solutions.

Will receive general direction from the Manager, work closely with business analysts to identify and specify complex business requirements and processes.

May co-ordinate the activities of the section with the client area and other IT sections (e.g., data base, operations, technical support). Work in conjunction with the data architect/modeler on the data warehouse reporting solution.

Possess expertise in writing and tuning, view, stored procedures, and functions. Strong problem-solving, interpersonal, written and oral communications skills with demonstrated ability to simultaneously adjust to changing priorities, successfully completing multiple tasks.

Prepares deliverables such as source-to-target mappings; transformation rules documentation.

7-10 Years of relevant work experience required.

Data cataloging/data profiling

SQL Server, DB2, Oracle

Must have knowledge of lineage and financial industry, technical metadata layer

Skills needed for DB Analyst specific: Data Scanning, Data Profiling",Monkey Algorithms LLC,"New York, NY",-1,-1
Data Analyst,"Non-Exempt*
Schedule: Can be 8a.m. – 5p.m. or 7a.m. – 4p.m. Monday - Friday.

Capital Systems Analyst
Overall responsibilities include providing systems support for the capital and project management systems within ***.

Roles and Responsibilities:

• Capital Systems Administration (Planview Enterprise One, Lean Kit, Project Place, Other)
• License and user permission management
• Functional configuration of Planview or other Capital Systems
• Administer Capital Systems SOX compliance process
• ServiceNow queue management and ticket resolution including working with IT on technical issues.
• Execute monthly financial uploads into Planview
• Provide System Help to users as well as training and job aids on Capricorn systems
• MS Power BI dashboard and reporting development and maintenance
• Participate on Capital Systems projects
• Create and upkeep work instructions and training documents
• Provide training to users
• Translate needs and best practices into tools & systems
• Facilitate continuous improvement of available tools and methods

Deliverables:

• Process improvement across the Capital Systems environment
• Capital System's administration
• Capital reporting and analysis
• Structure and methodology for document control and sharing
• Ongoing systems care to ensure continued value for ***

Education and Experience
• 3+ years of experience, preferably with software/ systems.
• 4-year degree
• Demonstrated system skills and knowledge
• Understanding of Capital projects, Project Management

Required Skills:

• Advanced Excel Skills including data analysis, formula functions, pivot tables, etc
• Quick Learner, self-starter.
• Technical curiosity for system capabilities. Ability to come up with innovative solutions.
• MS Power BI Dashboard development
• High attention to detail
• Problem solving and decision making

Desired Skills:

• SharePoint expertise
• Excel Macros, VBA
• MS Project experience
• ServiceNow queue management
• Basic Financial skills, especially in project costing
• Planview (Enterprise One, Lean Kit, Project Place) knowledge
• SQL Reporting
• Ability to Train others

Nesco Resource is an equal employment opportunity employer and does not discriminate on the basis of race, color, religion, sex, sexual orientation, gender identity, national origin, disability, age, or veteran status, or any other legally protected characteristics with respect to employment opportunities.","Nesco Resource, LLC
2.9","New York, NY",Staffing & Outsourcing,Business Services
Data Scientist,"Responsibilities:
Bring Creativity to Data products.
Apply machine learning methods to a variety of finance and accounting problems.
Responsible for building and maintaining the machine learning systems, data, platform and processes.
Build, integrate and deploy machine learning solutions into the BlackLine application in collaboration with product management, cloud, engineering and data science teams.
Perform qualitative and quantitative data analysis.
Cleanse and transform raw data used in machine models.
Perform data munging, data mining, clustering & classification methods, pattern recognition.
Comfortable with statistics, calculus and multivariate analysis.
Participate in ML POCs, validate the results and develop production implementations.
Build and optimize scalable machine learning solutions in the public cloud.
Familiar with SQL, Python, R, SparkML, TensorFlow, GCP, AWS, SQL Server.
Develop production systems in Python.
Work independently to research and solve business and technical problems.
Plan their work individually and as part of a team.
Mentor and train other Data Scientists on the team.
Qualifications:
Strong practical experience with machine learning techniques in the industry, accounting and financial industries is a plus.
Extensive experience solving analytical problems using quantitative approaches.
Experience with machine learning algorithms for building ML models, their accuracy, cleanliness, reliability.
Experience with predictive and prescriptive analyses, modeling, and segmentation.
Have strong passion for empirical data research for practical applications.
Ability to communicate complex quantitative analysis in clear, precise, and actionable
Comfortable with complex, high-volume, high-dimensionality data from varying sources.
Very comfortable with data engineering methods and pipelines.
Expert knowledge of analysis tools such as R, Matlab, or SAS
Experience with data warehousing, relational databases, ETL, BI, data mining.
Experience in SQL, R, Python languages.
Strong familiarity with GCP and AWS, SQL Server.
Practical experience with GIT version control.
Comfortable working with open source tools in a Unix/Linux environment.
Experience with and ownership of data-informed decision-making.
Experience translating business requirements into functional, and non-functional requirements.
Strong sense of product and data ownership.
Works independently without the need for supervision.
Strong written and verbal skills – able to explain the work in plain language.
MS/PhD in Computer Science or other quantitative disciplines","BlackLine
3.9","Woodland Hills, CA",Computer Hardware & Software,Information Technology
Data Scientist,"Data Scientist | AcornsAt Acorns, we're building a financial wellness system that enables everyday Americans to save and invest every day. We are transforming the category and recruiting a team that is relentless at fulfilling our mission. The Acorns team comes together every day to deliver a revolutionary product to its customers, the up-and-coming. If you thrive in an environment where you can push yourself beyond all previous thresholds of possibility, come join us at Acorns.Acorns is actively seeking a highly self-motivated, detail-oriented, and solution-focused Data Scientist. This position will reside in the Data Science group, which serves as the central data science team for the company. The team is responsible for developing and using state-of-the-art mathematical modeling, data mining, and machine learning techniques to be agents for good by helping look after the financial best interests of the up-and-coming.The Acorns Data Science group is obsessed with solving hard problems that directly affect customers, including recommendation engines, fraud prevention, and customer intention inference. But these aren't Kaggle-type problems; we operate fast and often with imperfect data. We focus on impact - we innovate and put the models into production quickly. We know that solving problems with data is an art and a science. Data Scientists at Acorns are as good at communicating and collaborating as they are at building models and writing code.At Acorns, Data Scientists have broad latitude around data and you will work across functional teams including Analytics, Engineering, Product Management, Marketing, Operations, Risk, and Business Development, and will play a key role in shaping the technology and product directions of the company.Within 1 month, you will:* Understand the Acorns products, data warehouse, and how data fits into the products.* Discover new opportunities to apply data science concepts to the portfolio of products.* Present findings to the Data Science team members.* Interact with multiple teams.Within 3 months, you will:* Have established architecture and implementation for an intelligence-driven product feature in a data-rich environment.* Have complete ownership of a data science product and made production quality code commits into the team's repository.* Contribute to the broader team's success by offering ideas and constructive feedback to other team member's projects.* Propose novel ML research directions that will eventually power new products.Within 6 months, you will:* Work independently and closely with the Product Management team to plan projects and recommend areas for the next generation of Acorns products.* Work independently and closely with Engineering teams to deliver data science solutions into the product with proper API design.* Build an identity within the company and can independently represent the Data Science team with other departments.What you will bring to Acorns:* A team player that is enthusiastic, self-motivated, detail-oriented, and solution-focused.* Empathy with our customers' financial situations and the desire to help our customers in need of personalized products and services.* Uphold the values of transparency, honesty, and unconditional support for the team.* Define problems, collect data, establish facts, draw valid conclusions, and make recommendations for continuous improvement.* An ability to explain complex problems in a simple way.* Capability to build algorithms that touch the cutting edge of statistics and machine learning.* Apply state of the art machine learning, statistics or data mining in a variety of areas, including user analysis and data product design.* Develop scalable and efficient methods for large scale data analysis and model development.* Derive pride from technical excellence, and pursue excellence in all areas of work.Requirements:* Hunger for impact, drive to learn fast, be creative, and win as a team.* BS in Computer Science, Statistics, Mathematics, Physics, Engineering or a related field, or equivalent experience.* 3-4+ years experience in working with noisy real world structured and semi-structured data.* Expert in Python or Scala, with related statistical and machine learning packages.* Background in data mining, machine learning, statistical analysis, or mathematical modeling, with experience deploying models in a production environment.* Experience with A/B testing methodologies and experiments.* Strong SQL abilities and experience with massive relational database systems.* Able to take a complex, ambiguous topic and turn it into a rigorously defined and well-formulated problem that answers the business question we are trying to solve.* Excellent communication skills to explain your results and solution to the stakeholders in a clear and compelling way.Bonus* MS or PhD in Statistics, Mathematics, Computer Science, Physics, Engineering or other quantitative field.* Patent, publication, or conference presentation in an AI or ML related field.* Experience writing production quality, version controlled code.* Experience considering user psychology and user experience.* Experience with Databricks, Spark, AWS, Kafka or Kinesis.* Knowledge of basic macroeconomic concepts.* Thirst for delivering game-changing products.* Exceptional drive and precision in delivery.* A belief that your work is tied to your life's mission.* Optimistic about the potential of societal change.What we offer:* Competitive salary and stock options.* A comprehensive benefits package to meet the needs of you and your family.* Flexible paid time off.* Corporate gym access.* Daily breakfast, weekly team lunches, and an endless supply of snacks.* Numerous career possibilities that allow you to grow with Acorns.* Talented and motivated team members who care deeply about one another, our mission and our customers.* The rare opportunity to create a new world. We inspire one another every day to do meaningful work that solves big societal challenges.About Acorns:Acorns is the leading micro-investing app in the U.S. It allows users to round up their daily purchases and automatically Invest the Change® into a low-cost, diversified portfolio of exchange-traded funds offered by some of the world's top asset managers (including Vanguard and BlackRock). Founded in Newport Beach, Calif., by father and son team Walter and Jeff Cruttenden, Acorns provides a simple entry-point using the Acorns app on iPhone or Android. Customers accumulate fractional shares in one of five portfolios constructed by world-renowned Nobel Laureate economist Dr. Harry Markowitz. Acorns' smart portfolio algorithms automatically work in the background of life, helping users build wealth naturally, pennies at a time. From Acorns mighty oaks do grow.Mission:With benevolence and courage, we look after the financial best interests of the up-and-coming; beginning with the empowering step of micro-investing.Values:* Lead with heart* Make bold decisions* Always build trust* Never stop growing* Find a way","Acorns
3.9","Anaheim, CA",Brokerage Services,Finance
Data Engineer,"Who we are
Albert is a new type of financial service that uses powerful technology to automate your finances, with a team of human experts to guide you. Albert saves and invests automatically for you, helps you avoid overdrafts, finds savings you’re missing, identifies bills you’re overpaying, and much more. Text Albert a financial question, and we’ll not only offer guidance; we’ll help you make it happen.
We’re an LA-based startup with a proven business model, backed by top-tier institutional investors, with over 2 million users who have trusted Albert to help them achieve their financial goals. We’re on a mission to improve the financial lives of millions of people with a beautifully-designed, simple product, and we’re looking for thoughtful, talented people to join us on our journey.

About the role
Managing, transforming, and accessing data efficiently is critical to every business process at Albert, from backend and mobile development to growth and business analytics. We are looking for a talented engineer to own our data analytics pipelines and systems as well as help us evolve our data architecture to support our growth as we scale.
Things you're good at
Shipping: Delivering great products that you're proud of on a regular basis.
Architecture: Getting it done is important. Getting it done in way that will scale is equally important.
Diving in: Taking ownership of the data stack.
Collaboration: We bring the best out of each other. We're looking for people who will bring the best out of all of us.
Responsibilities
Take over existing data pipelines, ETL and task running processes, starting with our ETL processes for BI analytics
Partner closely with VP of Analytics to make data accessible to the entire company so we can make timely decisions backed by data
Monitor our analytics data pipelines to ensure data quality and timeliness
Continuously improve our BI tooling, platforms and monitoring to help the team create dynamic tools and reporting
Drive optimization, testing, and tooling to improve data quality
Write clean, maintainable and well-documented code to support our data processes. Help improve and evolve out data architecture over time by planning, developing, and deploying infrastructure using state of the art tools and practices appropriate for our needs
Concisely and effectively communicate the benefits and implications of adding new data technologies and techniques to our infrastructure
Requirements
4+ years of experience in a Data Engineering role, with a focus on building data pipelines
BI tooling and/or data app development
4 year bachelor degree in Computer Science or other technical or science degree
Proficiency in Python
Experience with some or all of the following: Postgres, Redshift, Celery, Elasticsearch, Kafka, and Airflow.
Benefits
Competitive salary and meaningful equity
401k Match
Health, vision and dental insurance
Free lunch","Albert (CA)
3.7","Los Angeles, CA",Financial Analytics & Research,Finance
Data Scientist,"SUMMARY


At Hulu, the number one priority is our customers. We make business decisions around our customers preferences. The Data Science Team at Hulu combines deep data analysis and research of our rich user data to present a compelling vision around user retention and preferences across the vast ecosystem of Hulus product offerings and content. We are looking for a Data Scientist who is passionate about developing, improving and operationalizing models for personalizing content recommendations at scale. You will be engaged with other Data Scientists, and cross-functionally with analysts, product managers, and engineers to deliver machine learning based personalization products.

WHAT YOU'LL DO
Apply state of the art machine learning and statistics to develop personalization models
Implement and debug models in Python using various ML frameworks (e.g. tensorflow, scikit-learn, lightGBM, etc.)
Create and deploy training and prediction pipelines to operationalize models using a variety of technologies such Airflow/Luigi, Hive/Spark
Collaborate with developers, program managers, and product managers in an open, creative environment
WHAT TO BRING
Bachelor's degree in a quantitative field (e.g. Computer Science, Engineering, Mathematics, Physics, Operations Research, Econometrics, Statistics)
2+ years related experience with developing and operationalizing personalization models in either an academic or professional setting and 4+ years of relevant work experience
Ability to draw insights and conclusions from data to inform model development and business decisions
Desire to collaborate with other data scientists, data analysts, and business partners
Familiarity with machine-learning concepts and statistics
Proficient in analyzing data and developing machine-learning models using Python (with ML frameworks like tensorflow, scikit-learn, etc.)
Capable of reading and writing Object-Oriented code to review and implement modeling pipelines (Airflow, Luigi, etc.)
Working knowledge of SQL and distributed data technologies (Hive, Spark)
NICE-TO-HAVES
MS in Physics, Computer Science, Engineering, Economics, Statistics or related quantitative field (e.g. Econometrics, Mathematics, Operations Research)
Experience fully integrating data science solutions into the business and operationalizing ML models
Familiarity with Scala
Previous project experience using time-series forecasting, clustering, or regression/classification","Hulu
3.8","Santa Monica, CA",TV Broadcast & Cable Networks,Media
Data Scientist,"We are Mythical Games. A venture-backed next-generation game technology company at the intersection of video games and economics led by industry veterans. Our goal is to lead the industry with the launch of exceptional video game experiences that leverage distributed ledger technology, while also providing a platform of robust tools that will allow any other game developers to do the same.
ABOUT THE ROLE:
We are looking for a highly-skilled Data Scientist with a proven track record performing statistical analysis, prediction, and recommendation on diverse and large-scale e-commerce datasets preferably. In this role, you will be responsible for delivering models in production that optimize marketplace interactions, generate insights, and detect anomalies among other things. While this role is production focused, as one of the first members, you will be critical for the development of Data Science at Mythical Games.
WHAT YOU'LL DO:
Build machine learning systems to understand the secondary marketplace eCommerce ecosystem
Work with internal stakeholders to expand our technical capabilities, thereby creating a more robust data environment
Utilize natural language processing to uncover insights from contextual data
Develop models to optimize marketplace recommendations
Build anomaly detection systems for detecting fraud or erroneous data
The nasty but inevitable job of data wrangling
Internal Data Science reading group - spend time each week keeping up with current research and presenting interesting findings
WHO YOU ARE:
Bachelor’s Degree in a quantitative field, Ph.D. preferred
3+ years of professional experience with Python
Experience with tools and frameworks like Pytorch, TensorFlow, Scikit-Learn, SQL, etc
Familiarity with deployment and tracking tools such as MlFlow, Airflow, Docker, Kubernetes
Familiarity with mathematical models underlying data science methods
Drive to learn and improve","Mythical Games
4.6","Los Angeles, CA",Video Games,Media
Data Scientist,"Job Title:

Data Scientist

Department:

Technology

Location:

Santa Monica, CA, US, 90404

Summary of Position:
STARZ is looking for a skilled Data Scientist to join their growing team Santa Monica, CA. This resource will have access to a variety of different data sources available to the Data Products and Engineering team, entailing clickstream, financial, marketing, event, and internal data. This individual will be responsible for exploring data sets as large as 1 petabyte (1PB) and driving business results with their data-based insights using predictive modeling. The ideal candidate is adept at using large data sets to find opportunities for product and process optimization and can use models to test the effectiveness of different courses of action. Other responsibilities will include (but are not limited to) data visualization, data- driven problem solving, They have a passion for discovering solutions hidden in data sets and can brainstorm ways to improve business outcomes/determine future project focus. They must also have experience and interest in content analysis.
Experience & Skills:
4+ years of experience as a Data Scientist within a large, consumer-facing analytics environment
Strong python/R programming experience to extract, clean, analyze, and visualize data
Exposure to cloud environments (preferably AWS)
Strong experience utilizing Spark for data processing
Automation experience using Amazon S3 or other comparable storage service
Machine Learning experience using Tensorflow, Scikit-learn, or Spark ML
Experience using Amazon SageMaker for cloud machine learning
At least a B.S. in Computer Science, EE or Mathematical Science. MS or PhD preferred
Starz (www.starz.com), a Lionsgate company (NYSE: LGF.A, LGF.B), is a leading global media and entertainment company that produces and distributes premium streaming content to worldwide audiences across subscription television platforms. Starz is home to the flagship domestic STARZ® brand, STARZ ENCORE, 17 premium pay TV channels and the associated on-demand and online services, including the highly rated STARZ app. With the launch of the STARZPLAY international premium streaming platform and STARZ PLAY Arabia, Starz is expanding its global footprint in a growing number of territories. Sold through multichannel video distributors, including cable operators, satellite television providers, telecommunications companies, and other online and digital platforms, Starz offers subscribers more than 7,500 distinct premium television episodes and feature films, including STARZ Original series, first-run movies and other popular programming.

STARZ is an Equal Opportunity Employer. This means that all applicants will receive consideration for employment regardless of gender, age, race, national origin, disability, color, religion, sexual orientation, gender identity and/or expression, veteran status, or any other characteristic protected by federal, state or local law. In addition, STARZ will provide reasonable accommodations for qualified individuals with disabilities.

Nearest Major Market: Los Angeles","Starz
2.9","Santa Monica, CA",TV Broadcast & Cable Networks,Media
Data Scientist,"Requisition ID: 54021

All Locations: El Segundo, CA (California)

A trusted partner. A national resource. A leader in national security space. We are THE Aerospace Corporation. A team that takes pride in our readiness to solve some of the most complex technical challenges in existence. With challenges spanning government to commercial, you’ll have the unique opportunity to work on projects that are literally evolving our nation's space and launch capabilities. We all share a common passion and aspiration – to serve a mission much bigger than ourselves. When you join our team, you’ll be part of a rare collection of thought leaders and game-changing innovators. Are you ready to launch your career?
Responsibilities
Participate as part of a high-performing team supporting critical work for U.S. National Security Space. Apply cutting-edge skills in data science, data analytics, machine learning, artificial intelligence (AI), and/or big data to address a wide range of technical questions associated with the analysis of international space programs. Actively collaborate with well-established subject matter experts, inside and outside of Aerospace. Expand your own areas of expertise to be synergistic with the International Space Systems group within Project West Wing (PWW). Coordinate closely with the Data Management group to help facilitate an ongoing modernization effort that is critical to maintain and expand the unique capabilities at PWW. In this role, you will be expected to use your expertise in data science to serve as a force multiplier, as well as becoming an independent subject matter expert on international space systems.

Key Functions
Learn the existing methods of data analysis, data management, and technical reporting that are currently employed in Project West Wing.
Work under the guidance of existing subject matter experts in the International Space Systems group to develop new analytical, machine learning, and AI techniques and tools that will help improve the analytical throughput of the team.
Collaboratively interface with other experts in the community who are developing and applying modern data science techniques to enhance the ability to deal with large volumes of data that are complex and difficult to interpret.
Support and conduct detailed technical analyses of current and future space systems.
Identify short- and long-term technical challenges for a diverse customer base, including the USAF, the Intelligence Community, and other government and commercial customers.
Prepare technical reports, briefings, and other deliverable materials as required.
Critically review reports, briefings, and other materials produced by team members.
Support and develop customer relationships.
Occasional travel required (1-2x a year) for presentations and meetings with Aerospace/PWW personnel and U.S. Government agencies throughout the country. International travel to conferences or meetings is possible.
Qualifications
Required
Demonstrated expertise and experience in Data Science
Demonstrated experience with space systems and/or space operations
Highly motivated self-starter capable of both working independently and collaborating with teams
Flexibility to learn, build, and test new tools/capabilities
An affinity for challenging puzzles and problem solving is a plus
Superior written and oral communication skills; requires the ability to work well with other analysts and communicate to senior military and civilian customers
Strong interest and enthusiasm for understanding global space activities and operations
Bachelor’s degree in Data Science, Statistics, Computer Science/Engineering, Engineering, Mathematics, or Physical Sciences
Active TS/SCI clearance
A minimum of 8 years of progressively more responsible and related engineering/scientific experience
Preferred
Advanced degree in Data Science, Statistics, Computer Science/Engineering, Engineering, Mathematics, or Physical Sciences
Background in space systems engineering, space domain awareness, space system data analysis, or related fields
Understanding of astrodynamics fundamentals and experience with related analysis tools such as STK (Systems [previously Satellite] Took Kit) or SOAP (Aerospace’s Satellite Orbit Analysis Program)
Proficiency with Linux, UNIX, Python, MATLAB, and/or other scripting/programming languages
Experience with fusing and analyzing information from multiple sources and extrapolating to answer questions
Prior experience and familiarity with USAF and IC agencies and organizations
Reading comprehension and translation skills in selected foreign languages is of interest
Transcript Requirement
Transcripts are required for this position.

Additional Requisition Details

Clearance Requirement: Top Secret

Access: SCI

Polygraph: Counter Intelligence Polygraph

Relocation Available: Yes

Employment Type: Regular

Work Schedule: Full Time

Company Statement

The Aerospace Corporation has provided independent technical and scientific research, development, and advisory services to national security space programs since 1960. We operate a federally funded research and development center (FFRDC) for the United States Air Force and the National Reconnaissance Office, and support all national security space programs. We also apply more than 50 years of experience with space systems to provide critical solutions to technologically complex systems in such areas as communications, shipping, law enforcement, and cyber, among others.

From our inception, our highly skilled technical staff has focused on ensuring the success of every mission and developing the most effective and economic space-related hardware and software in the world. Our greatest asset is the technical expertise of our people. Our state-of-the-art laboratory facilities are staffed by some of the leading scientists in the world.

All Aerospace employees working in organizations with technical responsibilities are required to apply for and maintain at least a Secret clearance. U.S. citizenship is required for those positions.

Equal Opportunity Commitment

The Aerospace Corporation is an Equal Opportunity/Affirmative Action employer. We believe that a diverse workforce creates an environment in which unique ideas are developed and differing perspectives are valued, producing superior customer solutions. All qualified applicants will receive consideration for employment and will not be discriminated against on the basis of race, age, sex (including pregnancy, childbirth, and related medical conditions), sexual orientation, gender, gender identity or expression, color, religion, genetic information, marital status, ancestry, national origin, protected veteran status, physical disability, medical condition, mental disability, or disability status and any other characteristic protected by state or federal law. If you’re an individual with a disability or a disabled veteran who needs assistance using our online job search and application tools or need reasonable accommodation to complete the job application process, please contact us by phone at 310.336.5432 or by email at ieo.mailbox@aero.org. You can also review The Equal Employment Opportunity is the Law poster and the supplement, as well as the Pay Transparency Policy Statement.","The Aerospace Corporation
3.9","El Segundo, CA",Aerospace & Defense,Aerospace & Defense
Data Scientist,"Job Description
Company Mission and Highlights:

mPulse Mobile, the leader in Conversational AI solutions for the healthcare industry, drives improved health outcomes and business efficiencies by engaging individuals with tailored and meaningful dialogue. mPulse Mobile combines behavioral science, analytics and industry expertise that helps healthcare organizations activate their consumers to adopt healthy behaviors. With over a decade of experience, 70+ healthcare customers and more than 150 million conversations annually, mPulse Mobile has the data, the expertise and the solutions to drive healthy behavior change.

Our Core Values:
Model Integrity and Collaboration
Drive Innovation and Thought Leadership
Support Decision Making at All Levels
Create Value for Clients by Empowering Consumers
Improve Customer Experience Through Simple Design
Celebrate Success… Often
Purpose of the Role:

The mission of the Behavioral Data Science Team is to design and develop tailored content and algorithms driven by behavioral science and data analytics that drive better patient engagement and health outcomes. The Behavioral Data Science will assist with several projects relating to disease management and behavior change using mobile messaging.

We need someone who is comfortable with using data to track, understand and improve our programs. The Behavioral Data Science will also assist and manage the successful delivery of innovative solutions which includes troubleshooting the mobile solution, tracking user responses, collecting and summarizing data, writing new content and evaluating program needs. This requires a multidisciplinary blend of data handling, behavioral science and program coordination. The candidate should have experience working within behavioral science, have excellent organizational skills, be highly adaptable, be able to work independently and be able to work well as a member of a team.

Duties and Responsibilities:
Testing interactive text message workflows that engage users and drive them to be more activated about their health – whether making an appointment to see a doctor or taking on a health challenge to walk 10k steps every day for a week.
Gathering demographic data about different populations (age, income, ethnicity, zip code, etc.) to help the team build a model that uses the social determinants of health as a predictor of health and behavior change.
Analyzing patient responses to our messages to identify whether our message handling rules need to be changed or added.
Generate statistical reports to track performance using SQL, Excel, R and Tableau for data extraction, analysis, and visualization.
Helping generate new content to improve our behavior change programs.
Skills, Abilities, and Experience:
Bachelor’s degree, preferably in cognitive psychology or cognitive science
Experience in healthcare industry preferred
1-2 years of experience with SQL, Excel and R or Python
3-5 years of non-academic experience working in health care or behavioral science with a substantial portion of that time related to understanding consumer engagement, using data analytics, and tracking outcomes of innovative programs and policies. Candidates do not need to have experience in all of these areas but should have solid experience in at least one of them.
Strong writing and content development skills
Experience in research methods in behavioral science and exploratory data analysis
Intense intellectual curiosity – strong desire to always be learning new technologies
Analytical, creative, and innovative approach to solving difficult problems
Ability to communicate clearly and effectively – verbally and in writing
Extensive experience working with messy and diverse data-sets to generate both qualitative and quantitative analyses. (Our data at mPulse comes from a range of sources and is mostly unstructured and qualitative data. As a result, extracting relevant features from this data requires experience working with complex behavioral and social sciences data rather than conventional “big” data).
Have extensive experience pulling data from RDBMS using SQL for data analysis, data modeling and feature engineering; ability to write scripts using Python or R for data manipulation
Hands-on knowledge and experience with ML algorithms such as Bayesian classifiers, clustering, neural networks (CNN, RNN, deep learning, etc.), SVM, and decision trees. Have used in at least one or more of the following frameworks: Tensorflow, SciKit-learn, NumPy, Pandas, Weka, etc.
Health care domain expertise (i.e., expertise in impact evaluation, data analysis and intervention design as it relates to health and healthcare)
Experience with authoring project reports, briefs, and webinar presentations
Experience working with Tableau
Minimum Experience:
Advanced degree (or Bachelor's degree with relevant experience) in economics, psychology, sociology or statistics.
Thorough understanding and hands on experience with implementing behavioral science and/or behavioral economics theories within patient engagement programs
Behavioral Competencies:
Results oriented with a strong sense of urgency, and able to pivot as requirements change
Strong verbal and written skills for communicating with fellow team members and clients
Able to take charge and thrive in uncharted territory and with complex and ambiguous problems
Highly curious and able to independently learn new methodologies, tools, and processes as needed
Strong aptitude and passion for healthcare, technology and technology related innovation
Values accuracy and quality, is very detail oriented, and is highly organized
The Perks:
Enjoy flexible PTO and work hours
Full Vision, Dental and Healthcare - all individual premiums paid by mPulse!
401K Program with a 100% match of first 4%
3 Weeks Paid Maternity/Paternity Leave
Weekly team lunches to celebrate victories
Paid Parking as well as Car Pooling incentives
Laptop fitness stations
Ping pong conference table and Foosball
Free snacks and drinks
Contact Information:

mPulse Mobile, Inc.

Attn: HR Dept.

16530 Ventura Blvd, Suite #500

Encino, CA 91436

careers@mpulsemobile.com

(mPulse is an Equal Opportunity Employer)

Powered by JazzHR

FF5PoEzbdl","mPulse Mobile
3.7","Los Angeles, CA",Health Care Services & Hospitals,Health Care
Data Scientist,"Position Overview

Our data science team is expanding! The successful candidate will work with the data science and engineering teams on challenging projects in a variety of domains.

Beyond Limits is a pioneering Artificial Intelligence company and a satellite of NASA's Jet Propulsion Lab and Caltech. Beyond Limits cognitive computing technology combines numeric and symbolic techniques to provide advanced solutions that go far beyond conventional AI.

Job Duties/Responsibilities
Ingest, organize, and analyze data from various sources (e.g. CSV, relational database)
Scope unstructured problems or messy data for tractable insights
Identify candidate statistical or machine learning solutions and test their efficacy
Communicate technical work and findings both verbally and through written reports and visualizations
Work in a collaborative environment to brainstorm, design, implement and deliver solutions to challenging problems
Qualifications and Skills
5+ years of relevant industry work experience
Excellent understanding of statistical or machine learning techniques, such as clustering, regression, time series forecasting, tree-based methods, sampling methods
Demonstrated ability using scientific computing libraries, such as NumPy, Pandas, SciPy, Scikit-learn, Matplotlib, and Plotly
Programming proficiency in Python or R
Preferred Requirements
Ph.D. or Master’s
Strong statistical knowledge and experience with hypothesis testing
Fluency with machine learning algorithms, such as CNN, RNN, reinforcement learning, support vector machines, and graph-based models
Experience with TensorFlow, Keras, or PyTorch
Experience with version control systems (e.g. Git flow)
Strong oral and verbal communication skills
Research experience with high impact publications
Experience working with cross-functional teams and/or customer facing work
About Beyond Limits
Beyond Limits is a pioneering Artificial Intelligence engineering company creating advanced software solutions that go beyond conventional AI. Founded in 2014 with a legacy in space exploration, Beyond Limits is transforming proven technologies from Caltech and NASA’s Jet Propulsion Laboratory into advanced AI solutions, hardened to industrial strength, and put to work for forward-looking companies on earth. We leverage this unparalleled innovation portfolio, along with proprietary cognitive technologies, to help companies solve tough, complex, mission-critical problems and transform their business. We apply a unique hybrid approach to AI, combining numeric AI techniques like machine learning with higher-order symbolic AI and expert human knowledge to deliver intuitive cognitive reasoning and information. Our cognitive computing technology mimics human thought processes and provides explainable reasoning to aid human-like decision-making.

Beyond Limits provides equal employment opportunities (EEO) to all employees and applicants for employment without regard to race, color, religion, sex, national origin, age, disability or genetics. In addition to federal law requirements, Beyond Limits complies with applicable state and local laws governing nondiscrimination in employment in every location in which the company has facilities. This policy applies to all terms and conditions of employment, including recruiting, hiring, placement, promotion, termination, layoff, recall, transfer, leaves of absence, compensation and training.

Beyond Limits expressly prohibits any form of workplace harassment based on race, color, religion, gender, sexual orientation, gender identity or expression, national origin, age, genetic information, disability, or veteran status. Improper interference with the ability of Beyond Limit’s employees to perform their job duties may result in discipline up to and including discharge.","Beyond Limits
4.2","Glendale, CA",Research & Development,Business Services
Data Scientist,"Want to help the largest global telecom enterprises derive business value through the adoption of Artificial Intelligence (AI) and Machine Learning (ML)? Excited to help customers define use cases for massive amounts of disparate data to develop ML models? Eager to learn to apply ML to a diverse array of telecom use cases? Thrilled to be a part of Amazon who has been pioneering and shaping the worlds AI/ML technology for decades?

At Amazon Web Services (AWS), we are helping large enterprises build ML models on the AWS Cloud. We are applying predictive technology to large volumes of data and against a wide spectrum of problems.

AWS Professional Services team members leverage their deep knowledge of AIML and AWS technologies in collaboration with our sales and partner teams to propose, architect, and implement transformational solutions for customers. Helping make customer success a reality using AIML as an enabler and seeing the impact in real-time drives our teams to explore new frontiers in leveraging AWS for our customers.

The AIML Customer Delivery Architect (CDA) is a growth role within the Professional Services umbrella, and is principally oriented around a qualify-deliver-manage model. The CDA is responsible for partnering with Telecom Industry Professional Services leaders to dive deep into a customers business challenge, to collaboratively propose and qualify a particular set of outcomes, and lead a project/program to ensure high-value, predictable, and successful delivery.

A successful candidate will be a person who enjoys diving deep into data, doing analysis, discovering root causes, and designing long-term solutions. It is an individual with a unique hybrid of AWS platform expertise and hands-on building, coupled with cross-industry business acumen, including a heavy dose of passion for continued knowledge acquisition and growth, obsession for customers, and their success using AWS that will align well with the desired outcomes to be produced.

ROLE AND RESPONSIBILITIES
· Participate in deep architectural discussions and design exercises to create world-class solutions built on AWS while ensuring solutions are designed for successful deployment in the cloud
· Assist customers by being able to deliver a ML project from beginning to end, including understanding the business need, aggregating data, exploring data, building & validating predictive models, and deploying completed models with concept-drift monitoring and retraining to deliver business impact to the organization
· Be familiar with AWS AI services (e.g., Personalize), ML platforms (SageMaker), and frameworks (e.g., MXNet, TensorFlow, PyTorch, SparkML, scikit-learn) to help our customers build ML models
· Research and implement novel ML approaches, including hardware optimizations on platforms such as AWS Inferentia
· Work with our other Professional Services consultants (Big Data, IoT, HPC) to analyze, extract, normalize, and label relevant data, and with our Professional Services engineers to operationalize customers models after they are prototyped
· Author or otherwise contribute to AWS telecom customer-facing publications such as whitepapers and proof of concepts
· Build deep relationships with senior technical individuals within customers to enable them to be cloud advocates
· Capture and share best-practice knowledge, sales and delivery content amongst the AWS Professional Services community
This is a customer-facing role and you will be required to travel to client locations and deliver professional services as needed.


Basic Qualifications

· Bachelors degree in a highly quantitative field (Computer Science, Machine Learning, Operational Research, Statistics, Mathematics, etc.) or equivalent professional or military experience
· Experience with ML fields, e.g., natural language processing, computer vision, statistical learning theory
· 6+ years of industry experience in predictive modeling, data science, and analysis
· Experience in an ML engineer or data scientist role building ML models
· Experience writing code in Python, R, Scala, Java, C++ with documentation for reproducibility
· Experience handling terabyte size datasets, diving into data to discover hidden patterns, using data visualization tools, writing SQL, and working with GPUs to develop models


Preferred Qualifications

· Maters degree of PhD in a highly quantitative field (Computer Science, Machine Learning, Operational Research, Statistics, Mathematics, etc.)
· Experience writing and speaking about technical concepts to business, technical, and lay audiences and giving data-driven presentations
· Demonstrated ability to think strategically about business, product, and technical challenges
· Customer facing skills to represent AWS well within the customers environment and drive discussions with senior personnel regarding trade-offs, best practices, project management and risk mitigation
· Ability to develop strategic, baselined, data modeling processes; ability to accurately determine cause-and-effect relationships.
· Publications or presentations in recognized ML journals or conferences
· Deep technical skills, consulting experience, and business savvy to interface with all levels and disciplines within our customers organization
· Demonstrable track record of dealing well with ambiguity, prioritizing needs, and delivering results in a dynamic environment
· Experience architecting/operating solutions built on AWS
· Ability to understand and articulate business impact of technical decisions
· A proven track record of managing and delivering large-scale enterprise IT projects.

Amazon is committed to a diverse and inclusive workplace. Amazon is an equal opportunity employer and does not discriminate on the basis of race, national origin, gender, gender identity, sexual orientation, protected veteran status, disability, age, or other legally protected status. For individuals with disabilities who would like to request an accommodation, please visit https://www.amazon.jobs/en/disability/us.","Amazon
3.9","Santa Monica, CA",Internet,Information Technology
Data Scientist,"In this role you will join the Aviana Data Science practice as an individual contributor. You will be working on both client projects and strategic solutions development by leveraging your deep analytical skills and your ability to implement complex analytical methods using current Data Science tools and languages.

Responsibilities
Work on end-to-end predictive modeling engagements with Aviana clients
Contribute to multiple projects at the same time, as demand requires
Support team members with aspect of the projects that require advanced R/Python programming
Develop visualizations and presentations that communicate data insights and modeling results to business users.
Contribute to Aviana strategic solutions development in a Data Science role; collaborate with the Product Management and Product Development leads
Qualifications
Master degree in Computer Science, Statistics, Mathematics, Physics, Operations Research, Econometrics or related field – PhD Preferred
At least 5 years of relevant experience in Data Science, in particular with:
Advanced data preparation and transformation
Features engineering
Predictive model design, from approach to implementation
Non-predictive analytics, such as clustering, anomaly detection, PCA, etc
Model interpretation and communication of results to non-technical stakeholders
Model deployment and scoring in a production environment
Prior experience in a consulting role, with strong communication and presentation skills
Excellent data science programming skills: R and Python and associated data science-related libraries are mandatory. Knowledge of other programming and scripting languages as well data analytics platforms skill is a plus.
Advanced knowledge of relational databases and SQL
Knowledge of the tools and technologies in the Big-Data Ecosystem (Hive, Pig, Spark, Scala, etc) a plus
To learn more about Aviana and this position, please email your resume to recruiter@avianaglobal.com.","Aviana Global Technologies
4.2","Brea, CA",IT Services,Information Technology
Data Scientist,"About IpsosIpsos is the world's third largest market research company, present in 90 markets and employing more than 18,000 people. Our passionately curious research professionals, analysts and scientists have built unique multi-specialist capabilities that provide true understanding and powerful insights into the actions, opinions and motivations of citizens, consumers, patients, customers or employees. We serve more than 5000 clients across the world with 75 business solutions.Founded in France in 1975, Ipsos is listed on the Euronext Paris since July 1st, 1999. The company is part of the SBF 120 and the Mid-60 index and is eligible for the Deferred Settlement Service (SRD).ISIN code FR0000073298, Reuters ISOS.PA, Bloomberg IPS:FP www.ipsos.comData ScientistLocation: Culver City, Los Angeles CaliforniaDivision: Global Science Organization (GSO), Data Science & AI LabThe Data Science & AI Lab of the Ipsos GSO is a uniquely positioned group within Ipsos. We serve as the global R&D capability bridging data science with market research offerings. The team develops analytic tools, builds data science models for pilot studies and internal stakeholder analytics innovations, and consults on a broad range of data and research best practices. Working in a collaborative and supportive environment, we seek to expand what is possible in market research with data science.We're looking for someone with a deep interest in data and analytics and the dedication to apply that passion. We need someone that possesses the technical ability to write production-level code and implement data science methods for a diverse set of applications, as well as uncover insights from the models and communicate them concisely and clearly to stakeholders at varying levels of technical sophistication. The role also requires an observant attention to detail, the ability to work well on a small team, and a self-starter approach to problem-solving and debugging.As a Data Scientist, you will:* Work closely with team members on design and execution of large-scale modeling efforts, contributing to analytics libraries and integrating statistical theory* Collaborate on engineering new data science products by translating needs identified with stakeholders into analytic frameworks that can be built into polished user-facing tools* Build, maintain, and enhance existing codebases* Synthesize academic research, tech innovations, and cloud scalability, to elevate business value for clients, both current and prospective* Validate analytics innovations from marketing science and data science teams globally* Provide consulting for internal teams and clients on data engineering and hygiene, areas for improving process efficiency, and data science algorithms and resultsRequirements:* High proficiency writing R and/or Python, including the ability to produce and maintain reusable and modular codebases* Bachelor's degree* Desire to work in a highly collaborative, fun, consensus-oriented environment.* Experience in analytics, extracting and surfacing value from quantitative data* Attentive learner with excellent time-management skills* Ability to lucidly communicate data science concepts verbally and in written formPluses:* Professional or academic experience with modern techniques and algorithms in machine learning and statistical computing such as neural networks, genetic algorithms, Bayesian modeling, data fusion, drivers analysis, clustering, predictive analytics, network analysis, Monte Carlo, and agent-based models.* Experience developing data science models in cloud platforms (e.g. GCP, AWS)* Working knowledge of SQL and experience with database design and administration.* Experience with Linux server and system administration.* Experience with collaboration tools (e.g. Atlassian suite) and version control systems (e.g. Git).* Experience integrating R and/or Python with each other and C\C++.* Large dataset manipulation. Experience in distributed storage and computing.* Experience with ReactJS, TypeScript/JavaScript, visualization libraries (e.g. d3.js).* Experience creating and deploying web apps (e.g. Electron, web2py).* Advanced degree (M.S., Ph.D.), but not required.* Experience in the field of Market Research.Ipsos is An Equal Opportunity Employer. All qualified applicants will receive consideration for employment without regard to age, race, color, religion, sex, sexual orientation, gender identity, national origin, protected veteran status, or any other protected class and will not be discriminated against on the basis of disability. For all future offer negotiations - please target April 6th or after for their start date.","Ipsos
3.2","Culver City, CA",Consulting,Business Services
Data Scientist,"The Business

GradTests.com is a leading provider of practice psychometric tests to graduates, students and young professionals.

The Role

A data science all rounder role. The core purpose of the role is to build models to improve the product, the customer experience and ultimately the business. We're looking for someone with a nice blend of technical skills, and softer skills like business acumen, decision making and communication skills.

You'll do things like:
Conceive, devise, create, implement and fine tune data science models to solve a range of business problems, from customer churn through to
Set up, run and analyse A/B experiments for the website and email marketing campaigns
Help devise and layout a high quality infrastructure, upon which future data science can flourish
Help up skill other analytical team members into advanced data science techniques
Produce ad hoc analyses
And let's be honest, a whole load of data wrangling!
Skills and experience

Non negotiables:
SQL
Python or R
Data science models (K-means, random Forrest, neural nets etc.)
Strong foundational knowledge in stats and maths
Experience in actually productionising models and exposing to real customers
Business acumen
Strong communication skills, both written and verbal
Nice to haves:
Experience in working with developers, especially on experimentation
Some kind of cloud based experience (AWS preferred)
Some basic knowledge of source control with Git
Our application process consists of some online testing with Alooba, video call interview and then a case study. We expect the process to take about 10 business days end to end.

Job Types: Full-time, Contract

Salary: $120,000.00 /year

Experience:
Analytics: 1 year (Preferred)
Work Remotely:
Yes",GradTests (gradtests.com),"Los Angeles, CA",-1,-1
Statistician,"The U.S. Department of the Treasury has a distinguished history dating back to the founding of our nation. As the steward of U.S. economic and financial systems, Treasury is a major and influential leader in today's global economy. We have over 100,000 employees across the country and around the world. Come Join the Department of the Treasury and Invest in Tomorrow.
See Other Information for Locations
Positions are to be filled in the Large Business & International (LB&I), Data Solutions division.
Eight (8) positions are to be filled in any of the following locations:
Birmingham, AL
Fayetteville, AR
Little Rock, AR
Phoenix, AZ
El Monte, CA
Glendale, CA
Laguna Niguel, CA
Los Angeles, CA
Long Beach, CA
Oakland, CA
Sacramento, CA
San Diego, CA
San Francisco, CA
San Jose, CA
Santa Ana, CA
Lakewood, CO
Hartford, CT
New Haven, CT
Norwalk, CT
Washington, DC
Newark, DE
Miami, FL
Ft. Myers, FL
Jacksonville, FL
Maitland, FL
Plantation, FL
Tampa, FL
West Palm Beach, FL
Atlanta, GA
Honolulu, HI
Des Moines, IA
Chicago, IL
Downers Grove, IL
Schiller Park, IL
Springfield, IL
Indianapolis, IN
Wichita, KS
Louisville, KY
New Orleans, LA
Boston, MA
Brockton, MA
Stoneham, MA
Southborough, MA
Baltimore, MD
Lanham-Seabrook, MD
Rockville, MD
Ann Arbor, MI
Clinton Township, MI
Detroit, MI
Farmington Hills, MI
Flint, MI
Grand Rapids, MI
Pontiac, MI
Bloomington, MN
Chesterfield, MO
Lee's Summit, MO
Charlotte, NC
Greensboro, NC
Raleigh, NC
Omaha, NE
Edison, NJ
Iselin, NJ
Mountainside, NJ
Paterson, NJ
Las Vegas, NV
Albany, NY
Bethpage, NY
Buffalo, NY
New York, NY
Rochester, NY
Cincinnati, OH
Columbus, OH
Independence, OH
Oklahoma City, OK
Tulsa, OK
Portland, OR
Philadelphia, PA
Pittsburgh, PA
King Of Prussia, PA
Guaynabo, PR
Warwick, RI
Franklin, TN
Memphis, TN
Nashville, TN
Austin, TX
Farmers Branch, TX
Fort Worth, TX
Houston, TX
San Antonio, TX
Ogden, UT
Salt Lake City, UT
Norfolk, VA
Richmond, VA
Vienna, VA
Seattle, WA
Milwaukee, WI
Waukesha, WI
Kearneysville, WV
Martinsburg, WV
WHAT DOES A DATA SCIENTIST DO? The Data Scientist utilizes advanced analytical, statistical, and computer programming skills to develop data- driven solutions to difficult business challenges. As a data scientist, you are responsible for conducting data-centric projects to provide insight and informed decisions for mission- oriented programs of the Internal Revenue Service (IRS), which may impact multiple program segments, divisions, the Service, or segments of the taxpayer population. This is accomplished by utilizing a wide range of technical competencies such as statistics and machine learning, coding languages, data wrangling, and reporting and visualization techniques. The Data Scientist may lead team or cross functional projects, and will apply critical thinking, problem solving and ability to communicate complex analysis to advance the use of data-driven decision making in IRS operations.

WHAT IS THE LARGE BUSINESS AND INTERNATIONAL (LB&I) DIVISION OF THE INTERNAL REVENUE SERVICE? The Large Business and International (LB&I) business unit provides service and enforcement activities to support tax compliance of businesses and related entities with assets of $10 million or more, as well as small U.S. businesses engaged in international, U.S. citizens abroad, and foreign persons and businesses with a U.S. tax requirement.
As a Data Scientist, you will:
Serve as a technical expert with responsibility for the initiation, planning, implementation, controlling, modifying and executing of all or part of an entire project, including such tasks as formulation of workload estimates for program segments, specification of the methodology to be used, preparation of appropriate specifications and procedures, and review of computer systems specifications and materials and instructions needed for assuring the adequacy of the project’s design and objectives.
Explore novel methods of retrieving data and develop innovative recommendations to management and senior leadership as a means for making data driven decisions such as modification of processes and policies. Review, evaluate, validate, and document the results of the findings.
Assist the supervisor in determining the scope, goals and schedules for future programs in the Office. Collaborate with business or technology partners to understand business needs, identify opportunities, and develop and implement analytical solutions.
Identify and assess relevant data sources’ validity and reliability to meet project needs. Collate, clean, transform, analyze, and integrate structured and unstructured data from various sources in preparation for analysis.
Apply statistical methods and concepts including data mining, statistical theory and research procedures to test hypotheses using structured and unstructured data. Develop data product solutions to improve customer experiences, anomaly detection, and business outcomes. Develop proofs of concept or demonstrations to evaluate feasibility of project solutions and recommend visualization strategies.
Document project work and review deliverables for validity, reliability and timeliness. Communicate analytic solutions to technical and non-technical stakeholders, including during executive- level and/or cross-agency meetings, in a clear and effective manner using oral and written communications.
Maintain knowledge of state-of-the-art innovations in data science from both academic and industry sources and identify opportunities for implementation. Engage in general professional development to improve knowledge of IRS processes/programs.
Apply computer based mathematical/statistical techniques using software. Lead or participate in statistical projects or studies in survey sampling (design and estimation), modeling, or statistical research. Apply knowledge of programming/coding language (i.e., SQL, SAS, SPSS, RStudio) to develop scripts or applications.
Act as a troubleshooter in resolving bottlenecks at any step in a project by identifying and proposing solutions; this may include coordination with other project team members or stakeholders to mitigate issues.

WHERE CAN I FIND OUT MORE ABOUT OTHER IRS CAREERS? If you want to find out more about IRS careers, visit us on the web at www.jobs.irs.gov
#LI-POST
You must meet the following requirements by the closing date of this announcement
BASIC QUALIFICATION REQUIREMENTS:

GS-1530 Statistician All Grades:
You must have a Bachelor's degree that included 15 semester hours in statistics (or in mathematics and statistics, provided at least 6 semester hours were in statistics), and 9 additional semester hours in one or more of the following: physical or biological sciences, medicine, education, or engineering; or in the social sciences including demography, history, economics, social welfare, geography, international relations, social or cultural anthropology, health sociology, political science, public administration, psychology, etc. Credit toward meeting statistical course requirements should be given for courses in which 50 percent of the course content appears to be statistical methods, e.g., courses that included studies in research methods in psychology or economics such as tests and measurements or business cycles, or courses in methods of processing mass statistical data such as tabulating methods or electronic data processing. OR
Combination of education and experience -- courses as shown above, plus appropriate experience or additional education. The experience should have included a full range of professional statistical work such as (a) sampling, (b) collecting, computing, and analyzing statistical data, and (c) applying statistical techniques such as measurement of central tendency, dispersion, skewness, sampling error, simple and multiple correlation, analysis of variance, and tests of significance.
GS-13 LEVEL: You must have one year of specialized experience at a level of difficulty and responsibility equivalent to the GS-12 grade level in the Federal service. Specialized experience for this position includes all of the following:
Experience applying project management principles on a data science project
Experience planning and executing a variety of data science and/or analytics projects.
Experience using data mining process models (such as CRISP-DM, SEMMA, etc.,) to design and execute data science project.
Experience preparing and analyzing structured and unstructured datasets to explorations and evaluating data science centric models.
Experience working with multiple data types and formats as a part of a data science project.
Experience applying a range of analytic approaches, including (but not limited to) machine learning, text analytics, and natural language processing; graph theory, link analysis and optimization models; complex adaptive systems; and/or deep learning neural networks that are part of the exploration.
Experience coding in various programming languages (such as R, Python, SQL, or JAVA) to conduct various phases of data science projects.
Experience creating and querying different datastores and architectures (such as Sybase, Oracle, and open-source databases) to work with various types of data as part of the data science project.
Experience using tools for data visualization (graphs, tables, charts, etc.,) and end-user business intelligence.
-The experience may have been gained in the public sector, private sector or Volunteer Service. One year of experience refers to full-time work; part-time work is considered on a prorated basis.
-To ensure full credit for your work experience, please indicate dates of employment by month/year, and indicate number of hours worked per week, on your resume.","Internal Revenue Service
3.5","Los Angeles, CA",Federal Agencies,Government
Data Scientist,"ConsumerTrack is unique in the digital marketing and media industry - we combine marketing, digital, content and fintech. Our performance based approach increases brand awareness and generates targeted audience engagement on our internal web properties and partner sites.

Learn More About What We Do

ConsumerTrack is building new technology to improve our performance while elevating the user experience for the millions of people that engage with our content and financial partnerships. ConsumerTrack is seeking a Data Scientist with digital marketing experience to analyze large amounts of raw information to find patterns and build models that will allow for machine learning to drive additional automation and improved performance. We will rely on you to build data products to extract valuable business insights.

In this role, you should be highly analytical with a knack for analysis, math and statistics. Critical thinking and problem-solving skills are essential for interpreting data. We also want to see a passion for machine-learning and research.

Your goal will be to help our company analyze trends to make better decisions

Responsibilities:
Analyze large amounts of data and information with statistical rigor to discover optimization opportunities.
Ensure accurate interpretation by combining business acumen with detailed data knowledge and statistical expertise.
Develop causal inference methodology to analyze behavior in cases where A/B testing may not be possible.
Build statistical models that better leverage test results to uncover insights or effect changes in the product.
Translate analytical insights into concrete, actionable recommendations for business or product improvement, and communicate your research and insights to all levels of the company, clearly and concisely.
Identify valuable data sources and work with data engineers to undertake preprocessing of structured and unstructured data
Build predictive models and machine-learning algorithms for digital ad conversion, pacing, and yield
Combine models through ensemble modeling
Propose solutions and strategies to business challenges
Hands-on experience of statistical modeling from conceptualization, methodology creation, deployment and validation and ultimately delivering final insightful recommendations.
Robust mathematical skill, with strong working knowledge in some and the ability quickly to be competent in the rest of the gamut of modeling techniques and associated tooling, for examples:
Established statistical methods for data reduction (e.g., factor analysis, PCA) and for prediction (e.g., regression);
Established machine learning methods for feature extraction (e.g., neural nets), for data reduction (e.g., clustering) and for prediction (e.g., decision trees, graph/network analysis);
Excellent understanding of machine learning algorithms, such as k-NN, Naive Bayes, SVM, Random Forests, ensembles, etc.
Experiencence with common data science toolkits, such as sklearn, tensor-flow, keras, gensim, etc and NLP toolkits such as nltk, spacy, etc
Experience with data visualisation tools such as D3.js, plotly / seaborn / matplotlib / tensor-board, Tableau, etc
Proficiency in working with both NoSQL and relational databases such as DynamoDB, Elasticsearch, etc
Expert proficiency with statistical modeling tools like SAS, R, Python, etc.
Good scripting and programming skills using Python, bash, etc
Strong communication and interpersonal skills (both written and verbal)
Master's or advanced degree with 3+ years experience in CS, Statistics, Machine Learning, Applied Mathematics or a related field, PhD a plus.
Competitive salary with excellent growth opportunity; we pride ourselves in having a team that exudes leadership, high initiative, creativity and passion.
Awesome medical, dental and vision plans with heavy employer contribution
Paid maternity leave and paternity leave programs
Paid vacation, holidays, and sick days
Flexible time/work from home (for eligible employees)
Company funding for outside classes and conferences to help you improve your skills
Contribution to student loan debt payments after the first year of employment
401(k) -- employees can start contributing immediately. After the first year, CTI contributes 100% of the first 4% contributed of salary deferrals
In-office gym and weekly fitness and yoga classes
Fully stocked kitchen with snacks and beverages
We are an equal-opportunity employer, and all qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, disability status, protected veteran status, or any other characteristic protected by law.","ConsumerTrack
3.2","El Segundo, CA",Internet,Information Technology
Data Scientist,"Our entertainment company is seeking a Data Scientist to join our team! This is a critical role specializing in the application of machine learning methods to meet optimization and efficiency. The Data Scientist will work closely with engineering and business partners and collaborate across teams to resolve issues and provide automated solutions for our products.

We utilize and develop cutting-edge technology to deliver high-end and creative content on a global scale. We work across multiple platforms to transform how we see media. The ideal candidate will possess all of the required skills listed below and more! They will demonstrate excellent interpersonal and communication skills and adhere to the standards of quality and excellence at our company's core.

Please, only apply if you are able to work directly for a U.S. company for the next three years. We are not currently able to work with C2C, H1, or OPT for this position.

Duties & Responsibilities:
Reframe objectives as machine learning tasks.
Productively implement and execute machine learning.
Demonstrate how models and systems work for stakeholders.
Collaborate with other teams to create data-based products.
Process and verify data used for analysis.
Improve data collection procedures to develop better ML models.
Create automated anomaly detection systems and track performance.
Develop prototype solutions, mathematical models, algorithms, machine learning techniques, and analytics to support analytic visualization of complex data sets.
Provide recommendations to drive KPIs established by product, marketing, operations, PR teams, etc.
Explore new experimental methods and statistical techniques that will sharpen the product decision-making process.
Develop and deploy testing hypotheses and analyze test results.
Provide necessary analytical rigor to ensure date quality, consistency, and accuracy of insights.
Participate in an Open Source learning environment.
Qualifications:
5+ years of experience in Data Science.
Bachelors degree in Computer or Data Science.
Experience with ML frameworks (TensorFlow, SparkMLlib, Apache Mahout, PySpark, Torch, Caffe, H2o, etc.).
Ability to deliver machine learning techniques in real-time applications.
Expertise in modern statistics, data science, and machine learning.
Expertise in a statistical programming language (Python and R) and data access tools (SQL).
Knowledge and experience with classic statistical modeling techniques (ogistic regression, CART, K-means clustering) and machine learning algorithms (gradient boosting, neural networks, random forest).
Able to handle large, ambiguous streams of data across different formats and entry points.
Experience processing large datasets and cloud environments (AWS, Snowflake and Big Data technologies (Hadoop, Spark).
Ability to develop high value features.
Experience deploying models in real-time environments.
Able to present data science results to clients.
Experience with Apache Spark MLlib, Apache Spark GraphX, and Scala/Java, preferred.
Powered by JazzHR",Evolvinc,"Burbank, CA",IT Services,Information Technology
Data Scientist,"Aspiration is the first VC-backed neobank on a mission to be the leading consumer financial services brand and company focused on sustainability and the environment. At Aspiration, we created the category of sustainable, socially responsible retail consumer finance. We offer unique financial products to let people save, spend, and invest their money in ways that make them more financially secure and align with their personal values. Unlike other financial institutions, Aspiration is committed to building a relationship with our customers based on trust and aligning the customer’s success with our own. Aspiration has raised over $200M in funding to date, and is growing quickly.

Aspiration is looking for a Data Scientist to help design and develop machine learning models to drive our business forward. This role will play a pivotal role in implementing machine learning models across our products as well as, running high business impacting analytics that will help us provide the best possible experience for our customers.
What You'll Do
Develop machine learning models, explore new prediction algorithms, construct new features, and research new technologies
Creatively leverage new and existing data to increase the effectiveness and efficiency of our decision-making infrastructure
Work with engineers to design machine learning solutions that operate quickly and effectively at scale
Apply good software development practices and actively contribute to production code where practical
Help build the next generation of data products at Aspiration
What You'll Bring
4+ years of experience in a Data Science role
Bachelor’s degree in Data Science, Computer Science, Statistics, Mathematics, Physics, Engineering or a quantitative discipline
Masters/PhD degree in Data Science, Computer Science, Statistics, Mathematics, Physics, Engineering or a quantitative discipline preferred
Strong practical knowledge of XGBoost and/or other supervised machine learning techniques
Proficient in Python specifically for Data Science: Pandas, SciKit Learn, NumPy, etc
Proficient in SQL and able to wrangle data from many disparate data sources, including JSON, XML, etc
Experience with R and other Data Science tools is a plus
Experience with GitHub is a plus
Experience with business intelligence tools, such as Looker, Tableau, etc is a plus
Experience with deploying Data Science models into production environments
Ability to work well in a collaborative team environment, and an eagerness to share skills, and develop best practices
Prior experience in FinTech is a plus
What You'll Get
Work for a mission-driven company to transform the lives of millions by building a better, values-oriented financial firm
Competitive Salary and Equity Incentives
Robust Healthcare Plans (medical, dental, vision)
401K & Unlimited Vacation Time
Diverse & Inclusive Culture","Aspiration
2.4","Los Angeles, CA",Brokerage Services,Finance
Data Scientist,"Job Description
Client JD below:

We need a technical contractor to assist on building out data cleaning and manipulation tools for our machine learning system. The contractor will sit along side our data scientists to productionize and optimize the code that we have for data ingestion and optimization, and if necessary help to build out the machine learning tools that we are using. A strong background in Python and SQL is a must as that is what our systems are built upon. Additional experience with working with Google compute and cloud services is a plus as our algorithms are being calculated on those systems. We are located in the Flatiron district.
Company Description
SkillSoniq hires great talent for projects within SkillSoniq or with our Clients. Below is the hiring process we follow:
We review applications and resumes for relevant skills and experience
Profiles that get short-listed are contacted by SkillSoniq on next steps
You then go through a few rounds of interviews for the project
If you get selected, you are advised on next steps and paid by SkillSoniq","SkillSoniq
5.0","Los Angeles, CA",-1,-1
Data Engineer,"Join SADA as a Data Engineer!

Your Mission

As a Data Engineer at SADA, you will work collaboratively with architects and other engineers to recommend, prototype, build and debug data infrastructures on Google Cloud Platform (GCP). You will have an opportunity to work on real-world data issues facing our customers today. Engagements vary from being purely consultative to requiring heavy hands-on work and cover a diverse array of domain areas, such as data migrations, data archival and disaster recovery, and big data analytics solutions requiring a combination of batch or streaming data pipelines, data lakes and data warehouses.

You will be recognized as an established contributor by your team. You will contribute design and implementation components for multiple projects. You will work mostly independently with limited oversight. You will also participate in client-facing discussions in areas of expertise.
Pathway to Success

#BeOneStepAhead: At SADA we are in the business of change. We are focused on leading-edge technology that is ever-evolving. We embrace change enthusiastically and encourage adaptability. This means that not only do our engineers understand that change is inevitable, but they embrace this change to continuously broaden their skills, preparing for future customer needs.

Your success comes from your enthusiasm, insight, and positive impact. You will be given direct feedback quarterly with respect to the scope and quality of your contributions, your ability to estimate accurately, customer feedback at the close of projects, your collaboration with your peers, and the consultative skill you demonstrate in customer interactions.

As you continue to execute successfully, we will build a personalized development plan together that leads you through the engineering or management growth tracks.

Expectations

Required Travel - 30% travel to customer sites, conferences, and other related events
Customer Facing - You will interact with customers on a regular basis, sometimes daily, other times weekly/bi-weekly. Common touchpoints occur when qualifying potential opportunities, at project kickoff, throughout the engagement as progress is communicated, and at project close. You can expect to interact with a range of customer stakeholders, including engineers, technical project managers, and executives.
Training - Ongoing with a first-week orientation at HQ followed by a 90-day onboarding schedule. Details of the timeline can be shared.

Job Requirements

Required Credentials:
Google Professional Data Engineer Certified or able to complete within the first 45 days of employment

Required Qualifications:
Expertise in at least one of the following domain areas:
Data warehouse modernization: building complete data warehouse solutions, including technical architectures, star/snowflake schema designs, infrastructure components, ETL/ELT pipelines, and reporting/analytic tools. Must have hands-on experience working with batch or streaming data processing software (such as Beam, Airflow, Hadoop, Spark, Hive).
Data migration: migrating data stores to reliable and scalable cloud-based stores, including strategies for near zero-downtime.
Backup, restore & disaster recovery: building production-grade data backup and restore, and disaster recovery solutions. Up to petabytes in scale.
Experience writing software in one or more languages such as Python, Java, Scala, or Go
Experience building production-grade data solutions (relational and NoSQL)
Experience with systems monitoring/alerting, capacity planning and performance tuning
Experience in technical consulting or other customer-facing role

Useful Qualifications:
Experience working with Google Cloud data products (CloudSQL, Spanner, Cloud Storage, Pub/Sub, Dataflow, Dataproc, Bigtable, BigQuery, Dataprep, Composer, etc)
Experience with IoT architectures and building real-time data streaming pipelines
Applied experience operationalizing machine learning models on large datasets
Knowledge and understanding of industry trends and new technologies and ability to apply trends to architectural needs
Demonstrated leadership and self-direction -- a willingness to teach others and learn new techniques
Demonstrated skills in selecting the right statistical tools given a data analysis problem

About SADA

Values: We built our core values on themes that internally compel us to deliver our best to our partners, our customers and to each other. Ensuring a diverse and inclusive workplace where we learn from each other is core to SADA’s values. We welcome people of different backgrounds, experiences, abilities and perspectives. We are an equal opportunity employer.

Make them rave
Be data driven
Be one step ahead
Be a change agent
Do the right thing

Work with the best: SADA has been the largest partner in North America for GCP since 2016 and has been named the 2019 and 2018 Google Cloud Global Partner of the Year. SADA has also been awarded Best Place to Work by Inc. as well as LA Business Journal!

Benefits: Unlimited PTO, competitive and attractive compensation, performance-based bonuses, paid holidays, rich medical, dental, vision plans, life, short and long-term disability insurance, RRSP, professional development reimbursement program as well as Google Certified training programs.

Business Performance: SADA has been named to the INC 5000 Fastest-Growing Private Companies list for 12 years in a row garnering Honoree status. CRN has also named SADA on the Top 500 Global Solutions Providers for the past 5 years. The overall culture continues to evolve with engineering at its core: 3200+ projects completed, 3000+ customers served, 10K+ workloads and 25M+ users migrated to the cloud.","SADA
4.7","Los Angeles, CA",IT Services,Information Technology
Data Scientist,"Req ID: 177448
The Job

Warner Bros. Entertainment Inc. seeks a Data Scientist for the Digital Product, Platform & Strategy: Data Intelligence Operations department. We are looking for a talented data scientist to join our Data Intelligence Team. The data scientist will be responsible for predictive modeling and analysis of customer data, as well as researching best practices in analytics and data science, and sharing them across the company to improve analytic capabilities at Warner Bros.

The Daily
Analyze and model internal customer data.
Build relationships and collaborate with analysts and researchers across WB.
Produce statistical and machine learning models that inform how we communicate with our customers.
Drive improvement in our methodologies, systems and processes.
Provide analysis, reporting, and modeling to internal organizations based on customer data.
Prepare and present results of analyses to leadership.
The Essentials
B.A./B.S. degree in Statistics, Mathematics, Computer Science, Economics, Political Science, or similar quantitative field.
Quantitative oriented Masters Degree or Ph.D preferred.
Minimum of 1-2 years of experience in analytics and data science.
1+ years of experience with conducting analysis in R, Python, SAS, or similar analytical languages.
Experience with relational databases and SQL.
Experience with working in cloud based environments like AWS a plus.
Expertise in machine learning and predictive modeling approaches such as Random Forest, GBM, xgBoost, neural networks/deep learning, etc.
Skilled researcher, able to distill large bodies of research to key findings and explain them to varied audiences.
Experience developing testing plans for evaluating campaigns or changes to products
Knowledge of basic survey design and analysis.
Strong history of identifying opportunities for developing predictive models to meet business needs.
Love of TV, Movies, Games, and Comics is a Plus!
Must be able to communicate effectively and tactfully with all levels of personnel, both in person and on the telephone.
Must be able to pay close attention to complex detail and understand written and oral instructions.
Must be able to organize and schedule work effectively.
Must be able to work well under time constraints.
Must be able to handle multiple tasks with changing priorities, communicating changes in scope and schedule to all parties concerned.
Must be able to work independently.
Must be able to maintain confidentiality.
177448","Turner Broadcasting
3.7","Burbank, CA",TV Broadcast & Cable Networks,Media
Data Scientist,"AccessHope is seeking a Data Scientist responsible for advising the business on the potential of data, to provide new insights into the business's mission, and through the use of advanced statistical analysis, data mining, and data visualization techniques, to create solutions that enable enhanced business performance.

Join a thriving company that is changing the way cancer care is delivered for millions of patients around the country. Recently spun off from an internationally renowned research and treatment hospital, AccessHope understands that cancer doesnt play by the rules, so we dont either. We are an agile, disruptive brand thats backed by a founding member of the National Cancer Center Network. Now, were joining forces with employers to bring state-of-the-art cancer expertise to their employees and give patients access to the latest developments in precision medicine, genetic risk assessment and clinical trials, regardless of where they live. The goal? To dramatically improve care, outcomes and value during cancer treatment.

Its a revolutionary new model and were looking for revolutionary thinkers to join us.

Role
Undertaking data collection, preprocessing and analysis
Building models to address business problems
Presenting information using data visualization techniques
Identify valuable data sources and automate collection processes
Analyze large amounts of information to discover trends and patterns
Follows established AccessHope and department policies, procedures, objectives, performance improvement, attendance, safety, environmental, and infection control guidelines, including adherence to the workplace Code of Conduct and Compliance Plan. Practices a high level of integrity and honesty in maintaining confidentiality.

Performs other related duties as assigned or requested.

Qualifications
Your background
Masters degree with 0+ years of experience; or
Bachelors degree with 3+ years of experience
BS/BA in Computer Science, Engineering or relevant field
Preferred
Healthcare experience a plus, but not required.
Additional skills
Understanding of machine-learning and operations research
Knowledge of R, SQL and Python; familiarity with Scala, Java or C++ is an asset
Experience with in-depth rate development templates, risk score analyses, trend analyses, cost management/financial initiatives, back-end technical development and programming
Experience using business intelligence tools (e.g. Tableau, Power BI) and data frameworks (e.g. Hadoop)
Analytical mind and business acumen
Problem-solving aptitude
Excellent communication and presentation skills
Experience in data mining
Programming
Statistics
Data Wrangling
Data Visualization & Communication
Data Intuition
Machine Learning (algorithms)
AccessHope is committed to creating a diverse environment and is proud to be an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to race, religion, color, national origin, sex, sexual orientation, gender identity, age, status as a protected veteran, or status as a qualified individual with disability.

#LI-TT","City of Hope
3.3","Irwindale, CA",Health Care Services & Hospitals,Health Care
Data Scientist,"Anchor Loans is the nation’s leading provider of quick bridge funding to fix-and-flip investors—originating more than 16,000 loans totaling over $7.25 billion since its founding in 1998. Anchor’s experience, relationships and proprietary Fintech technology platform set it apart from other lenders.

At the core of our company is our proprietary technology. We are seeking a Data Scientist to join the quickly expanding Technology Operations team. The goal of the department is to solve business needs through our proprietary technology solutions.

We are constantly improving processes and efficiencies for our operations staff. The primary focus of this position is to be an integrated quality resource for project teams on our biggest products. Anchor is an entrepreneurial company and this position will have significant impact on the future of the business and its technology solutions as we grow and expand our operations nationwide.

Responsibilities

Duties include but are not limited to:
Understand business stakeholders' needs and translate those into a data insights program with solutions for each stakeholder
Deliver on data analytics and insights by planning and performing end-to-end analysis: including aggregating and processing data, exploring data, building and validating predictive models, and presenting to business
Analyze our existing data model/structure and provide recommendations to the Tech team for optimization to support our data strategy
Design and implement statistical algorithms and predictive analysis
Explain data analytics and data science findings and machine learning models to internal and external stakeholders
Work with Data Analysts, Product Managers and Software Engineers to gather data insight requirements, set goals and influence the product roadmap
Minimum Qualifications
B.S. or M.S. in computer science, Mathematics, Statistics, Physics, Economics or equivalent experience
4+ years of industry experience in predictive analysis and modeling, data analysis and science
3+ years of industry experience in data analytics
Knowledge of data engineering, database architecture and ETL process
Experience building ML models
Proficient in either Python and R
Experience using ML libraries
Knowledge of machine learning frameworks and toolsets
Experience writing and optimizing SQL
Experience using data visualization tools
Experience presenting data findings
Preferred Qualifications
PhD in computer science, Mathematics, Statistics, Physics, Economics, Bio-Engineering/Science field
6+ years of industry experience in predictive analysis and modeling, data analysis and science
4+ years of industry experience in data analytics
Proven ability to tackle business problems with data science solutions
Expert level SQL experience; deep experience with statistical packages such as Python and R.
Ability to develop analytic plans for data modeling process
Ability to accurately determine correlations
Experience with AWS data technologies such as Redshift, S3, Data Pipeline
Experience with MS PowerBI
Skills and Competencies
Ability to think critically
Ability to translate business problems into data questions, create solutions and drive results
Ability to aggregate and analyze data from multiple data sources and build a holistic view
Ability to build clear visualizations to explain complex ideas and analysis result to executives and business unit leaders
Ability to provide guidance to other program and project managers
Ability to resolve conflicts and negotiate agreement
Ability to proactively identify impediments in project/program delivery and craft solutions
Anchor Loans, LP is subject to the California Consumer Privacy Act of 2018 (“CCPA”). A copy of Anchor’s California Privacy Policy can be found at www.anchorloans.com/privacy.","Anchor Loans LP
3.3","Calabasas, CA",Real Estate,Real Estate
Data Scientist,"Job Description
Gurucul is seeking an innovative analytics thinker for the role of senior level Data Scientist, to be part of Gurucul’s Data Science team. The candidate will be a key individual contributor responsible for the design and development of predictive models using latest technologies in machine learning. The ideal candidate will have previous experience in the Cyber Security domain analyzing large data sets to develop actionable analytics solution. The candidate must also have experience in developing business intelligence solutions to improve operational efficiency, and in using data visualization tools to help in building visualization ideas to present the results to management teams.

The individual will be responsible for the creation of data models that can be applied for variety of Cyber security and Fraud use cases. He/she must be able to pick suitable analytic techniques to address the problem and demonstrate expertise in using various algorithms and other modeling techniques.

The individual will report directly to CTO. This position will also provide candidates the opportunity to interact with some of the best brains in information security space and Fortune 500 C-level executives and showcase their skills and passion as a Data Scientist in the Cyber Security Analytics field.

Responsibilities
Development of state-of-the-art algorithms and models for Cybersecurity and Fraud use case
Work with large (terabytes of data, billions of daily transactions) structured and unstructured data sets.
Design and analysis of new algorithms for real time data analytics
Should coordinate with offshore development team to provide guidance on models and algorithms developed
Work closely and iterate quickly with product teams throughout the organization showing demos and prototypes of the models created.
Education & Experience
Prior experience in Cyber Security domain applied analytics, statistics, business intelligence, or predictive modeling
MS/PhD Computer Science, Statistics, Applied Mathematics, Physics or Engineering
Thorough knowledge and experience in supervised and unsupervised learning methods such as SVMs, linear classifiers, Bayesian networks and clustering techniques.
Possesses strong combination of theoretical knowledge and hands-on experience in statistical techniques, regression analysis and machine learning algorithms
Familiarity with reinforcement learning methods.
Comfortable with multiple databases and large data sets
Strong initiative and ability to manage multiple projects as well as ability to work well with others in a fast-paced, dynamic environment
Strong skills in scripting languages such as Python, Perl or Bash;
Proficient in core Java development and Java EE technologies
Excellent oral and written communication","Gurucul
3.0","El Segundo, CA",Computer Hardware & Software,Information Technology
Data Scientist,"Responsibilities:* Bring Creativity to Data products.* Apply machine learning methods to a variety of finance and accounting problems.* Responsible for building and maintaining the machine learning systems, data, platform and processes.* Build, integrate and deploy machine learning solutions into the BlackLine application in collaboration with product management, cloud, engineering and data science teams.* Perform qualitative and quantitative data analysis.* Cleanse and transform raw data used in machine models.* Perform data munging, data mining, clustering & classification methods, pattern recognition.* Comfortable with statistics, calculus and multivariate analysis.* Participate in ML POCs, validate the results and develop production implementations.* Build and optimize scalable machine learning solutions in the public cloud.* Familiar with SQL, Python, R, SparkML, TensorFlow, GCP, AWS, SQL Server.* Develop production systems in Python.* Work independently to research and solve business and technical problems.* Plan their work individually and as part of a team.* Mentor and train other Data Scientists on the team.Qualifications:* Strong practical experience with machine learning techniques in the industry, accounting and financial industries is a plus.* Extensive experience solving analytical problems using quantitative approaches.* Experience with machine learning algorithms for building ML models, their accuracy, cleanliness, reliability.* Experience with predictive and prescriptive analyses, modeling, and segmentation.* Have strong passion for empirical data research for practical applications.* Ability to communicate complex quantitative analysis in clear, precise, and actionable* Comfortable with complex, high-volume, high-dimensionality data from varying sources.* Very comfortable with data engineering methods and pipelines.* Expert knowledge of analysis tools such as R, Matlab, or SAS* Experience with data warehousing, relational databases, ETL, BI, data mining.* Experience in SQL, R, Python languages.* Strong familiarity with GCP and AWS, SQL Server.* Practical experience with GIT version control.* Comfortable working with open source tools in a Unix/Linux environment.* Experience with and ownership of data-informed decision-making.* Experience translating business requirements into functional, and non-functional requirements.* Strong sense of product and data ownership.* Works independently without the need for supervision.* Strong written and verbal skills - able to explain the work in plain language.* MS/PhD in Computer Science or other quantitative disciplines",BlackLine Systems,"Woodland Hills, CA",-1,-1
Data Analyst,"Job Description
We hiring a Data Analyst, for our client, an eCommerce company. The office is located in beautiful Hermosa Beach, California. Walk to the beach on your lunch!

In this role, you will help set the framework for the Digital Marketing and Data Science initiatives. We’re looking for a self-motivated critical thinker who loves the numbers! The ideal candidate will turn data into information, information into insight and insight into business decisions. We want an individual with the highest work ethics, who takes pride in telling stories with data. A team player who is an excellent communicator and quick learner.
This is a high visibility position that reports to the Director of eCommerce and offers a lot of opportunity for a resourceful, motivated individual.

In this role you will:
Provide data-driven recommendations for the marketing strategy by analyzing customer metrics from email, advertising, and sampling initiatives.
Leverage historical data to build out targeted audiences for sampling, mailing, email and advertising campaigns.
Leverage the Marketing CRM to accelerate the business by providing deeper insights into prospect and customer behaviors.
Support customer lifecycle campaigns with data-driven insights for new customer acquisition, retention, and growth.
Increase the marketing team’s use of data and set a high bar for analytics across the department.
Create dashboards and automate reports to support the Marketing team with data-driven decisions.
Assist the marketing team in pulling reports and insights for various marketing campaigns and presentations.
Work closely with the Director of Ecommerce to support all digital marketing efforts.
To succeed in this role you will need:
BS in Mathematics, Economics, Computer Science, Information Management or Statistics
Proven working experience as a data analyst or business data analyst
A proven track record of initiating and delivering actionable analyses/recommendations in order to drive business impact
Some experience building data science models to provide deeper insights
Excellent communication skills (technical and non-technical) and comfort working in a fast-paced environment
Excellent SQL skills, fluency with BI/visualization tools, deep knowledge of Excel.
Additional knowledge in R, Python, programming (XML, Javascript, or ETL frameworks) a plus
Technical expertise regarding data models, database design development, data mining, and segmentation techniques
Adept at queries, report writing and presenting findings
Ability to work autonomously
If you are a California resident applying for a job, you consent to our California Job Applicant Privacy Notice. https://hirepeopletree.com/ccpa",People Tree,"Hermosa Beach, CA",Staffing & Outsourcing,Business Services
Data Analyst,"Wellth is a fast-growing digital health startup with offices in Los Angeles and New York City. Our mission is to help people living with chronic conditions make healthier choices every day. Chronic disease is one of the largest challenges facing our nation. This challenge is largely created due to patient non-adherence to medications and care plans. Only about 50% of people with chronic conditions follow their care plan as prescribed. This creates enormous health and economic burdens on individuals, families, and communities that are largely preventable. Our platform deploys evidence-based interventions from behavioral economics through a mobile app to dramatically improve patient adherence, health outcomes, and costs of care. Wellth is at the forefront of designing powerful new tools rooted in behavioral science to deliver value to our customers: healthcare providers and insurers.

Behavioral Economics is at the heart of what we do. If you are a fan of books like Nudge, Freakonomics, and Predictably Irrational and were as excited as us that a Nobel Prize went to a professor of behavioral economics in 2017, then this is the place for you. Help us build and scale a platform that is helping hundreds of patients manage their care plan and improve their health. Visit us at www.wellthapp.com for more information.

We have created a smartphone app that uses the power of financial incentives to improve patient adherence. Our technology also provides valuable information to nurses and other healthcare professionals in the form of weekly adherence report cards and real-time alerts to help provide high-touch care to their patients. Patients check in every day by taking a photo of their medications in their hand.

Job Description

We are looking for a data geek that will turn our growing data into understandable information. This new role will provide data-driven insight across Wellth functions to help answer key questions, improving revenue, margins and users experiences and operational workflow. You will work with multiple systems and have exposure across the business. You speak SQL and love to go digging for answers and clues. Come help us grow Wellth leveraging the power of data!

Key Qualifications
2+ years using SQL and other data extraction methods to produce data that leads to answers, insight and supports decisions
A passion for providing data-driven insight that answers key questions, helping improve revenue, margins, users experiences and operational workflow
Extensive investigative skills - an ability to dive deep into the data and figure out whats really going on
Ability to walk someone through what data is being presented, where it comes from, and what it is telling us
Hands on experience creating polished, crisp reports or dashboards when appropriate for ongoing use
Get the right information to the right teams at the right time
Ability to work with multiple teams, set priorities, stay organized and work on multiple projects simultaneously
Regularly report key findings for strategic initiatives
Motivated by a fast-paced environment!
Key skills
Expert experience pulling large and complex data using SQL
Experience with different visualization approaches and when each are appropriate
Comfort with common statistical methods & analysis
Methodical, logical approach with excellent attention to detail
Experience with data visualization tools ( e.g. Periscope, Looker, Mode, Chartio, Tableau)
Strong proficiency in SQL (multiple years of experience)
Proficiency in statistical modeling working with Python/R
BONUS - Familiarity with AWS
BONUS - Familiarity with web analytics tools (e.g. Google Analytics) and/or product analytics (e.g. Mixpanel, Amplitude)
We are open to individuals interested in Part-time/Full Time opportunities","Wellth Inc.
5.0","Los Angeles, CA",Enterprise Software & Network Solutions,Information Technology
Data Scientist,"OverviewWelcome to Allscripts! Our Mission is to be the most trusted provider of innovative solutions that empower all stakeholders across the healthcare continuum to deliver world-class outcomes. Our Vision is a Connected Community of Health that spans continents and borders. With the largest community of clients in healthcare, Allscripts is able to deliver an integrated platform of clinical, financial, connectivity and information solutions to facilitate enhanced collaboration and exchange of critical patient information.

The primary purpose of the Data Scientist role is to conduct analytics research that leads to improved health outcomes across PIH Health in Whittier, CA. The Data Scientist will be responsible for enterprise-wide data analysis, scorecards and dashboard development and reporting solutions.This will role will consist of daily operational tasks and project based activities.

Responsibilities

• Conducts analytical research based on project assigned that leads to new or improved products to maintain Allscripts competitive position.
• Under direction of more senior resources, researches emerging technologies to support improved health outcomes
• Performs testing of predictive models on data
• Designs, codes, tests and documents in areas assigned on projects
• Collaborates with SMEs to select relevant sources of information
• Works with teams to support data collection, integration and retention requirements incorporating business knowledge and best practices
• Uses expected qualification and assurance of information to quantify the accuracy of metrics and analysis
• Works to ensure information is used in compliance with regulatory and security policies
• Provides on-going tracking and monitoring of performance decision systems and statistical models

Qualifications

Academic and Professional Qualifications:

• Bachelors or Masters degree in a relevant field of study (health sciences, computer science, engineering or other quantitative)

Experience:

• 2+ years experience in an healthcare analytics role
• Experience with data management
• Experience with pre-processing, cleaning of data
• Knowledge of statistical techniques
• Effectively uses research and cutting edge technology and data to solve problems
• Experience with SQL, SSIS, Tableau and database development
• Demonstrated critical thinking skills and attention to detail
• Excellent client facing skills with the ability to thrive in a highly critical, fast paced environment

Travel Requirements:

• No usual travel
• Travel to educational conferences as needed

Working Arrangements:

• Work is performed in a standard office environment with minimal exposure to health or safety hazards

At Allscripts, our greatest strength comes from bringing together talented people with diverse perspectives to support the technology needs of 180,000 physicians, 1,500 hospitals and 10,000 post-acute organizations across the globe. Allscripts offers a comprehensive compensation and benefits package, including holidays, vacation, medical, dental, and vision insurance, company paid life insurance and retirement savings.

Allscripts policy is to provide equal employment opportunity and affirmative action in all of its employment practices without regard to race, color, religion, sex, national origin, ancestry, marital status, protected veteran status, age, individuals with disabilities, sexual orientation or gender identity or expression or any other legally protected category. Applicants for North American based positions with Allscripts must be legally authorized to work in the United States or Canada. Verification of employment eligibility will be required as a condition of hire.

From a ""VEVRAA Federal Contractor"" We request Priority Referral of Protected Veterans

This is an official Allscripts Job posting. To avoid identity theft, please only consider applying to jobs posted on our official corporate site.

Job Requirements:","Allscripts
3.3","Whittier, CA",Computer Hardware & Software,Information Technology
Data Analyst,"PeerStreet is a leading marketplace for investing in real estate backed loans (www.PeerStreet.com). Data is the foundation of our operational processes, ranging from loan underwriting, lender acquisition, loan servicing, to product decision making. It is imperative for the company to have easy access to high quality data, both internal and external, in order to continuously optimize our operations and derive insights into how we can continue to improve our product and service offerings on both sides of the marketplace.

We are looking for a talented detail-oriented Data Analyst with a strong technical background and one who is passionate about developing elegant and impactful solutions to data reporting problems and creating an environment that allows users to dive deep into financial and user data with cutting-edge analytics and data insights. Your day-to-day will involve close collaboration with Engineering, Product, and Business organizations.

The Lender Experience group works on creating the best origination and funding experience for our lenders. The team builds software that helps both internal and external users manage the loan origination process and track the entire lifecycle of a loan.

The Financial Operations group works on our banking and transactions systems that move hundreds of millions of dollars monthly all while managing the vast complexity, integrations and various reporting needs. These systems handle all purchase, payment, draw, and distribution transactions at PeerStreet and are the foundation for both sides of the marketplace.

The Investor Experience group is responsible for creating a world-class experience for our investors, from initial investment to portfolio management.

Each group consists of one or more self-sufficient teams that each include product managers, designers, engineers, quality assurance and data, and each works closely with both our internal stakeholders and our customers to develop innovative solutions.

We're moving fast and transforming real estate finance. Join us if you want to make a huge impact on a very visible commercial product and transform an entire industry.

Key Responsibilities:
Develop and maintain high quality, maintainable dashboards & reports for internal and external stakeholders.
Partner with product managers, engineers and business stakeholders to become a source data expert.
Run ad hoc analyses to answer specific business or product questions that translate into.
Identify and develop methods of using PeerStreet data sets to enable scalable self-service data solutions for stakeholders.
Evangelize our data internally and teach reporting skills to other members of the organization.
Collaborate with a broad range of stakeholders, including the executive team, on translating data insights into smarter decisions and applications.
Requirements:


2+ years experience in data analysis or business intelligence.
Solid understanding of relational databases and data modeling.
Excellent SQL skills.
Excellent communication skills, both written and spoken.
Authorization to work in the United States without sponsorship.
Bonus Points:
Bachelor's degree (or better) in a STEM field
Finance or real estate experience.
Experience with self-service BI systems (Tableau, Sisense, etc)
Experience with managing ETL processes (dbt, Airflow, etc)
PeerStreet is an award-winning software platform for investing in real estate debt, acting as a two-sided marketplace that serves both investors and private lenders. Much like Amazon and Airbnb have aligned buyers and sellers through their marketplace, PeerStreet does the same, connecting investors with unprecedented access to quality real estate investments and lenders with global, diversified capital sources.

We're a private financial technology company backed by Andreessen Horowitz, Thomvest, and Felicis Ventures, among others. Founded in 2013, PeerStreet continues to grow at a rapid pace, and has already funded well over $2 billion in loans through our platform. We strive to ensure our best-in-class company culture grows with us by investing in our employees so they can perform at their best. And we walk the walk, with company equity, unlimited PTO, full health coverage, company-wide celebrations (in and out of the office), and more. So join us at our sunny headquarters in El Segundo, CA, and help us transform the real estate investing industry—forever and for the better.","PeerStreet
4.7","El Segundo, CA",Real Estate,Real Estate
Machine Learning Engineer,"Role: Machine Learning Engineer

Location: Los Angeles, New York, Flexible*

Hours: Full time

About Trevor

The Trevor Project is the worlds largest suicide prevention and crisis intervention organization for LGBTQ young people. We are a non-profit that provides 24/7 life-saving support via phone, text, and chat. We also operate the worlds largest safe space social networking site for LGBTQ youth and run innovative research, education, and advocacy programs. Weve been saving lives every day for over 20 years.

On May 7th 2019, Google announced that The Trevor Project is one of 20 organizations that will share $25 million in grants from Google.org, credit and consulting from Google Cloud, and coaching by Googles AI experts as a grantee of the Google AI Impact Challenge. The Google AI Impact Challenge was an open call to nonprofits, social enterprises, and research institutions from around the world to submit their ideas to use AI to help address societal challenges. Over 2,600 organizations applied. And on June 15, 2020, Google announced that a new cohort of Google.org engineering fellows will be joining our team full-time in 2020.

Overview of the Role

Our Machine Learning Engineer will contribute to The Trevor Projects life-saving work by developing machine learning and natural language processing models that drive significant increases in quality of care and scalability for our crisis services and other internal processes. This individual will help the team to contribute to the development of the machine learning models from concept to productionization, and integrate them across our platforms and services. The successful candidate will work closely with domain experts across The Trevor Project and will leverage advice and expertise from external partners and advisors.

Who you are
Experienced. You have at least 2 years of machine learning, using one of these libraries: TensorFlow, PyTorch, Keras; and natural language processing experience in a high-tech environment. You have developed high-performing models from concept to web production. You understand fundamental statistical methodologies
Perpetual Learner. You are energized by learning about new topics and can quickly get up to speed and contribute to initiatives
Collaborative. People love how you can explain complex concepts in a way that everyone can understand
Innovative. You stay up-to-date on the latest research in AI, but always approach the problem-solving process first with practical, simple, and proven methods
Organized and efficient. You know how to manage multiple projects and prioritize appropriately. You create clear and logical systems and processes to support your work and that of the organization
Inspirational. You love working with people and know how to excite them about the opportunities to use data and technology to improve the work that we do
Empathetic. You care about the wellbeing of LGBTQ youth and respect those around you regardless of race, ethnic origin, gender, age, sexual orientation, gender identity and physical ability
User Experience. You can put yourself in the shoes of the audience and oversee operations that prioritize their experience
Fun. The work we do is very serious, but that doesnt mean we dont have fun. We know how to have a good time and you should too
What youll do
Train and test machine learning and natural language processing models (e.g. BERT, GPT-2, etc.) in accordance with internally defined best practices
Deploy machine learning solutions and monitor for system reliability and fairness in accordance with internally defined standards for fairness, accountability, and transparency
Develop new approaches to sourcing and labeling data for machine learning models
Develop automated tools to process and evaluate data privacy protection
Evaluate and select machine learning model architectures using appropriate statistical methods
Develop optimization techniques for machine learning models
Learn the latest techniques and stay apprised of the latest research in machine learning and natural language processing
Work closely with the product team to prototype new features
Work with domain experts to understand our external and internal processes
Benefits
Generous vacation and holidays (like a full day off to celebrate Harvey Milk Day!), including Summer Fridays
Comprehensive health insurance (we pay 100% of your premiums for medical, dental, and life), including gender affirmation surgery
Fun office environment and passionate team. Its NBD around here if Daniel Radcliffe or Imagine Dragons drops into our office
The Trevor Project is an equal opportunity employer
Meaningful work at an organization that is saving the lives of LGBTQ young people every day
Your Application:

Were excited to hear from you! To join Team Trevor, please upload a resume and cover letter. Applications without cover letters will not be considered.

If this sounds like you, we are open to hiring in the following states: California, Colorado, D.C., Hawaii, Illinois, Maryland, Michigan, Minnesota, Nebraska, Nevada, New Jersey, New York, Oregon, Pennsylvania, Texas, Utah, and Virginia.","The Trevor Project
4.6","Los Angeles, CA",Social Assistance,Non-Profit
Data Analyst,"Data Analyst


A prominent financial affiliate network is seeking a Senior Data Analyst to monitor and support its data processes.
The ideal candidate would be able to develop new reports, frameworks, dashboards, and other tools for the company.

Responsibilities
Track ROI
Close interaction with IT Team to design/improve data architecture
Identify optimization opportunities using predictive modeling
Develop and implement advanced custom models and algorithms
Develop tools to monitor and analyze model performance and data accuracy

Qualifications
Bachelor in Mathematics or computer science
Knowledge of R, Python, SQL
Rigorous statistical intuition, deep understanding of core statistical principles, and extensive experience with core methods
Knowledge of advanced statistical techniques and concepts
Experience creating and using advanced machine learning algorithms

Your current skills should include
You are highly organized with the ability to multi-task and prioritize in a fast-paced culture
You are a critical thinker and able to problem solve
You have strong verbal communication skills
Russian fluency is preferred but not required
We look forward to hearing from all applicants who meet the requirements listed above.

Submit Your Resume Online","Dot818
5.0","Glendale, CA",Advertising & Marketing,Business Services
Data Analyst,"Role: Data Analyst

Reports to: Manager of Organizational Performance

Location: New York City / Los Angeles

Hours: Full time

About Trevor

The Trevor Project is the world’s largest suicide prevention and crisis intervention organization for LGBTQ young people. We are a non-profit that provides 24/7 life-saving support via phone, text, and chat. We also operate the world’s largest safe space social networking site for LGBTQ youth and run innovative research, education, and advocacy programs. We’ve been saving lives every day for 20 years.

Overview of the role

Data is at the core of Trevor’s DNA, and enables us to make informed decisions on how to expand and improve our services for hundreds and thousands of youth each year. The Data Analyst will not only help conduct high-impact analyses for cross-functional stakeholders, they will also help to build out our analytics systems that enable teams at Trevor to make data-informed decisions every single day. You will serve as a thought partner for folks across the organization on how to best structure their problem to find answers in the data.

Who you are:
Passionate.You care about LGBTQ youth. You care about saving lives. You want to come to work and feel inspired every day. You want to change the world
Tech Savvy. You’re fluent in SQL, comfortable wrangling large datasets in Excel/Google Sheets, and have experience with data visualization tools (Looker, Periscope/Sisense, Tableau) Ideally you’ve used statistical analyses tools like R or Python, and are familiar with navigating a data warehousing solution (AWS, Bigquery)
Collaborative.You have experience working in cross-functional roles and are able to clearly communicate complex analyses to folks with varying levels of data fluency
Entrepreneurial.You love thinking outside the box, building impactful systems and processes, and enjoy coming up with creative solutions to overcome obstacles
Action-Oriented.You’re a self-starter who can prioritize multiple projects at one time. You know the importance of creating metrics that are meaningful and actionable
Fun.The work we do is very serious, but that doesn’t mean we don’t have fun. We know how to have a good time and you should too
What you’ll do:
Design, analyze, and interpret results of an experiment to answer important strategic questions
Lead stakeholders - oftentimes senior level execs - through your findings and recommendations
Innovate on current and establish new analytics processes as our data needs expand
Build and automate reports, empowering end-users to make data-driven decisions themselves
Work with key stakeholders to ensure we’re capturing the data we need to, in the formats that we need
Organize our data definitions, sources, and processes to ensure longevity of the data infrastructure at Trevor
Leverage skills you’ve already built in prior roles to expand our data capacities, with opportunities to grow your technical toolstack along the way
Typical tools and technologies you’ll use:
Bigquery
Fivetran
dbt (our data transformation framework)
Sisense CDT (formerly Periscope)
Excel/Google Sheets
Jira
Benefits
Generous vacation and holidays (like a full day off to celebrate Harvey Milk Day!), including Summer Fridays
Comprehensive health insurance (we pay 100% of your premiums for medical, and dental), including gender affirmation surgery
Fun office environment and passionate team
The Trevor Project is an equal opportunity employer
Meaningful work at an organization that is saving the lives of LGBTQ young people across America every day
Your Application

We’re excited to hear from you! To join Team Trevor, please upload a CV/resume and cover letter. Applications without cover letters will not be considered.

APPLY HERE","The Trevor Project
4.6","Los Angeles, CA",Social Assistance,Non-Profit
Data Engineer,"Do you believe that people with compassion will support one another to create a better world? Well, we do! GoFundMe is the largest social fundraising community in the world and is just getting started. With over $9 billion raised from more than 120 million donations, GoFundMe is the largest social fundraising community in the world and is just getting started.Data is at the center of all decisions and strategy at GoFundMe. The Data Engineer will be a key part of our growing platform engineering team to help build scalable data platforms that enable business analytics, data science and data products, resulting in driving business growth toward a global culture of peer-to-peer giving. This role requires technical expertise in a wide variety of technologies to develop and own our enterprise data warehouse, sourcing data from various databases/web APIs and integrate data with external systems. If you are interested in working in a fast paced environment and like being challenged with fun data problems to solve, come join us in our Los Angeles or San Diego offices.What you'll be doing day to day...* Develop and maintain enterprise data warehouse (in Amazon Redshift)* Create and manage ETL data pipelines (sourcing data from databases, streaming data, various web APIs, etc.)* Integrate data from data warehouse into 3rd party tools to make data actionable* Develop and maintain REST API endpoints for data science products* Provide ongoing maintenance and enhancements to existing data warehouse solutions* Ensure data quality through automated testing* Collaborate with analysts, engineers and business users to design solutions* Research innovative technologies and make continuous improvementsWhat you bring to the role...* 3+ years as a data engineer designing, developing and maintaining enterprise data warehouse solutions consisting of structured and unstructured data* Proficiency with building data pipelines using ETL/data preparation tools* Experience with web APIs and data integrations across internal and external systems* Expertise in writing and optimizing SQL queries* Knowledge of Python, Java, C++ or other scripting languages* Experience with Spark and Scala* Good understanding of database architecture and best practices* Understanding of data science and machine learning technologies a plus* Experience with event tracking is a plus* Bachelor's degree in Engineering* Ping pong skills, a love for boba tea, and a sense of humorWhy you'll love it here...* Your work has real purpose and will be helping to change lives at a global scale.* Our people consistently vote GoFundMe a Great Place to Work®.* You can nominate your favorite GoFundMes to receive a donation from the company.* Great perks like lunch, snacks, wellness, company/team activities, and full benefits.* The company is strong and growing with incredible opportunities ahead.* We're a fun, close team of people who care about their work and impact.More about GoFundMe...https://www.gofundme.com/2019https://www.gofundme.com/c/heroeshttps://medium.com/gofundme-storieshttps://www.gofundme.com/why-gofundmeGoFundMe is changing the way the world gives. Every day friends, family, and members of the community come together to support one another and the causes they care about most. Our campaigners have raised over $9 billion for medical expenses, education, community projects, sports, emergencies, pets and other personal causes and life events--making us the world's largest crowdfunding platform.GoFundMe has assembled one of the best teams to go build the next leading consumer Internet company - including leaders from LinkedIn, Intuit, Groupon, YouTube, Facebook, Twitter, GoPro, Uber and several others. We are also funded by some of Silicon Valley's best venture capital firms, including Accel, Greylock, TCV, and others.GoFundMe is proud to be an equal opportunity employer that actively pursues candidates of diverse backgrounds and experiences. We are committed to providing diversity, equity, and inclusion training to all employees, and we do not discriminate on the basis of race, color, religion, ethnicity, nationality or national origin, sex, sexual orientation, gender, gender identity or expression, pregnancy status, marital status, age, medical condition, mental or physical disability, or military or veteran status.","CrowdRise
4.5","Los Angeles, CA",Internet,Information Technology
Data Analyst,"Company

Kharon is a research and data analytics firm that examines critical issues at the intersection of global security and the economy. Enabled by a proprietary technology platform connecting customers with expert analysts, Kharon produces structured, qualitative research and analysis for financial institutions and multinational organizations.

We are experts in assessing and analyzing markets impacted by regulatory risk, sanctioned actors, political upheaval, violent conflict, and corruption. Our approach to research and analysis utilizes open-source research methods, network analysis, and data analytics to generate insights into some of today's most complex policy, regulatory, and security issues.

This position is located in Los Angeles, CA.

About You

The successful candidate will be intelligent, accomplished, and energetic as demonstrated by his or her academic and professional credentials. They will be passionate about telling stories through data. This position requires creative and proactive critical thinking skills, an insatiable appetite for current events, foreign affairs and international policy, and an ability to manage priorities in meeting deadlines.

Individuals with additional experience in business intelligence research, conflict and illicit finance analysis, banking sector risk management and compliance, and other national security-related matters may wish to apply.

Role & Responsibilities
Work closely with expert researchers to mine large online datasets and design workflows to supercharge investigations.
Communicate the potential business value of new datasets or insights from existing datasets.
Perform exploratory analysis on large datasets to identify potential insights.
Acquire, clean, standardize, transform, structure, and store data.
Develop modules to extract data from documents and identify entities and relationships.
Maintain data integrity and consistency across multiple databases and applications.
Build dashboards and visualizations to convey status, changes, and analysis of data.
Research and learn new frameworks, languages, and technologies as needed.
Skills & Experience
Web crawling and scraping (i.e. Scrapy, Selenium, BS4).
SQL and NoSQL databases (i.e PostgreSQL, DynamoDB, Neo4J, MongoDB).
Search frameworks (i.e. Elasticsearch).
Extracting, cleaning, and structuring data from unstructured or semi-structured sources.
Proficiency in Python.
Familiarity with data visualization libraries (i.e. D3.js, Seaborn).
Professional engineering habits, including commenting code and version control (Git).
Demonstrated experience in self-directed, primary-source research.
Qualifications
1+ years professional and relevant experience.
Bachelor’s degree in a related field, or equivalent self-study and demonstrated technical proficiency.
Bonus
Demonstrated knowledge of key international security and business issues through professional or academic experience.
Proficiency in a foreign language, for example: Spanish, French, Portuguese, Arabic, Farsi, Russian, Ukrainian, Turkish, Chinese, Korean, Japanese.",Kharon,"Los Angeles, CA",-1,-1
Machine Learning Engineer,"OVERVIEW OF THE COMPANY
Fox Corporation
Under the FOX banner, we produce and distribute content through some of the world’s leading and most valued brands, including: FOX News, FOX Sports, the Fox Network, and the FOX Television Stations. We empower a diverse range of creators to imagine and develop culturally significant content, while building an organization that thrives on creative ideas, operational expertise and strategic thinking.
JOB DESCRIPTION
At Fox, we are building state of the art software and algorithms to improve the way that our media company transacts and interacts with consumers and makes vital business decisions with large revenue impacts. As a Machine Learning Engineer, you will be supporting the Data Science team by framing, posing, and translating business problems to build AI-powered solutions that directly contribute to data products. As a member of the Data Science & Engineering team, you will be designing and building scalable models & architectures upon which ML algorithms can thrive.
A SNAPSHOT OF RESPONSIBILITIES
Collaborate with data science and engineering teams to build and productionize Data Science and ML solutions
Manage enterprise-grade big data architecture and pipelines for ML projects within AWS suite of products
Collaborate with product management and engineering departments to understand company needs, devise, evaluate and implement industry-standard and beyond AI-powered solutions
Build tools and products that will increase the productivity of the Fox Data Analytics team-members developing and maintaining AI-based systems
WHAT YOU WILL NEED
3-5 years of experience as a Machine Learning Engineer with a BS, MS or Ph.D. and demonstrated implementations of Data Products using ML models, pipelines, and techniques
Hands-on experience with AWS infrastructure (AWS Certifications are a plus), including EC2, Redshift, EMR/Spark, S3, Lambda, Sagemaker, IAM, Step Functions, Containers, etc
3-5 years of experience with Python, R, Java, SQL and Pyspark in production environments
3-5 years of experience developing and working on enterprise-grade large scale systems managing terabytes of data
Knowledge of Hadoop or other distributed computing systems
Multiple Implementations that utilized best optimizations as - good memory, disk I/O, and CPU/GPU management
Familiarity with common ML processes (e.g., tree-based methods, supervised & unsupervised learning, feature engineering) and ML frameworks (e.g., scikit-learn, H2o, MLib)
Experience with automation, modular software design practices, and containers
Experience working in Agile environment
We are an equal opportunity employer and all qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, gender identity, disability, protected veteran status, or any other characteristic protected by law. We will consider for employment qualified applicants with criminal histories consistent with applicable law.","Fox Corporation
4.0","Los Angeles, CA",TV Broadcast & Cable Networks,Media
Data Analyst,"Data Analyst

Expertise.com connects over 8 million consumers annually to the best local experts in their area, whether they need a dog walker, financial advisor, or wedding photographer. With over 200,000 providers across more than 200 different industries, we dive deep into figuring out what makes a professional the best in their area of expertise and how to help the reader find the professional best for them.

We're looking for a Data Analyst based in the Los Angeles (Encino) area to join full-time. You will be joining Expertise.com at a formative time where there is large amounts of data being gathered (including site analytics, Google rankings, marketing operations, and more), but little of it exposed to the business. You will play a major role in tapping into this data to help shape & define the business strategy and execution plan going forward.

What Youll Do
Influence business strategy by discovering and exposing compelling data insights
Translate data insights into actionable recommendations, balancing strategic objectives and tactical optimization
Ensure data integrity by testing and comparing similar data sources
Build and refine models to support business growth, such as pricing and forecasting
Consult with business leaders in Sales, Marketing, Operations, Content and other team members, helping define the business strategy
What Itll Take
2 to 5 plus years of experience in a data-oriented role
Highly skilled in building queries using SQL & analysis in Excel
Experience building visualizations in tools such as Tableau, Qlikview or PowerBI
Experience with Salesforce SOQL (APEX is a plus)
Experience with Python and API creation a plus
Must be intellectually curious, extremely detail oriented and passionate about learning new technologies
A hands-on, team player with a positive outlook, an entrepreneurial spirit, the capacity to thrive in ambiguity, and the willingness to adapt to the needs of the business
Ability to work with diverse remote teams.
B.S. in engineering, economics, applied math, stats or any other quantitative field (preferred)
Who We Are
Were a small but rapidly growing team driven by a bias-to-action mentality, balanced with a sense of humor.
We love to problem-solve creatively while keeping a sharp focus on the important drivers of the business.
We prioritize relentlessly to ensure that whatever we're working on is vital to our business' growth
Were results-focused, but not afraid of failure as we lean into change and pursue our goals.
Were open to new ideas and not afraid to break the status quo
Powered by JazzHR",Expertise LLC,"Los Angeles, CA",-1,-1
Data Analyst,"WHO WE ARE

Signal Sciences is the fastest growing web application security company in the world and has been named one of the Best Places To Work in Los Angeles by the Los Angeles Business Journal. With its award-winning next-gen WAF and RASP solution, Signal Sciences protects 40,000+ applications, APIs, and over 2 trillion production requests per month. Signal Sciences' patented architecture allows our customers to embrace cloud and DevOps while bringing actionable security visibility to development, DevOps, and security teams for the first time.

We work with some of the world's most recognizable companies, like Datadog, Under Armour, Duo, and Aflac across industries, including five of the top eCommerce companies, five of the largest software companies, and many of the top companies in financial services, retail, healthcare, media, and entertainment. Signal Sciences has won numerous technology and business awards including Technology of the Year from InfoWorld. Above all, we focus on collaborating as a team to deliver a product our customers truly enjoy working with.

SUMMARY

We are searching for an analyst who is passionate about translating data into impactful insights to drive business decisions. You will work with our Sr. Data Analyst and across all departments to support key business initiatives for the company. These initiatives will help scale the business and allow Signal Sciences to continue to grow. In addition, you will own several projects, as well as work collaboratively, to continually improve reporting and data quality.

RESPONSIBILITIES
Champion the data analytics process to help inform strategic and tactical business decisions across all teams
Monitor and measure performance of all lead generation channels, analyze the effectiveness of our marketing campaigns, and identify areas for optimization of lead conversion through every stage of the funnel
Design and analyze A/B and multivariate tests to drive KPI improvement
Communicate effectively with business stakeholders with varying technical and non-technical backgrounds
Support recurring and ad hoc requests from stakeholders by gathering, analyzing, interpreting data, and communicating the relevant results effectively
Use statistical and predictive modeling techniques to answer key business questions
Build out data documentation in Confluence
QUALITIES / EXPERIENCE WE'RE SEEKING
You enjoy using data to tell and communicate a story
Proficiency with SQL and Excel including advanced formulas/macros
Experience with Python, R, SPSS, and SAS
Exposure to BI tools such as Tableau, Looker a plus
Familiarity with Salesforce and other CRM tools
Experience with building dashboards
Empathetic collaborator who can communicate clearly across multiple cross-functional teams, including Sales, Marketing, Finance, Product, and Engineering
Process improvements and the development of tools to automate commonly requested analyses
Strong analytical skills with the ability to collect, organize, analyze, and distribute significant amounts of information with high-levels of accuracy
Understanding of a quantitative field, such as mathematics, statistics, engineering, computer science, business analytics, etc.
WHY YOU SHOULD JOIN SIGSCI

Named a Best Place to Work in 2019 by LA Business Journal and Comparably, SigSci is built on a cultural foundation of passionate, driven, and unique individuals. As a team member, you will enjoy 100% employer-sponsored medical, dental, and vision benefits, 401K retirement plan, and flexible work arrangements. Most of all, you will have the opportunity to make a positive impact with the industry leader in web application security.","Signal Sciences
4.3","Los Angeles, CA",Enterprise Software & Network Solutions,Information Technology
Data Analyst,"Title: Data Analyst
Location: Chatsworth, CA
Duration: 12 Months

Responsibilities:
Perform compliance-driven data processing and data analysis
Prepare data reports
Coordinate and communicate with various departments to effectively execute assignments
Perform field verification to ensure data integrity
Support the development of Company projects
Other tasks as assigned
Qualifications
B.S. in Engineering required
1-3 years of experience
Knowledge of spreadsheets and database analysis tools (OSIsoft PI, Excel formulas/macros/programming)
Computer knowledge (Microsoft Office)
Ability to effectively interact with various departments to maintain open lines of communication
Clear and concise verbal and written communication skills to communicate technical and non-technical information and concepts with various levels of management in both formal and informal settings
Engineering/technical principles to analyze and resolve problems","HireTalent
4.5","Los Angeles, CA",Staffing & Outsourcing,Business Services
Data Engineer,"The Enterprise Data Intelligence Team of Cedars-Sinai is looking for an experienced Data Engineer/Data Intelligence Analyst. The ideal candidate is passionate about data, coding, technology and will utilize their skills to help solve complex healthcare questions. The candidate should possess a data engineering background, business acumen to think strategically and love working with people. Within this role, the candidate will experience a wide range of problem solving situations requiring extensive use of data collection and analysis. The successful candidate will work with Data Engineers, Data Scientists, Business Analysts, Doctors, Nurses and other stakeholders across organization.

Summary of Essential Job Duties:
Expert Oracle Query and Development Skills (Extensive RedShift skills a plus).
Strong AWS Cloud Platform tools: S3, Kinesis, RedShift.
Familiar with Dashboarding tools like Tableau/Qlik.
Good Linux, Python, Bash skills.
Desire to learn new tools, techniques and solve data challenges.

Educational Requirements:
Four (4) year degree in Computer Science or similar experience.

Experience:
Hospital Based Healthcare experience, especially Epic Clarity data model is a plus.","Cedars-Sinai
3.9","Los Angeles, CA",Health Care Services & Hospitals,Health Care
Data Scientist,"About Ipsos

Ipsos is the world’s third largest market research company, present in 90 markets and employing more than 18,000 people. Our passionately curious research professionals, analysts and scientists have built unique multi-specialist capabilities that provide true understanding and powerful insights into the actions, opinions and motivations of citizens, consumers, patients, customers or employees. We serve more than 5000 clients across the world with 75 business solutions.

Founded in France in 1975, Ipsos is listed on the Euronext Paris since July 1st, 1999. The company is part of the SBF 120 and the Mid-60 index and is eligible for the Deferred Settlement Service (SRD).

ISIN code FR0000073298, Reuters ISOS.PA, Bloomberg IPS:FP www.ipsos.com

Data Scientist

Location: Culver City, Los Angeles California

Division: Global Science Organization (GSO), Data Science & AI Lab

The Data Science & AI Lab of the Ipsos GSO is a uniquely positioned group within Ipsos. We serve as the global R&D capability bridging data science with market research offerings. The team develops analytic tools, builds data science models for pilot studies and internal stakeholder analytics innovations, and consults on a broad range of data and research best practices. Working in a collaborative and supportive environment, we seek to expand what is possible in market research with data science.

We’re looking for someone with a deep interest in data and analytics and the dedication to apply that passion. We need someone that possesses the technical ability to write production-level code and implement data science methods for a diverse set of applications, as well as uncover insights from the models and communicate them concisely and clearly to stakeholders at varying levels of technical sophistication. The role also requires an observant attention to detail, the ability to work well on a small team, and a self-starter approach to problem-solving and debugging.

As a Data Scientist, you will:
Work closely with team members on design and execution of large-scale modeling efforts, contributing to analytics libraries and integrating statistical theory
Collaborate on engineering new data science products by translating needs identified with stakeholders into analytic frameworks that can be built into polished user-facing tools
Build, maintain, and enhance existing codebases
Synthesize academic research, tech innovations, and cloud scalability, to elevate business value for clients, both current and prospective
Validate analytics innovations from marketing science and data science teams globally
Provide consulting for internal teams and clients on data engineering and hygiene, areas for improving process efficiency, and data science algorithms and results
Requirements:
High proficiency writing R and/or Python, including the ability to produce and maintain reusable and modular codebases
Bachelor’s degree
Desire to work in a highly collaborative, fun, consensus-oriented environment.
Experience in analytics, extracting and surfacing value from quantitative data
Attentive learner with excellent time-management skills
Ability to lucidly communicate data science concepts verbally and in written form


Pluses:
Professional or academic experience with modern techniques and algorithms in machine learning and statistical computing such as neural networks, genetic algorithms, Bayesian modeling, data fusion, drivers analysis, clustering, predictive analytics, network analysis, Monte Carlo, and agent-based models.
Experience developing data science models in cloud platforms (e.g. GCP, AWS)
Working knowledge of SQL and experience with database design and administration.
Experience with Linux server and system administration.
Experience with collaboration tools (e.g. Atlassian suite) and version control systems (e.g. Git).
Experience integrating R and/or Python with each other and C\C++.
Large dataset manipulation. Experience in distributed storage and computing.
Experience with ReactJS, TypeScript/JavaScript, visualization libraries (e.g. d3.js).
Experience creating and deploying web apps (e.g. Electron, web2py).
Advanced degree (M.S., Ph.D.), but not required.
Experience in the field of Market Research.
Ipsos is An Equal Opportunity Employer. All qualified applicants will receive consideration for employment without regard to age, race, color, religion, sex, sexual orientation, gender identity, national origin, protected veteran status, or any other protected class and will not be discriminated against on the basis of disability. For all future offer negotiations – please target April 6th or after for their start date.

Required Skills

Required Experience

Job Location
Culver City, US-CA",Ipsos North America,"Culver City, CA",-1,-1
Machine Learning Engineer,"Title: Machine Learning Engineer
Job ID: SM496888731
Location: Los Angeles, CA

Do you have strong passion or curiosity for artificial intelligence and the ability to learn fast? Do you have continuous drive to learn, explore and be challenged? Are you detail-oriented, well organized and self-motivated? Can you work well in teams and communicate ideas clearly?
If yes, then apply now!

What You Will Do:
Develop deep learning models (CNN/RNN) for production purposes which serves the need of product features
Write production and deployment code, optimize model performance and inference speed
Provide insights of data collection and annotation and collaborate with data team for in-house data management and labelling
Collaborate and contribute in R&D activates via high-quality and productivity scripts
Document experiments on Confluence with supporting summary statistics and results for peer discussion and review
What We Need:
MS, BS degree in computer science, statistics or related field
2+ years experience in using CNNs for classification, detection, segmentation, etc.
Proficient with at least one major deep learning framework, preferably TensorFlow
Solid understanding and hands on experience with solving computer vision problems using deep learning
For information about TEEMA and to consider other career opportunities, please visit us at www.teemagroup.com","TEEMA
4.7","Los Angeles, CA",Staffing & Outsourcing,Business Services
Data Analyst,"Lucky Day Entertainment, Inc. is a startup based in Los Angeles, CA. Our mission is to impact lives for the better by creating winning moments for anyone.

With our first product, Lucky Day, we reimagined the lottery. Lucky Day is a top 10 free app on the Google Play Store with over 10 million installs. It gives anyone the chance to win cold hard cash by playing free scratchers and lotto. Incredibly, we've managed to pay our players over $8 millions since we started in 2015! Our goal for 2019 alone is $10 million and we are well on our way. All without ever taking a dime from our players.

We’re looking for intelligent people to join our team in building out Lucky Day and our exciting new products from the ground up. People that see barriers as a challenge, and want to break the status quo. Come help us build new ways for people to experience winning moments.
What You'll Do
Define and implement business metrics and KPIs and deliver actionable analyses
Own the design, development, and maintenance of ongoing metrics, dashboards, analyses, and roadmaps
Partner closely with the leadership, Product, and Tech teams to drive product decisions
Design and analyze A/B multivariate tests to drive KPI improvement
Build high-impact dashboards and analytic tools to increase visibility on our data
What You'll Bring
Bachelor’s Degree in a field such as Computer Science, Electric engineering or equivalent work
2+ years of experience in data management or analysis
2+ years of experience with SQL
Experience working with large data sets
Experience working with a Business Intelligence tool (Tableau, Amplitude, Mode)
Self-starter attitude and able to work independently as well as in a team environment","Lucky Day
3.9","Los Angeles, CA",Internet,Information Technology
Data Analyst,"Job Description
What is HITRECORD?

Founded and led by actor and artist Joseph Gordon-Levitt, HITRECORD is an open online community with the mission to inspire creativity through collaboration. Users don’t just post about themselves and vie for attention; they work together on a variety of art and media projects that they couldn’t have completed on their own.
So far, HITRECORD has operated as a successful production company, winning an Emmy for its television show, partnering with numerous brands from Samsung and LG to the ACLU, paying contributing community members a total of nearly three million dollars.
With over 900,000 registered community members, our next step is to bring creativity to millions of people across the world.

Our Commitment to Diversity and Inclusion:

The HITRECORD community is made up of people from just about everywhere in the world—a wide-ranging multitude of backgrounds, ages, genders, and beliefs—and we strive to reflect that diversity as much as possible in our workplace. We also prioritize inclusion at our company, striving to create an environment where everyone can be authentically themselves and do their best work. That includes offering competitive salary, health benefits, insurance, and paid parental leave for all employees. We encourage people from underrepresented backgrounds to apply.

About the Role:

HITRECORD is looking for our first Data Analyst to help build the function from the ground up and be part of the process in setting up the best practices and tools in data collection and visualization. This role will work cross-functionally across Product, Finance, Engineering, and other departments and help each team collect, clean and analyze data - which will drive decision making and provide direction for future growth of the business.
We’re looking for someone who’s a self-starter who has worked at a startup before and wants to be part of building the product analytics function at HITRECORD!

What you’ll do:
Own and master the analytical understanding of user funnel, segmentation and behavior across all facets of the product to drive growth and engagement
Provide the insights to help improve product or creative efforts.
Partner with key stakeholders in Product, Engineering, Finance, Community, etc. to clearly communicate results in order to advise strategy and prioritize initiatives/launches
Create dashboards for executive management teams to stay up to date with company metrics.
Be proactive with any spikes or dips in KPIs and alert key stakeholders with analysis or hypothesis of causes.
Conduct funnel analysis of retention and drop offs to identify opportunities or holes in product flows.
What makes this different:
You will have the opportunity to create a role and impact the path of the company
This role provides a high potential for growth with exposure across all aspects of the organization and significant interaction with key stakeholders in all departments.
You will work with and be exposed to top talent in technology, entertainment and media
Must Haves:
Direct-to-consumer startup experience is a must - especially being part of the implementation of new processes or new systems
2+ years of experience in a Data Insights, Data Analytics, Data Science or Business Analytics role
A self-starter who has built things from the ground up and is looking for autonomy
Strong experience in SQL and product analytics packages; Python and R skills are a plus
Expertise with statistical analyses and concepts (e.g. regressions, experiment design, etc.)

Nice to Haves:
A passion for solving puzzles, understanding user behavior and hypothesizing answers where there were none
The ability to tactfully engage with strong points of view at all levels of the organization
Experience with Amplitude and Segment is highly preferred
Expertise with statistical analyses and concepts (e.g. regressions, experiment design, etc.)
Strategically-minded yet detail-oriented
Excellent interpersonal communication and presentation skills
BA/BS degree in a related field (Computer Science, Math, Statistics, Engineering)
Ability to work in a fun, creative team with a sense of humor","HITRECORD
3.5","Los Angeles, CA",-1,-1
Data Engineer,"Position: Data Engineer

Reason Open: Has a project coming up-very similar to current project and set to launch in September. This person will lead the Data Side. Must be a senior person- very innovative product. Need someone who can think out of the box!

Start: ASAP!

Budget: DOE

Duration: 1+ year contract- ongoing

Work hours: 40 hours per week and must attend 9:30 am PST scrum meeting but can be flexible with hours!

Location: 100% REMOTE

Day to Day:
Lead the data side of a brand new, cutting edge product from the ground up
Product will find new sports insights anonymously (deep insights across multiple dimensions) - will span across multiple data sets (i.e. NFL, MBL, eventually the news)
Data heavy / data driven project with some AI involved
Work closely with Data Scientist
Data engineer will set the foundation for data scientist to build upon
Startup mentality- must want to wear multiple hats and be comfortable in a fast paced environment with high level direction
Must Haves:
Senior level Data Engineer (5+ years ideally)
Experience with Databases (SQL, redshift, etc- client open to any)
Must have experiencing setting up architecture from scratch
Docker
Will be building on Postgres databases into docker
Must have experience with POSTGRES (AKA PostgreSQL)
Need to have worked in a distributed environment
Sports acumen / go getter / out of the box thinker
Python coding is a HUGE nice to have!
Nice to haves:
Python coding
Redshift","Mondo
3.8","Los Angeles, CA",Staffing & Outsourcing,Business Services
Data Engineer,"We appreciate your interest in employment with The Honest Company! The Honest Company is committed to a policy of equal employment opportunity, and will not discriminate against an applicant or employee on the basis of race, color, religion, creed, national origin, ancestry, sex, gender, age, physical or mental disability, veteran or military status, genetic information, sexual orientation, gender identity, gender expression, marital status, or any other legally-recognized protected basis under federal, state, or local law. Applicants with disabilities who need assistance with the application process may be entitled to a reasonable accommodation in accordance with applicable law. If you need assistance in completing this application or with the application process because of a disability, please contact the Human Resources Department at 1.888.862.8818 or 1.310.857.3020.

About Us


Founded in 2012, The Honest Company® is a mission-driven consumer products company dedicated to empowering people to live happy, healthy lives. Consumers seeking thoughtfully formulated, safe and effective baby, personal care and beauty products, along with education and support can find The Honest Company products across North America via honest.com and honestbeauty.com and at more than 17,000 retail locations. Beginning in spring 2019, consumers in Europe can find Honest Beauty at select Douglas retail locations. A leader in the natural baby category and a trailblazer in clean beauty, The Honest Company is committed to ensuring all families have access to basic necessities and the latest health information for safe growth and development — a commitment reflected in its ongoing partnerships with organizations such as Baby2Baby and Mount Sinai. The Honest Company is privately held and headquartered in Los Angeles, California.

Our Mission


We're on a mission to empower people to live happy, healthy lives. We're a wellness brand with values rooted in consciousness, community, transparency, and design. Every day and in every way, we hold ourselves to an Honest standard. We believe that it is our responsibility to do our part to help create a healthy and sustainable future for all.

The Role


The Honest Company is looking for a Data Engineer to help us in our mission of delivering safe affordable products to current and future customers. We sit at the center of technology and the business, supplying the company with the tools and training to make better use of our vast datasets. You will serve a key function, integrating critical systems, and translating raw data into information that drives the business forward.

What you'll do:
Build data pipelines to integrate systems and move data into our data warehouse. We use Amazon Redshift, Apache Airflow, Fivetran, Mule ESB, Python and Bash, among other tools.
Collaborate with data analysts across the business to build the tables and tools they need to support better decisions.
Integrate data flows between operational systems, build tools for data reconciliation
Intimately understand the company's operational data models, troubleshoot data flow issues, and improve system reliability and fault-tolerance
You'll love this job if you:
Love data and have a passion for turning it into insights
Are a dynamite problem solver. You're motivated to solve customer issues and are always thinking one step ahead.
Create strong partnerships with stakeholders
Love iterating quickly on software
Are a strong advocate of high-quality code
What you'll need:
2+ years software or data engineering experience
Strong SQL skills
Strong analytical and problem-solving skills
The ability to take business requirements and translate them into technical requirements
Effective communication and interpersonal skills
Bonus Points for:
Knowledge of the AWS ecosystem, especially as it relates to data
Experience with Mule ESB, Java, Python, Ruby and/or Apache Airflow
Experience in a retail or ecommerce environment
Benefits & Perks


We offer a competitive benefits package including comprehensive health and wellness coverage, 401k with company match, wellness incentives including a monthly fitness reimbursement and onsite fitness classes, options for education reimbursement, and a discount on all products. We value work-life balance and offer a generous and flexible vacation policy. Thinking about adding little ones to your family? Honest offers generous maternity and paternity leave. We love the furry kids too and offer pet insurance so your companions are well taken care of.

California Privacy Rights Notice for Californian Job Applicants and Prospective Talent

Effective Date: January 1, 2020

Under the California Consumer Privacy Act of 2018 (""CCPA""), The Honest Company, Inc. (""Honest"" or ""us"" or ""we"") is required to inform California residents who are our job applicants or prospective talent (together ""job applicants"" or ""you"") about the categories of personal information we may collect about you and the purposes for which we use this information. Click here if you are a California resident to read disclosures required by the CCPA. Note this notice applies only to personal information that is subject to the CCPA.

Categories of Personal Information We Collect. We may collect the following categories of personal information about our job applicants, who are California residents:
Name
Signature
Social Security Number
Email and mailing address
Telephone number
Education
Employment history
How We Use Job Applicants' Personal Data. We use and disclose the personal information we collect for our business purposes. These business purposes include, without limitation:
Processing evaluating your application to determine your qualifications for the role to which you've applied, and communicating with you about your application, including to check references or your background, and communicate with you about other jobs that may interest you.
Other business purposes as identified in the CCPA, which include:
Auditing related to our interactions with you;
Legal compliance
Detecting and protecting against security incidents, fraud, and illegal activity;
Debugging;
Performing services for us, such as analytics;
Internal research for technological improvement; and
Internal operations.
Other Interactions with The Honest Company. More information about our privacy practices can be found in our Privacy Policy, which is incorporated herein by reference.

Contact Us. For questions or concerns about our Privacy Policy, please contact us at privacy@honest.com.","The Honest Company
3.1","Los Angeles, CA",Internet,Information Technology
Data Scientist,"Join a thriving company that is changing the way cancer care is delivered for millions of patients around the country. Recently spun off from an internationally renowned research and treatment hospital, AccessHope understands that cancer doesn’t play by the rules, so we don’t either. We are an agile innovative brand that’s backed by a founding member of the National Cancer Center Network. Now, we’re joining forces with employers to bring state-of-the-art cancer expertise to their employees and give patients access to the latest developments in precision medicine, genetic risk assessment and clinical trials, regardless of where they live. The goal? To dramatically improve care, outcomes and value during cancer treatment.

It’s a revolutionary new model – and we’re looking for revolutionary thinkers to join us.

A data scientist is someone who knows how to extract meaning from and interpret data, which requires both tools and methods from statistics and machine learning, as well as being human.

Role & Responsibility

The Data Scientist is responsible for advising the business on the potential of data, to provide new insights into the business's mission, and through the use of advanced statistical analysis, data mining, and data visualization techniques, to create solutions that enable enhanced business performance.

The Data Scientist functions include:
Undertaking data collection, pre-processing and analysis
Building models to address business problems
Presenting information using data visualization techniques
Identify valuable data sources and automate collection processes
Analyze large amounts of information to discover trends and patterns
Skills
Programming
Statistics
Data Wrangling
Data Visualization & Communication
Data Intuition
Machine Learning (algorithms
Requirements
Minimum 3 years’ experience as a Data Scientist or Data Analyst
Experience in data mining
Understanding of machine-learning and operations research
Knowledge of R, SQL and Python; familiarity with Scala, Java or C++ is an asset
Experience with in-depth rate development templates, risk score analyses, trend analyses, cost management/financial initiatives, back-end technical development and programming
Experience using business intelligence tools (e.g. Tableau, Power BI) and data frameworks (e.g. Hadoop)
Analytical mind and business acumen
Problem-solving aptitude
Excellent communication and presentation skills
BSc/BA in Computer Science, Engineering or relevant field; graduate degree in Data Science or other quantitative field is preferred
Healthcare experience a plus, but not required.
Education
BSc/BA in Computer Science, Engineering or relevant field; graduate degree in Data Science or other quantitative field is preferred
Healthcare experience a plus, but not required.",AccessHope,"Irwindale, CA",-1,-1
Data Analyst,"Job Description
We have partnered with a large Mining and Metals company in the Sun Valley, CA area to provide them with a Data Analyst.

Please review the below description and if you are interested please contact:
Vahidin Topcagic at vtopcagic@relevante.biz, 314-853-6670
Responsibilities of the Data Analyst:
Ensures business systems are efficient and operating in supported environments
Proactively reviews the business operations for ongoing process improvements
Works with process owners to document detailed business requirements
Coordinates with IT, consultants and process owners to validate solutions
Analyses processes and dependencies across integrated software applications
Prepares functional documents and technical specifications, RFP's, RFI's, etc.
Recommends new functionality, middleware for ERP, CRM and related applications
Proposes solutions to improve productivity and or save operating capital
Drives development, acceptance testing and subsequent promotion of changes
Prioritizes projects and various change requests in conjunction with management
Coordinates upgrades and data integration efforts with the HRIS users
Proven SQL experience in writing queries and user dashboards in a manufacturing/distribution and/or production environment.
Develops SQL Queries and Smart Views with SQL reporting services
Participates in the back-end maintenance of SQL based applications as needed
Supports point of sale systems and credit card devices for retail operations
Utilizes Microsoft Office (Word, Excel and PowerPoint) to present analysis
Implements Cross-Functional strategy and methods to solve systems issues
Evaluates new functional requests, business impacts and recommends solutions
Works with Quality and Safety teams to ensure process meets all requirements
Coordinates with Infrastructure and Help Desk teams to ensure project readiness
Participates in the Business Continuity Planning design and implementation
Attends and participates in regular planning and staff meetings
Liaison with process owners, application support, end users and customers
Assists the Help Desk in problem resolution for corporate applications
Works closely and assists the Business Systems Manager
May be required to travel to various office branches as needed
Qualifications of the Data Analyst:

The following are the minimum qualifications which an individual requires in order to successfully perform the duties and responsibilities of this position. Please note that the minimum qualifications may vary based upon the department size and/or geographic location.
Driven professional attitude, enthusiastic, self-reliant
Self-motivated, responsible and reliable
Excellent interpersonal and communication skills
Detail oriented with strong analytical and problem-solving skills.
Ability to drive projects from concept to completion
Negotiating skills
Strong sense of ownership of issues
Understands the value of human capital
Requirements of the Data Analyst:

The ideal candidate will have experience with any combination of the following:
Experience with a major ERP system and ……solutions Epicor BisTrack and Microsoft Dynamics GP in a Terminal Server environment
Databases such as Microsoft SQL Server 2014
Nesting applications such as SigmaNEST
Customer Relationship Management (CRM) such as Salesforce
HRIS applications such as Ascentis
Medium to large scale ERP/CRM/HRIS application experience
Experience in the metals industry, supply chain, distribution or retail sales environments
Experience working across multiple geographic locations using video conferencing
Benefits of the Data Analyst:
Health Insurance
Dental Insurance
Life Insurance
401 (k)","Relevante, Inc.
3.1","Los Angeles, CA",Consulting,Business Services
Data Analyst,"Kite is continuing to hire for all open roles. Our interview process may be conducted virtually and some roles will be asked to temporarily work from home. Over the coming weeks and months, we will be implementing a phased approach to bringing employees back to site to ensure the health and safety of our teams.

For Current Kite Pharma Employees and Contractors:


Please log onto your Internal Career Site to apply for this job

Job Description


Everyone at Kite is grounded by one common goal – curing cancer. Every single day, we seek to establish a direct line between that purpose and our day-to-day work. Join us in our mission!

Kite is seeking a highly motivated, experienced, and resourceful Data Analyst to support the Global Quality Organization operating out of our headquarters in Santa Monica, CA. Kite Quality is responsible for adhering to regulatory requirements while improving existing processes, reducing waste, and lowering costs to safely improve patient access to our life-saving therapies.

In this role you will collect, measure, visualize and interpret data across multiple functions that include Manufacturing, Quality, Supply Chain, and Process Development with the intent of turning data into information, information into insights and insights into informed business decisions.

Responsibilities (include but are not limited to):
Partner with decision makers across functional domains to clearly define business & technical problems and then collect/present the information required to address
Interpret data, analyze results and craft engaging narratives around insights derived through the data
Use SQL to develop ad hoc queries for data stored across multiple tables and databases
Uses data patterns & trends to identify root cause of operational gaps and inefficiencies then collaborate with other functional domains to develop solutions
Develop regular dashboards in data visualization tools such as Tableau and Spotfire and provide to business stakeholders to measure and better manage their respective areas
Filter and “clean” data within Kite’s enterprise data analytics platform and identify potential enhancements to source systems to improve quality of data collected
Coordinate business and IT stakeholders to define data requirements, ETL flows, development, and testing/validation in support of continued integration of enterprise data analytics platform to key operational source systems
Work with Quality leadership to prioritize information/reporting needs to support business objectives
Scheduling tool, daily, historical modeling
Skills/Qualifications:
2+ years of relevant experience and a BS or an MS
Strong knowledge of and experience with data visualization/reporting packages (Tableau, Power BI, Spotfire, etc.), databases (MS-SQL Server, Impala, etc.), and programming (XML, JavaScript, or ETL frameworks)
Strong analytical skills with the ability to collect, organize, analyze, and disseminate significant amounts of information with attention to detail and accuracy
Knowledge of statistics and experience using statistical packages for analyzing datasets (Excel, Minitab, etc.)
BS in Computer Science, Statistics/Biostatistics, or Mathematics or equivalent practical experience
Initiative to develop understanding of gene & cell therapy, its associated manufacturing process coupled with expanding technical knowledge of tools supporting data analytics
Technical knowledge regarding data models, database design development, data mining and segmentation techniques a plus
Experience working within an AWS environment a plus
Kite is a biopharmaceutical company engaged in the development of innovative cancer immunotherapies with a goal of providing rapid, long-term durable response and eliminating the burden of chronic care. The company is focused on chimeric antigen receptor (CAR) and T cell receptor (TCR) engineered cell therapies designed to empower the immune system's ability to recognize and kill tumors. Kite is based in Santa Monica, CA. For more information on Kite, please visit www.kitepharma.com. Sign up to follow @KitePharma on Twitter at www.twitter.com/kitepharma.

For jobs in the United States:


As an equal opportunity employer, Gilead Sciences Inc. is committed to a diverse workforce. Employment decisions regarding recruitment and selection will be made without discrimination based on race, color, religion, national origin, gender, age, sexual orientation, physical or mental disability, genetic information or characteristic, gender identity and expression, veteran status, or other non-job related characteristics or other prohibited grounds specified in applicable federal, state and local laws. In order to ensure reasonable accommodation for individuals protected by Section 503 of the Rehabilitation Act of 1973, the Vietnam Era Veterans' Readjustment Act of 1974, and Title I of the Americans with Disabilities Act of 1990, applicants who require accommodation in the job application process may contact careers@gilead.com for assistance.

For more information about equal employment opportunity protections, please view the ‘EEO is the Law’ poster.

NOTICE: EMPLOYEE POLYGRAPH PROTECTION ACT
YOUR RIGHTS UNDER THE FAMILY AND MEDICAL LEAVE ACT

PAY TRANSPARENCY NONDISCRIMINATION PROVISION

Our environment respects individual differences and recognizes each employee as an integral member of our company. Our workforce reflects these values and celebrates the individuals who make up our growing team.

Gilead provides a work environment free of harassment and prohibited conduct. We promote and support individual differences and diversity of thoughts and opinion.

For Current Kite Pharma Employees and Contractors:


Please log onto your Internal Career Site to apply for this job.","Gilead Sciences
3.4","Santa Monica, CA",Biotech & Pharmaceuticals,Biotech & Pharmaceuticals
Data Engineer,"Position at codeSpark

About codeSpark
codeSpark is turning programming into play for kids everywhere. We’re building the largest community of young kid coders in the world. Our award-winning app, codeSpark Academy, has a unique word-free interface that allows kids as young as four to become makers. We have a strong focus on making codeSpark Academy exciting for both girls and boys.

We believe all kids should have the opportunity to master this new form of literacy and creative expression. Our self-directed subscription service thoughtfully combines structured challenges and open-ended creative play.

Our new Data Engineer will have the opportunity to explore all sorts of interesting data about kids’ learning through play. You’ll also help us improve our marketing efforts through development and reporting on success metrics. The right person joining us will be interested in our mission and motivated to find all sorts of other cool data to analyze to help us grow, too!

Data Engineer Job Overview
We are looking for a Data Engineer who will support our product, marketing, and leadership with insights gained from analyzing company data. The ideal candidate is self-sufficient and adept at using large data sets to find opportunities for product and process optimization, and in building and using models to test the effectiveness of different courses of action. They are experienced in using a variety of data mining/data analysis methods, using a variety of data tools, building and implementing models, using/creating algorithms and creating/running simulations. They must demonstrate a proven ability to drive business results with their data-based insights. Finally, they must be comfortable working with a wide range of stakeholders and functional teams. The right candidate will have a passion for discovering solutions hidden in large data sets and working with stakeholders to improve business outcomes.

Responsibilities:
● Collaborate with stakeholders throughout the organization to identify opportunities to leverage company data in driving business solutions.
● Mine and analyze data from company databases to drive optimization and improvement of product development, marketing techniques and business strategies.
● Assess the effectiveness and accuracy of new data sources and data gathering techniques.
● Develop custom data models and algorithms to apply to data sets.
● Use predictive modeling to increase and optimize customer experiences, onboarding, revenue generation, ad targeting and other business outcomes.
● Leverage A/B testing framework and test model quality.
● Develop processes and tools to monitor and analyze model performance and data accuracy.
● Maintain company KPI dashboard.

Essential Qualifications:
● 5-7 years of experience manipulating data sets and building statistical models.
● Bachelor’s or Master’s in Statistics, Mathematics, Computer Science or another quantitative field.
● Coding knowledge of several languages: C#, Python, JavaScript, Go, or similar.
● Querying databases and using statistical computer languages: R, Python, Mongo, JQL, etc.
● Using AWS services.
● Analyzing data from 3rd party providers: Google Analytics, Mixpanel, Facebook, Appsflyer, Email service providers, etc.
● Experience visualizing/presenting data for stakeholders.

Highly desired:
● Experience working with product development and marketing teams, especially subscription products and kids games or apps.
● Experience using statistical computer languages to manipulate data and draw insights from large data sets.
● Experience working with and creating data architectures.
● Knowledge of advanced statistical techniques and concepts (regression, properties of distributions, statistical tests and proper usage, etc.) and experience with applications.
● Excellent written and verbal communication skills for coordinating across teams.
● A proactive approach to learning and mastering new technologies and techniques.

Perks
● Opportunity to shape strategy for a company having a global impact on K-5 education.
● The rare opportunity to change the world by helping create the first generation in history that is truly connected and collaborative.
● The fun of working with an effective and multi-award winning product that is beloved by customers.
● Sharp, motivated co-workers in a creative and supportive office environment.

Commitment to Diversity and Inclusion
codeSpark believes in diversity and inclusion of all people, of all genders, races, ethnicities, sexual orientations, educational backgrounds, religions, abilities, socioeconomic backgrounds, immigration statuses, and more. Just as we hope to close access gaps in computer science education, we aim to create a culture within codeSpark that is inclusive and accessible to all current and potential employees.

codeSpark is an Equal Opportunity Employer.","Idealab
4.0","Pasadena, CA",Investment Banking & Asset Management,Finance
Data Scientist,"The Job

Warner Bros. Entertainment Inc. seeks a Data Scientist for the Digital Product, Platform & Strategy: Data Intelligence Operations department. We are looking for a talented data scientist to join our Data Intelligence Team. The data scientist will be responsible for predictive modeling and analysis of customer data, as well as researching best practices in analytics and data science, and sharing them across the company to improve analytic capabilities at Warner Bros.

The Daily
Analyze and model internal customer data.
Build relationships and collaborate with analysts and researchers across WB.
Produce statistical and machine learning models that inform how we communicate with our customers.
Drive improvement in our methodologies, systems and processes.
Provide analysis, reporting, and modeling to internal organizations based on customer data.
Prepare and present results of analyses to leadership.
The Essentials
B.A./B.S. degree in Statistics, Mathematics, Computer Science, Economics, Political Science, or similar quantitative field.
Quantitative oriented Masters Degree or Ph.D preferred.
Minimum of 1-2 years of experience in analytics and data science.
1+ years of experience with conducting analysis in R, Python, SAS, or similar analytical languages.
Experience with relational databases and SQL.
Experience with working in cloud based environments like AWS a plus.
Expertise in machine learning and predictive modeling approaches such as Random Forest, GBM, xgBoost, neural networks/deep learning, etc.
Skilled researcher, able to distill large bodies of research to key findings and explain them to varied audiences.
Experience developing testing plans for evaluating campaigns or changes to products
Knowledge of basic survey design and analysis.
Strong history of identifying opportunities for developing predictive models to meet business needs.
Love of TV, Movies, Games, and Comics is a Plus!
Must be able to communicate effectively and tactfully with all levels of personnel, both in person and on the telephone.
Must be able to pay close attention to complex detail and understand written and oral instructions.
Must be able to organize and schedule work effectively.
Must be able to work well under time constraints.
Must be able to handle multiple tasks with changing priorities, communicating changes in scope and schedule to all parties concerned.
Must be able to work independently.
Must be able to maintain confidentiality.
Requisition #
177448BR

Area of Interest
Technology/Information Technology

Industry
Film Production and Distribution

Location
United States - California - Burbank

Position Type
Full Time

Business Unit
WB Technology

Business Unit Overview
WB Technology combines Warner Bros.’ industry-leading technologists and disciplines to ensure global alignment with business strategy and accelerated delivery of innovative technology solutions studio- and industry-wide. From pre-production through archiving, the WBT organization will provide critical business and technology intelligence and services to all Studio business units. WBT manages the Studio’s enterprise systems and solutions, emerging platforms, information security, consumer intelligence, content mastering and delivery, and more.

Company Overview
WarnerMedia is a leading media and entertainment company that creates and distributes premium and popular content from a diverse array of talented storytellers and journalists to global audiences through its consumer brands including: HBO, HBO Now, HBO Max, Warner Bros., TNT, TBS, truTV, CNN, DC Entertainment, New Line, Cartoon Network, Adult Swim, Turner Classic Movies and others.

Warner Media, LLC and its subsidiaries are equal opportunity employers. Qualified candidates will receive consideration for employment without regard to race, color, religion, national origin, gender, sexual orientation, gender identity or expression, age, mental or physical disability, and genetic information, marital status, citizenship status, military status, protected veteran status or any other category protected by law.","WB Technology
5.0","Burbank, CA",-1,-1
Data Analyst,"Provide project analytical support to chemical safety management program, including but not limited to the following activities: a. Process requests for chemical product approvals including uploading the request form and safety data sheet into a Sharepoint database and notifying the reviewers of pending requests. b. Uses the SAP Master Data Governance System to request material codes for approved chemical products. c. Maintains the SCE catalog in the chemical management database, including entering new products, adjusting inventories, updating existing products and the vendor reports. d. Update the chemical management database in response to reports from SAP Master Data Governance. e. Maintain the Consumer Products list. 2. Provide project analytical support to Automated External Defibrillator (AED) program, including but not limited to the following activities: a. Support inspection compliance by providing monthly analytic support (run and analyze reports) and resolve issues related to non-compliant AED's (follow up communications with AED users) b. Support in development of AED related job aids as needed 3. Provide project analytical support to various health and safety programs, including, but not limited to, development of presentation materials, tracking of action item completion, development and maintenance of SharePoint sites.
Job category

Branch

Pay rate

Posted date

12/5/2018

Job ID

Job type
MS Office Skills
Strong written communication skills
Highly organized and attentive to detail.
Ability to document processes in a clear and precise manner.
Ability to manage multiple tasks and assignments.
Able to work independently with a minimum of supervision.
Able to work well within a team.
Pluses:
Familiar with Sharepoint and how to administer databases in Sharepoint.
Familiar with SAP data systems and how to use them","Cenergy
3.5","Irwindale, CA",Construction,"Construction, Repair & Maintenance"
Data Engineer,"ResponsibilitiesThe Analytics Center of Excellence (ACOE) at NBCUniversal is looking for a passionate problem solver who's looking to build the next generation of data pipelines and applications. Reporting to the Director supporting the research portfolio, the Data Engineer role is right for you if you're a ""hands-on"" coder who can build and cleanse large datasets in order to report out actionable insights.As part of the global Operations & Technology organization, the ACOE is focused on data and analytics strategies for the future. We support NBCU's vast portfolio of brands - from broadcast, cable, news, and sports networks to film studios, world-renowned theme parks, and a diverse suite of digital properties. We take pride in supplying our business groups with data to advise and shape strategic business decisions related to our content.In the Data Engineer role, you'll be working with internal stakeholders, data engineers, visualization experts, data scientists, and other technologists across the business. If you're someone who loves to take large, disparate data sets and build them into flexible and scalable analytics applications and databases, you've come to the right place. Here you can create the extraordinary. Join us.Responsibilities:* Collaborate with business leaders, engineers, and product managers to understand data needs.* Interface with other technology teams to extract, transform, and load data from a wide variety of data sources using SQL and AWS big data technologies* Design, build, and scale data pipelines across a variety of source systems and streams (internal, third-party, as well as cloud-based), distributed/elastic environments, and downstream applications and/or self-service solutions* Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc.* Help continually improve ongoing reporting and analysis processes, automating or simplifying self-service support for customers* Participate in development sprints, demos, and retrospectives, as well as release and deployment* Build and manage relationships with supporting IT teams in order to effectively deliver work products to productionQualifications:* 1+ years of experience in a data engineering role* Direct experience with data modeling, ETL development, and data warehousing* Knowledge of data management fundamentals and data storage principles* Experience with Python/Javascript or similar programming languages* Hands-on experience with SQL and Tableau* Bachelor's degree in Computer Science, Data Science, Statistics, Informatics, Information Systems or related field.Desired Characteristics:* Analytical - You have experience in delivering data analytics solutions that promote data discovery* Proficient with ETL processes, application development, and data science principles* Experience with Snowflake, Amazon Web Services, or related cloud platforms a plus* Media-focused - Strong knowledge/passion for media including broadcast TV, digital, and mobile* Experience working with data sources such as Nielsen, Adobe Analytics, comScore, and other industry research sources a plus* Communicator - You have excellent verbal and written skills with the ability to communicate ideas effectively across all levels of the organization, both technical and non-technical* Action-oriented - You're constantly figuring out new problems and are regularly showing results with a positive attitude, always displaying ethical behavior, integrity, and building trust* Strong understanding of Agile principles and best practices* You've dealt with ambiguity and can make quality decisions in a dynamic, fast-paced environment","NBC Universal
3.8","Universal City, CA",TV Broadcast & Cable Networks,Media
Data Engineer,"Tapcart makes launching a mobile shopping app easy, fun and attainable for every brand.
The world of shopping will one day be powered entirely by mobile, made possible by our products, team and vision.
We are inspired by the future of mobile. We work to inspire that future.

As the market leader in mobile Ecommerce, we focus on providing great experiences for our customers and for mobile shoppers worldwide. Our platform powers the mobile apps of some of the largest shopping brands, including Fashion Nova, Chubbies, The Hundreds and many more.

Tapcart is trusted by over 10,000 brands to launch and manage their mobile apps. We were recently featured at Google I/O, Shopify UNITE and in The Verge.

This role is perfect for an ambitious Data Engineer looking to grow and work with real-time data. Someone who is engineering-driven, can translate business and data requirements into production-ready stacks, and provide innovative systems with a focus on data resilience and accuracy for the e-commerce space.

We are looking for someone who shows passion and can champion data not only internally but to our customers. This person would help shape data collection, compliance, processes, and work cross-functionally with all Tapcart teams.
What you need to know
Be confident working within a real-time data collection system
Provide data-focused solutions and obtain buy-in from stakeholders
Experience working with stacks such as BigQuery, DataFlow, DataPrep, Data Studio, Pub/Sub, Kafka, Apache Airflow and the like
Experience defining schemas and growing a Data Warehouse
Experience with HBASE derived databases, especially BigTable
What you'll be doing
Creating data pipelines to handle batch and steaming ETLs
Create and implement efficient solutions to enrich existing data workflows
Create software/technology that will be the foundations for future machine learning engines such as personalization and recommendations
Identifying and report data resilience issues to key stakeholders
Bonus if you have
Experience at a B2B and/or SaaS startup
Experience creating data pipelines for SaaS dashboard products like Intercom, Canva, FreshBooks
Worked within highly functional engineering teams


Who we are.
We are a well funded, young and growing startup located in sunny Santa Monica, CA . Our employees and culture are very important to us and as such, we aim to make coming to work fun, challenging and rewarding for our team. We know that doing great work depends on showing up with creative solutions to face our many business challenges. It all starts with having good people, and helping them grow both personally and professionally. We can't wait to hear how your unique skills and personality will add to our company and culture.

Learn more about who we are and what we offer on our careers page, and check out some of our recent features on Google I/O, Shopify UNITE and in The Verge.","Tapcart
5.0","Santa Monica, CA",Enterprise Software & Network Solutions,Information Technology
Data Engineer,"ZEFR is hiring! Our Software Engineering team is hiring a Data Engineer to be involved in designing and building large-scale applications and systems to acquire, process, store, and illuminate multi-terabytes of YouTube, Facebook and other social media data. This role is an important part of the rapidly scaling infrastructure and data management demands of being the leader in VideoID technology for enterprise media companies and content owners.

Technology @ ZEFR:
Languages: Python, Scala, Java, and Kotlin
Data stores: PostreSQL, Elasticsearch, Redshift
Data processing: Apache Kafka, Apache Spark
DevOps: Jenkins, Docker, Terraform, Ansible, AWS ECS, AWS EMR

Here's what you'll get to do:
Provide seamless and timely data access for your users
Build reliable and dependable ETL
Build and maintain production machine learning infrastructure
Troubleshoot complex issues in distributed systems
Debate data processing philosophies and methodologies with your team
Here's what we're looking for:
Bachelor's or Master's degree in Computer Science or related field
Fluency with Python, Java, Kotlin, or Scala
Experience with distributed systems
Strong foundation in data structures, algorithms and software design
Experience with digital media, social media, and video APIs such as YouTube's Data API is a big plus
Thorough testing and code review standards/practices
Strong verbal and written communication skills
Openness to new technologies and creative solutions","ZEFR
3.3","Marina del Rey, CA",Motion Picture Production & Distribution,Media
Data Engineer,"Job Summary


The J. Paul Getty Trust is looking for an enthusiastic Data Engineer, with the experience and passion to carry out the execution of technical projects to enhance the institution's cultural heritage knowledge bases, through the application of machine learning and other data transformation techniques. Our aim is to provide a deeply connected and consistent experience for scholars, researchers, and enthusiasts as they explore the complex information held across the organization, and your participation is crucial for that to be successful.

You will report to the Enterprise Semantic Architect, and interact with software engineers, data engineers and content specialists in the cultural heritage programs. Your work will improve the quality, reliability, connectedness, and consistency of our data by engineering project-specific data pipelines to produce new knowledge from existing internal and external data sources. You will have a hands-on role with content specialists in the programs, and be responsible for working with them to understand data requirements and then implement those requirements in software.

The initial focus of this role is to assess and gather the necessary data to apply computer vision tools to a collection of more than half a million digitized photographs of paintings, drawings and prints. The aim of this work is to enhance our descriptions of these objects with high confidence metadata generated without expert curatorial intervention. The use of computer vision is a high priority in the institution's digital strategy and the success of this work will lead to further exciting projects that put the developed skills, transformation workflows and systems to good use.

The Getty is among the most prestigious cultural heritage organizations in the world, dedicated to furthering the study of the history of art. You will work on an amazing campus amongst fabulous art, architecture, and information systems, collaborating with world-class scientists, curators, librarians, archivists, and academics. We offer paid vacation, personal and sick leave plus every other Friday off, excellent benefits, and a very strong commitment to balancing work and personal life.

Major Job Responsibilities
With the Semantic Architect, work with technical and content stakeholders to understand data-oriented project requirements
With other Data Engineers, ensure high quality data transformation pipelines can migrate and enhance institutional managed collections
Integrate external content services to enrich and reconcile our datasets
Assess the feasibility of applying data enhancement tools and the quality of their results to determine their suitability for project requirements
Work in an agile way, including supporting testing, continuous integration and deployment
Assist software engineering teams by translating stakeholder requirements into feature requests
Qualifications
Bachelor's degree in a related field or a combination of education and relevant experience
2-5 years software development experience
Knowledge, Skills and Abilities
Experience of data-oriented work within cultural heritage organizations
Attention to detail combined with a focus on data usability
Excellent verbal and written communication skills, especially when interacting with non-technical stakeholders
Proficiency in Python, or willingness to translate experience in equivalent language
Familiarity with machine learning techniques and/or tools
Familiarity with cultural heritage data standards, such as Linked Open Data
Familiarity with engineering tools such as git
Familiarity with test driven and agile software development methodologies","J. Paul Getty Trust
3.6","Los Angeles, CA",Grantmaking Foundations,Non-Profit
Data Analyst,"Job Description
Our client is looking to hire an experienced full-time Data Analyst to work in their Los Angeles office.

Responsibilities:

Analyze user behavior and translate results from data into actionable insights that help drive business goals and improve company performance.

Develop and automate analytical reports for various business units and stakeholders throughout the organization.

Regularly present and share findings to drive new business initiatives and content strategy.

Monitor and analyze key metrics and execute recurring analyses and reporting.

Regularly analyze websites to ensure site traffic and conversion funnels are performant and provide recommendations to test and optimize new features and products.

Develop and maintain strong relationships with internal teams and provide analytical support as necessary.

Requirements & Qualifications:

BA / BS degree in related field

3-5 years of experience in Business Intelligence or Analytics space, specifically dealing with site traffic

SQL / query language skills are a plus

Ability to analyze large data sets, manipulate data, and make data-driven recommendations.

Experience managing various tagging and tracking platforms especially Google Analytics

Experience with the following technologies is a Plus: Hadoop, AWS, Tableau or other OLAP cube/data visualization, Oracle database, Adobe Marketing Cloud (Omniture), Clicktale, ExactTarget/Salesforce (or similar ESP)

Experience coordinating and communicating with cross-functional teams

Strong Critical Thinking Required

Understanding of eCommerce and online sales attribution methodologies a Plus

Excellent organizational, oral and interpersonal communication skills, and keen attention to detail.

Strong Ability to prioritize and handle multiple initiatives/tasks in parallel as well as changing priorities

Experience from a Media Company or Digital Publisher Preferred",Eleven Recruiting - CHURN,"Los Angeles, CA",-1,-1
Data Engineer,"Title: Data Engineer
Job ID: TJ3682741021
Location: Los Angeles, CA

Our client is looking to hire a Data Engineer to join their team. The ideal candidate thrives in a fast paced environment has the ability to communicate clearly. This role will be responsible for automating and maintaining batch pipelines that collect and process data; automating and maintaining batch pipelines that collect and process data; designing and building tools that provide confidence in their data quality; and mentoring and coaching other software engineers.

Qualifications:

Bachelor’s degree in Computer Science or comparable field
5+ years experience in Python and SQL
5+ years experience in Java, Scala, or similar OO experience
5+ years experience with Spark, Hadoop, or Databricks
Experience with data analysis, processing, and validation
Professional experience with open source ETL frameworks such as Airflow, Luigi, or similar
Knowledge within a diverse set of public cloud technologies: AWS RDS, S3, EC2, Lambda, Google Cloud Big Query, Google Cloud Bigtable, etc.
For more information about TEEMA and to consider other career opportunities, please visit our website at www.teemagroup.com","TEEMA
4.7","Los Angeles, CA",Staffing & Outsourcing,Business Services
Data Scientist,"Data Scientist
If you are a Data Scientist with experience, please read on!

What You Will Be Doing
We're looking for a skilled Data Scientist to join our growing LA team. This resource will have access to a variety of different data sources available to the Data Products and Engineering team, entailing clickstream, financial, marketing, event, and internal data. This individual will be responsible for exploring data sets as large as 1 petabyte (1PB) and driving business results with their data-based insights using predictive modeling. The ideal candidate is adept at using large data sets to find opportunities for product and process optimization and can use models to test the effectiveness of different courses of action. Other responsibilities will include (but are not limited to) data visualization, data- driven problem solving, They have a passion for discovering solutions hidden in data sets and can brainstorm ways to improve business outcomes/determine future project focus. They must also have experience and interest in content analysis.

What You Need for this Position
"" 4+ years of experience as a Data Scientist within a large, consumer-facing analytics environment
"" Strong python/R programming experience to extract, clean, analyze, and visualize data
"" Exposure to cloud environments (preferably AWS)
"" Strong experience utilizing Spark for data processing
"" Automation experience using Amazon S3 or other comparable storage service
"" Machine Learning experience using Tensorflow, Scikit-learn, or Spark ML
"" Experience using Amazon SageMaker for cloud machine learning
"" At least a B.S. in Computer Science, EE or Mathematical Science. MS or PhD preferred

What's In It for You
Great Compensation and Benefits Package

So, if you are a Data Scientist with experience, please apply today!
Applicants must be authorized to work in the U.S.

CyberCoders, Inc is proud to be an Equal Opportunity Employer
All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, disability, protected veteran status, or any other characteristic protected by law.

Your Right to Work In compliance with federal law, all persons hired will be required to verify identity and eligibility to work in the United States and to complete the required employment eligibility verification document form upon hire.

CyberCoders will consider for Employment in the City of Los Angeles qualified Applicants with Criminal Histories in a manner consistent with the requirements of the Los Angeles Fair Chance Initiative for Hiring (Ban the Box) Ordinance.","CyberCoders
4.2","El Segundo, CA",Staffing & Outsourcing,Business Services
Data Analyst,"Data Analyst Location Glendale, CA Duration 3 months contract Client is looking for Data Analyst to build reports, run statistical analysis, etc.","iSpace, Inc
3.7","Glendale, CA",IT Services,Information Technology
Data Analyst,"Kite is continuing to hire for all open roles. Our interview process may be conducted virtually and some roles will be asked to temporarily work from home. Over the coming weeks and months, we will be implementing a phased approach to bringing employees back to site to ensure the health and safety of our teams.

For Current Kite Pharma Employees and Contractors:


Please log onto your Internal Career Site to apply for this job

Job Description


Everyone at Kite is grounded by one common goal – curing cancer. Every single day, we seek to establish a direct line between that purpose and our day-to-day work. Join us in our mission!

Kite is seeking a highly motivated, experienced, and resourceful Data Analyst to support the Global Quality Organization operating out of our headquarters in Santa Monica, CA. Kite Quality is responsible for adhering to regulatory requirements while improving existing processes, reducing waste, and lowering costs to safely improve patient access to our life-saving therapies.

In this role you will collect, measure, visualize and interpret data across multiple functions that include Manufacturing, Quality, Supply Chain, and Process Development with the intent of turning data into information, information into insights and insights into informed business decisions.

Responsibilities (include but are not limited to):
Partner with decision makers across functional domains to clearly define business & technical problems and then collect/present the information required to address
Interpret data, analyze results and craft engaging narratives around insights derived through the data
Use SQL to develop ad hoc queries for data stored across multiple tables and databases
Uses data patterns & trends to identify root cause of operational gaps and inefficiencies then collaborate with other functional domains to develop solutions
Develop regular dashboards in data visualization tools such as Tableau and Spotfire and provide to business stakeholders to measure and better manage their respective areas
Filter and “clean” data within Kite’s enterprise data analytics platform and identify potential enhancements to source systems to improve quality of data collected
Coordinate business and IT stakeholders to define data requirements, ETL flows, development, and testing/validation in support of continued integration of enterprise data analytics platform to key operational source systems
Work with Quality leadership to prioritize information/reporting needs to support business objectives
Scheduling tool, daily, historical modeling
Skills/Qualifications:
2+ years of relevant experience and a BS or an MS
Strong knowledge of and experience with data visualization/reporting packages (Tableau, Power BI, Spotfire, etc.), databases (MS-SQL Server, Impala, etc.), and programming (XML, JavaScript, or ETL frameworks)
Strong analytical skills with the ability to collect, organize, analyze, and disseminate significant amounts of information with attention to detail and accuracy
Knowledge of statistics and experience using statistical packages for analyzing datasets (Excel, Minitab, etc.)
BS in Computer Science, Statistics/Biostatistics, or Mathematics or equivalent practical experience
Initiative to develop understanding of gene & cell therapy, its associated manufacturing process coupled with expanding technical knowledge of tools supporting data analytics
Technical knowledge regarding data models, database design development, data mining and segmentation techniques a plus
Experience working within an AWS environment a plus
Kite is a biopharmaceutical company engaged in the development of innovative cancer immunotherapies with a goal of providing rapid, long-term durable response and eliminating the burden of chronic care. The company is focused on chimeric antigen receptor (CAR) and T cell receptor (TCR) engineered cell therapies designed to empower the immune system's ability to recognize and kill tumors. Kite is based in Santa Monica, CA. For more information on Kite, please visit www.kitepharma.com. Sign up to follow @KitePharma on Twitter at www.twitter.com/kitepharma.

For jobs in the United States:


As an equal opportunity employer, Gilead Sciences Inc. is committed to a diverse workforce. Employment decisions regarding recruitment and selection will be made without discrimination based on race, color, religion, national origin, gender, age, sexual orientation, physical or mental disability, genetic information or characteristic, gender identity and expression, veteran status, or other non-job related characteristics or other prohibited grounds specified in applicable federal, state and local laws. In order to ensure reasonable accommodation for individuals protected by Section 503 of the Rehabilitation Act of 1973, the Vietnam Era Veterans' Readjustment Act of 1974, and Title I of the Americans with Disabilities Act of 1990, applicants who require accommodation in the job application process may contact careers@gilead.com for assistance.

For more information about equal employment opportunity protections, please view the ‘EEO is the Law’ poster.

NOTICE: EMPLOYEE POLYGRAPH PROTECTION ACT
YOUR RIGHTS UNDER THE FAMILY AND MEDICAL LEAVE ACT

PAY TRANSPARENCY NONDISCRIMINATION PROVISION

Our environment respects individual differences and recognizes each employee as an integral member of our company. Our workforce reflects these values and celebrates the individuals who make up our growing team.

Gilead provides a work environment free of harassment and prohibited conduct. We promote and support individual differences and diversity of thoughts and opinion.

For Current Kite Pharma Employees and Contractors:","Kite Pharma
3.4","Santa Monica, CA",Biotech & Pharmaceuticals,Biotech & Pharmaceuticals
Data Analyst,"We are looking for a data analyst with skills in SQL data extraction, data exploration and data integration that will be used to create interactive cloud-based analytic visualizations and dashboards for internal operations, quality, finance and executive use.

Required Education, Skills and Experience
BS in Computer Science or equivalent field
SQL and SAS proficiency
Linux familiarity
2+ years relevant experience
Ability to work in high-performing technical team
Strong interpersonal and oral and written communication skills, and the ability to build and maintain relationships with customers and colleagues
Intellectually curious, passionate, and inventive


Desired Skills:
SQL experience - Epic Clarity, MySQL, MS SQL, etc.
SAS experience
Cloud Experience – Azure, Google Cloud, etc.
Familiarity or experience with Agile - Jira, SAFe Agile framework
Experience with Power BI
Exposure or experience with programming languages and frameworks – Java, C++, JavaScript, JQuery, HTML, CSS, Python, R, Scala, Spark, SAS, etc.
Exposure to or experience with building Tableau interfaces and dashboards
Exposure to or Experience with integrating front and back-end technologies for analytics.","Tilde Staff Inc.
5.0","Pasadena, CA",-1,-1
Data Analyst,"Data Analyst Location Burbank, CA Start Date Jul 20, 2020 Apply Now Sign Up For Job Alerts Email Job Refer a Friend Apply with LinkedIn Job Description Data Analyst Burbank, CA Direct Hire Up to 100k year Successful candidate will engage with business teams to define business questions, prepare and model data, and perform analyses with the purpose of understanding or drawing conclusions from the data. This role will join the Analytics Team and will work closely to build, deploy and administer self-service analytics across business units. In this role, you will utilize the Plans diverse analytics tools to turn data into actionable insights with the goal of creating a data-driven culture across the organization. Required Skills Bachelor's Degree in Computer Science, Information Systems, or other related field as well as equivalent work experience. Minimum 5 years in a quantitative data analytics role with emphasis on data preparation and analysis. Strong ability to blend and wrangle data, create logical data models to be used as a basis for analysis. Proficiency in using enterprise analytics platforms, data visualization tools Tableau, Alteryx, ThoughtSpot, Business Intelligence solutions or equivalent. Knowledge of relational DBMS, specifically Oracle, and ability to script and execute SQL queries. Understanding of the principles and tools of statistical analysis and machine learning is a plus. Bonus Skills Previous work experience in the HealthCare industry preferred. Be a part of the ConsultNet difference. As a leading national provider of IT staffing and solutions, ConsultNet delivers exceptional services to startup, midmarket and Fortune 1000 companies across North America. Since 1996, we've partnered with clients to create rewarding opportunities for our consultants, successfully building teams that have surefire results. In the past two years alone, we have placed more than 1,500 consultants in contract, contract-to-hire, or direct placement opportunities. We understand communication is key to finding the right job that matches your skills and career goals. For us, it's not just the work that we do it's how we do the work. Our breadth of offerings extends to multiple IT positions in major markets throughout the country, see more at www.consultnet.com Id 20-01031","ConsultNet, LLC
4.3","Burbank, CA",Staffing & Outsourcing,Business Services
Data Engineer,"The Business

GradTests.com is a leading provider of practice psychometric tests to graduates, students and young professionals.

The Role

The core purpose of the role is to make high quality, high availability, accurate data available for our data analysts and data scientists to do their analysis, derive their insights and build their models. You are the Scotty Pippin to the Michael Jordans. You are the Xavi to the Messis.

You'll do things like:
Ensure our data warehouse is well structured, running smoothly and efficiently for all business intelligence
Set up and maintain various data pipelines used for customer analytics, marketing analytics and product analytics
Skills and experience

Non negotiables:
SQL
Python
Strong knowledge of traditional relational databases - we don't mind which
Some experience with cloud technologies - again we don't mind if it's AWS, GCP or Azure
Experience in any streaming technology
Great experience in using third party APIs at scale
Some web scraping experience
An obsession with data quality
Strong communication skills
Nice to haves:
Experience in working with analysts
Any basic knowledge of advanced analytics techniques
Experience in a visualisation tool like Tableau
Job Types: Full-time, Contract

Salary: $100,000.00 /year

Work Remotely:
Yes",GradTests (gradtests.com.au),"Los Angeles, CA",-1,-1
Data Engineer,"Data Engineer

Bigtime Entertainment Co. building state of the art software and
algorithms to improve the way that our
media company transacts; interacts with consumers and customers;
and makes
vital business decisions with large revenue impacts. As a Data
Engineer
supporting the Data Science team, you will frame, pose and
translate business
problems to build AI-powered solutions that directly contribute
to data
products. As a member of the Data Science & Engineering team, you
will be
designing and building scalable models & architectures upon while
ML algorithms
can thrive, as well as refining existing model implementations so
that they
automatically build context in order to perform above and beyond
expectations.

From creating
experiments and prototyping implementations to designing new
architectures, we
resolve challenging and meaningful problems with compelling
business use cases.
Our team is committed to continuously leveraging and furthering
the latest
advances in ML research to transform the broader media market
through our data
product successes

In this role you will:

· Collaborate with the
data science team to build future-proof frameworks and
abstractions

· Collaborate with
product management and engineering departments to understand
company needs and
devise AI powered solutions

· Build tools that
will increase the productivity of the Data Analytics team-members
developing AI-based systems

· Implement models
that the data science team develops into working prototypes,
proof of concepts,
self-supporting model ecosystems

· Build data pipelines
that contribute to a self-sustaining data model system

· Build demos and
conduct training in conjunction with data scientist to help the
broader
engineering organization (and/or business partners) effectively
use the product

· Demonstrate and
apply theories through research efforts to develop new and
improved products,
processes, or technologies

· Participate in
cutting-edge research in artificial intelligence and machine
learning
applications

· Optimize models for
on-device and multi-modal intelligence

Qualifications:

• Experienced Data
Engineer with a BS, MS or PhD in a quantitative field (CS,
Engineering,
Physics, etc.)

• 4+ years hands-on
business experience, demonstrated implementations of ML models
and techniques
is a plus

• Advanced in Python

• Experience with AWS
infrastructure (AWS Certifications are a plus)

• Strong knowledge of
relational and distributed databases, extremely strong in SQL

• Multiple
Implementations that feature good memory, disk I/O, and CPU/GPU
management.

• Experience with
Apache infrastructure

• Experience with
streaming data and video manipulation

• Familiarity with
common ML algorithms (i.e. neural networks, tree-based methods,
unsupervised
learning, feature engineering)

• Familiarity with
ML/AI frameworks, e.g,. TensorFlow, Spark, and modular/modern
software design
practices.

• History of research
publications and/or implementations of state of the art
techniques hosted on
open source repositories is a plus

• Passionate about
ML/AI and how it can improve both the media industry and the
world

Technologies we use:

AWS, Python, Python
Data Science packages, Spark, Hadoop, Apache

Resumes sent to: jim@ingenium.agency

Top base salary, excellent benefits and work culture","ingenium.agency
5.0","Los Angeles, CA",Staffing & Outsourcing,Business Services
Data Analyst,"Minimum 2 to 3 years of experience in data analysis.
You must have working experience in data warehousing and expected to know at least one ETL tool.
Strong understanding in oracle is required.
You should be proficient in analyzing upstream and downstream source systems, preparing Data mapping documents, prompt analysis and solutions.
Experience working with developers to get the requirement done, doing analysis in UAT environment and helping client in the UAT Testing phase.","Lorven Technologies Inc
4.0","Los Angeles, CA",Accounting,Accounting & Legal
Data Analyst,"Location: LA, DC, or NYC preferred; Remote for the right candidate

The Data Analyst plays an important role in executing on the National Justice Database analysis plan. The uniquely robust and ever-growing National Justice Database is the first and largest database on police behavior in the country (e.g., vehicle stops, pedestrian stops, use of force, complaints against officers).
Key Responsibilities
Execute on analyses outlined in the National Justice Database analysis plan
Delivery of all code and syntax developed to conduct the analyses
Perform data pre-processing/wrangling tasks to prepare the data for analysis
Produce compelling data visualizations
Set up regression models and provide interpretation of the results
Conduct quality assurance checks to ensure there are no errors in the analyses or the interpretation of the output
Qualifications
Background in statistics/data science with specific experience in performing multiple regression, multilevel (hierarchical) modeling, and Bayesian inference
Highly proficient in R and/or Python
Ability to produce markdown notebooks with Jupyter and/or RMD/Knitr
Expertise in interpreting syntax across statistical software platforms (including, but not limited to, R, Python, SAS, Stata, and SPSS)
Experience working with geographic data (GIS shapefiles; desired, but not required)
Ability to explain analysis findings in clear terms that can be understood by non-technical audiences
Familiarity with administrative dataset cleaning and merging
Comfort with collaboration across a geographically distributed team
Collaborative Institutional Training Initiative (CITI) certified (or equivalent; this may be completed after an offer has been extended)
Benefits
Medical
Dental
Vision
Life Insurance
Pet Care
Generous Vacation
Sick Pay
Paid Holidays
Application Submission Guidelines
Applications will be considered on a rolling basis. However, applications received after the close date will receive delayed consideration. To apply, please submit the following materials:
CV/resume
Cover Letter
Two example analyses (preferably as Jupyter notebooks or RMD documents, though other formats are acceptable)
Please be sure to label each PDF file by including your name. For example, your submitted CV should be labeled, “LASTNAME\_FIRSTNAME.CV.pdf.”

Job Types: Full-time, Part-time",Center For Policing Equity,"Los Angeles, CA",Colleges & Universities,Education
Data Analyst,"We're committed to bringing passion and customer focus to the business.


Job Description Summary:

Works to develop lasting and pervasive solutions that enable customers to make data-informed business decisions. Primary point of contact between customers and IT for the development of data visualizations to assist in day-to-day and strategic business decision making.

Job Description:

POSITION RESPONSIBILITIES AND DUTIES:
• Primary point of contact between customers and IT for development of data visualizations to assist in day-to-day and strategic business decision making
• Consult with customers to develop understanding of business goals and objectives for data visualizations
• Directly support customers in use of data visualization tools to develop and deploy reports, charts, dashboards, alerts, etc.
• Assists in selection and deployment of data visualization tools across the company
• Provide in-depth data analysis to assist in answering complex business questions
• Responsible for collection, analysis and documentation of business and functional requirements in support of development of data marts
• Responsible for data mapping and validation in support of data mart development and data conversions
• Work with project teams to develop data visualizations and conduct data conversion activities as part of new or modified IT services
• Maintain relationship with outside vendors/partners for the purposes of supporting data visualization tools and augmenting staff for data analysis activities
• Work with training department and customers to develop, deliver, and/or coordinate data visualization training, documentation, and other educational tools and materials
• Study use and performance of data visualization tools, data marts and makes recommendations for enhancements
• Make recommendations for strategic direction of data analysis tools and procedures in alignment with business strategy
• Document business data sources as a reference for customers in development of data visualizations
• Requires moderate amount of travel to meet with customers at division offices
• Complete other responsibilities as assigned

MINIMUM SKILLS OR EXPERIENCE REQUIREMENTS:
• Minimum 3 years of work experience with data analysis

• Bachelor’s Degree or foreign academic equivalent in Data Science, Business Communication, or related field of study.
• Formal education in the use of data analysis tools and practices required
• High level of competency with Microsoft Excel and other data analysis tools
• High level of literacy in both relational and non-relational database concepts and structures
• Proficient with data query languages (SQL, Excel Pivot Tables etc.)
• High level of literacy in Business Intelligence concepts, tools and frameworks
• Knowledge of data governance structures and purpose
• Use resources effectively and efficiently; can orchestrate multiple activities at once to accomplish goals
• Fast learner when facing new problems and situations; thrives with challenges
• Keen listening, written and verbal skills, while ensuring clear, effortless explanations to users
• Ability to work independently, as well as effectively within a team
• Negotiate skillfully in tough situations with internal and external groups
• Effective problem-solving ability and strong analytical skills; can see underlying or hidden problems and patterns; looks beyond the obvious
• Demonstrate flexibility, reliability, and dependability

If you like wild growth and working with happy, enthusiastic over-achievers, you'll enjoy your career with us!","Swinerton Builders
4.0","Los Angeles, CA",Construction,"Construction, Repair & Maintenance"
Data Analyst,"Description FOR IMMEDIATE CONSIDERATION email Valerie Nielsen at Valerie.Nielsenrht.com with your resume titled Data Analyst The Position Data Analyst Location El Segundo, CA Please note this is a direct hire (not contract) Target Salary 70,000 Data Analyst You didn't get to where you are by following an expected path. You follow your instincts, while everyone around you sits back and waits for life to happen. You are a catalyst, an agent of change. You're smart, energetic, and aggressive. You possess an entrepreneurial spirit. You are inquisitive, innovative, and resourceful. You have a fresh perspective. Our client is looking to build out their team from and bring on a Data Analyst! Requirements Top Requirements 1-MS Excel and VBA 2-1+ years of experience 3-Degree in IT, computer science, or other relevant field 3-Access -nice to have 4-MS Excel cert- nice to have and understanding of basic legal or bankruptcy concepts helpful FOR IMMEDIATE CONSIDERATION email Valerie Nielsen at Valerie.Nielsenrht.com with your resume titled Data Analyst Robert Half Technology matches IT professionals with some of the best companies on a temporary, project or full-time basis. From roles in software and applications to IT infrastructure and operations, we provide you unparalleled access to exciting career opportunities. Our personalized approach, innovative matching technology and global network with local market expertise help you find the technology jobs that match your skills and priorities - fast. By working with us, you have access to challenging opportunities, competitive compensation and benefits, and training to enhance your skill sets. From philanthropy to environmental stewardship to employee programs, Robert Half is proud to have an active role in the communities in which we live and work. Our company has appeared on FORTUNE's ""Most Admired Companies"" list every year since 1998. Download our mobile app to take your job search on the go! Contact your local Robert Half Technology office at 888.490.4429 or visit www.roberthalf.comjobstechnology to apply for this job now or find out more about other job opportunities. All applicants applying for U.S. job openings must be authorized to work in the United States. All applicants applying for Canadian job openings must be authorized to work in Canada. 2020 Robert Half Technology. An Equal Opportunity Employer MFDisabilityVeterans. By clicking 'Apply Now' you are agreeing to Robert Half Terms of Use httpswww.roberthalf.comterms-of-use .","Robert Half
3.5","El Segundo, CA",Staffing & Outsourcing,Business Services
Data Engineer,"Click ""Apply for this Job"" below to submit your application. After doing so, please take our 4-minute web analytics assessment followed by a 15-minute aptitude test by clicking the following link:

Start Assessment

Who We Are:

2-time winner of Crain's 100 Best Places to Work, Direct Agents is a data-driven digital marketing agency with offices in NY and LA.

Established in 2003, we are an independent company, and our business has been built on adapting and driving change since the very beginning. Fueled by the grit and hustle of our diverse team, we’re inspired by experimentation and seek to push the boundaries on innovative approaches to advertising. Our teams are committed to growing and innovating alongside clients like Colgate, Walker & Co., Belkin, The CW, Wacoal, and more.

Together, we think differently and we continue to shape the digital space into the future…

We are the Shapers of the Digital World. Join us and become a shaper of change!

As a Data Engineer, you will create tangible value by helping to develop innovative data and tech systems for current and future clients. The work you do directly contributes to our ability to improve holistic business and marketing strategies aimed to meet and exceed client expectations.

You will have the opportunity to work on leading-edge AI/ML, data automation, and predictive analytics projects including: bidding algorithms, image recognition, attribution modeling, performance forecasting, propensity scoring, and much more. The position requires fostering close working relationships with internal marketing teams as well as clients.

What You’ll Do:
Create automated data systems using APIs, Selenium, web scrapers, etc.
Set up and maintain database ecosystems
Build advanced data models to provide granular and predictive insights
Develop AI systems to perform advanced operations based upon data inputs
Visualize data in an easily digestible format
Supplying internal teams with datasets to be used for strategic optimizations
Maintain data integrity and work with teams to troubleshoot discrepancies
Stay abreast of latest industry topics, trends, news, methodologies, and tools
What You’ll Need:
Bachelor's or Master’s Degree in Mathematics/Computer Science/Engineering/Finance or related field
Advanced Python skillset
Strong Statistical and/or Machine Learning background
Strong knowledge of database structures and SQL
Excellent quantitative skills and attention to detail
Experience using Power BI data visualization software is a plus
Highly motivated to identify and develop solutions to complex problems
Strong time management skills – ability to prioritize and meet deadlines
Diligent work ethic. Must be self-motivated and able to take the initiative to get the job done
Digital Marketing experience is preferred but definitely not required
What You’ll Get:
Competitive pay & health benefits.
Weekly social, wellness, and team building events
Access to health benefits and many other perks like One Medical
An amazing values based company culture ripe with collaboration, encouragement and camaraderie
Monthly education and training in digital advertising
Access to the best in class marketing technology and methodology
Ability to innovate and make an impact with your ideas in real-time
A fast tracked path to growth based on what you put into the role and your passion for learning in the company
Check out our Culture Videos:

Welcome to Direct Agents: https://www.youtube.com/watch?v=EC-LBxTw0To

DA 2019 Culture in Review: https://www.youtube.com/watch?v=rP12YTMF4Dg","Direct Agents
4.4","Culver City, CA",Advertising & Marketing,Business Services
Data Engineer,"Pluto TV is the leading free streaming television service in America, delivering 100+ live and original channels and thousands of on-demand movies in partnership with major TV networks, movie studios, publishers, and digital media companies. Pluto TV is available on all mobile, web and connected TV streaming devices and millions of viewers tune in each month to watch premium news, TV shows, movies, sports, lifestyle, and trending digital series. Headquartered in Los Angeles, Pluto TV has offices in New York, Silicon Valley, Chicago and Berlin. Pluto is a subsidiary of ViacomCBS (NASDAQ: VIAB, VIA), a global content company with premier television, film and digital entertainment brands.
As a Data Engineer, you have a solid understanding of both the business and the technical aspects of BI in relation to digital media business. You will drive the completion of projects within the established scope, while simultaneously planning for and leading unknown future BI requirements in a dynamic environment.
Design, model and develop data sets to support reporting and analytics in a cloud environment.
ETL development: cover all aspects of programming assignments and assist with systems design.
Develop and maintain a technical metadata framework and repository of data events and ETL operations.
Lead and administer Analytics tools and tag management systems.
Help plan and maintain the technical infrastructure, its configuration, performance, and storage requirements, with consideration of tiered data and data archiving.
Generate ad-hoc queries and reports based on business requirements.
Provide ongoing evaluations of technology solutions and capabilities to ensure alignment with business objectives, identify areas of risk, while monitoring the current environment and potential improvement areas.
Work with business partners to gather, analyze, and translate requirements in BI reporting area – either recommending an existing solution, developing a solution, or synthesizing delivery requirements to engineering teams for development.
Actively question and challenge customers to understand their requirements and reach the best solutions, near and long term.
Understand and adhere to development and documentation standards, database design and storage.
Successfully execute process improvements impacting own work and work of others.
On-call application support is required.

3+ years of premier Data engineering experience; at least 2 years on cloud Infrastructure.
Working knowledge of digital media ecosystem, including how digital video streaming, ad servers, DSPs, SSPs work.
Experience with a mix of Cloud and Enterprise data environments with real world implementation of data collection and processing on AWS environment.
Knowledge of web technologies and online advertising systems.
Experience with real-time Big Data analytics.
Experience with Hadoop, MapReduce, Spark, Flink and/or other Big Data processing platforms.
Excellent knowledge of OLAP concepts.
Familiarity with columnar databases like Redshift, Vertica etc.
Programming language such as Java, and scripting languages like python, ruby and Unix shell scripts.
Experienced working in a fast-paced, high-tech environment (preferably software development) and comfortable navigating conflicting priorities and ambiguous problems.
Experience with data visualization tools such as Looker, Tableau.

Great communication and collaboration skills across technical and non-technical partners.
A Bachelor’s degree in Computer Science or equivalent preferred.","ViacomCBS
3.6","Los Angeles, CA",Motion Picture Production & Distribution,Media
Data Analyst,"We have a
unique opportunity for someone to contribute their talents and strengths as a Data
Analyst.

A COMPANY TO BE PROUD
OF

Kurtzman
Carson Consultants LLC (KCC), a Computershare company, is a leading
Restructuring claims, noticing, ballot and information agent responsible for
the distribution of client related notices, bankruptcy claims administration
and creditor communications, including the hosting of case-specific websites and
call centers. KCC has gained client and industry recognition for its
industry expertise, professional-level client service and proprietary
technologies.

At Computershare we invite you to share our vision and
commitment to excellence in everything that we do. Our 12,000 people around the
globe are entrepreneurial and innovative, serving 16,000 clients and customers
with precision and reliability because they count on us to deliver, every time.

Computershare (ASX: CPU) is a global market
leader in transfer agency and share registration, employee equity plans,
mortgage servicing, proxy solicitation and stakeholder communications. We also
specialize in corporate trust, bankruptcy, class action and utility
administration, and a range of other diversified financial and governance
services.

Founded in 1978, Computershare is renowned
for its expertise in high integrity data management, high volume transaction
processing and reconciliations, payments and stakeholder engagement. Many of
the world’s leading organizations use us to streamline and maximize the value
of relationships with their investors, employees, creditors and customers.

Computershare is
represented in all major financial markets and has over 12,000 employees
worldwide.

DIVERSITY IS A STRENGTH

Across our global team, we see
diversity as a source of strength. The more perspectives we have, the better
equipped we’ll be to meet the demands of our diverse global customer base. We
want every person who joins out team, every customer and every supplier to feel
welcome. We are an Equal Opportunity Employer and believe in equality for
everyone, regardless of age, national or ethnic origin, sex, gender identity or
expression, race, color, religion, disability, sexual orientation, protected
veteran status or other characteristics protected be applicable law. That
applies throughout our company, around the world with no exceptions, regardless
of differences. We will hire, develop, reward, promote and retain people purely
on the basis of their talents, commitment, potential and the results they
achieve. We will work hard to make sure everyone is included within our
organization, removing barriers and obstacles to give everyone an equal
opportunity to succeed.

OUR VALUES

Our key values – Certainty,
Ingenuity and Advantage – drive everything we do: you can count on us to
deliver with precision and reliability, every time. We look beyond today’s
problems to find tomorrow’s solutions, focusing on finding new and better way
to unlock your competitive edge and help you achieve your business goals.

A ROLE YOU WILL LOVE

Work in the
interesting and complex world of corporate restructuring and learn from one of
the top administrative-support providers in the country. We are currently
looking for bright and ambitious individuals to fill the position of Data
Consultant. As a Data Consultant, you will work hand-in-hand with
lawyers, financial advisors and court employees to help administer large
corporate Chapter 11 reorganization cases. This position reports to Senior
Managing Consultants and the Vice President or Director of Restructuring.

WHAT
WE NEED FROM YOU
Interact and provide service for internal case teams,
clients, clients’ counsel and other professionals.
Data gathering, formatting and management of databases,
including initial creditor matrix, service lists, claims registers,
Schedules/SOFA data, voting amount spreadsheets and voting tabulation
reports.
Review, reformat, input and export data for Schedules
of Assets and Liabilities and Statement of Financial Affairs.
Format service lists and merge files for complex
variable data mailings.
Review claims, perform claims reconciliation and
prepare and reformat various claims reports for internal and external
purposes.
Coordinate preparation of contract review databases,
including delegation of contract review, compilation of completed files
and review final work product.
Advanced working knowledge of and experience with
Microsoft Excel and Microsoft Access. Proficiency with other aspects
Microsoft Office, especially Outlook and Word. Working knowledge of VBA and SQL
preferred.
Possess advanced technical skills to facilitate
creating financial models, databases, pivot tables, analytics, etc.
Ability to quickly learn and navigate proprietary
software.
Technical aptitude and ability to understand technical
and functional concepts quickly
Other duties or tasks as assigned by management. May be
asked to work and stay after regular work hours.
Excellent attention to detail
Strong written and verbal communication
Energetic and self-motivated.
Possess good interpersonal skills and be able to work
on a team.
Be able to thrive in a fast-pace and dynamic work
environment.
Detail oriented, conscientious and reliable.
The noise level in the environment is moderate.
KEY QUALIFICATIONS

To perform
this job successfully, an individual must be able to perform each essential duty
satisfactorily. The requirements listed below are representative of the
knowledge, skill, and/or ability required. Reasonable accommodations may be
made to enable individuals with disabilities to perform the essential
functions.

Education
and Experience
Bachelor's degree (B. A.) from four-year college or
university, preferably in Information Technology or Computer Science. One
to two years of experience in a related field.
Microsoft Excel Certification, Preferred
Travel Required

It is
expected that this position may include travel up to 10
of the time.
This is subject to change based on many factors, including business needs.

Language Ability

Ability to read/comprehend simple
instructions, short correspondence, and memos; write simple correspondence;
effectively present information in one-on-one/small group situations to
customers, clients, and other employees of the organization

Mathematical Ability

Ability to add and
subtract two-digit numbers and to multiply and divide with 10's and
100's. Ability to perform these operations using units of American money
and weight measurement, volume, and distance.

Work Environment
The work environment characteristics described here are representative of
those an employee encounters while performing the essential functions of this
job. Reasonable accommodations may be made to enable individuals with
disabilities to perform the essential functions.
The noise level in the environment is
typical of an open office environment.
Physical Demands

The physical demands
described here are representative of those that must be met by an employee to
successfully perform the essential functions of this job. Reasonable
accommodations may be made to enable individuals with disabilities to perform
the essential functions.
Sedentary work: Exerting up to 10 pounds of force occasionally and/or a
negligible amount of force frequently or constantly to lift, carry, push, pull
or otherwise move objects. Sedentary work involves sitting most of
the time. Jobs are sedentary if walking and standing are required only
occasionally and all other sedentary criteria are met.
REWARDS
AS UNIQUE AS YOU
A choice medical insurance
plans designed to meet your needs
Dental & Vision insurance
Life & Disability insurance
Flexible spending and health
savings accounts
Employee Stock Purchase Plan
Paid time off - You’ll accrue 3
weeks your first year!
Nine Holidays
$1,000 Employee Referral
Program
Wellness programs
Matching 401(k)
Tuition Reimbursement
Banking and investments plans
Rewards and recognition
programs
Employee discounts for
wellness, auto & homeowners insurance, wireless service and more…
To learn more, visit us at www.computershare.com/mycareer.

Your
career is waiting.

Computershare is an Equal
Opportunity Employer. Qualified applicants will receive consideration for
employment without regard to race, color, religion, sex, sexual orientation,
gender identity or expression, national or ethnic origin, age, disability,
protected veteran status, or other characteristics protected by applicable
law.","Computershare
3.1","El Segundo, CA",Financial Transaction Processing,Finance
Data Analyst,"Job Description
Job description
Interpret data, analyze results using statistical techniques and provide ongoing reports
Develop and implement databases, data collection systems, data analytics and other strategies that optimize statistical efficiency and quality
Acquire data from primary or secondary data sources and maintain databases/data systems
Identify, analyze, and interpret trends or patterns in complex data sets
Filter and “clean” data by reviewing computer reports, printouts, and performance indicators to locate and correct code problems
Work with management to prioritize business and information needs
Locate and define new process improvement opportunities
Requirements
Proven work experience as a data analyst or business data analyst
Technical expertise regarding data models, database design development, data mining and segmentation techniques
Strong knowledge of and experience with reporting packages (Business Objects etc), databases (SQL etc), programming (XML, Javascript, or ETL frameworks)
Knowledge of statistics and experience using statistical packages for analyzing datasets (Excel, SPSS, SAS etc)
Strong analytical skills with the ability to collect, organize, analyze, and disseminate significant amounts of information with attention to detail and accuracy
Adept at queries, report writing and presenting findings
Master's in Computer Science or Engineering Management or Project Management or Information Systems/Technology (Preferred)
Powered by JazzHR

0yE3DxVz2X","Staffigo Technical Services, LLC
5.0","Los Angeles, CA",IT Services,Information Technology
Data Analyst,"Our client is looking to hire an experienced full-time Data
Analyst to work in their Los Angeles office.

Responsibilities:

· Analyze user behavior and translate results from data into
actionable insights that help drive business goals and improve
company performance.

· Develop and automate analytical reports for various business
units and stakeholders throughout the organization.

· Regularly present and share findings to drive new business
initiatives and content strategy.

· Monitor and analyze key metrics and execute recurring analyses
and reporting.

· Regularly analyze websites to ensure site traffic and
conversion funnels are performant and provide recommendations to
test and optimize new features and products.

· Develop and maintain strong relationships with internal teams
and provide analytical support as necessary.

Requirements & Qualifications:

· BA / BS degree in related field

· 3-5 years of experience in Business Intelligence or Analytics
space, specifically dealing with site traffic

· SQL / query language skills are a plus

· Ability to analyze large data sets, manipulate data, and make
data-driven recommendations.

· Experience managing various tagging and tracking platforms
especially Google Analytics

· Experience with the following technologies is a Plus: Hadoop,
AWS, Tableau or other OLAP cube/data visualization, Oracle
database, Adobe Marketing Cloud (Omniture), Clicktale,
ExactTarget/Salesforce (or similar ESP)

· Experience coordinating and communicating with cross-functional
teams

· Strong Critical Thinking Required

· Understanding of eCommerce and online sales attribution
methodologies a Plus

· Excellent organizational, oral and interpersonal communication
skills, and keen attention to detail.

· Strong Ability to prioritize and handle multiple
initiatives/tasks in parallel as well as changing priorities

· Experience from a Media Company or Digital Publisher Preferred",Eleven Recruiting - CHURN,"Los Angeles, CA",IT Services,Information Technology
Data Analyst,"DatamanUSA LLC has an exciting opportunity for a Data AnalystÂto work onsite with one of our direct clients in Los Angeles, CA. If you are not available or not interested then we love referrals! Please refer us to your friends, family, and colleagues for this opportunity. DatamanUSA gives referral bonuses (up to $500) if they get selected and perform well for our clients. Position Title: Data Analyst Duration: 1+ Month (with possible extension) Location: Los Angeles, California Required Skills and Experience:
4+ years of work experience with data analysis, statistical analysis, and data mining in business administration, public administration, IT, or other related industry.
4+ years of work experience gathering data requirements (including functional, user, system requirements); creating application wireframes, developing process flow diagrams, writing quality technical and user guide documentation; perform heavy research; and any other analysis tasks necessary for software implementation projects.
4+ years of work experience using SQL databases and database query languages.
Extensive experience in data management, data analysis, managing large data sets, data scrubbing, and identifying and resolving data, code or scripting issues.
Intermediate to advanced knowledge of Microsoft Word, Excel, Project, and PowerPoint is required.
Intermediate to advanced knowledge of Microsoft Access and Outlook are strongly desired.","DatamanUSA
3.4","Los Angeles, CA",IT Services,Information Technology
Data Engineer,"Job Description
Company Mission and Highlights:

mPulse Mobile, the leader in mobile health engagement, drives improved health outcomes and business efficiencies by engaging individuals with tailored and meaningful dialogue. mPulse Mobile combines technology, analytics and industry expertise that helps healthcare organizations activate their consumers to adopt healthy behaviors. With 9 years, 60+ healthcare customers, and more than a hundred million messages sent annually, mPulse Mobile has the data, the experience and the technology to drive healthy behavior change.

Our Core Values:
Model Integrity and Collaboration
Drive Innovation and Thought Leadership
Support Decision Making at All Levels
Create Value for Clients by Empowering Consumers
Improve Customer Experience Through Simple Design
Celebrate Success… Often
Purpose of the Role:

The mission of the Data Science and Analytics (DSA) team at mPulse is to uncover insights from data in order to help drive better patient engagement and health outcomes. We are looking at everything from tactical optimizations to broad level strategic direction that is grounded in data evidence and heavy analytical rigor.

This requires a multidisciplinary blend of data science, behavioral science, and business strategy, all applied in tandem to discover key insights that lie hidden in our data sets. The Data Engineer will help build a research-based and data-driven approach to optimize mobile customer engagement. This role will focus on deep diving into a broad variety of exploratory initiatives to improve segmentation, tailoring and personalization of mobile engagement.

Duties and Responsibilities:
Working with the data science and data analytics team to refine and develop data science and analytics (DSA) product roadmap
Support Redshift cluster management including monitoring, performance tuning, and optimization
Responsible for data loads and data extracts via Airflow DAG and python code.
Engaging in exploratory A/B studies to extract data features and determine the relative value of multiple data types
Building rich and interactive data visualizations to display findings from A/B studies, to guide and inform exploratory data analysis, and to deepen customer engagement
Understanding and applying data mining techniques, including NLP, clustering algorithms and regression analysis to generate deep insight and discover effective solutions to challenging problems
Skills, Abilities, and Experience:
2-5 years of experience in a corporate, start-up, or research environment
2-5 years of experience mentoring data analysts (corporate) or graduate students (academia)
2-5 years of experience in Airflow DAG creation, debugging and maintenance
2-5 years of experience in PostgreSQL and Elasticsearch
Strong background and solid skills in interactive data visualization (Tableau, Django, Shiny, D3.js)
Experience in research methods, exploratory data analysis, and machine learning
Intense intellectual curiosity – strong desire to always be learning
Analytical, creative, and innovative approach to solving difficult problems
Minimum Qualifications:
4 year BS/ BA Degree in Computer Science, Computer Engineering or other related field
2 years of direct experience as a data engineer or working directing in data engineering / data science.
1-2 years of experience with Python (Pandas, NumPy, sciKit-learn), SQL and R
*Please note, due to the requirements of this position, responses may automatically disqualify you from moving forward in the application process. Please review minimum qualifications thoroughly before applying.

Behavioral Competencies:
Customer Focused
Attention to Detail
Independent Self-Starter
Highly Organized
Critical Thinker
Problem Solver
Excellent Communicator
Ability to Prioritize
Team Work & Collaboration
Multi-Tasker with Strong Sense of Urgency
The Perks:
Enjoy Flexible PTO and flexible work hours
Full Vision, Dental and Healthcare - all individual premiums paid by mPulse!
401K Program with a 4% match
3 Weeks Paid Maternity/Paternity Leave
Weekly team lunches to celebrate victories
Paid Parking as well as Car Pooling incentives
Laptop fitness stations
Ping pong conference table and Foosball
Free snacks and drinks
Powered by JazzHR

XkixHHJBSj","mPulse Mobile
3.7","Los Angeles, CA",Health Care Services & Hospitals,Health Care
Data Engineer,"Greetings from Trovetechs!!!

Â

We have an immediate need for Data Engineer Role @ Universal City, CA. Please find the below Job Description for your kind reference.

Â

Duration: Long term Contract

Experience: 8+ Years

Rate: DOE$/hr.

Â

Deploy and maintain data pipelines
Assemble large, complex data sets
Build optimal ETL infrastructure using AWS offerings
Build high performance, fault-tolerant, and scalable systems
Collaborate and coordinate with other teams and parts of the business
Communicate technical concepts to non-technical stakeholders
Strong Python programming skills
Strong hands-on Spark programming experience
Strong SQL coding abilityÂ
Redshift experience
Strong experience with AWS Services, well versed with various AWS ETL Services (EMR, Glue, etc.), RDS, AWS Lambda, etc. (Preferred)
Work experience with Databricks is highly desirable
Â

If you are interested, please send us your updated resume along with best Time & Number to reach you ASAP.

Â

Thanks and look forward to working with you,

Â",Trovetechs Inc,"Universal City, CA",-1,-1
Machine Learning Engineer,"As a Machine Learning/Data Engineer, you will:
Work as a member of the machine learning team to analyze client datasets to find key insights and intuitive visualizations using the software we are building
Write production code for algorithms in C#/Python
Build data processing pipelines and machine learning models to satisfy client needs on an as-needed basis
Assist clients to better understand data visualization + machine learning through workshops and other sessions
Requirements:
1-5 years of professional experience writing production-ready code
Professional experience working with machine learning models and other data science techniques
Professional experience with Git (or alternative version control tool)
Professional experience with Python and Jupyter Notebooks/Lab
Professional experience with C, C++, C#, Java, or similar
Ability to thrive in start-up environment; quick to take responsibility
Strong sense of ownership and accountability
Excellent written and verbal communication skills
Able to wear an Oculus virtual reality headset as necessary (our application is at a ""Comfortable "" level on the Oculus Comfort Rating scale)
Available to work on-site and authorized to work in US without sponsorship
Pluses:
Undergraduate degree in Computer Science
Experience with SQL or other database systems
Experience with deep learning techniques",Tangerine Search Inc,"Los Angeles, CA",-1,-1
Data Engineer,"Job Description
Our client is looking for a Sr. ETL Developer with IICS, DW design and implementation experience with Snowflake, as well as Cloud experience in AWS

• Responsibilities include performing data analysis, defining ETL architecture, data modeling and implementing robust data pipelines in the cloud using AWS, IICS and Snowflake. Requirements:

• 7+ years hands-on experience in BI and Data Warehousing with at least 2 full life cycle implementations. Includes architecture, design, data modeling (Kimball methodology), ETL and reporting.

• 2+ years experience implementing a Cloud DW/Data Lake.

• Demonstrably deep understanding of SQL, relational and analytical databases (Snowflake, Redshift, BigQuery, etc.)

• Hands-on, expert level experience of Informatica Intelligent Cloud Services

• Experience with AWS services (S3, Lambdas, etc.)

• Knowledge of Agile (Scrum) practices required

• Knowledge of ERPs (Oracle EBS, etc.) highly desired","Prosum
4.0","Los Angeles, CA",IT Services,Information Technology
Machine Learning Engineer,"Job Description
Machine Learning Engineer - Aliso Viejo, CA

AWM Smart Shelf is reinventing retail and looking for smart, talented people to work on building exciting applications. The initial focus of this position is working on AWM Frictionless which is a cashierless-shopping solution for shoppers to be able to grab what they want from a store and simply walk out.

Our solution uses real-time computer vision and deep learning to determine what shoppers take. We're looking for a Machine Learning Engineer to run with the selection, training, and evaluation of our item and action recognition models.

If your ML background is not in image processing, but something like NLP or finance, you may still be a great fit! We’re looking for nimble, practical problem solvers and we value a diversity of perspectives.

We tinker, experiment, and hack on many different approaches and love people who aren't afraid to jump around. A successful Machine Learning Engineer will rapidly iterate – failing fast to identify the most promising paths forward.

If this sounds like fun, we'd love to hear from you!

THE JOB
Implement machine learning models for item classification and action recognition
Ability to evaluate model performance and monitor the training process
Adapt existing models to better handle problems specific to our domain
Integrate models into our production pipeline for real-time processing
Test cutting-edge models on our custom datasets
WHO YOU ARE
Someone who executes – a focus on action and results - can self-manage to timelines and deliver
Practical coding knowledge (Python preferred) to quickly iterate on training and testing models
Understanding of CNNs and the tradeoffs of different architectures
Knowledge of best practices in machine learning
NICE TO HAVE (but not mandatory)
Experience with video data
Experience with distributive training in the cloud
Experience with sequence modeling
Relevant education in an undergraduate or graduate program
WHAT WE OFFER
A dynamic environment where you can make an impact using the latest technologies
Paid vacation and sick time
Health benefits
Opportunity for growth
401k plan
Potential for employee stock option plan participation
**PLEASE APPLY TO BE CONSIDERED**
Company Description
Please visit www.smartshelf.com to learn more and watch videos of our solutions.","Adroit Worldwide Media, Inc. (AWM Smart Shelf)
3.2","Los Angeles, CA",-1,-1
Data Engineer,"Analog Devices (NASDAQ: ADI) designs and manufactures semiconductor products and solutions. We enable our customers to interpret the world around us by intelligently bridging the physical and digital worlds with unmatched technologies that sense, measure and connect.

Analog Devices (NASDAQ: ADI) designs and manufactures semiconductor products and solutions. We enable our customers to interpret the world around us by intelligently bridging the physical and digital worlds with unmatched technologies that sense, measure, connect, and analyze. We are world leader in the measurement of real-world signals for challenging applications the and interpretation of these measurements, which is enabling Industrial IoT applications.

ADI is a leader in the industrial space, and Industrial IOT has the potential to be a significant future growth driver for the company in both product sales and emerging analytics revenues. It has been recognized as a corporate priority to drive expansion. This role requires an energetic and motivated individual with strong vision and technical acumen to drive this initiative forward.

The Analytics Insights & Diagnostics Group (AID) is responsible for developing and delivering full end to end solutions in a variety of applications, where a combination of core differentiating ADI hardware and software technology is brought to market. This postion is responsible for using and growing the OtoSense AI framework powering Sensing Interpretation systems for a large variety of customers. The ideal candidate will be fluent in Python, familiar with the processing of sensing data and familiar with machine learning techniques and implementations methods. There is no expectation of any deep expertise in Machine Learning or Data Science, but more an eargerness to learn from the system in place and its current architects. This person must be exceedingly well organized, detail oriented and flexible, embracing the challenges of working with a variety of situations and circumstances while having the ability to interact with collaborators and external stakeholders at all levels in a complex environment. The AID group is a fast paced and dynamic team where innovation is nurtured. The variety and scope of projects provides an interesting and challenging opportunity for an impactful individual.

Responsibilities
Processing datasets using provided data processing, machine learning and visualization components of the OtoSense AI platform.
Communicating with all stakeholders (data science, product engineering, marketing, sales etc.) to present results matching specific evaluation metrics.
Improving platforms components and processes related to data processing pipelines.
Respecting software engineering best practices, from abstracted architecture to variable naming.
Documenting all changes brought to the system following established documentation guidelines.
Requirements
Bachelor or Master degree in a data-intensive and software-intensive discipline.
Proficient in Python.
Good understanding of featurization and machine learning techniques.
Excellent analytical and problem-solving skills.
Excellent interpersonal skills and an ability to develop and articulate system requirements as part of a broader strategy.
#LI-NS1

For positions requiring access to technical data, Analog Devices, Inc. may have to obtain export licensing approval from the U.S. Department of Commerce - Bureau of Industry and Security and/or the U.S. Department of State - Directorate of Defense Trade Controls. As such, applicants for this position except US Citizens, US Permanent Residents, and protected individuals as defined by 8 U.S.C. 1324b(a)(3) may have to go through an export licensing review process.

Analog Devices, Inc. is an Equal Opportunity Employer Minorities/Females/Vet/Disability

EEO is the Law: Notice of Applicant Rights Under the Law

Education Level: Bachelor's Degree
Travel Required: No","Analog Devices
3.9","Wilmington, CA",Electrical & Electronic Manufacturing,Manufacturing
Data Analyst,"Location: Sunnyvale, CAPosition Overview:

Development and maintenance support for key data infrastructure supporting the Chrome OS client team, specifically the channel/customer sales teams. The Analyst will have very strong SQL skills, strong time management and self-direction, be comfortable cleaning up tech debt and maintaining pipelines, strong attention to detail, and strong documentation skills.

Job Requirements:

Skill/Experience/Education:

Mandatory:
1-3 years developing SQL workflows.
Project management experience.
Must be a strong self-directed contributor.
Skill Matrix:

Skill Name: SQL

Level: 4

Years: 0-3 years

Mandatory: Yes

Description: Must have a high level of comfort writing and maintaining SQL pipelines

As an equal opportunity employer, ICONMA prides itself on creating an employment environment that supports and encourages the abilities of all persons regardless of race, color, gender, age, sexual orientation, citizenship, or disability.","ICONMA
3.6","Culver City, CA",Staffing & Outsourcing,Business Services
Data Engineer,"The Enterprise Data Intelligence Team of Cedars-Sinai is looking for an experienced Data Engineer/Data Intelligence Analyst. The ideal candidate is passionate about data, coding, technology and will utilize their skills to help solve complex healthcare questions. The candidate should possess a data engineering background, business acumen to think strategically and love working with people. Within this role, the candidate will experience a wide range of problem solving situations requiring extensive use of data collection and analysis. The successful candidate will work with Data Engineers, Data Scientists, Business Analysts, Doctors, Nurses and other stakeholders across organization.
Summary of Essential Job Duties:
Expert Oracle Query and Development Skills (Extensive RedShift skills a plus).
Strong AWS Cloud Platform tools: S3, Kinesis, RedShift.
Familiar with Dashboarding tools like Tableau/Qlik.
Good Linux, Python, Bash skills.
Desire to learn new tools, techniques and solve data challenges.
Educational Requirements:
Four (4) year degree in Computer Science or similar experience.

Experience:
Hospital Based Healthcare experience, especially Epic Clarity data model is a plus.
Working Title: Data Engineer
Department: EIS Data Analytics Team
Business Entity: Corporate Services
City: Los Angeles
Job Category: Information Technology
Job Specialty: Business Intelligence/Reporting
Position Type: Full-time
Shift Length: 8 hour shift
Shift Type: Day",Bloomstaff,"Los Angeles, CA",-1,-1
Data Engineer,"Job Description
Data Engineer

Bigtime Entertainment Co. building state of the art software and algorithms to improve the way that our media company transacts; interacts with consumers and customers; and makes vital business decisions with large revenue impacts. As a Data Engineer supporting the Data Science team, you will frame, pose and translate business problems to build AI-powered solutions that directly contribute to data products. As a member of the Data Science & Engineering team, you will be designing and building scalable models & architectures upon while ML algorithms can thrive, as well as refining existing model implementations so that they automatically build context in order to perform above and beyond expectations.

From creating experiments and prototyping implementations to designing new architectures, we resolve challenging and meaningful problems with compelling business use cases. Our team is committed to continuously leveraging and furthering the latest advances in ML research to transform the broader media market through our data product successes

In this role you will:

Collaborate with the data science team to build future-proof frameworks and abstractions

Collaborate with product management and engineering departments to understand company needs and devise AI powered solutions

Build tools that will increase the productivity of the Data Analytics team-members developing AI-based systems

Implement models that the data science team develops into working prototypes, proof of concepts, self-supporting model ecosystems

Build data pipelines that contribute to a self-sustaining data model system

Build demos and conduct training in conjunction with data scientist to help the broader engineering organization (and/or business partners) effectively use the product

Demonstrate and apply theories through research efforts to develop new and improved products, processes, or technologies

Participate in cutting-edge research in artificial intelligence and machine learning applications

Optimize models for on-device and multi-modal intelligence

Qualifications:

Experienced Data Engineer with a BS, MS or PhD in a quantitative field (CS, Engineering, Physics, etc.)

4+ years hands-on business experience, demonstrated implementations of ML models and techniques is a plus

Advanced in Python

Experience with AWS infrastructure (AWS Certifications are a plus)

Strong knowledge of relational and distributed databases, extremely strong in SQL

Multiple Implementations that feature good memory, disk I/O, and CPU/GPU management.

Experience with Apache infrastructure

Experience with streaming data and video manipulation

Familiarity with common ML algorithms (i.e. neural networks, tree-based methods, unsupervised learning, feature engineering)

Familiarity with ML/AI frameworks, e.g,. TensorFlow, Spark, and modular/modern software design practices.

History of research publications and/or implementations of state of the art techniques hosted on open source repositories is a plus

Passionate about ML/AI and how it can improve both the media industry and the world

Technologies we use:

AWS, Python, Python Data Science packages, Spark, Hadoop, Apache

Resumes sent to: jim@ingenium.agency

Top base salary, excellent benefits and work culture",ingenium.agency,"Los Angeles, CA",-1,-1
Data Engineer,"Job Description
Our entertainment company is seeking an innovative Senior Data Engineer to join our fast-paced team! We utilize and develop cutting-edge technology to deliver high-end and creative content on a global scale. We work across multiple platforms to transform how we see media.

The ideal candidate will possess all of the required skills listed below and more! They will demonstrate excellent interpersonal and communication skills and adhere to the standards of quality and excellence at our company's core.

Please, only apply if you are able to work directly for a U.S. company for the next three years. We are not currently able to work with C2C, H1, or OPT for this position.

Duties & Responsibilities:
Build data pipelines orchestration.
Create the design and architecture for data-lake, data-marts, data-models, and data-warehouse.
Ensure efficiency of data science workflows and advanced machine learning algorithms.
Build and optimize performance of Hadoop and Spark batch jobs (Spark, Kafka, Cassandra, etc.).
Construct and improve ElasticSearch performance.
Contribute to open source solutions and communities.
Stay current on emerging tools and technologies.
Collaborate cross-functionally with other software engineers and their teams.
Establish and demonstrate technologies, solutions, and leading practices.
Balance resources, requirements, and complexity.
Qualifications:
5+ years of experience in full software development lifecycle.
5+ years of experience developing bis data apps.
Bachelor’s or Master’s degree in Computer Science, Engineering, Mathematics or Physical Sciences.
Minimum 3 years’ experience with Apache Spark and Spark Streaming.
Minimum 3 years’ experience with Hadoop batch processing framework and map reduce design patterns.
Minimum 3 years’ experience with Java/Scala/Python in support of data applications.
Expertise in Java 1.8+, Scala 2.11, and Linux.
Demonstrated proficiency in programming and analysis (design patterns, hardware, software requirements, systems requirements, deployment protocols, etc.).
Previous experience in an Agile environment using Scrum.
Previous experience with open source technologies, widely used RDBMS’ and SQL, and at least one columnar NoSQL solution.
Preferred Qualifications:
Prior experience developing and maintaining large scale, consumer facing web apps.
Prior experience working for a large data enterprise organization, creating robust and reliable data pipelines, and using multiple NoSQL solutions (HBase, MongoDB, Neo4j).
Previous operational experience with large software systems.
Previous Schema or Cube design experience.
Familiarity with statistics, machine learning, and natural language processing apps.
Knowledge of security and PII and PCI compliance issues.
Previous experience with the following preferred:
Apache Airflow
Amazon AWS
AWS EMR
docker and Kubernetes
Restful APIs
Apache Kafka
Apache HBase
Apache Hive and/or Apache Crunch
Apache Avro
Powered by JazzHR

h23E4mKY4q",EvolvInc,"Burbank, CA",IT Services,Information Technology
Data Engineer,"Data Engineer
If you are a Data Engineer looking for a new opportunity, read on!

We are a technology company based in Pasadena and we are growing rapidly. Currently, we are looking for a Data Engineer to join our team!

As a Data Engineer, you will work within our engineering team to maintain, expand and optimize the data warehouse and data pipeline processes. You will also work with our data scientists, data analysts and product stakeholders to implement processes and infrastructure in order to support our data driven reports and
analytics. These systems process billions of location data points per day.

Apply now!
What You Need for this Position
- SPARK
- Redshift
- Linux
- UNIX
- Shell
- AWS
- SQL
So, if you are a Data Engineer with experience, please apply today!
-
Applicants must be authorized to work in the U.S.


CyberCoders, Inc is proud to be an Equal Opportunity Employer

All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, disability, protected veteran status, or any other characteristic protected by law.

Your Right to Work In compliance with federal law, all persons hired will be required to verify identity and eligibility to work in the United States and to complete the required employment eligibility verification document form upon hire.

CyberCoders will consider for Employment in the City of Los Angeles qualified Applicants with Criminal Histories in a manner consistent with the requirements of the Los Angeles Fair Chance Initiative for Hiring (Ban the Box) Ordinance.","CyberCoders
4.2","Pasadena, CA",Staffing & Outsourcing,Business Services
Data Engineer,"Role Data Engineer Location Sherman Oaks, CA Duration 6 Months 2+ years of professional experience as a Data Engineer Experience with SQL and NoSQL databases and tools of the trade such as Snowflake, Redshift, Airflow, etc. Experience with Python Strong experience writing and optimizing SQL statements Some knowledge of schema design (logical and physical) is desired Familiarity with distributed processing (Map Reduce, MPP, etc.) An interest in learning new languages, identifying and using best-in-class tools, and applying industry best practices","Agilisium LLC
4.8","Los Angeles, CA",IT Services,Information Technology
Machine Learning Engineer,"Machine Learning Engineer
If you are a Machine Learning Engineer with experience, please read on!

Based in beautiful, Calabasas, we are well-established and highly innovative software company dominating the space of human identification technology and solutions. With over 10 years of R&D studies, and 100+ patents issued/pending patents, we continue to be a true market leader in our industry.

Due to growth and demand for our services we are in need of a talented Machine Learning Engineer to join our brilliant team and help us continue to lead the charge!

Job Type: DIRECT HIRE / PERMANENT
LOCATION: CALABASAS, CA
Top Reasons to Work with Us
- HUGE opportunities for growth!
- Small, diverse, and BRILLIANT team of scientists, engineers, and PhDs!
- Highly lucrative area of study and development!
What You Will Be Doing
- Assist in our product technology development
- Design and implement integration and testing
- Help to develop techniques and strategies to ensure system dynamics are performing optimally, and to ensure client deliverables are being met
- Work cross-organizationally with multiple teams / individuals
What You Need for this Position
- Bachelor's, Master's, or PhD in relevant field of study
- 5+ years of experience working in R&D or Machine Learning field
- Experience with Python or Shell scripting
- Experience with facial recognition algorithms or machine learning
- Experience with profiling and benchmarking
- Experience with regression testing

HUGE bonus points if you have the following:
- Experience with LiDAR
- Experience with C/C++ or Matlab programming
- Experience with embedded systems
What's In It for You
- Competitive base salary
- EQUITY
- Medical, Dental, and Vision
- 401(K)
- PTO
- Small, close-knit team
- Brilliant leadership team
- We are one of the leaders in our field of study
- Great office location!
- Great company culture
- Much more!
So, if you are a Machine Learning Engineer with experience, please apply today!
-
Applicants must be authorized to work in the U.S.


CyberCoders, Inc is proud to be an Equal Opportunity Employer

All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, disability, protected veteran status, or any other characteristic protected by law.

Your Right to Work In compliance with federal law, all persons hired will be required to verify identity and eligibility to work in the United States and to complete the required employment eligibility verification document form upon hire.

CyberCoders will consider for Employment in the City of Los Angeles qualified Applicants with Criminal Histories in a manner consistent with the requirements of the Los Angeles Fair Chance Initiative for Hiring (Ban the Box) Ordinance.","CyberCoders
4.2","Calabasas, CA",Staffing & Outsourcing,Business Services
Data Engineer,"Job Description
Qualifications
Bachelor’s Degree in Computer Science, Data Analytics or similar discipline including Mathematics, Statistics, Physics, or Engineering is preferred
Advanced degree in Life or Physical Science, Bioengineering, Biomedical Engineering or closely related discipline is preferred
Minimum of 4 years work related experience with degree or sufficient transferable experience to demonstrate functional equivalence to a degree
Advanced Experience with programming scripts such as Python, Java, Scala, C++ in Linux/Unix, and R
Experience in applying data analysis techniques to a large set of data using big data systems such as Hadoop, Spark, MongoDB, or similar software
Advanced analytics knowledge and application in the field of
Statistics
Mathematical programming
Business acumen and experience with operational or strategic systems

Company Description
We are an equal opportunity employer and make hiring decisions based on merit. Recruitment, hiring, training, and job assignments are made without regard to race, color, national origin, age, ancestry, religion, sex, sexual orientation, gender identity, gender expression, marital status, disability, or any other protected classification.","Ledgent Technology
2.0","Los Angeles, CA",-1,-1
Data Engineer,"Who are we?

Sense360 is a Series A startup that is funded by prominent VC funds such as FirstMark Capital (Airbnb, Pinterest, Riot Games) and Upfront Ventures (Maker, TrueCar). Our data insights have been referenced by many publications including Bloomberg and CNBC. Sense360 was founded by successful repeat entrepreneurs.

We are transforming the way businesses make decisions by combining massive, disparate datasets and turning them into accessible, actionable, and accurate insights that drive the strategic decisions that brands make. See our Culture Deck here.



What will you do?

As a data engineer you will working on our data pipeline that processes 1.6+ TB sensor data/day and that is built using Spark, AWS, Python, Airflow and Rails. Below is a list of the major initiatives that you will be helping with.

Scale our data pipeline to handle 5MM+ users
Research, analyze and integrate new 3rd party datasets
Move our system from batch-based to real-time
Work closely with our data science team to build model building platforms
Build new data delivery mechanisms for our clients


What do we look for?

Engineers who thrive at Sense360 have a few key traits:

Care about their work, their team and their company
Heavy bias towards delivering value
Expect their ideas to be challenged because they believe that the best ideas can come from anywhere
View feedback as a gift that they give and receive
Fun and interesting


Qualifications

3+ years experience
experience with a distributed processing technology (e.g. Spark, Storm, Presto, Hadoop, Samza, Flink, etc)
solid CS and testing fundamentals
experience working in a startup or an extremely strong desire to do so


Willing to relocate if already within the US and sponsor visas.","Sense360
5.0","Culver City, CA",Enterprise Software & Network Solutions,Information Technology
Machine Learning Engineer,"One of the world’s leading financial service providers are looking for experts in Machine Learning to help them with development of predictive financial algorithms.

The company has more than 1,500 employees and 30+ years of experience, they are the perfect destination for the best and the brightest analytical minds in the world.

Job Description

Work with the Data Science team and the wider R&D teams to design and implement a new predictive data and information analytics system.

Key Responsibilities
Design and develop a new ML and deep learning system according to requirements
Implement ML algorithms and tools, as appropriate
Run ML tests and experiments to ensure everything runs smoothly
Ensure the new system runs in parallel with the new dashboard application
Extend our existing ML libraries, and migrate data to the library as and when required
Keep up to date with the latest developments and best practices in the ML field and implement new changes where appropriate
Education, Experience and Skills
An Advanced Degree/PhD in a related subject (such as Data Science, ML, Statistics, Mathematics, Computer Science etc.)
4+ years experience working with ML/deep learning systems
Expertise in coding/developing algorithms for ML/deep learning systems
Proven experience using deep learning, analytical, NLP, classifications or predictive modelling
Proficiency in Python, R, RStudios
A working knowledge of SQL/Postgresql servers
Familiarity with open source systems such as Linux, Unix or Shell
Excellent attention to detail
Ability to work as part of a team, as well as independently with minimal supervision
Great time management and organisational skills
Desirable Knowledge & Skills
Knowledge and/or experience using AWS cloud system and applications
Proficiency or a good understanding of Java programming
Great knowledge of statistical modelling
Benefits Package
Competitive pay
Remote-working opportunities
Company laptop
Apply directly at: https://prolancer.com/jobs/send-proposal/301

Benefits:
Work from home opportunities
Job Types: Full-time, Contract

Salary: $70,000.00 - $95,000.00 per year

Experience:
Machine Learning: 2 years (Preferred)",Pro Lancer,"Los Angeles, CA",-1,-1
Data Analyst,"As a Data Analyst, you will engage with business teams to define business questions, prepare and model data, and perform analyses with the purpose of understanding or drawing conclusions from the data. This role will join the Analytics Team and will work closely to build, deploy and administer self-service analytics across business units. In this role, you will utilize the Plans diverse analytics tools to turn data into actionable insights with the goal of creating a data-driven culture across the organization.

Essential Job Functions:
Engage business teams to understand business challenges, define analytics questions and apply analysis techniques to generate data products including interactive reports and dashboards.
Work closely with Analytics Team to deliver on key analytics projects. This will include data provisioning, exploratory data analysis, data visualization and in some instances, machine learning and statistical modeling.
Work with the team to implement organization KPI’s while adhering to the Plans analytics process– from business understanding, data understanding, data preparation, data modeling, evaluation, and deployment; lead by example and by training business stakeholders with varying technical and non-technical backgrounds.
Design, enable and maintian trustee reporting, executive scorecards and cross-functional tactical reports on the Plans enterprise analytics platform.
Drive the adoption self-service analytics through the analytics platform for operational reporting across multiple departments including Finance Accounting, Participant Services, Eligibility,Claims and Pension departments.
Become front-line support the analytics platform and to handle related questions, issues and requests.
Understand data requirements required by consultants and provision the data in an efficient, traceable and secure manner.
Coordinate with consultants on research and analysis workload to build indepth understanding of projects and analysis outcomes; validate approach used and evaluate outcomes.
Continuously advance your skills and those of others on the team through discussions, work assignments, training and mentoring.
Knowledge, Skills, & Abilities:
Strong ability to blend and wrangle data, create logical data models to be used as a basis for analysis.
Proficiency in using enterprise analytics platforms, data visualization tools– Tableau, Alteryx, ThoughtSpot, Business Intelligence solutions or equivalent.
Knowledge of relational DBMS, specifically Oracle, and ability to script and execute SQL queries.
Understanding of the principles and tools of statistical analysis and machine learning is a plus.
Competencies:
Customer focus - Gains insight into customer needs; identifies opportunities that benefit the customer; builds and delivers solutions that meet customer expectations; establishes and maintains effective customer relationships.
Decision quality– Makes sound decisions, even in the absence of complete information; relies on a mixture of analysis, wisdom, experience, and judgment when making decisions; considers all relevant factors and uses appropriate decision-making criteria and principles; recognizes when a quick 80% solution will suffice.
Communicates effectively– Is effective in a variety of communication settings: one-on-one, small and large groups, or among diverse styles and position levels; attentively listens to others; adjusts to fit the audience and the message; provides timely and helpful information to others across the organization; encourages the open expression of diverse ideas and opinions.
Ensures accountability– follows through on commitments and makes sure others do the same; acts with a clear sense of ownership; takes personal responsibility for decisions, actions, and failures; establishes clear responsibilities and processes for monitoring work and measuring results; designs feedback loops into work.
Instills trust– follows through on commitments; is seen as direct and truthful; keeps confidences; practices what he/she preaches; shows consistency between words and actions.
Minimum Qualifications:
Bachelor’s Degree in Computer Science, Information Systems, or other related field as well as equivalent work experience.
Minimum 5 years in a quantitative data analytics role with emphasis on data preparation and analysis.
Requirements
Inspired to perform without outside help
Inspired to perform well by the chance to take on more responsibility
Inspired to perform well by the completion of tasks
Inspired to perform well by the ability to contribute to the success of a project or the organization
Previous work experience in the HealthCare industry preferred.
In a quantitative data analytics role with emphasis on data preparation and analysis.","SAG-AFTRA Health Plan and SAG-Producers Pension Plan
2.8","Burbank, CA",-1,-1
Data Analyst,"Title: Data Analyst
Company: Arize Corporation
Location: Anaheim, CA
Job Type: Full-time
We are seeking a Data Analyst to join our team! One who will advise in business-wide decision making based on data analysis.
What the Data Analyst needs:
BA/BS – Bachelor’s Degree in Business Information Systems, Statistics, or related fields
1+ years’ experience as a business data analyst
Technical expertise of data models, data mining and segmentation techniques
Experience using statistical modeling tools and methodologies to analyze datasets
Strong analytical skills with the ability to collect, organize, analyze, and disseminate significant amounts of information with attention to detail and accuracy
Adept at queries, report writing and presenting findings
What the Data Analyst will be doing:
Collect and interpret data then analyze datasets using statistical tools and techniques
Provide ongoing support and present findings to all internal departments
Develop and implement databases, data collection systems, data analytics and other strategies that optimize statistical efficiency and quality
Acquire data from primary or secondary data sources and maintain databases/data systems
Identify, analyze, and interpret trends or patterns in complex data sets
Filter and “clean” data by reviewing computer reports, printouts, and performance indicators to locate and correct code problems
Work with management to prioritize business and information needs
Locate and define new process improvement opportunities
What we offer the Data Analyst:
Fully Covered Employee Medical, Dental and Vision Coverage
Company Paid Life/A&D and LTD Insurance
Health and Dependent FSA
Generous Time Off Policy
401(k) Match
EAP
*Applicants must be authorized to work in the U.S.
Arize Corporation is proud to be an Equal Opportunity Employer
All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, disability, protected veteran status, or any other characteristic protected by law.
Job Type: Full-time
Benefits:
401(k)
401(k) Matching
Dental Insurance
Employee Assistance Program
Flexible Schedule
Flexible Spending Account
Health Insurance
Life Insurance
Paid Time Off
Retirement Plan
Vision Insurance
COVID-19 considerations:
This job may be on-boarded remotely and is considered a temporary position for the first 90-days. Afterwards, this role becomes permanent and may require attendance in the Anaheim, CA office.
Experience:
data analysis: 1 year (Required)
Education:
Bachelor's (Required)
Location:
Anaheim, CA 92806 (Required)
Work authorization:
United States (Required)
Schedule:
Monday to Friday
Company's website:
arizehub.com
Work Remotely:
Temporarily due to COVID-19","Arize Corporation
3.0","Anaheim, CA",Publishing,Media
Data Engineer,"Req ID: 177937

The Job

The Data Engineer will be a member of the Media Supply Chain (MSC) team within the WarnerMedia Technology (WMTO) organization, the position will be responsible for the design and implementation of search and data relationship functionality for the WB content platform. The Data Engineer must have experience with data modeling, modern database technologies, and API driven search design and development. The Data Engineer will make technology and design decisions, and partner across the organization in a collaborative manner to achieve results for our mission critical content and data management and distribution applications.

The Media Supply Chain Who We Are
Media Supply Chain is tasked to architect, engineer, and program manage a wide range of applications, workflows and services for our internal partners who operationally manage and distribute WarnerMedia content globally. Our applications and technology solutions are responsible for scheduling, image & asset metadata management, as well as, content processing and delivery as well as content mastering, localization and preservation. We are the team pioneering new ways to process and deliver WarnerMedia content to its global customers

The Media Supply Chain Mission
Our mission is to provide and sustain practical, innovative, agile software and technology solutions which are highly reliable, automated, measurable, optimized, modern systems capable of distributing high-quality content and metadata to our domestic and global platforms & partners.

The Daily
Develop and provide support for core data relationship, data ingest, data transformation services and search capabilities. Creates functional and technical specifications. Creates and executes against a plan to launch and maintain applications.
Review project objectives and determine best technology for implementation. Implement best practice standards for development, build and deployment automation.
Evaluate software products and vendors for WarnerMedia (WM) Technology and other divisions. Recommend action, develop and lead implementation of selected products/services.
Work with internal and external developers to ensure (WM) Technology code standards and best practices are performed for development of applications.
The Essentials
B.S. in Computer Science or equivalent experience.
AWS Developer Certification preferred.
AWS Database or Data Analytics Certification preferred.
3+ years data engineering experience.
Demonstrated proficiency in data modeling and data structures.
Demonstrated experience implementing database technologies such as NoSQL, and Relational. Experience in graph databases a plus.
Demonstrated expertise and experience in ELK stack (elasticsearch, logstash, kibana).
Demonstrated expertise and experience in modern databases such as Mongo, Couchbase, Neptune, Neo4j, or equivalent. Experience in MarkLogic a plus.
Proficient in one or more modern query languages such as elasticsearch query DSL, cypher, gremlin, or graphql. xQuery preferred but not required.
Highly proficient in XML, JSON and YAML data exchange formats. Experience in XSDs and triple stores.
Proficient in API design and development, specifically REST APIs. Experience with Swagger 2.0 and AWS API gateway is highly preferred.
Demonstrated experience in data analytics tools such as Tableau, Kibana etc.
Experience in working with data streaming technologies such as Amazon Kinesis, Apache Kafka etc.
Experience in AWS at scale leveraging services such as elasticsearch, RDS, Redshift, Neptune and ec2.
Highly proficient in at least one modern programming language such python, java, or node.js. Bash experience preferred.
Demonstrated expertise and experience in deploying containerized application using Docker, Kubernetes or equivalent.
Experience with source code and knowledge repositories such as git, jira, or equivalent systems.
Proficient in a Linux environment.
Proficient in core DevOps principles.
Proficient in the SDLC in an agile environment.
Systems design and architecture.
Ability to work with outside vendors and clients under sometimes adverse circumstances and under time critical constraints.
Must be able communicate effectively and tactfully with all levels of personnel (in person, written, telephone).
Must be able to pay close attention to detail.
Must be able to handle multiple tasks in a fast-paced environment.
Must be able to organize and schedule work effectively.
Must be able to work flexible hours, including overtime, if and when necessary.
Must be able to respond to after-hours pager notifications to provide support for applications as necessary.
177937","Turner Broadcasting
3.7","Burbank, CA",TV Broadcast & Cable Networks,Media
Data Engineer,"Responsibilities:
Responsible for building and maintaining the machine learning data and development platform.
Build, integrate and deploy machine learning solutions into the BlackLine application in collaboration with product management, cloud, engineering and data science teams.
Create and maintain scalable data pipeline in the cloud (AWS and GCP).
Assemble large, complex data sets that meet functional / non-functional business requirements.
Identify, design, and implement processes automation and data delivery.
Build infrastructure for optimal extraction, transformation, and loading of data from a wide variety of data sources.
Execute extract, transform and load (ETL) operations on large datasets including data identification, mapping, aggregation, conditioning, cleansing, and analyzing.
Build analytics tools to provide actionable insights into business and product performance.
Keep data separated, isolated and secured.
Assist data scientists in implementing achine learning algorithms and contribute to building and optimizing our product into an innovative industry leader.
Participate in establishing best practices while team is transitioning to new technologies, tools and infrastructure. Maintain specifications and metadata; follow the best practices.
Recommend and implement process improvements.
Maintain specifications and metadata; follow and develop best practices.
Coach and technically train data analysts, if needed.
Qualifications:
5+ years as a data engineer.
Experience with SQL, Python, R languages.
ETL experience using Python.
Experience with Hadoop, Spark, Hive. Presto is a plus.
Practical experience with GIT version control.
Strong familiarity with GCP, AWS, SQL Server.
Comfortable working with open source tools in Unix/Linux environments.
Data warehousing experience, data modeling and database design.
Experience with machine learning packages and various ML algorithms.
Experience with predictive and prescriptive analytics, modeling, and segmentation.
Experience with data analytics, big data, and analytics architectures.
Comfortable handling large amounts of data.
Experience ensuring data and modeling accuracy, cleanliness, reliability.
Works independently without the need for supervision.
Experience translating business requirements into functional, and non-functional requirements.
Strong sense systems and data ownership.","BlackLine
3.9","Woodland Hills, CA",Computer Hardware & Software,Information Technology
Data Engineer,"Aspiration is the first VC-backed neobank on a mission to be the leading consumer financial services brand and company focused on sustainability and the environment. At Aspiration, we created the category of sustainable, socially responsible retail consumer finance. We offer unique financial products to let people save, spend, and invest their money in ways that make them more financially secure and align with their personal values. Unlike other financial institutions, Aspiration is committed to building a relationship with our customers based on trust and aligning the customer’s success with our own. Aspiration has raised over $200M in funding to date, and is growing quickly.

We are looking for smart and highly motivated individuals of our Data Engineering team to contribute towards the success of Aspiration goals - to bring fair financial products to masses. This is a hands-on technical role and will be responsible for building scalable solutions as it relates to data architecture strategies, data standards, and data integration tools.

What You'll Do
Build and extend a scalable and modern data analytical environment
Architect, design and develop end-to-end data pipelines across multiple data sources and systems of record
Develop, design data models, data structures for data acquisition and manipulation purposes
Build custom metadata-driven frameworks using programming languages as well as leveraging off-the-shelf integration tools, as appropriate
Create ETL/ELT processes based on mapping specification documents (STMs)
Ensure data quality, integrity, security and completeness throughout the data lifecycle
Perform ongoing monitoring, automation and refinement of data engineering solutions
Surface data in company chosen BI tool for self-service usage
Analytical infrastructure support and enhancement
Enable data science team by providing necessary infrastructure and tools
Interface closely with product, engineering and business divisions
Deep understanding of the cloud offerings and engage in quick proof of concepts and proof of value in prototyping data and analytics solutions and derive viability
Ability to interact with the business stakeholders to understand requirements and translate into technical solutions
Build and meet project timelines and manage delivery commitments with proper communication to management
What You'll Bring
5+ years of experience with SQL
5+ years of experience in ETL concepts/technologies and data modeling
Thorough understanding of relational and analytical databases
Strong technical, logical and problem-solving skills
Experience with working on multiple tasks/projects in parallel
Ability to manage multiple deliverables in a highly energized and fast-paced environment within a framework of constantly shifting deadlines and deliverables
Working experience in a fast-paced and agile environment
Ability to work well in a team environment and brainstorm ideas with other team members.
Flexibility to adapt to a change and willing to learn and develop new skill sets as applicable
Ability to learn new technologies without formal training
Experience with ETL/ELT tools, e.g. Matillion, Talend, Pentaho, SyncSort, SSIS is a big plus
Experience with BI tools, e.g. Looker, Tableau, MicroStrategy, Mode is a big plus
Experience in programming/scripting languages (c#/java/bash/powershell/ruby/python) is a big plus
Experience with Snowflake,Amazon Redshift, S3, Elastic MapReduce, Hive, and other AWS services, or equivalent technologies is a big plus
Experience ingesting and transforming data from APIs is a big plus
Experience with real-time data capture, processing, and storing using technologies like Kafka, AWS Kinesis.
Prior experience with MPP databases and maintaining a large amount of data processing is a big plus
What You'll Get
Work for a mission-driven company to transform the lives of millions by building a better, values-oriented financial firm
Competitive Salary and Equity Incentives
Robust Healthcare Plans (medical, dental, vision)
401K & Unlimited Vacation Time
Diverse & Inclusive Culture","Aspiration
2.4","Los Angeles, CA",Brokerage Services,Finance
Data Engineer,"Job Description:About the Team:TrueCar is seeking to add Engineers to our Data Engineering team. This team applies subject matter expertise to ingest, analyze, and validate the automotive data required from internal and 3rd party sources. Data engineers are responsible for building and maintaining highly scalable data pipelines to power the website while also providing data for our analytical engine to derive insights in a meaningful fashion.About the Job:* Design and develop efficient and scalable data processing pipelines using big data technologies ( Hadoop, Spark, HBase, Kinesis, MapReduce, etc.) on large scale structured/unstructured data sets for optimal extraction, transformation, and loading of data from a wide variety of data sources using SQL/NoSQL.* Build complex workflows and orchestrate data dependencies.* Monitor and support data pipelines to honor internal and external SLA's.* Work within standard engineering practices (i.e. SCRUM, unit/integration testing, design review, code reviews, continuous integration, etc.) to deliver product features with optimal efficiency for TrueCar customers and clients.* Closely work with product owners & analysts to understand business and functional requirements and contribute to the design and prioritization discussions.* Working with a team of engineers where mentorship is valued.* Ability to learn and adapt to continually evolving technologies in the big data ecosystem.What you need:* 3 years of experience programming in Java.* 1+ years of experience in the Big Data technologies.* Experience in any of big data technologies: MapReduce, Spark, HBase,* Proficient in SQL and experience with RDBMS/NoSQL databases.* Experience working with Cloudera/Hortonworks/EMR distribution in AWS.* Ability to self-manage tasks and be proactive in working with other teams to accomplish them while taking pride and ownership in their work.* Team-player with strong collaboration and communication skills, who is able to respond positively to feedback.* Bachelor degree (or Master) in Computer Science or related engineering fieldAbout TrueCar:TrueCar is a leading automotive digital marketplace that enables car buyers to connect to our nationwide network of Certified Dealers. We are building the industry's most personalized and efficient car buying experience as we seek to bring more of the purchasing process online. Consumers who visit our marketplace will find a suite of vehicle discovery tools, price ratings, and market context on new and used cars -- all with a clear view of what's a great deal. When they are ready, TrueCar will enable them to connect with a local Certified Dealer who shares in our belief that truth, transparency, and fairness are the foundation of a great car buying experience. As part of our marketplace, TrueCar powers car-buying programs for over 250 leading brands, including AARP, Sam's Club, and American Express. Nearly half of all new-car buyers engage with TrueCar powered sites, where they buy smarter and drive happier.TrueCar is headquartered in Santa Monica, California, with offices in Austin, Texas, and Boston, Massachusetts.Location(s):Santa Monica, CA","TrueCar
2.7","Santa Monica, CA",Internet,Information Technology
Data Analyst,"Job Description
Data Analyst

Online Retailer

Torrence CA

Our client is currently seeking an outstanding data analyst with extensive data analytics experience to work in the newly built Data Science team. The candidate will be responsible for analyses of large amount of data from different scopes of business, developing new dashboards and improving existing reports. The role involves a tight collaboration with many departments including Supply Chain, IT, Pricing, Merchandising and C-level managers. The ideal candidate is a highly data-driven individual with great communication skills.

You Will
Develop forward-thinking strategies for gross margin optimization;
Use statistical methods to analyze data and generate useful business reports;
Identify and recommend new ways to cost optimization by streamlining business processes;
Continually evaluate sales data and develop data-driven decisions;
Work with other departments to outline specific data needs for each business method;
Develop and maintain reporting that adapts to changing business needs;Extract, clean, and validate large amounts of data.
You Are
Master’s degree in a quantitative field;
At least 2 years of professional experience in data analytics;
Highly proficient skills: SQL, Python (pandas), Excel, data visualization tools (e.g. Tableau, matplotlib), NoSQL knowledge is preferred;
Outstanding strategic thinking and analytic skills;
Demonstrated ability to synthesize facts and insights into concrete, actionable recommendations;
Excellent communicator, both verbal and written, with the ability to influence at all levels of the organization;
Results-driven with a desire to work in a fast-paced environment;
Detail-oriented with a lot of patience in analyzing data;
Strong organizational, planning, and time management skills.",NextDeavor Services,"Carson, CA",-1,-1
Data Engineer,"Develops and maintains scalable cloud-based ingress and egress data pipelines
Support continuing increases in data volume and complexity
Collaborates with team’s analytics members to improve data models that feed business intelligence tools, increasing data accessibility and fostering data-driven decision making across the organization
Implements processes and systems to monitor data quality, ensuring production data is always accurate and available for key stakeholders and business processes that depend on it
Writes unit/integration tests, contribute to engineering wiki, and documents work
Performs data integrity tasks required to troubleshoot data-related issues and assist in the resolution of data issues
Design data integrations and data quality framework
Contribute to the continuing technology stacks advancements in a leadership level
Works closely with engineering clients/partners to develop strategies for long term data platform architecture
Qualifications / Skills:
Knowledge of Microsoft Azure-based ETL best practices and IT operations in an always-up, always-available service
Experience with or knowledge of Agile Software Development methodologies
Excellent problem solving and troubleshooting skills
Process-oriented with great documentation skills
Excellent oral and written communication skills with a keen sense of customer service
Experience Requirements:
BS or MS degree in Computer Science or a related technical field
4+ years of Python or Java development experience
4+ years of SQL experience, specifically in sparkSQL and hiveSQL
4+ years of experience with schema design and dimensional data modeling
2+ years of DataBricks or equivalent spark development using scala or python
2+ years of Apache Data Frames in Microsoft Azure data blob, Databricks Delta Lake experience preferred.
2+ years of experience designing, building, and maintaining ETL systems
Experience of Azure Function Apps, Event Hub and TomCat Servers
Experience of supporting Microsoft SQL and MySQL
Experience of Kafka, Oracle, Splunk, Google Analytics, Apple Store data interface
Experience of developing JDBC and ODBC connection
Experience of developing REST API interface
#LI-AS

NortonLifeLock is proud to be an equal opportunity employer. We celebrate diversity and are committed to creating an inclusive and accessible environment for all employees. All employment decisions are based on merit, experience, and business needs, without regard to race, color, national origin, age, religion, sex, pregnancy (including childbirth or related medical conditions), genetic information, disability (physical or mental), medical condition, marital status, sexual orientation, gender identity or gender expression, military or veteran status, or any other consideration made unlawful by federal, state, or local law. NortonLifeLock strictly prohibits unlawful discrimination based on such protected characteristics and seeks to recruit the most talented candidates from diverse cultures and backgrounds.

We also consider for employment qualified individuals with arrest and conviction records. In addition, NortonLifeLock will not discharge or in any other manner discriminate against employees or applicants because they have inquired about, discussed, or disclosed their own pay or the pay of another employee or applicant. Learn more about pay transparency.

EEO is the law. Applicants and employees of NortonLifeLock Inc. are protected under Federal law from discrimination. See the EEO poster and supplement.

Apply","NortonLifeLock
3.7","Culver City, CA",Internet,Information Technology
Data Analyst,"Data Analyst

Category: Information Systems
Type: Contractor
Description: A leading Third Party Claims Administrator, located in Pittsburgh, PA, is seeking (2) Data Analysts for a 9+ month contract role.

Summary: The Senior Data Analyst position is responsible for MySQL data monitoring, enhancements and improvements deemed warranted by the compliance team and product manager. This role will serve as gatekeeper of the MySQL data and include automating of data conversions and procurement, interpretation and conversion of Medical Bill Review data as required by the needs of the data team.

Responsibilities:
● Application/data monitoring and improvements to enhance efficiency and productivity.
● Automation of data conversions.
● Work with the database assigned product manager and database infrastructure lead to implement changes aimed at efficiency and scalability.
● Procurement, interpretation and documentation of all data applicable to Medical Bill Review. (CMS Pricer, CMS APC, Physician Fee Schedules, Usual and Customary, Pharmaceutical, CPT, ICD9, etc?)
● Knowledge of state, federal and industry standard fee schedules, reimbursement methodologies and regulations, including but not limited to: DRG, ASC, APR-DRG, OPPS and RBRVS
● Populating and/or manipulating data in development, test and production environments.
● Work with software developers to implement changes defined by the State and Federal laws.
● Internal support and assistance to other members of the data team.

Qualifications:
● Knowledge of SQL and related database tools.
● Knowledge of Microsoft Access.
● Ability to work with the software development community.

Experience/Education

Six (6) years of related experience or equivalent combination of education and experience required. Experience in multi-line claims management processes and system requirements strongly preferred.

● Experience working in a relational database environment
● MySQL experience preferred
● Experience in the medical field necessary
● Detail oriented person desired

Location Pittsburgh , PA
Minimum Experience (yrs):
Required Education: Not Specified
Benefits:

Return to search results Email this job to a friend

*Logged in members may also add jobs to their job cart","Login Consulting Services
3.8","El Segundo, CA",Consulting,Business Services
Data Engineer,"Job DescriptionTechStyle Fashion Group is looking for a Data Engineer.How Do You Fit In?As the Data Engineer, you will take ownership of Development oversight, guidance, and direction setting for the data pipeline as well as the Data Management platforms. The right candidate would be a self-motivated, highly detail-oriented team-player with a positive drive to strategize and implement BI Solutions that enable the business to derive valuable insights. You will join a tight knit group of key contributors who are actively working together to achieve aggressive goals and meet timelines to drive the business forward. This role is critical in laying the foundation for the key Decision support systems that will form the backbone of our Big Data ecosystem.This position will report to the Director of Data AnalyticsResponsibilities:* Design, Build and Maintain hundreds of data pipelines using Airflow (Python)+ SQL(Snowflake) to extract, transform, clean, audit and move data from internal or external systems into a Cloud Based Data Warehouse (Snowflake)* Work with Data / Data Warehouse Architect to develop data warehouse models, design specifications, metadata process and documentation. Develop detailed ETL specifications based on business requirements* Interface with other technology teams to develop/maintain the ETL footprint and quality from a wide variety of in-house and 3rd party data sources* Implement and monitor machine learning algorithms and solutions in production.* Constantly Monitor, refine and maintain system performance and provide statistical reporting* Participate in cross-functional meetings to review business requirements/use stories, assist in fit/gap analysis and provide detailed technical design documentation* Partner with business users, senior architects, product managers, engineering teams, and other teams to deliver a robust data services platform* Diagnose ETL and database related issues, perform root cause analysis(RCA), and recommend corrective actions to management* Recommend ways to improve data reliability, efficiency and quality* Profile and understand the large amounts of source data available, including structured and semi-structured/web/mobile activity data* Mentor the team on the industry standards and best practices for effective use of data integration and data quality technologies and exception handling* Provide cross organizational business stakeholders operational support on existing and newly developed data pipelineRequired Skills:* 3+ years of data engineering experience with high performance Big Data platforms including cloud-based Data Warehousing on large scale development efforts leveraging industry standard ETL tools* 3+ years of experience creating and managing data pipelines using Python (experience with Airflow preferred)* 3+ years of Data Warehouse development for 100's of gigabytes of data and billions of records (Snowflake or Redshift is preferred)* Experience developing ELT pipelines using Snowflake, Terradata, Vertica, Redshift or similar data warehousing technologies* Experience implementing streaming pipelines (Kinesis, Kafka, Storm, Spark, Flink)* Experience working in an environment that ingests large amounts of raw data (web logs, Click stream, data feeds)* Experience with source code management using Git or Subversion and release processes.* Experience with scalable systems in a load balanced environment and experience conducting load tests* Ability to extend your scope into the Analytics domain and partner with that team to optimize the output of the Analytics function* Ability to create and interact with very large data processing pipelines, distributed data stores, and distributed file systems* Experience with Spark or Databricks in a production setting is a plus* Ability to learn quickly and multi-task in a fast-paced, dynamic environment* Understanding of data warehouse architectures (Kimball a plus) & Strong metadata modeling experience* Experience with EDA (Exploratory Data Analysis) and Data Visualization a plus* E-commerce or retail or internet experience a plusTechStyle is an Equal Opportunity Employer: M/F/PV/D (minority, female, protected veteran, disability)","Techstyle Group LLC
5.0","El Segundo, CA",Industrial Manufacturing,Manufacturing
Data Engineer,"Who are we?Sense360 is a Series A startup that is funded by prominent VC funds such as FirstMark Capital (Airbnb, Pinterest, Riot Games) and Upfront Ventures (Maker, TrueCar). Our data insights have been referenced by many publications including Bloomberg and CNBC. Sense360 was founded by successful repeat entrepreneurs.We are transforming the way businesses make decisions by combining massive, disparate datasets and turning them into accessible, actionable, and accurate insights that drive the strategic decisions that brands make. See our Culture Deck here.What will you do?As a data engineer you will working on our data pipeline that processes 1.6+ TB sensor data/day and that is built using Spark, AWS, Python, Airflow and Rails. Below is a list of the major initiatives that you will be helping with.Scale our data pipeline to handle 5MM+ usersResearch, analyze and integrate new 3rd party datasetsMove our system from batch-based to real-timeWork closely with our data science team to build model building platformsBuild new data delivery mechanisms for our clientsWhat do we look for?Engineers who thrive at Sense360 have a few key traits:Care about their work, their team and their companyHeavy bias towards delivering valueExpect their ideas to be challenged because they believe that the best ideas can come from anywhereView feedback as a gift that they give and receiveFun and interestingQualifications3+ years experienceexperience with a distributed processing technology (e.g. Spark, Storm, Presto, Hadoop, Samza, Flink, etc)solid CS and testing fundamentalsexperience working in a startup or an extremely strong desire to do soWilling to relocate if already within the US and sponsor visas.",Sense 360,"Culver City, CA",-1,-1
Data Engineer,"Company Overview:
Age of Learning is a leading education technology innovator based in Glendale, California, with a talented team of 500+ individuals comprised of nationally-renowned educators, curriculum experts, designers, animators, engineers, and more. We develop engaging, effective digital learning technology and content to help children build a strong academic foundation for lifelong success.
Our flagship product ABCmouse.com Early Learning Academy® is a comprehensive online curriculum and the #1 digital learning product for young children. To-date, more than 30 million children worldwide have completed over 6 billion Learning Activities on ABCmouse. We recently launched Adventure Academy, the first massively multiplayer online (MMO) game designed specifically to help elementary- and middle-school-aged children learn. It features thousands of engaging Learning Activities—including minigames, books, original animated and live action series, and more—in a fun and safe virtual world. Other Age of Learning programs include immersive English language learning products for children in China and Japan; ReadingIQ, a digital library and literacy platform; and a groundbreaking personalized, adaptive digital learning system that individualizes math instruction for every child through AI-driven technology.

We are committed to helping all children succeed. We provide our educational programs at no cost to teachers, Head Start programs, public libraries, and other community organizations, and have served millions of children through these initiatives. We recently established the Age of Learning Foundation to expand this work globally.
As we expand our global reach and increase the educational impact of our programs, we’re looking for passionate, ambitious, and collaborative leaders to become a part of our growing team.


Summary:
We are seeking a full-time, in-house Senior Data Engineer to join our development team. This person will be helping us develop high performance, high-throughput services using modern technologies and techniques.
Responsibilities:
Design, develop, test, implement and support applications using custom ETL (Extract Transform Load) or open source tools such as Talend
Prepare high-level component architecture; design documents, data flow diagrams, detail design documents, data schema and modeling combined with test plan documents
Design, develop and test highly available and scalable data pipelines and relevant data storage systems to enable business success across a multi-product functionality
Proactively identify operational and systemic issues within the data supply value chain (from collection to processing to reporting) and work with production operations (DevOps) team to implement monitoring solutions
Ensure testing and validation best practices are followed across the team so that accuracy of data transformations and data verification are complete and documented
Execute in a fast-paced matrix organization across product and engineering teams to identify best data-driven solutions for the underlying data infrastructure and platform
Ensure high operational efficiency and quality of your solutions to meet SLA (Service Level Agreement) and support commitment to stakeholders (both internal and external)
Be an active participant and advocate of agile/scrum practice to ensure health and process improvements for your team
Required Qualifications:
Experience designing and building large, scalable data systems, preferably across a multi-product portfolio
Strong SQL skills with proven ability to write complex data queries across large data sets.
Exposure to software development, preferably in an Agile/Scrum/Kanban environment across multiple products
Experience analyzing and manipulating data across diverse data sources (Python, Scala)
Experience working across AWS (Amazon Web Services) cloud environment (EC2, S3, RDS, Sagemaker)
Strong exposure to Big Data technology, preferably across a containerized environment (Hadoop, Spark, Hive, Presto)
Experience with sourcing and modeling data from Restful API (Application Programming Interface)
Strong attention to detail with excellent analytical, problem-solving, and communication skills
Bachelor’s degree in Computer Science, Computer Engineering, or Information Technology or a related field, or an equivalent combination of education and experience
Exemplary communication skills (both written and verbal), with experience producing technical and design documentation of complex processes
Good time management and ability to work on concurrent assignments with different priorities
Ability to work in a fast paced, iterative development environment with short turnaround times
Preferred Qualifications:
Experience with A/B Testing and related optimization across desktop and mobile in a digital environment a plus (examples include: Optimizely, Leanplum, deltaDNA)
Experience analyzing and manipulating data across several data formats (JSON, Avro, Parquet, ORC)
Experience building and architecting data warehouse workflows in large cloud-based production environments (Snowflake is an example)
Understanding of columnar data warehouse solutions (Redshift, Vertica)
Experience migrating on-prem data solutions to the cloud with a strong data operational hygiene
Experience developing and maintaining metadata catalogue APIs across a variety of data sources (AWS Glue, Metacat)
Prior experience working in educational technology companies or a related competitive landscape is a plus
We Provide:
Medical, Dental, Vision + 401k
Highly competitive PTO policy
Casual Dress Code
Snacks + Drinks (Coca Cola Freestyle Machine)
Gaming room including an Arcade (2,000+ games)
Frequent team and company outings
Limitless opportunities for professional growth!","Age of Learning
3.3","Glendale, CA",K-12 Education,Education
Data Engineer,"Responsibilities:* Responsible for building and maintaining the machine learning data and development platform.* Build, integrate and deploy machine learning solutions into the BlackLine application in collaboration with product management, cloud, engineering and data science teams.* Create and maintain scalable data pipeline in the cloud (AWS and GCP).* Assemble large, complex data sets that meet functional / non-functional business requirements.* Identify, design, and implement processes automation and data delivery.* Build infrastructure for optimal extraction, transformation, and loading of data from a wide variety of data sources.* Execute extract, transform and load (ETL) operations on large datasets including data identification, mapping, aggregation, conditioning, cleansing, and analyzing.* Build analytics tools to provide actionable insights into business and product performance.* Keep data separated, isolated and secured.* Assist data scientists in implementing achine learning algorithms and contribute to building and optimizing our product into an innovative industry leader.* Participate in establishing best practices while team is transitioning to new technologies, tools and infrastructure. Maintain specifications and metadata; follow the best practices.* Recommend and implement process improvements.* Maintain specifications and metadata; follow and develop best practices.* Coach and technically train data analysts, if needed.Qualifications:* 5+ years as a data engineer.* Experience with SQL, Python, R languages.* ETL experience using Python.* Experience with Hadoop, Spark, Hive. Presto is a plus.* Practical experience with GIT version control.* Strong familiarity with GCP, AWS, SQL Server.* Comfortable working with open source tools in Unix/Linux environments.* Data warehousing experience, data modeling and database design.* Experience with machine learning packages and various ML algorithms.* Experience with predictive and prescriptive analytics, modeling, and segmentation.* Experience with data analytics, big data, and analytics architectures.* Comfortable handling large amounts of data.* Experience ensuring data and modeling accuracy, cleanliness, reliability.* Works independently without the need for supervision.* Experience translating business requirements into functional, and non-functional requirements.* Strong sense systems and data ownership.",BlackLine Systems,"Woodland Hills, CA",-1,-1
Data Scientist,"Ready to write the best chapter of your career? XSELL Technologies is an artificial intelligence company focused on increasing sales. Our cloud-based machine learning engine uses predictive analytics and natural language processing to equip sales professionals with the best real-time responses, driving improved conversion rates and customer experiences. We pride ourselves on our high performing, collaborative culture. We are passionate about our product, our clients, and our industry leading results.

XSELL is currently seeking a Data Scientist to serve as a key member of our Data Science team. This role will work within the SAFe Agile framework of continuous delivery, work with other Data Scientists, and be a critical resource for our growing Data Science staff.

Job Description
Designing, implementing and improving XSELL’s proprietary softwares, real time messaging recommendation systems, HiPerCoBot and QABOt using various mathematical, Natural Language Processing (NLP) algorithms and machine learning models.
Developing new systems using Python NLP (lemmatization, stemming, named entity recognition) and updating the existing systems by adding new features to enhance the customers experience.
Interacting with stakeholders to identify the requirements and define new processes.
Closely work with the team to define the architecture of the Microservice environment and deploy systems using RESTful API’s.
Planning, development, and analysis of dialogue prediction/sentiment models, causal models of customer/agent behavior.
Improving the accuracy of the in house XSELL Recommendation System software suite by evaluating and monitoring annotations manually labelled by Ontology team.
Analyzing and researching the current market trends for possible AI opportunities/improvements.
Qualifications
MS/PhD in a quantitative discipline (e.g. Machine Learning, Data Science, Computer Science, Mathematics, Statistics, or a related field).
3+ years full time employment or postdoctoral experience building and validating predictive models on structured or unstructured data.
Proficiency in Python with knowledge of basic libraries for data manipulation, machine learning, natural language processing and text mining.
Experience creating and using advanced machine learning algorithms (regression, neural networks, etc.)
Understanding of deep learning algorithms and experience with related libraries such as TensorFlow, PyTorch.
Nice to Have
Experience in SQL.
Understanding of object oriented design.
Ability to craft new concepts and stay current with academic research
Experience with graph databases and graph designs.
Experience in designing/developing production level machine learning architectures (using Flask or Redis)
We provide competitive compensation, generous benefits, and a professional atmosphere. XSELL fosters an entrepreneurial, results driven work environment where you will have the opportunity to be part of a collaborative, inclusive team and be able to grow and develop your professional career.

XSELL Technologies is an Equal Employment Opportunity Employer and all employment decisions shall be made without regard to age, race, creed, color, religion, sex, national origin, ancestry, disability status, veteran status, sexual orientation, gender identity or expression, genetic information, marital status, citizenship status or any other basis as protected by federal, state, or local law.

Location: Chicago, IL

Role: Full-Time / Salaried","XSELL Technologies
3.8","Chicago, IL",Enterprise Software & Network Solutions,Information Technology
Data Analyst,"Data
Analyst

Wintrust Wealth Management

Chicago, Illinois

Preeminent firm in Chicago Loop is seeking a data analyst
to support our company’s data functions.

The
ideal candidate will be responsible for various data analytics and intelligence
functions including, but not limited to, the following:
Project-based
and ad-hoc data analysis and reporting requests
Compile
complex data sets from various source systems
Assist
with data governance initiatives, identifying and documenting key data elements
and source systems
Performs
data quality control checks and validation processes on housed data
Follow procedures for data preparation and analysis
including data standardization, cleansing, and validation
Educate front line data entry individuals on data
quality standards required for effective database management
Create various exception and control reports to
improve the quality of data
Monitor the receipt and transfer of data to/from
third parties and internal sources; ensuring that ETL processes are timely and
accurate.
Work with existing team members to continuously
evaluate and improve upon the technology and methodologies utilized
Discover, troubleshoot, and resolve errors and
discrepancies in data and report issues to impacted stakeholders
Perform
data analysis in support of strategic initiatives
Identify,
analyze and interpret patterns in complex data sets
Prepare ad-hoc reporting and analysis for various
functional areas within the organization
Maintain
monthly, quarterly and annual data reports for various firm functions that are
available on demand through self-service reporting portals and tools
Qualifications and Experience
Detail-oriented,
with expert problem-solving capabilities
5
years of experience developing in SQL, C#, or Python
5
years of experience with database management and analysis (data profiling, data
architecture, data governance)
3
– 5 years of experience developing and maintaining ETL processes
1
3 years of experience working with data visualization tools (PowerBI,
Tableau, Qlik, etc.)
Exceptional
interpersonal skills and the ability to partner with different functional areas
across an organization
Experience
with translating business objectives into technical requirements
Ability
to multi-task and meet deadlines
Displays
ethics, integrity, and professionalism at all times
Excellent
communication skills, both verbal and written
Bachelor’s Degree in Computer Science, Engineering, Mathematics,
or Finance
Wintrust
Financial Corporation (including community banking and financial services
subsidiaries) is an Equal Opportunity/Affirmative Action/Veterans/Disability
employer. EOE.

Please
forward resumes and cover letters to Jelena Jovovic, Director of Human
Resources and Recruiting, at jjovovic@wintrustwealth.com.","Wintrust Financial
3.9","Chicago, IL",Banks & Credit Unions,Finance
Data Engineer,"77 West Wacker Dr (35012), United States of America, Chicago, Illinois

At Capital One, were building a leading information-based technology company. Still founder-led by Chairman and Chief Executive Officer Richard Fairbank, Capital One is on a mission to help our customers succeed by bringing ingenuity, simplicity, and humanity to banking. We measure our efforts by the success our customers enjoy and the advocacy they exhibit. We are succeeding because they are succeeding.

Guided by our shared values, we thrive in an environment where collaboration and openness are valued. We believe that innovation is powered by perspective and that teamwork and respect for each other lead to superior results. We elevate each other and obsess about doing the right thing. Our associates serve with humility and a deep respect for their responsibility in helping our customers achieve their goals and realize their dreams. Together, we are on a quest to change banking for good.

Data Engineer

Do you want to work for a tech company that writes its own code, develops its own software, and builds its own products? We experiment and innovate leveraging the latest technologies, engineer breakthrough customer experiences, and bring simplicity and humanity to banking. We make a difference for 65 million customers. We're changing banking for good. At Capital One, you'll be part of a big group of makers, breakers, doers and disruptors, who love to solve real problems and meet real customer needs. We want you to be curious and ask what if? Capital One started as an information strategy company that specialized in credit cards, and we have become one of the most impactful and disruptive players in the industry. We have grown to see ourselves as a technology company in consumer finance, with great opportunities for software engineers who want to build innovative applications to give users smarter ways to save, transact, borrow and invest their money, as we seek to disrupt the industry again. As a Capital One Software Engineer, you'll work on everything from customer-facing web and mobile applications using cutting-edge open source frameworks, to highly-available RESTful services, to back-end Java based systems using the hottest techniques in Big Data.

You'll bring solid experience in emerging and traditional technologies such as: node.js, Java, AngularJS, React, Python, REST, JSON, XML, Ruby, HTML / HTML5, CSS, NoSQL databases, relational databases, Hadoop, Chef, Maven, iOS, Android, and AWS/Cloud Infrastructure to name a few.

You will:

- Work with product owners to understand desired application capabilities and testing scenarios

- Continuously improve software engineering practices

- Work within and across Agile teams to design, develop, test, implement, and support technical solutions across a full-stack of development tools and technologies

- Lead the craftsmanship, availability, resilience, and scalability of your solutions

- Bring a passion to stay on top of tech trends, experiment with and learn new technologies, participate in internal & external technology communities, and mentor other members of the engineering community

- Encourage innovation, implementation of cutting-edge technologies, inclusion, outside-of-the-box thinking, teamwork, self-organization, and diversity

Basic Qualifications:

- Bachelors Degree

- At least 3 years of SDLC experience using Java technologies

- At least 3 years experience with leading big data technologies like Cassandra, Accumulo, Python, HBase, Scala, Hadoop, HDFS, AVRO, MongoDB, or Zookeeper

- At least 1 years experience in one of the following Cloud technologies: AWS, Azure, OpenStack, Docker, Ansible, Chef or Terraform

Preferred Qualifications:

- Master's Degree

- 2+ year experience with Spark

- 3+ years experience developing software solutions to solve complex business problems

At this time, Capital One will NOT sponsor a new applicant for employment authorization for this position.","Capital One
3.9","Chicago, IL",Banks & Credit Unions,Finance
Data Engineer,"The Job Details are as follows:

OVERVIEW

We are looking for creative and enthusiastic Data Engineers to join our team in building the best Data Platform on the street and enabling our investment teams to monetize data assets. We treat our data systems as software systems and engineer them accordingly. In your role, you will:
Develop cloud-first data ingestion processes using Python, SQL, and Spark
Engineer data models and infrastructure for a wide variety of market and alternative datasets
Design and build services and plugins to enhance our Data Acquisition Platform
Maintain alerting systems to ensure smooth day-to-day operations for hundreds of datasets
Author tests to validate data quality and the stability of the platform
Investigate and defuse time-sensitive data incidents
Communicate with data providers to onboard new datasets and troubleshoot technical issues
Evangelize best practices to our partners throughout the firm
Work directly with Analysts, Quants, and Portfolio Managers to understand requirements and provide end-to-end data solutions
WHAT YOU’LL BRING
Bachelors/Masters degree in Computer Science or a related field
3+ years experience with at least one of Spark, Airflow, data warehousing
Strong analytical, data and programming skills (Python/SQL/NoSQL/Spark)
Ability to understand and contribute to our existing data system software
Experience containerizing workloads with Docker (Kubernetes a plus)
Aptitude for designing infrastructure, data products, and tools for Data Scientists a plus
Strong oral and written communication skills, most importantly, must be a team player","Balyasny Asset Management
3.9","Chicago, IL",Investment Banking & Asset Management,Finance
Data Engineer,"Company Description
Sagence is a management advisory firm dedicated to helping our clients optimize the value of their data assets. From thinking to doing, Sagence works with leading institutions in the acquisition, evaluation, development and management of their critical data assets and in the application of analytics to discover new insights, shorten time-to-value, and drive competitive advantage.
**All candidates must be currently authorized to work in the US on a full-time basis. Sagence does not provide sponsorship for work visas upon hire or once on board.**
Job Overview
Sagence is looking for experienced, client-facing Data Engineers to help us build and sustain our client’s data capabilities and our competitive advantage. Along with the requirements below, candidates must possess deep, practical experience in one or more of the following Data Management competencies; data warehousing, data lakes, reference data or master data management, data architecture, data modeling, data governance, data analysis, business intelligence.
Skills & Requirements:
MUST BE HANDS ON. Candidates should have system development experience and proficiency with system development methodologies and possess the following skills and knowledge:
Must have significant hands-on experience with various IT concepts of data management/engineering (ETL, data modeling, data warehousing, etc.)
Must have significant hands-on experience with SQL, data profiling, and data discovery
Experience building business intelligence, analytics, or reporting solutions - either front-end consumption mechanisms (e.g., Microsoft, Tableau & Qlik) or supply of data for these purposes
Familiarity with data architecture principles/approaches, data environment infrastructure considerations, and data modeling principles/approaches
Ability to drive out technical requirements with business and IT stakeholders for implementations of data solutions
Hands-on experience with Agile delivery methodology
Prior professional experience in an IT management, management consulting, or client facing role is preferred
Knowledge of the Financial Services, Insurance, Healthcare or Retail industries is preferred
Demonstrated ability in engaging, communicating, and presenting to stakeholders across both business and technology functions
Tools and Technology:
Proficient at leveraging tools and technology to drive value for clients. Examples include the following;
Database Management Tools:
Relational – e.g. Oracle, MySQL, Microsoft SQL Server, PostgreSQL, DB, or similar
NoSQL – e.g. MongoDB, Couchbase, DataStax, Redix, MarkLogic, or similar
Cloud – e.g. AWS, Azure, xxx, xxx, xxx
ETL Tools - e.g. Informatica, Talend, Microsoft SSIS, or similar
Data Modeling tools - e.g., Toad, ERWin, ER/Studio, PowerDesigner, IBM Data Architect, or similar
Industry Leading BI tools - e.g., Business Objects, Microsoft, Cognos, Tableau, OBIEE, Qlickview, or similar
General:
Must be currently authorized to work in the US on a full-time basis. Sagence does not provide sponsorship for work visas
3+ years of professional experience working in a related role
Must be collaborative, innovative, curious, and resourceful, and exhibit a positive attitude
Strong desire to work on interesting projects with smart and creative people
Willingness to travel up to 80% of the week (M-Th)
Chicago or New York area candidates preferred, but will consider candidates in other parts of U.S.
Our Culture
Passionate, diverse, creative, genuine, flexible, hands-on…these are just a few of the words that describe our culture. Our Partners are deeply involved in the client work on a daily basis. We have a high-energy workplace with a focus on producing high-quality, impactful results. We are committed to equality of opportunity, fairness, work and lifestyle balance, and mutual respect. We promote an entrepreneurial spirit by encouraging individual initiative and foster a collaborative culture and work environment which includes open communication and on-going learning. We build teamwork through small, dedicated teams who continuously teach each other and learn from one another. We strongly believe these characteristics enable our employees to develop to their fullest potential. To learn more, please visit us at www.sagenceconsulting.com","Sagence
4.5","Chicago, IL",Consulting,Business Services
Data Scientist,"What We DoUptake helps industrial companies digitally transform with open, purpose-built software that delivers outcomes that matter. Built on a foundation of data science and machine learning, our vision is to create a world that always works - one where the machines and equipment we depend on daily don't break, and industrial companies are once again the creators of economic growth and opportunity.Why Work HereUptake is a values-driven organization, and we are excited about what we do. We're flexible, honest, hardworking, and collaborative. As a team, we bring our diverse backgrounds, beliefs, and experiences together to solve tough, important problems. We support and challenge one another to bring out the best in each of us, and we might have a little fun along the way. We're also proud to be one of Chicago's best places to work in 2018 according to Forbes and Great Place to Work Institute.We offer generous benefits including health, dental, vision, parental leave, 401K match, and unlimited vacation. We are lifelong learners, and our Uptake University program offers training and professional development on a wide variety of topics. We also have employee-led community groups including Women@Uptake, Pride@Uptake, Science@Uptake, Parents@Uptake, and many more. Learn more at https://www.uptake.com/careers.What Data Scientists Do HereData science is at the core of what we do at Uptake. We collaborate with engineering, UX, product, and other teams to contribute insights and data science best practices to all parts of the business.Typical day to day tasks for a data scientist might include:* Collaborate with teams to analyze problems* Learn a new programming language or data science technique - we continually build our skills and explore new things.* Build, test, and deploy supervised or unsupervised learning models* Write data analysis reports for internal use* Build tools to enable other data scientists to scale their knowledge and increase impact* Work with customers to develop analyses that help them solve business problems and drive valueFor more on what we look for in data scientists, visit https://upt.ac/16ee15fc.What We Are Looking For* Passion for data science! We want candidates who love data science and are excited about what they do.* Some ways previous successful candidates have demonstrated this are:* Actively writes relevant blog posts and/or articles* Active participant in relevant online communities* Recognized via professional or academic awards (example: Most Valuable Employee, scholastic grants)* Expressing detailed knowledge of and genuine interest in Uptake's unique methods, products, data, and technology within a cover letter.* Ability to write sophisticated machine learning and data analysis code in R, Matlab, or Python* Some ways previous successful candidates have demonstrated this are:* Contributing to influential Open Source Projects like sklearn, XGBoost, tidyverse, Tensorflow, pytorch, Kafka, Spark, Elasticsearch etc.* By describing a data science model they developed that is deployed in a live setting within a resume or cover letter* Made a high quality data science project available in a public forum like GitHub or Kaggle* Published work in Data Science related journals or conferences such as ICML, NIPS, JML, KDD, and INFORMS* Experience communicating effectively with people at all levels of an organization. Our data scientists regularly share complex insights with all kinds of people.* Some ways previous successful candidates have demonstrated this are:* Teaching data science to non-data scientists in an academic or professional setting* Elaborating in a cover letter or resume ways that they have professionally collaborated with others in the organization and the impact that collaboration had on the organizations KPIs* Bachelor's degree or higher in a quantitative or relevant field* Candidates must be authorized to work in the US.Nice to Have* 2+ years professional experience working in an analytics focused role* Experience writing production code in one or more of: C++, C, Java, Scala, or Spark* Experience working with IoT systems, ranging from DIY home projects to industrial IoT deployments* Have made substantive contributions to open source projects in the areas of data science or machine learning* Experience developing software projects with large teams using technologies like; git, mercurial, jenkins, travis, jira, asana, etc.* Master's degree or PhD in a quantitative or relevant fieldUptake welcomes and encourages applications from all individuals, without regard to any prohibited ground of discrimination, including from people with disabilities. Accommodations are available on request for candidates taking part in all aspects of the selection process.","Uptake
2.2","Chicago, IL",Computer Hardware & Software,Information Technology
Data Analyst,"Data Analyst

Next College Student Athlete (NCSA) is growing our Data & Analytics team and we are looking for a Data Analyst to step in and provide clear focus on solving our analytics challenges.

Youll be working with a team of data scientists and analysts while collaborating with managers and executives, thus you will need to be able to articulate insights and work together to improve the operations of the entire organization. At NCSA, we help families realize their collegiate dreams by fulfilling the need for today's student-athletes to become better college recruits. Our users are high school and college athletic coaches, student athletes, their families, and our in-house teams of recruiting coaches and sales specialists.

Responsibilities:

Be the key data resource defining and driving strategic initiatives, helping Executives and Managers push the business forward.
Build and level-up Tableau dashboards that power the day-to-day operations for hundreds of employees.
Analyze and obtain insights on the most impactful data we have, finding new opportunities.
Guide and assist the Analytics team in cultivating partnerships across departments, bringing insights to every corner of our operation.
Create tailored data solutions that use repeatable patterns and can be leveraged across the business.
Manage and refine project process and relevant metrics.
Be part of a collaborative, learning culture.
Qualifications:

Bachelors degree in a quantitative discipline (Mathematics, Statistics, Economics or related).
Strong SQL experience in Relational DB engines such as MSSQL Server and PostgreSQL.
3 to 5 years of experience working in data analysis.
Strong data process definition and refinement skills.
Experience finding areas of pain and providing clear analysis of them.
Excellent written and oral communication skills we are a team-oriented company so experience communicating with both technical and non-technical team members is important
Preferred Qualifications:

Able to self-manage multiple projects and tasks at one time
Unafraid to manage up or sideways
Familiarity with standard source control methods
A team-player, always looking to make things better and easier for a co-worker
Experience working within cross-functional AGILE teams in a collaborative development environment
Benefits & Perks
Stay Healthy: Enroll in comprehensive benefits & insurance plans with no waiting period
Be Well: Expense up to $65 per month for health & wellness
Maximize Savings: Contribute to your 401k retirement savings with company matching
Be Comfortable: Enjoy a relaxed casual dress code
Give Back: Receive paid time off to volunteer in your community
Take Time: Enjoy paid parental leave to bond with & care for a newborn or newly adopted child
Stay Connected: Expense up to $350 towards the purchase of a laptop, tablet or computer
PAWesome Perk: Enroll your furry friends in our Voluntary Pet Insurance Plan
ABOUT NEXT COLLEGE STUDENT ATHLETE (NCSA)

NCSA is the world's largest and most successful collegiate athletic recruiting network. A wholly owned subsidiary of Reigning Champs LLC (www.reigningchamps.com), NCSA's 750 teammates leverage exclusive data, proprietary matching algorithms and personal relationships built over nearly two decades as the industry leader to connect tens of thousands of college-bound student-athletes to more than 35,000 college coaches nationwide across 34 sports every year. You can learn more about NCSA at www.ncsasports.org.

National Collegiate Scouting Association, LLC is committed to providing equal employment opportunities to all employees and applicants without regard to race, religion, color, sex, national origin, citizenship status, uniform service member status, age, disability, sexual and gender orientation, genetic information or any other protected status in accordance with all applicable federal, state, and local laws.","NCSA - Next College Student Athlete
3.7","Chicago, IL",Sports & Recreation,"Arts, Entertainment & Recreation"
Data Scientist,"Waystar modernizes the healthcare revenue cycle through innovative, cloud-based technology. We provide the highest-rated client experience to more than 450,000 providers, 22,000 healthcare organizations and 750 health systems and hospitals around the country. Together, our technology, data and client support streamline workflows and improve financials for our clients, so that they can focus on their patients. We are deeply committed to living out our organizational values: honesty; passion; curiosity; fanatical focus; best work, always; making it happen; and joyful, optimistic and fun.What is the purpose of this position?We are looking for an experienced Data Scientist, who has previously supported Healthcare software applications. The data scientist role involves solving technical, data-driven Healthcare problems using computer science, mathematical, predictive modeling and statistical methods, & knowledge. This person will interact with teams from Account Management to Application Engineering and R&D, to conduct detailed analysis and experimentation to maximize the utility of predictive modeling, analytic and machine learning across Waystar's product line. The role will focus on extending machine learning, predictive modeling, and analytic components to provide up-to-date intelligence to Healthcare providers maximizing outcomes. An ideal candidate for this position can approach problem-solving challenges independently, has a strong attention to detail, and enjoys working in a fast-paced, collaborative, and team-based environment.Looking for some details?* Works closely with Application Engineering, Product Management, and Operational teams in designing, experimenting-with, and implementing machine learning and analytical systems applied to design information and user behavior* Works closely with Application Engineering teams to gather and process data, as well as in surfacing various analytically-based features in core products* Works on groundbreaking new applications of machine learning and analytic technology to Healthcare, producing quantitative, justifiable results to guide feature planning* Translates real-world Healthcare problems to mathematical frameworks* Works with Product Management, Marketing, and Sales as needed to promote sales and to incorporate market and customer feedback* Data exploration, hypothesis creation (from business and product goals), testing algorithms, scaling to large data-sets and validating results will be common tasks for this role* Understands, organizes, and communicates root causes of problems and successes succinctlyDo you fit our team?* Complete familiarity with various statistical and machine learning techniques including: classification, regression, dimension reduction, clustering, and various multivariate methods* Complete familiarity with empirical approaches to estimate performance of machine learning models including: hold-out sets, cross-validation, leave-one-out testing* Understanding of orders of algorithms and how they scale* Demonstrated competency in R/Python predictive modeling* Demonstrated competency in RDBMS (e.g. SQL Server)* Ability to code in 1+ general purpose programming language (C#, Java, etc.)* Must be a quick-learner with the ability to multi-task in a fast-paced environment* Outstanding presentation abilities and the ability to communicate with all levels of the Business* Comfortable working in newly-forming, ambiguous areas where learning and adaptability are key skills* Outstanding communication and interpersonal skills* Must possess strong analytical, problem-solving, and writing skills* Proficient in Microsoft Office applications* Detail-orientedPreferred Skills:* Master of Science degree or higher in the fields of Computer Science, Statistics, or Mathematics is preferred* An aptitude for medical informatics is preferredIn compliance with federal law, all persons hired will be required to verify identity and eligibility to work in the United States and to complete the required employment eligibility verification document form upon hire.","Waystar
3.4","Chicago, IL",Enterprise Software & Network Solutions,Information Technology
Data Scientist,"Key Competencies:* Strong analytical mind, problem-solving skills and foundation in Statistics* Ability to collaborate well with individuals on-site and in remote offices* Intermediate to advanced level of expertise using SAS, SQL, Tableau, Python* Outstanding analytical skill set: a clear expert in the Analytics/ Data Science field* Experience working with large volumes of data, combining and reconciling data from different sources* Experience in MS Office applications with very strong Excel skillsRequirements:* Minimum B.S. in Mathematics, Statistics, Data Analytics or related quant field* 5+ years in a similar analytical role generating insights through data analytics* Strong communication skills: both written and verbal* Ability to work independently on multiple concurrent assignments* Self-driven for continual learning and ongoing training/development* Highly organized, detail-oriented","Harry and David, LLC
3.4","Melrose Park, IL",Food & Beverage Stores,Retail
Data Scientist,"Goodway Group is a fully-remote, digital marketing, and advertising firm. We sit at the intersection of top talent, amazing technical partnerships, and game-changing analytics within the ad technology and marketing technology space. We're well-established with the pace of a start-up. This position is work from home (or anywhere else you have reliable internet) and can be located anywhere within the United States.

Who We Are

Goodway Group aims to be the beacon of honesty and intelligence in the programmatic marketplace. We deliver authentic results for our clients by running smart advertising campaigns. Data Science & & Analytics at Goodway Group develops data products that ensure the company's media campaigns are running efficiently. Doing this involves:
showing feasibility through data analysis,
designing and producing prototypes
deploying models to production.
Who You Are

A Data Scientist is a key member of the Data Science and Analytics team at Goodway. This team utilizes advanced tools and innovative techniques to maximize advertising results for our clients, as well as demonstrates thought leadership within the digital advertising industry.

You will be at the center of data analysis, modeling, machine learning, and data engineering and on the bleeding-edge in the ad-tech space.

The ideal candidate will have hands-on experience working on a wide range of optimization and analytics problems in ad-tech including fraud detection/mitigation, price prediction, conversion attribution, and modeling, as well as experience with the tools of the trade including SQL, Python, Hive, R, Athena, and others.

What You Will Do
Design, build and deploy algorithms to optimize the performance of advertising campaigns.
Define data requirements and gather/validate information, applying judgment and statistical tests.
Apply various models and methods to test, learn, and improve the manner in which data is being evaluated and algorithms are being built.
Construct data narratives to convey complex ideas to non-technical stakeholders.
Be constantly learning the latest technologies and trends.
Work with analysts and stakeholders to gather, understand, and develop business initiatives and specifications.
Provide expertise and leadership on making technical decisions, thus delivering a platform that provides business value and meets end-user goals.
What We Offer

Goodway Group is a wholly remote organization, so no commute to consider! We offer unlimited PTO (MyTime) because we know you're at your best when your life has balance. We have the usual steak and potatoes array of benefits, as well as some great wellness programs that are available to both you and your family. While we work remotely, we foster an environment that promotes connectedness and community.

For a lot more detail, make sure to check us out on Glassdoor!

You’ll Be Successful Because You Are
Knowledgeable: B.S., M.S. or Ph.D. in computer science, math, statistics or a strong quantitative educational background
Experienced: Minimum of 2 years’ experience in applied data science, machine learning or modeling
Adept with Python/Bash and some exposure to modern software development practices including GitHub/git-flow and automated testing
Experience working with big data tools such as Hadoop, Hive, Spark, Pig, Presto, Athena or Qubole
Excellent communication skills and ability to convey ideas accurately and concisely to both technical and non-technical employees
Adaptable to any and every situation: You have a knack for being fluid and embracing change.
A quick study: swiftly demonstrate an understanding of the business, organizational structure, culture, client base, and industry.
Masterful ability to evangelize Goodway’s values and culture to both prospects and employees.
Results-Oriented: we call this grit. You can be counted on to exceed goals, and you’re known to push yourself and others across the finish line
Ability to learn new paradigms, tools, and processes quickly and thrive in a fast-paced, rapidly changing, exciting work environment
Excellent communication skills and ability to convey ideas accurately and concisely to both technical and non-technical employees
Work From Home: we all work from our home offices throughout the United States
Things You Should Know
Our workdays can sometimes be long and unpredictable. You should be comfortable and capable of sitting and/or standing at a desk for at least 8 hours.
Twice per year, we gather together to work and play for a week. Both retreats are “can’t miss” events (like seriously…they are mandatory). There may also be other opportunities to travel depending on your specific role and business needs.
Goodway embraces a culture of equality and wants applications from everyone, regardless of race, creed, color, religion, sex, sexual orientation, gender identity, national origin, marital status, citizen status, age, disability, military or protected veteran status, genetic predisposition or carrier status or any other legally protected status.","Goodway Group
4.2","Chicago, IL",Advertising & Marketing,Business Services
Data Scientist,"Job Description
What We Do
Kalderos delivers technology that solves the challenges facing the US healthcare system. At Kalderos, we develop technology solutions with a focus on simplifying the complex coordination of drug discount programs from exhaustive data services to intelligent reporting to issue resolution.

To learn more: https://www.kalderos.com/company/about

What Data Scientists Do

The Data Science team’s mission at Kalderos is to maximize the trust of all participants in our Drug Discount Management Platform. This starts with having trust in each other as a team, then expanding it to do this work in three primary ways: building differentiated datasets, measuring what matters, and optimizing the right process transparently. If that means a model, great! If that means working with design to develop a different product approach, also great! Below are some possible day to day tasks for a data scientist at Kalderos.
Build, test, deploy, and maintain supervised or unsupervised learning models. Work with internal teams that operationalize that work to ensure their output is high quality and continually improving for end users
Create internal dashboards to monitor processes and measure impact
Participate in generating collateral that supports our sales process or creates valuable industry content that showcases Kalderos’ unique position in the industry
Work with product teams to collect forward looking data points to enable future data science solutions
Build internal tools to enable team mates to scale their knowledge and increase impact
Learn a new programming language, data science technique, or about the pharmaceutical industry - we continually build our skills and explore new things

What We Are Looking For
Some work experience as a Data Scientist in a full time role
Ability to write machine learning and data analysis code in R or Python
Some ways you may demonstrate this are:
Open GitHub Repositories or portfolios
Project descriptions of what you have accomplished
Kaggle competitions
Published or working papers that use data science methods
Ability to take complex information and communicate it clearly for different stakeholders, both technical and non-technical
Some ways you may demonstrate this are:
Talks or presentations you have given in the past
Speaking through your work history in a phone interview
High quality data visualizations that communicate complex information clearly
Candidates must be authorized to work in the US and be able to work in Chicago

What May Set You Apart
Experience in healthcare or pharmaceuticals
Open source contributions to popular data science tools
Experience with data engineering tools such as Airflow
Experience working with Azure or similar public cloud
Experience working with SQL Server or similar databases

If you think you meet some of the list of the above, but not everything, that’s perfectly fine! We encourage you to apply regardless. At Kalderos, we know talent comes in many forms, and we’re willing to look beyond a set of rigid criteria to find the right teammate.

Company Perks
401K plan with matching
Healthcare benefits
Flexible schedule and a fair PTO system that allows for a healthy work-life balance
Opportunity to work on new technologies and learn new skills
Celebration, and education stipends

To learn more: https://www.kalderos.com/company/culture

Kalderos is an equal opportunity workplace. We are committed to equal opportunity regardless of race, color, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, or veteran status.

Due to the circumstances of the COVID-19 pandemic, Kalderos has decided to protect our current and future employees by shifting to an entirely remote workforce. We will continue to operate, interview, onboard, and work remotely. Please be aware that some of our roles will not be remote long-term and will return to an office setting once we're safe to do so following the guidance of local health authorities and the CDC.","Kalderos
5.0","Chicago, IL",Enterprise Software & Network Solutions,Information Technology
Data Analyst,"GoHealth is looking for a Data Analyst to join its Operational Analytics team. You will be responsible for using a combination of business intuition and analytics to provide executive leadership with actionable insights to drive strategic decision-making and maximize company-wide value. You will be responding to the live needs of the business, and helping to solve problems and answer questions as they arise. Due to the dynamic nature of the Operational Analytics team, and this role in particular, we seek entrepreneurial candidates with the ability to derive analytical insights from a variety of business contexts.

Due to the unprecedented situation of COVID-19, GoHealth has decided to protect our current and future employees by managing our business remotely. This is inclusive of interviewing, onboarding and each role day-to-day. Please consider that our roles will not be remote long-term and will return to an office setting once we're safe to do so following the guidance of local health authorities' and the CDC.

Responsibilities:
Understand GoHealth's business processes, including the role each business unit plays in supporting the company's ultimate objectives
Collaborate with leaders to understand key value drivers and challenges within their business unites and determine the key metrics and insights that can help improve performance as a result.
Provide new and creative insights to business leaders through a combination of descriptive and diagnostic analytics
Test hypotheses across functions using measurable, statistically-significant methods to evaluate best performing strategies
Build interactive dashboards and reports that provide insights that can be easily interpreted and applied by business leaders to help improve their performance
Collect, analyze, and evaluate data to track project performance and important developments
Synthesize raw data into digestible and actionable information
Continually think of new ways that data-based insights can help support GoHealth
Skills & Experience:
BS or BA degree in business, economics, finance, accounting, marketing analytics, MIS, computer science, engineering, or equivalent work experience.
0-2 years of related experience in an internship or full-time role guiding strategic decision-making using data and analytics.
Ability to take insights and turn them into actionable steps that can drive business value.
Proficiency in Microsoft Excel.
Track record of effective verbal and written communication of complex concepts to colleagues with varying degrees of analytical knowledge and understanding.
Desire to improve and expand analytical and data visualization skills.
SQL, Python, and/or Tableau skills are preferred.
Benefits & Perks:
Open vacation policy
401k program with company match
Medical, dental, vision, and life insurance benefits
Flexible spending accounts
Commuter and transit benefits
Professional growth opportunities
Casual dress code
Generous employee referral bonuses
Happy hours, ping-pong tournaments, and more company-sponsored events
Subsidized gym memberships
GoHealth is an Equal Opportunity Employer
*LI-JC1","GoHealth
3.2","Chicago, IL",Health Care Services & Hospitals,Health Care
Data Scientist,"HNI Corporation, an industry leader in office furniture design and manufacturing is in search of a Data Scientist to join our team in Chicago, IL!

As a member of the Decision Science team, the Data Scientist will play a crucial role in building HNI's data science practice in Chicago. In this new role, you'll tackle cross-functional and high-profile business problems that add value and establish competitive advantages for HNI. As a key hire in a new department you and the team will develop and define the end-to-end data science process that will enable the business to make data-driven decisions using different machine learning techniques, form proof of concept to deploying models in production.

If you like the sound of solving business problems, helping to build a new functional area from scratch, implementing new approaches to data and making a major impact at a leading global company HNI might be the place for you.

What will you do:
Use SQL, R & Python, and other data tools to analyze internal and external data in order to build predictive models and provide insights to business partners.
Present highly technical information to business units not versed in such technicalities.
Interpret data and analyze results using statistical techniques and provide on-going reports in a timely and professional manner.
Develop and implement databases, data collection systems, data analytics, and other strategies that will provide efficient data and reporting solutions.
Identify business trends from big data sources to enable faster and better decision making.
Who you are:
1+ years of advanced analytic/data science/machine learning experience
MS/PhD in Computer Science, Statistics, Applied Mathematics, Engineering, or a related quantitative field
Proven track record of end-to-end experience in model development, testing, implementation and performance tracking
Hands-on knowledge of SQL, R, Python and Spark
Familiarity with Linux and AWS/Azure
Excellent communication, teamwork and consulting skills.
Strong analytical and problem-solving skill set.
We look forward to hearing from you!

Why HNI Corporation?

HNI Corporation (NYSE: HNI), is a $2.3 billion-dollar, global office furniture and hearth product enterprise. Our furniture brands are among the strongest, most widely known in the industry, including HON, Allsteel, Gunlocke, HBF, Maxon, and OFM. The depth and breadth of our brands, the scale and capability of our manufacturing, and the strength of our distribution enables us to provide the best office furniture solutions to meet the needs of every customer.

The fourth largest employer in Iowa, HNI Corporation has been ranked by Industry Week magazine as one of the ""Top 100 Best Managed Companies in the World"", by Fortune magazine as ""The Most Admired Company"" in the furniture industry; and named by Chief Executive Magazine as one of the world's best companies for leadership development.

We invite you to visit us at www.HNICorp.com for the best visual overview of our organization.

EEO/Male/Female/Veteran/Disabled","HNI
3.4","Chicago, IL",Consumer Products Manufacturing,Manufacturing
Data Scientist,"Chicago, IL
Posted 2 weeks ago

The Process Monitoring, Automation and Control (PMAC) team is responsible for driving the development and implementation of advanced analytics and control solutions that deliver value for today and build capability for tomorrow.
As a member of PMAC, this role will have the opportunity to work closely with the IT organization to
develop and implement Advanced Analytics, AI, APC and IIoT solutions/capabilities in manufacturing
settings to achieve actionable insights and enable continued improvement for pharmaceutical
manufacturing and quality operations.
Responsibilities
• You will contribute to the development of the multiple use cases across manufacturing operations,
leveraging IIOT and analytics, in areas such as energy management, predictive maintenance, production
scheduling and process optimization.
• Development and implementation of analytic models and tools using advanced analytics, machine
learning and artificial intelligence;
• Work with the IIoT developers to integrate predictive/prescriptive analytics with the IIoT platform to
achieve visibility, predictability and learning across multiple automation layers from process to plant and
to enterprise
• Understand Advanced Analytics approaches in other businesses;
Qualifications
• Bachelor’s Degree or higher in Mathematics, Statistics, Physics, Engineering and/or Computer Science
• Hands-on experience in data science, advanced analytics, multivariate data analysis, machine learning,
artificial intelligence, and familiarity with related open source libraries (e.g. Tensor Flow, AWS ML)
• Proficient in one or more of the following programming environments: Python (preferred), R, Matlab,
PMML, JAVA, Spark
• Familiarity with deep Learning, Neural Networks, Natural Language Processing or related fields
• Experience with cloud-based analytics platforms
• Experience with ThingWorx IIoT platform preferred
• Familiarity with industrial process control system, operations management system and/or SAP is a plus
• Pharmaceutical experience preferred but not necessary
• Independent, self-motivated personality with excellent oral and written communication skills
• Ability to work collaboratively in diverse cross-functional teams on innovative solutions and tools with
an open attitude towards fast learning

To apply for this job email your details to suda@sutoer.com","Sutoer
4.7","Chicago, IL",Advertising & Marketing,Business Services
Data Scientist,"Hi Greetings from Photon!!!!!!! We are looking for an experienced Data Scientist to join our client with a focus on Big Data and Cloud technology. The candidate will work on the Search and Gallery piece of a retail eCommerce website and they plan on implementing Data Science techniques such as Heuristic Ranking, Query Understand, Filters and Personal Local Results Responsibilities Include Apply your expertise in machine learningdata mining techniques and build forecasting, prediction, segmentation, recommendation and fraud detection systems in retail domain Collaborate with product and engineering teams to solve business problems and identify opportunities Build ML algorithms to drive personalized and relevant customer experience Extendaugment company data with third party data, enhance data collection procedures to include information required to build analytic systems Assist with designing and building infrastructure to facilitate analytics and experimentation Present results and make recommendations in a clear manner to leadership Provide thought leadership and mentor data science community across the organization Core Competencies Accomplishments Masterrsquos degree in Computer Science or Statistics and minimum 2 years of hands on experience in data sciencemachine learning Understanding of software engineering best practices, development and validation of machine learning algorithms Prior Experience in Search Algorithms Excellent understanding of machine learning algorithms Clustering, Regression, Decision forests, k-nn Proven track record working on distributed, scalable cloud platforms. Good scripting and programming skills Knowledge in Cassandra or Hadoop platform is critical. Hands on experience with data modeling, data loading, optimization, and warehousing techniques and technologies in either of the following Teradata, Hive, Python, Spark, NoSQL, or Cassandra Experience in data ingestionextraction (Hive, SQL), data manipulation (Python, Spark, R, Hive) and machine learning development (R, Python, Spark, H2O) Ability to work on large volume of data Ability to create data for search relevancy. Specifically Geography ndash query ndash pp data Persona ndash Geography ndash query ndash pp data Using NLP to create vector representation of query-pp attribute relation Data quality check Feature engineering techniques to remove bias, standardize and normalize data Familiarity with Ranking and classification model creation and evaluation Strongly prefer prior experience in retail e-Commerce or related domain and on Search Ranking Algorithms Strong customer service and communication skills, ability to interact with diverse team of people across business and engineering","Photon Infotech
3.0","Chicago, IL",IT Services,Information Technology
Data Scientist,"Role Description
As a data scientist at Triplebyte, you’ll have the opportunity to work on a variety of challenges to help us scale. You'll be part of a small team, who are leveraging data to fix technical hiring. Your day to day, will include a mix of dataset acquisition, statistical modeling, exploratory data analysis, and software engineering. You’ll report directly to Triplebytes' Head of Machine Learning and will work alongside a team of 6-8 machine learning engineers and data scientists.
Fields your work will touch on
Psychometrics
Recommender systems
Time series analysis
Survival analysis
Bayesian inference
Probabilistic programming
This is an ideal role for a data scientist who wants the scope and responsibility to own features/products from the inception and research phase through to measuring real-world results.

About Triplebyte
Triplebyte is a hiring marketplace used by companies like Apple, Dropbox, Stripe, and Instacart to hire the best technical talent. We are on a mission to build a meritocratic hiring process, and we do all our evaluation background blind. Our ultimate goal is to collect the largest dataset and use this to build the world's best technical hiring process. No other company has successfully done what we're doing in this field.
We are growing extremely quickly, working on a problem that is fundamental, sitting at the crossroads between the workforce and employers. Ten years from now, it'll look silly to use anything other than Triplebyte for technical hiring.
Company Culture
We have a laid-back, friendly office culture. Over lunch you'll often find us discussing the latest in technology, books, and pop culture, and then maybe getting in a quick game of chess or babyfoot (foosball).
Since we're an early-stage company, we move fast, and it's important that each member of our team is able to take ownership of projects by defining problems, brainstorming solutions, and running experiments.","Triplebyte
3.2","Chicago, IL",Computer Hardware & Software,Information Technology
Data Scientist,"Goby Inc seeks a Data Scientist in Chicago, IL to work with various connectors like Amazon RDS, Heroku etc. Des. & CR8 Dashboards, Reports, Stories, & Dataflows in Einstein Analytics & Discovery. Work with Salesforce Communities.

recblid bncl9ujswg0zqxp9a2k50xo76uz5d9",Goby Inc,"Chicago, IL",IT Services,Information Technology
Data Scientist,"Are you looking for a unique, truly innovative role? What if it could be with one of the most impactful IT companies in the world? Then we have the right opportunitywe are looking for a Data Scientist to join us! In this amazing role, you will be responsible for working in machine learning space on the core tooling for customers need to successfully use the company products and other open source Cloud Native tools such as Apache Spark, Apache Kafka, Kubeflow and Argo. You have a broad understanding of the wide range of machine learning tools for example Tensorflow, Kubeflow, AWS Sagemaker, ML Flw, Spark, etc. You will be working with a set of architects working on various aspects of the hybrid cloud which includes public as well as private cloud services. You will be providing strong support across all data science uses cases to our customers and development teams around implementation of services and best practices for hybrid cloud deployments. You'll work with the teams spanning all of HPE to design and deliver our Hybrid Cloud solutions. Were not learning a new way of doing things were defining the best way to do them.

How youll make your mark:
You will evaluate and influence the products we are delivering to enterprise customers in the field of machine learning
You will play a key role in the development of enterprise products working alongside our key customers.
You will partner and collaborate with customers and internal data science teams in building capabilities for GreenLake Hybrid Cloud.
You will leverage Machine Learning algorithms to solve real-life problems.
You will analyze various data sets and solve problems from ideation to production, experimenting, training, tuning, and deploying production quality machine learning models.
You will lead key, cross-functional analytical projects, identifying and bringing together stakeholders to translate business challenges into Data Science problems.
About you:
You have 10+ years of experience in the field of data science
You have a Masters, PhD or equivalent experience in quantitative field (Computer Science, Machine Learning, Mathematics, Physics, Artificial Intelligence, etc.)
You have expertise in at least one programming language for data analysis (e.g. Python, R).
You are familiar with relevant ML packages for example Tensorflow, Kubeflow, Scikit-learn, Keras, pyTouch, SageMaker, MLFlow.
You have deep understanding of statistical modeling, machine learning, deep learning, or data mining concepts, and a track record of solving problems with these methods.
You are skilled in designing and testing experimentYou have experience driving the end to end lifecycle from model creation to deployment.
You are a strong written and verbal communicator with good analytical and problem solving skills.
You have proven success working on a fast paced and agile environment and have an understanding of Agile Methodologies.
You have worked with big data techniques (such as Hardoop, MapReduce, Hive, Pig, Spark).
What we can offer you:

Extensive benefits, a competitive salary and participation in the shared values and purpose that make Hewlett Packard Enterprise one of the world´s most attractive employers! At HPE, our goal is to provide equal opportunities, flexible work-life balance, and constantly evolving career growth.

If you are looking for challenges in an exciting, supportive and international work environment, then we definitely want to hear from you. Continue the conversation by clicking apply now below, or directly via our Careers Portal at www.hpe.com/careers.

Join us and make your mark!

Find out more about us and follow us on:

https://www.facebook.com/HPECareers

https://twitter.com/HPE_Careers

HPE is an Equal Employment Opportunity/ Veterans/Disabled/LGBT and Affirmative Action employer. We are committed to diversity and building a team that represents a variety of backgrounds, perspectives, and skills. We do not discriminate and all decisions we make are made on the basis of qualifications, merit, and business need. Our goal is to be one global diverse team that is representative of our customers, in an inclusive environment where we can continue to innovate and grow together.

1065050","Hewlett Packard Enterprise
3.8","Chicago, IL",Enterprise Software & Network Solutions,Information Technology
Data Scientist,"GreenKey is a group of ambitious people working on audacious technology built around solving an important problem: how can voice improve workflows? Over the last five years, we have unlocked the power of voice for the financial industry and are expanding to support critical emergency services functions.

To apply for this position, please email careers@greenkeytech.com with your resume.

We’re Hiring


GreenKey is currently hiring data scientists to lead the development of ground-breaking technologies in the field of speech recognition & natural language processing (NLP) for the financial markets. As a GreenKey Data Scientist, you have influence on our overall NLP strategy by helping define product features, build machine-learning models, drive system architecture decisions, and spearhead industry-best practices. GreenKey Data Scientists have direct lines of communication with clients to have a tight feedback loop between customer problems and machine learning solutions
The ideal candidate is passionate about new opportunities and has a demonstrable track record of success in understanding business problems and crafting mathematical and statistical models to answer them. A commitment to team work and strong communication skills (to both business and technical partners) are core requirements.
What Success Looks Like

In your first 90 days, you will:
Dive into the financial and emergency services domains
Train new ASR and NLP models to structure data from unstructured conversations
Understand the needs of GreenKey’s clients
After six months on the job, you will:
Explore cutting-edge NLP research methods and apply them to client problems
Identify new data sources and algorithms to improve NLP and ASR accuracy
Discover new insights of value to our clients and develop models to extract them
One year in, you will:
Work directly with customers to shape our data strategy
Make an impact on the direction of GreenKey
About GreenKey


GreenKey is a group of engineers, data scientists, finance experts and hard workers building technology. We know that our work gives police officers more time to protect communities, and makes the finance industry more efficient while keeping it honest.

Our users are:
Traders and brokers from the top 15 financial institutions in the world
Police officers and emergency services dispatches in cities across America
Working at GreenKey


We are proud of the culture we’ve created in offices across Chicago, New York and London. Our team is made up of dynamic, humble engineers, data scientists, sales people and business leaders. Our culture is comprised of seven core principles: curiosity, optimism, candor, work ethic, empathy, self awareness and integrity. Success at GreenKey is beyond technical aptitude. Those who demonstrate these values will find themselves surrounded by like-minded individuals ready to tackle challenges together

When you join our team, you can expect: Generous PTO, remote work flexibility, comprehensive insurance, 401k plan with matching","Green Key Technologies
4.3","Chicago, IL",Computer Hardware & Software,Information Technology
Data Scientist,"Description


Do you want to work at the forefront of artificial intelligence and machine learning? CapaxGlobal has a significant data analytics and management presence across many industries. With that footprint comes massive amounts of data that can inform us about markets and ways to improve our client business practices. This position will be part of the Data Science and Machine Learning team and will bring strong quantitative skills to our data science capabilities. You work in a multidisciplinary team exploring, connecting and mining internal data sources and will develop data models using algorithms for pattern detection and forecasting. In this position you will be managing projects that use advanced analytics techniques, such as optimization, forecasting, machine learning, predictive analytics, and statistical analysis, to develop solutions that help deliver significant value to a variety of Capax’s partners and clients. Candidates will be exposed to a wide spectrum of high visibility projects ranging from sales effectiveness, competitive intelligence, fraud detection, time series forecasting, operational efficiency, sourcing and procurement, supply-chain optimization and financial analysis.
Location: Chicago IL | Philadelphia PA | Remote
Travel: Up to 30%
Responsibilities
Develop and code models by applying algorithms to large structured as well as unstructured data sets for our more complex projects. Develop visualization products to share analysis across a large group of business users.
Design strategies and propose algorithms to analyze and leverage data from existing as well as new data sources.
Continuously seek out industry best practices and develop skills to create new capabilities for data analytics at clients to improve business decisions.
Network with business stakeholders to develop a pipeline of data science projects aligned with business strategies. Translate complex and ambiguous business problems into project charters clearly identifying technical risks and project scope.
Participate on cross-disciplinary project team of database specialists, data scientists, and business subject-matter experts to complete project deliverables.
Qualifications
Bachelor’s degree from an accredited college/university in Computer Science, Computational Linguistics, Statistics, Mathematics, Engineering, Bioinformatics, Physics, Operations Research or related fields.
Master’s degree in data science, applied mathematics, or bioinformatics preferred.
Minimum 6 years relevant work experience (if Bachelor’s degree) or minimum 3 years relevant work experience (if Master’s degree) with a proven track record in driving value in a commercial setting using data science skills.
In-depth knowledge of various modeling algorithms e.g. Linear, GLMs, trees based models, neural networks, clustering, PCA, and time series models.
Proficiency in R (e.g. ggplot2, cluster, dplyr, caret), Python (e.g. pandas, scikit-learn, bokeh, nltk), Spark – MLlib, H20, or other statistical tools.
Minimum 2 years experience working in a data science or machine learning environment.
In-depth knowledge of databases, data modeling, Hadoop, and distributed computing frameworks.
Experience in software development environment, Agile, and code management/versioning (e.g. git).
Strong EDA skills and experience/knowledge.
Ability to understand complex and ambiguous business needs and applying the right tools and approaches.
Collaborative team player.
Excellent communication skills, both written and verbal.
Experience developing and testing machine learning and/or statistical projects.
Strong presentation skills. Ability to present statistical results to lay persons in an easy to understand way.
We are looking for all levels of data science experience, jr through sr.","Capax Global
4.7","Chicago, IL",IT Services,Information Technology
Data Scientist,"Data Scientist

Chicago, Illinois, United States

DESCRIPTION

CreditNinja is a FinTech company founded in 2017 by veteran serial entrepreneurs who were part of the core team behind Enova (NYSE:ENVA), a leading publicly traded consumer financial services company. CreditNinja's mission is to provide hardworking Americans with financial solutions when unexpected expenses arise. Unlike traditional banks, CreditNinja works hard to ensure that people with less-than-perfect credit can have quick access to the money they need. Headquartered in downtown Chicago, we are a lean and innovative team seeking like-minded talent to help us disrupt the consumer finance industry.

CreditNinja is seeking a Data Scientist who will focus on the latest cutting-edge data mining and statistical modeling techniques to make a direct impact in a data-driven company. This is an exciting and rare opportunity to join a well-capitalized startup on the ground floor and help drive our success.

Key Responsibilities:
Conduct ad hoc analysis using advanced data mining tools to support risk management, operations and marketing strategies
Work with cross-functional teams to explore new ways of finding insights from data and provide recommendations
Develop dashboards to monitor key performance indicators
Support development of companys models to optimize lending decisions by using advanced statistical modeling and simulation techniques
Support implementation of the models working closely with software engineering team
Assist with development of technical tools and platforms to standardize and streamline model development and monitoring processes
REQUIREMENTS
A Bachelor's, Master's or PhD in math, statistics, computer science, engineering or related field
2+ years of experience with data analytics and statistical modeling
Advanced experience with relational databases, such as SQL
Experience with Python or R
Experience working within an open source environment
Strong quantitative and problem-solving skills with key attention to detail
Ability to manage multiple projects with tight deadlines, follow through to completion, and present conclusions of analysis to senior management in an organized and thoughtful manner
Experience working with specialty finance or FinTech is a plus
Start-up experience is a plus
BENEFITS
Competitive salary and benefits package, including material equity grant
Casual dress policy
Fun, fast-paced work environment
Dynamic start-up culture
Ability to make an immediate impact in a growth stage company
Convenient downtown Chicago office located in the heart of the city
Equal opportunity employer","CreditNinja
5.0","Chicago, IL",Lending,Finance
Data Scientist,"Job Description
Role : Data Scientist

Location : Chicago, IL

Job Description:
Knowledge and experience in API development, AI/ML, SageMaker, Data Lake, Data Analytics, Cloud Monitoring and Analytics,
Strong cloud programming skill with experience in API and AWS Lambda functions or any other scripting languages like Python / Bash using Python & Node.js
Good understanding in using AWS CLI, Cloud formation, Terraform, Ansible with troubleshooting experiences
Strong knowledge of Cloud Security practices and IAM Policy preparation for AWS
Regards,

Pranali Fulzele | Recruiter

Mobile No: +1 (512)-562-2452

Email: pranali@fisecglobal.net

Website: www.fisecglobal.net","Fisec Global
4.0","Chicago, IL",IT Services,Information Technology
Data Scientist,"Job Description
Data Scientist, Chicago, IL

Smarter Thinking. Real Results. Technology consulting has been our story for over 14 years. Companies from all industries partner with us for our innovative mindset to help them digitally transform to create market advantages, become resilient, and prepare for what’s next. With us, the possible becomes actual.

We provide strategic and innovative consulting services focused on digital experiences, engineering, automation, data and analytics, and salesforce solutions. Saggezza consultants work as part of a global team, and throughout their tenure, have the opportunity to work on a variety of different projects across various clients and industries. We are chartered to do one thing, and one thing only – to bring enabling technology to our clients that allow them to move their business forward.

We are currently looking to hire a Data Scientist to join our team.

What You’ll Definitely Need
BA degree in a closely related field with data analysis orientation. Analytical background with a creative approach to problem solving
4+ years’ experience with Python worked in building analytical solutions using Statistical, Machine Learning, Deep Learning etc. Proficiency with 3rd-party data visualization tools (Tableau, Power BI, etc.)
Good working experience in Data Analysis, Data Wrangling, Data Cleaning and Data Transformation.
Excellent working experience of machine learning on technology stacks such as Python, NumPy, SciPy, Scikit-Learn, Apache Spark and R using libraries such as e1071 and Caret
Excellent fluency in data manipulation tasks using frameworks. such as pandas, plyr, Spark
Good understanding of machine learning techniques and algorithms, such as k-NN, Naive Bayes, SVM, Decision Forests, Random Forest etc.
Knowledge of some common data science toolkits, such as Weka, NumPy, MATLAB, etc.
Broad business perspective with the ability to articulate meaningful ROI and financial impacts.
Worked on projects in the Retail, Banking & Finance and Insurance Industries.
Working from Chicago office and requires visits to customer location if needed.
From a cultural perspective, we look for individuals who possess the following qualities that will contribute to our success and the success of our clients:
Entrepreneurial spirit: We seek individuals who enjoy contributing to the growth of an organization and who show commitment to the success of their team.
Problem-solving skills: Individuals at our company have well-honed analytical skills coupled with business acumen to structure problems, deliver solutions, and communicate insights.
Drive: Our team sets ambitious goals and seeks energetic professionals, enjoy a fast pace environment, and thrive in taking on responsibility.
What We Would Love to See
Consultative application of analytic solutions to solve business issues
Able to engage in a consultative manner across multiple levels (c-suite to end user) with a strong executive presence, demonstrating strong
Demonstrated leadership, communication and interpersonal skills: the ability to manage and mentor functional experts and lead cross- functional teams
Don’t tick all the boxes? Don’t worry about it: we still want to hear from you if you think

you’re the right person for the job.

Why Join Our Team?
Diverse culture, experiences, and skills.
Our nurturing and supportive environment fosters collaboration across the entire organization.
We are not hierarchical but operate as a flat surface where every opinion matters, ideas are cultivated and innovation is encouraged.
At Saggezza, we are fortunate to have a strong mentorship program that provides every one of our employees the ability to thrive professionally and personally.
We are only as good as our people. Saggezza, Italian for wisdom, is rooted from the perspective that knowledge is power. We create thought-leaders who are constantly exposed and trained in different technologies in the ever-evolving world of software development.
We welcome innovators with entrepreneurial spirits to grow with our team.
Consulting Magazine - Fastest Growing Firms 2019
Built-In Top Places to Work in Chicago 2020
Best and Brightest Companies in the Nation 2019 and 2020, Best and Brightest Companies in Milwaukee 2020 and Best and Brightest Companies in Chicago 2020
Saggezza is an Equal Employment Opportunity Employer: We believe in treating each employee and applicant for employment fairly and with dignity. We base our employment decisions on merit, experience, and potential, without regard to race, color, national origin, sex, sexual orientation, gender identity, marital status, age, religion, disability, veteran status, or any other characteristic prohibited by federal, state or local law.

Powered by JazzHR

oCJ1zhRdvn","Saggezza
2.6","Chicago, IL",IT Services,Information Technology
Data Scientist,"Role Type: Data Scientist

Reports To: Chief Technology Officer

About Us

CareAdvisors is a technology company that helps patients get access to healthcare and social service benefits they need by automating the manual enrollment role taken on by hospitals.

Many patients who receive care at hospitals are eligible for Medicaid and other social service benefits, but some have barriers to enroll or re-enroll in their benefits. Using a modern technology stack focused on automation, CareAdvisorswe remove those barriers so that patients can get access to the benefits they need, and lift the financial burden hospitals endure when providing care to patients.

Our Customer Relationship Management tool empowers care navigators and social workers with a search and communication platform that is connected to a network of community resources and hospitals. We use the data gathered across our network to power our automated analytics engine. Join us in building out our platformCRM so we can connect people to the care they need.

About the Role

As a Data Scientist, you will research and develop predictive models for population health. You will work closely with business stakeholders to build robust data science models across all aspects of our business.

Responsibilities
Deliver analytic insights in several business domains including population health, social determinants of health (SDoH), and health disparities in vulnerable populations.
Drive the definition, design, implementation and validation of cutting-edge algorithms to analyze disparate data sources to achieve targeted outcomes by leveraging machine-learning approaches, predictive and statistical modeling concepts, clustering and classification techniques.
Deliver insights and values from complex data structures to investigate opportunities in population health research.
Deliver on data-driven research projects through hands-on consultative approach and team effort.
Actively listen, integrate inputs from multiple sources and collaboratively translate healthcare or business inquiries into data and analysis requirements.
Drive informed decision making and be comfortable with presenting findings to both technical and non-technical audiences.
Continually find ways to improve how the team operates and delivers results that align with Care Advisors’ objectives.
We are looking for a team member with the following background
Currently based in the Chicagoland area (REQUIRED).
Master’s Degree in Statistics, Mathematics, Computer Science, Informatics, Data Science or a related quantitative field.
Familiarity with the data science lifecycle: posing a question, collecting data, exploring the data, developing models, making inferences, and communicating results.
Ability to communicate data in a compelling way to a variety of audiences and work in a multidisciplinary environment
Conduct statistical modeling and experimental design on a variety of healthcare datasets, including claims data and healthcare outcomes. Train and validate predictive and categorical algorithms from large datasets.
Professional experience with a healthcare organization (provider, payer, social sector or government) preferred.
Experience working in a startup or entrepreneurial environment preferred.
Familiarity with public health, population health, and social determinants of health are preferred.
At least 5 years of professional experience demonstrating a trajectory of growth in software engineering, data science, or data engineering.
Advanced hands-on knowledge of programming languages R, SQL, and/or Python.
Experience in advanced machine learning topics, including Natural Language Processing, Neural Networks, regression, Deep Learning, and unsupervised learning.
Familiarity with relational databases, data visualization and database management tools.
Able to provide access to high quality open source data science projects available in a public forum such as GitHub, data.gov or Kaggle.
--------------

At Care Advisors we value diversity and endeavor to treat everyone with respect, no matter their age, gender, race, ethnicity, or sexual, cultural or ideological preferences.

Due to the unprecedented situation of COVID-19, Care Advisors has decided to protect our current and future employees by managing our business remotely. This is inclusive of interviewing, onboarding, and daily operations each role day-to-day. Please consider that our roles will not be remote long-term and we will return to an office environment setting once it is deemed we're safe to do so following the guidance of local health authorities’ and the Centers for Disease Control.

Job Type: Full-time

Benefits:
Dental Insurance
Employee Assistance Program
Health Insurance
Paid Time Off
Parental Leave
Professional Development Assistance
Tuition Reimbursement
Vision Insurance
Schedule:
Monday to Friday
Experience:
R, SQL, and/or Python: 3 years (Required)
statistical modeling and experimental design: 3 years (Required)
data science lifecycle: 3 years (Required)
healthcare organization: 3 years (Required)
Education:
Master's (Required)
Location:
Chicago, IL 60654 (Required)
Work Location:
One location
Benefit Conditions:
Waiting period may apply
Work Remotely:
No","Care Advisors Inc
3.5","Chicago, IL",Computer Hardware & Software,Information Technology
Data Scientist,"Job Description
Being a Data Scientist at iManage means…

You are excited to join forces and collaborate with a multi-disciplinary team of engineers and analysts. You will bring analytical rigor and statistical methods to the challenges of measuring our product quality, improving consumer products and understanding the behavior of end-users.

As a Data Scientist on our team, you’ll be working on various algorithms and using Natural Language Processing (NLP) methods to work on some of our most interesting problems using expertly curated datasets.

iM Responsible For…
Analyzing and modelling structured data using advanced statistical methods, implement algorithms and software needed to perform analyses
Performing machine learning, predictive analytics, optimization, and statistical analysis methods
Using various Natural Language Processing (NLP) methods, to rigorously measure our product quality, improve enterprise products, and understand the behavior of end-users
Structuring and solving problems, conducting and interpreting analysis independently while demonstrating analytical and quantitative skills
Performing explanatory data analyses, generating and testing working hypotheses, preparing and analyzing historical data and identifying patterns
Contributing research, and trying new techniques or experiments to analyze and interpret data from documents using standard statistical tools
iM Qualified Because I have…
2-5 years of professional experience working as a Data Scientist
A Master’s or PhD (preferred) in Computer Science, Statistics, Mathematics, Engineering, Physics, Operations Research, or related fields
Experience with the theory and practice of standard NLP problems and approaches
An understanding of statistical data analysis such as linear models, multivariate analysis, stochastic models, cross validation, error analysis, statistical tests, and sampling methods
An Ability to implement, maintain, and troubleshoot big data infrastructure
Perform experimentations, draw conclusions and present recommended actions
A passion for learning, connecting and collaborating with others
About iManage

iManage combines artificial intelligence with content and email management to free, secure, and understand information. Over 3000 companies and 1 million users worldwide rely on our market-leading software to share and protect their most valuable data. Our work is not always easy but it is ambitious and rewarding.

So we’re looking for people who love a challenge. People who are happiest when they’re solving problems and collaborating with the industry’s best and brightest. In exchange, we’ll make sure the work you do here is worth doing. That’s the iManage way. It’s how we do things that might appear impossible. How we develop our employees’ strengths and unlock their potential. It’s how we find meaning in everything we do.

Whoever you are, whatever you do, however you work. Make it mean something at iManage.

Learn more at: www.imanage.com

Please see our privacy statement for more information on how we handle your personal data: https://imanage.com/privacy-policy/

Powered by JazzHR

w98J6ezvgj","iManage
4.1","Chicago, IL",Computer Hardware & Software,Information Technology
Data Engineer,"Job Description

Data Engineer

At Citadel, data is the core of the investment process. Data Engineers architect and build our data platforms which drive how we source, enrich, and store data that integrates into the investment process. These Data Engineers own the entire data pipeline starting with how we ingest data from the outside world, transforming that information into actionable insights, and ultimately designing the interfaces and APIs that our investment professionals and quantitative researchers use to monetize ideas. Throughout the process, our Data Engineers partner with top investment professionals and data scientists to design systems that solve our most critical problems and answer the most challenging questions in finance.

YOUR OPPORTUNITY:

Develop solutions that enable investment professionals to efficiently extract insights from data. This includes owning the ingestion (web scrapes, S3/FTP sync, sensor collection), transformations (Spark, SQL, Kafka, Python/C++/Java), and interface (API, schema design, events)
Partner with the industry’s top investment professionals, quantitative researchers, and data scientists to design, develop, and deploy solutions that answer fundamental questions about financial markets
Build tools and automation capabilities for data pipelines that improve the efficiency, quality and resiliency of our data platform
Drive the evolution of our data strategy by challenging the status quo and identifying opportunities to enhance our platform
YOUR SKILLS & TALENTS:

Passion for working with data in order to accurately model and analyze complex systems such as a publicly traded company, commodity market, economy, or financial instruments
Strong interest in financial markets and a desire to work directly with investment professionals
Proficiency with one or more programming languages such as Java or C++ or Python
Proficiency with RDBMS, NoSQL, distributed compute platforms such as Spark, Dask or Hadoop
Experience with any of the following systems: Apache Airflow, AWS/GCE/Azure, Jupyter, Kafka, Docker, Kubernetes, or Snowflake
Strong written and verbal communications skills
Bachelor’s, Master’s or PhD degree in Computer Science or equivalent experience
About Citadel


Citadel is a global investment firm built around world-class talent, sound risk management, and innovative leading-edge technology. For a quarter of a century, Citadel’s hedge funds have delivered meaningful and measurable results to top-tier investors around the world, including sovereign wealth funds, public institutions, corporate pensions, endowments and foundations.

With an unparalleled ability to identify and execute on great ideas, Citadel’s team of more than 675 investment professionals, operating from offices including Chicago, New York, San Francisco, London, Hong Kong and Shanghai, deploy capital across all major asset classes, in all major financial markets.","Citadel
3.8","Chicago, IL",-1,-1
Data Scientist,"Job Description
BCforward is seeking a highly motivated and experienced Data Scientistin Chicago (IL) 60604.

Duration: 06+ Months Contract to Hire

Pay Rate: Open/Negotiable on W2

This position will accommodate working form home during the pandemic, they eventually will be going into the office.

Overview:

Leverage your “science first” mentality, curiosity, deep technical expertise, and problem-solving skills to explore, discover, and predict patterns and insights within complex data sets. This includes enabling government to capitalize on the value proposition of advanced analytics, and the derivation of clear narratives that help our clients understand their data and how those insights address their research questions. An active DoD Secret clearance is required upon start date.

Responsibilities:
Use analytical and statistical tools to evaluate data and aid in decision making.
Manipulate / create social media analytics and data to strengthen marketing campaign effectiveness
Manipulate common data formats, including comma-delimited, text files, and JSON.
Transform data and analysis into informative visualizations and interactive dashboards using open-source and commercially available tools.
Work with clients to prioritize research and modeling initiatives
Derive insights and analytic narratives from data and visualizations for effective storytelling and clear communication in response to client research questions.
Support the development of a mature analytics function informed by industry best practices
Work in a fast-paced, solutions-oriented, and collaborative environment focused on client deliverables, analysis, and reporting.
Qualifications:
Degree (Master’s required) in science, technology, engineering, mathematics, computer science, economics, or other related business or technical discipline is required
Extensive experience in social media analytics and marketing campaign effectiveness.
Experience in Salesforce, Sprinklr, and Adobe Analytics - marketing analytics background
Experience working with tools, including object-oriented programming (Python, Java), computational analysis tools (R, MATLAB), and associated data science libraries (scikit-learn)
Significant experience in the AI/ML lifecycle, from ideation and solution concept development, to rapid prototyping and validation in operational environments, and importantly, in the sustainment of AI/ML solutions for CI/CD.
Significant experience and knowledge of best practices in the practical application and execution of AI/ML in operational environments.
Ability to frame and scale data problems to analyze, visualize, and find data solutions, and translate customer qualitative requirements into quantitative and technical approaches
Experience creating meaningful data visualizations and interactive dashboards using platforms such as Tableau, Qlik, Power BI, RShiny, plotly, and d3.js to communicate findings and relate them back to how your insights create business impact
Working knowledge of databases and SQL; preferred qualifications include linking analytic and data visualization products to database connections
At least 5+ years of experience in the field
DoD Secret clearance required
Superior communication skills, both oral and written
Preferred experience in the following areas:
DoD experience is preferred, in particular with human capital data and workforce analytics.o Data science methods related to data architecture, data munging, data and feature engineering, and predictive analytics
Knowledge of AI/ML SaaS platforms (e.g., DataRobot, H2O DriverlessAI)
Unstructured text and natural language processing
Computational tools such as R, Python, SAS, SQL, and MATLAB
Anaconda, IBM Blue, and Oracle Big Data to analyze large data sets and develop automated analytics in making sense of data affecting DoD operations
Developing machine learning, data mining, statistical network, natural language processing, text analytics, and graph-based algorithms to analyze massive data sets
Supervising algorithm implementation in on-premise and cloud-based computing environments
Developing software to generate reports and visualizations that summarize data sets and provide data-driven insights
Developing and implementing statistical, machine learning, and heuristic techniques to create descriptive, predictive, and prescriptive analytics as well as to develop statistical tests to make data-driven recommendations and decisions
Thank you for your time and consideration. If you are not interested, but you know someone who may be more of a fit for this position, feel free to pass along my information.

About BCforward:

BCforward began as an IT business solution and staffing firm. Founded in 1998, BCforward has grown with our customers’ needs into a full-service personnel solution’s organization. Headquartered in Indianapolis, Indiana, BCforward also operates numerous delivery centers across North America and India. We are currently the largest consulting firm and largest MBE certified firm in Indiana. Our uninterrupted growth has allowed BCforward to deliver uniquely configured IT staffing and project solutions for overthe years of catering to our customers’ specific needs. BCforward currently maintains a team of over 5000 global resources. With our additional brand, Stafforward, together we have the capabilities to deliver services for a variety of industries in both public and private sectors which allows us to address your most challenging needs.

www.BCforward.com

www.facebook.com/bcforward

We must inform you that during the hiring process, we may ask for you to disclose and provide us with various categories of your personal information, including identifiers such as your name and address, professional information, commercial information, education information, and other related information. Please note that we will only use this information to facilitate and complete the recruiting process. This posting is not an offer of employment. All applicants must be authorized to work in the United States and willing to cooperate with a background check and drug screen, to the extent permitted by federal and local laws up to and including both criminal and financial reviews. The submission of intentionally false or fraudulent information in response to this job posting shall render the applicant ineligible for the position. BCforward is an equal opportunity employer. Any subsequent offer of employment shall be considered employment at will regardless of the anticipated assignment duration.
Company Description
About BCforward
BCforward began as an IT business solutions and staffing firm. Founded in 1998, BCforward has grown with our customers’ needs into a full-service personnel solutions organization. BCforward’s headquarters are in Indianapolis, Indiana and also operates delivery centers in 17 locations in North America as well as Hyderabad, India and Puerto Rico. We are currently the largest consulting firm and largest MBE certified firm headquartered in Indiana. With 14+ years of uninterrupted growth, the addition of two brands (Stafforward and PMforward) and a team of more than 1400 resources our teams deliver services for multiple industries from both public and private sectors. BCforward’s team of dedicated staffing professionals has placed thousands of talented people over the past decade, with retention rates that are consistently higher than the industry average.

www.bcforward.com","BCforward
2.8","Chicago, IL",IT Services,Information Technology
Data Scientist,"Job Description
Illinois insurer is looking to grow its analytics team with a Data Scientist who has at least 3 years of experience and is proficient in data analysis, machine learning, and statistical modeling. Candidate should also be proficient in high-level programming languages, data visualization, and have an understanding of healthcare. Must be highly skills in all Microsoft applications including Access, Excel, Word and Power Point. Actuarial designation, Masters or Ph.D. preferred. (#48068)","DW Simpson
4.2","Chicago, IL",Staffing & Outsourcing,Business Services
Statistician,"The U.S. Department of the Treasury has a distinguished history dating back to the founding of our nation. As the steward of U.S. economic and financial systems, Treasury is a major and influential leader in today's global economy. We have over 100,000 employees across the country and around the world. Come Join the Department of the Treasury and Invest in Tomorrow.
See Other Information for Locations
Positions are to be filled in the Large Business & International (LB&I), Data Solutions division.
Eight (8) positions are to be filled in any of the following locations:
Birmingham, AL
Fayetteville, AR
Little Rock, AR
Phoenix, AZ
El Monte, CA
Glendale, CA
Laguna Niguel, CA
Los Angeles, CA
Long Beach, CA
Oakland, CA
Sacramento, CA
San Diego, CA
San Francisco, CA
San Jose, CA
Santa Ana, CA
Lakewood, CO
Hartford, CT
New Haven, CT
Norwalk, CT
Washington, DC
Newark, DE
Miami, FL
Ft. Myers, FL
Jacksonville, FL
Maitland, FL
Plantation, FL
Tampa, FL
West Palm Beach, FL
Atlanta, GA
Honolulu, HI
Des Moines, IA
Chicago, IL
Downers Grove, IL
Schiller Park, IL
Springfield, IL
Indianapolis, IN
Wichita, KS
Louisville, KY
New Orleans, LA
Boston, MA
Brockton, MA
Stoneham, MA
Southborough, MA
Baltimore, MD
Lanham-Seabrook, MD
Rockville, MD
Ann Arbor, MI
Clinton Township, MI
Detroit, MI
Farmington Hills, MI
Flint, MI
Grand Rapids, MI
Pontiac, MI
Bloomington, MN
Chesterfield, MO
Lee's Summit, MO
Charlotte, NC
Greensboro, NC
Raleigh, NC
Omaha, NE
Edison, NJ
Iselin, NJ
Mountainside, NJ
Paterson, NJ
Las Vegas, NV
Albany, NY
Bethpage, NY
Buffalo, NY
New York, NY
Rochester, NY
Cincinnati, OH
Columbus, OH
Independence, OH
Oklahoma City, OK
Tulsa, OK
Portland, OR
Philadelphia, PA
Pittsburgh, PA
King Of Prussia, PA
Guaynabo, PR
Warwick, RI
Franklin, TN
Memphis, TN
Nashville, TN
Austin, TX
Farmers Branch, TX
Fort Worth, TX
Houston, TX
San Antonio, TX
Ogden, UT
Salt Lake City, UT
Norfolk, VA
Richmond, VA
Vienna, VA
Seattle, WA
Milwaukee, WI
Waukesha, WI
Kearneysville, WV
Martinsburg, WV
WHAT DOES A DATA SCIENTIST DO? The Data Scientist utilizes advanced analytical, statistical, and computer programming skills to develop data- driven solutions to difficult business challenges. As a data scientist, you are responsible for conducting data-centric projects to provide insight and informed decisions for mission- oriented programs of the Internal Revenue Service (IRS), which may impact multiple program segments, divisions, the Service, or segments of the taxpayer population. This is accomplished by utilizing a wide range of technical competencies such as statistics and machine learning, coding languages, data wrangling, and reporting and visualization techniques. The Data Scientist may lead team or cross functional projects, and will apply critical thinking, problem solving and ability to communicate complex analysis to advance the use of data-driven decision making in IRS operations.

WHAT IS THE LARGE BUSINESS AND INTERNATIONAL (LB&I) DIVISION OF THE INTERNAL REVENUE SERVICE? The Large Business and International (LB&I) business unit provides service and enforcement activities to support tax compliance of businesses and related entities with assets of $10 million or more, as well as small U.S. businesses engaged in international, U.S. citizens abroad, and foreign persons and businesses with a U.S. tax requirement.
As a Data Scientist, you will:
Serve as a technical expert with responsibility for the initiation, planning, implementation, controlling, modifying and executing of all or part of an entire project, including such tasks as formulation of workload estimates for program segments, specification of the methodology to be used, preparation of appropriate specifications and procedures, and review of computer systems specifications and materials and instructions needed for assuring the adequacy of the project’s design and objectives.
Explore novel methods of retrieving data and develop innovative recommendations to management and senior leadership as a means for making data driven decisions such as modification of processes and policies. Review, evaluate, validate, and document the results of the findings.
Assist the supervisor in determining the scope, goals and schedules for future programs in the Office. Collaborate with business or technology partners to understand business needs, identify opportunities, and develop and implement analytical solutions.
Identify and assess relevant data sources’ validity and reliability to meet project needs. Collate, clean, transform, analyze, and integrate structured and unstructured data from various sources in preparation for analysis.
Apply statistical methods and concepts including data mining, statistical theory and research procedures to test hypotheses using structured and unstructured data. Develop data product solutions to improve customer experiences, anomaly detection, and business outcomes. Develop proofs of concept or demonstrations to evaluate feasibility of project solutions and recommend visualization strategies.
Document project work and review deliverables for validity, reliability and timeliness. Communicate analytic solutions to technical and non-technical stakeholders, including during executive- level and/or cross-agency meetings, in a clear and effective manner using oral and written communications.
Maintain knowledge of state-of-the-art innovations in data science from both academic and industry sources and identify opportunities for implementation. Engage in general professional development to improve knowledge of IRS processes/programs.
Apply computer based mathematical/statistical techniques using software. Lead or participate in statistical projects or studies in survey sampling (design and estimation), modeling, or statistical research. Apply knowledge of programming/coding language (i.e., SQL, SAS, SPSS, RStudio) to develop scripts or applications.
Act as a troubleshooter in resolving bottlenecks at any step in a project by identifying and proposing solutions; this may include coordination with other project team members or stakeholders to mitigate issues.

WHERE CAN I FIND OUT MORE ABOUT OTHER IRS CAREERS? If you want to find out more about IRS careers, visit us on the web at www.jobs.irs.gov
#LI-POST
You must meet the following requirements by the closing date of this announcement
BASIC QUALIFICATION REQUIREMENTS:

GS-1530 Statistician All Grades:
You must have a Bachelor's degree that included 15 semester hours in statistics (or in mathematics and statistics, provided at least 6 semester hours were in statistics), and 9 additional semester hours in one or more of the following: physical or biological sciences, medicine, education, or engineering; or in the social sciences including demography, history, economics, social welfare, geography, international relations, social or cultural anthropology, health sociology, political science, public administration, psychology, etc. Credit toward meeting statistical course requirements should be given for courses in which 50 percent of the course content appears to be statistical methods, e.g., courses that included studies in research methods in psychology or economics such as tests and measurements or business cycles, or courses in methods of processing mass statistical data such as tabulating methods or electronic data processing. OR
Combination of education and experience -- courses as shown above, plus appropriate experience or additional education. The experience should have included a full range of professional statistical work such as (a) sampling, (b) collecting, computing, and analyzing statistical data, and (c) applying statistical techniques such as measurement of central tendency, dispersion, skewness, sampling error, simple and multiple correlation, analysis of variance, and tests of significance.
GS-13 LEVEL: You must have one year of specialized experience at a level of difficulty and responsibility equivalent to the GS-12 grade level in the Federal service. Specialized experience for this position includes all of the following:
Experience applying project management principles on a data science project
Experience planning and executing a variety of data science and/or analytics projects.
Experience using data mining process models (such as CRISP-DM, SEMMA, etc.,) to design and execute data science project.
Experience preparing and analyzing structured and unstructured datasets to explorations and evaluating data science centric models.
Experience working with multiple data types and formats as a part of a data science project.
Experience applying a range of analytic approaches, including (but not limited to) machine learning, text analytics, and natural language processing; graph theory, link analysis and optimization models; complex adaptive systems; and/or deep learning neural networks that are part of the exploration.
Experience coding in various programming languages (such as R, Python, SQL, or JAVA) to conduct various phases of data science projects.
Experience creating and querying different datastores and architectures (such as Sybase, Oracle, and open-source databases) to work with various types of data as part of the data science project.
Experience using tools for data visualization (graphs, tables, charts, etc.,) and end-user business intelligence.
-The experience may have been gained in the public sector, private sector or Volunteer Service. One year of experience refers to full-time work; part-time work is considered on a prorated basis.
-To ensure full credit for your work experience, please indicate dates of employment by month/year, and indicate number of hours worked per week, on your resume.","Internal Revenue Service
3.5","Chicago, IL",Federal Agencies,Government
Data Engineer,"Join SADA as a Data Engineer!

Your Mission

As a Data Engineer at SADA, you will work collaboratively with architects and other engineers to recommend, prototype, build and debug data infrastructures on Google Cloud Platform (GCP). You will have an opportunity to work on real-world data issues facing our customers today. Engagements vary from being purely consultative to requiring heavy hands-on work and cover a diverse array of domain areas, such as data migrations, data archival and disaster recovery, and big data analytics solutions requiring a combination of batch or streaming data pipelines, data lakes and data warehouses.

You will be recognized as an established contributor by your team. You will contribute design and implementation components for multiple projects. You will work mostly independently with limited oversight. You will also participate in client-facing discussions in areas of expertise.
Pathway to Success

#BeOneStepAhead: At SADA we are in the business of change. We are focused on leading-edge technology that is ever-evolving. We embrace change enthusiastically and encourage adaptability. This means that not only do our engineers understand that change is inevitable, but they embrace this change to continuously broaden their skills, preparing for future customer needs.

Your success comes from your enthusiasm, insight, and positive impact. You will be given direct feedback quarterly with respect to the scope and quality of your contributions, your ability to estimate accurately, customer feedback at the close of projects, your collaboration with your peers, and the consultative skill you demonstrate in customer interactions.

As you continue to execute successfully, we will build a personalized development plan together that leads you through the engineering or management growth tracks.

Expectations

Required Travel - 30% travel to customer sites, conferences, and other related events
Customer Facing - You will interact with customers on a regular basis, sometimes daily, other times weekly/bi-weekly. Common touchpoints occur when qualifying potential opportunities, at project kickoff, throughout the engagement as progress is communicated, and at project close. You can expect to interact with a range of customer stakeholders, including engineers, technical project managers, and executives.
Training - Ongoing with a first-week orientation at HQ followed by a 90-day onboarding schedule. Details of the timeline can be shared.

Job Requirements

Required Credentials:
Google Professional Data Engineer Certified or able to complete within the first 45 days of employment

Required Qualifications:
Expertise in at least one of the following domain areas:
Data warehouse modernization: building complete data warehouse solutions, including technical architectures, star/snowflake schema designs, infrastructure components, ETL/ELT pipelines, and reporting/analytic tools. Must have hands-on experience working with batch or streaming data processing software (such as Beam, Airflow, Hadoop, Spark, Hive).
Data migration: migrating data stores to reliable and scalable cloud-based stores, including strategies for near zero-downtime.
Backup, restore & disaster recovery: building production-grade data backup and restore, and disaster recovery solutions. Up to petabytes in scale.
Experience writing software in one or more languages such as Python, Java, Scala, or Go
Experience building production-grade data solutions (relational and NoSQL)
Experience with systems monitoring/alerting, capacity planning and performance tuning
Experience in technical consulting or other customer-facing role

Useful Qualifications:
Experience working with Google Cloud data products (CloudSQL, Spanner, Cloud Storage, Pub/Sub, Dataflow, Dataproc, Bigtable, BigQuery, Dataprep, Composer, etc)
Experience with IoT architectures and building real-time data streaming pipelines
Applied experience operationalizing machine learning models on large datasets
Knowledge and understanding of industry trends and new technologies and ability to apply trends to architectural needs
Demonstrated leadership and self-direction -- a willingness to teach others and learn new techniques
Demonstrated skills in selecting the right statistical tools given a data analysis problem

About SADA

Values: We built our core values on themes that internally compel us to deliver our best to our partners, our customers and to each other. Ensuring a diverse and inclusive workplace where we learn from each other is core to SADA’s values. We welcome people of different backgrounds, experiences, abilities and perspectives. We are an equal opportunity employer.

Make them rave
Be data driven
Be one step ahead
Be a change agent
Do the right thing


Work with the best: SADA has been the largest partner in North America for GCP since 2016 and has been named the 2019 and 2018 Google Cloud Global Partner of the Year. SADA has also been awarded Best Place to Work by Inc. as well as LA Business Journal!

Benefits: Unlimited PTO, competitive and attractive compensation, performance-based bonuses, paid holidays, rich medical, dental, vision plans, life, short and long-term disability insurance, RRSP, professional development reimbursement program as well as Google Certified training programs.

Business Performance: SADA has been named to the INC 5000 Fastest-Growing Private Companies list for 12 years in a row garnering Honoree status. CRN has also named SADA on the Top 500 Global Solutions Providers for the past 5 years. The overall culture continues to evolve with engineering at its core: 3200+ projects completed, 3000+ customers served, 10K+ workloads and 25M+ users migrated to the cloud.","SADA
4.7","Chicago, IL",IT Services,Information Technology
Data Scientist,"Learn and work on meaningful initiatives with some of the best and brightest in the market research industry. The NPD Group provides the world’s most successful brands with leading market research, combining consumer and retail point-of-sale data with analytic solutions to interpret today’s market trends while anticipating tomorrow’s. In addition, we offer a career filled with innovation and growth to the forward-thinking problem solvers who join our team. Position Overview NPD group is looking for a data scientist with significant statistical modeling and programming experience. This position exists within the Methodology team, a core function in Research Science that is responsible for building models and code that help achieve quality outcomes. Sampling of issues we might tackle: Differential non response Selection bias Differential use of scales Differential recruitment Data imputation Ecological inference Quantifying uncertainty Choosing between alternate methodologies Identifying spurious drivers / sources of bias Sampling of techniques we might use: Multilevel regression and post stratification (MRP) Multilevel modeling / hierarchical modeling Propensity-adjustments Matching Raking Post-stratification Causal modeling Generative models Optimization Artificial intelligence Although modeling expertise is central to this role, candidates will also benefit from experience modifying model-based approaches to be used at production scale. Also helpful is experience triangulating estimates from disparate data sources with different sample frames, levels of measurement, and frequency of collection. The ideal candidate will be an experienced statistical programmer using R who also has experience working with survey and sales data, refining and developing methodological improvements, and familiarity with or willingness to learn Agile or Lean approaches to developing new product improvements. Responsibilities: Use various modeling approaches to design enhancements to NPD methodologies Quantify improvements to data due to modeling Carry out tests of alternative implementations of these enhancements Making sure code to implement models on an ongoing basis is robust by creating unit tests Investigating unexpected results and brainstorming alternative methodological solutions. Provide peer mentoring of other team members via code reviews, pair programming, unit test/acceptance test reviews, and brainstorming sessions. Adopt and continue to improve usage of development practices and patterns, such as test-driven development, version control, and use of agile management tools. Conduct original research-on-research (e.g., through simulations and/or evaluations of historical data) to improve methodologies, processes, and data integrity for both survey and scanner (point-of-sale) data. Promote consistency in implementation of designed enhancements across different businesses Maintain relationships with Research Science client teams to understand what is working well with NPD methodology and what could be improved Listen to internal customers and build an understanding of their needs before building solutions Communicate results and procedures in a concise and polished manner to diverse internal stakeholders Back up assertions with facts, and design experiments to quantify or reduce uncertainty when dealing with the unknown Qualifications: Degree in statistics, quantitative social science, computer science, mathematics, or related fields is required. Graduate-level experience preferred. 6+ years of work experience, with solid breadth and depth of knowledge of statistical and analytic techniques. Excellent time management and creative problem solving skills. Experience with data analysis in R is required. Experience with additional languages and/or more extensive proficiency in R preferred. Excellent written and oral communication skills, with the ability to communicate effectively to both technical and non-technical audiences. Experience with one or more development methodologies (Agile, Lean, Scrum) is preferred. Experience with tools for managing software development is preferred (tools such as JIRA, Confluence, Github/Gitlab issue tracker, Trello, Team Foundation Server/DevOps Server, etc). Location: We would prefer to find a candidate who can work from either our corporate headquarters in Port Washington, NY, or one of our other largest offices, in Rosemont, IL. However, we are committed to finding the right candidate across all US locations. We have offices in many US cities, including: Chicago, IL; New York, NY; Los Angeles, CA; San Diego, CA; Cincinnati, OH; Boulder, CO; Bentonville, AR; Greensboro, NC; Houston, TX. The NPD Group, Inc. is an Affirmative Action/Equal Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability or protected veteran status or any other characteristic protected by law.","NPD
3.8","Rosemont, IL",Research & Development,Business Services
Data Scientist,"Company Description

MessageControl is a cybersecurity start-up in Chicago providing human layer email and messaging security. Our innovative technology protects users from phishing, spoofing, fraud, business email compromise (BEC), and other types of attacks.

Job Description

As a Data Scientist at MessageControl you’ll be building intelligent products to protect people from sophisticated email attacks. In this position, your data science expertise will help us build new features and improve our existing security products. Our transparent and collaborative culture means we work both independently and together as a team on projects in an agile environment.

What you bring to the team:
Partner with stakeholders across the organization to identify high-impact opportunities to use our data to further our innovative product strategy.
Build complex predictive models using Machine Learning and Deep Learning algorithms to substantially improve our email security tools.
Assess the potential usefulness and validity of new ML and DL approaches and data sources.
Develop proof-of-concept prototypes to prove out hypotheses.
Manage experience with data, including complex queries, exploratory data analysis, data visualization, advanced modeling and communication of applicable insights to audiences at varying levels of technical sophistication.
Help drive our data science culture and strategy.
Qualifications

Desirable Skills and Experience:
Must have at least 3 years of professional experience outside of academic or internship settings. Prior research, data science modeling and taking machine learning features to market.
Outstanding quantitative background (e.g. statistics, math, machine learning, operations research, etc.): Bachelors degree required, masters is a plus.
Familiarity with technical tools for analysis - Python (with Pandas, Scikit-learn, etc.), SQL, etc. Prior experience using natural language processing techniques is a plus.
Previous software development experience is required, including usage of version control systems such as git and writing tests
Research mindset with a bias towards action. You are able to structure a project from idea to experimentation to prototype to implementation.
Must be a passionate and attentive self-starter, a great communicator, and possess the ability to follow-through initiatives to completion. You have a great work ethic and love the responsibility of being held accountable for the results.
Additional Information

Perks/Benefits:
Direct access to senior management – our leadership team works alongside our team members every day.
Comprehensive medical, dental, and vision insurance.
Company paid life insurance, short term disability and long term disability.
Flexible paid time off (PTO) policy, plus sick days.
Ongoing professional development opportunities by level and function.
Your choice of Windows or Mac laptop.
Onsite gym.
Casual dress in a fun, friendly and collaborative work environment.
The ability to have significant impact every day.
Location:
Thisposition is onsite at our office in the Chicago Loop. We're not offering remote employment at this time.",MessageControl,"Chicago, IL",Enterprise Software & Network Solutions,Information Technology
Data Scientist,"Overview
Leverage your science first mentality, curiosity, deep technical expertise, and problem-solving skills to explore, discover, and predict patterns and insights within complex data sets. This includes enabling government to capitalize on the value proposition of advanced analytics, and the derivation of clear narratives that help our clients understand their data and how those insights address their research questions.

Responsibilities
Use analytical and statistical tools to evaluate data and aid in decision making.
Manipulate / create social media analytics and data to strengthen marketing campaign effectiveness.
Manipulate common data formats, including comma-delimited, text files, and JSON.
Transform data and analysis into informative visualizations and interactive dashboards using open-source and commercially available tools.
Work with clients to prioritize research and modeling initiatives• Derive insights and analytic narratives from data and visualizations for effective storytelling and clear communication in response to client research questions.
Support the development of a mature analytics function informed by industry best practices.
Work in a fast-paced, solutions-oriented, and collaborative environment focused on client deliverables, analysis, and reporting.
Qualifications
Active Secret Clearance.
Degree (Masters required) in science, technology, engineering, mathematics, computer science, economics, or other related business or technical discipline is required.
Extensive experience in social media analytics and marketing campaign effectiveness.
Experience in Salesforce, Sprinklr, and Adobe Analytics - marketing analytics background.
Experience working with tools, including object-oriented programming (Python, Java), computational analysis tools (R, MATLAB), and associated data science libraries (scikit-learn).
Significant experience in the AI/ML lifecycle, from ideation and solution concept development, to rapid prototyping and validation in operational environments, and importantly, in the sustainment of AI/ML solutions for CI/CD.
Significant experience and knowledge of best practices in the practical application and execution of AI/ML in operational environments.
Ability to frame and scale data problems to analyze, visualize, and find data solutions, and translate customer qualitative requirements into quantitative and technical approaches.
Experience creating meaningful data visualizations and interactive dashboards using platforms such as Tableau, Qlik, Power BI, RShiny, plotly, and d3.js to communicate findings and relate them back to how your insights create business impact.
Working knowledge of databases and SQL; preferred qualifications include linking analytic and data visualization products to database connections.
At least 5+ years of experience in the field.
DoD Secret clearance required.
Superior communication skills, both oral and written
Preferred Experience
DoD experience is preferred, in particular with human capital data and workforce analytics.
Data science methods related to data architecture, data munging, data and feature engineering, and predictive analyticso Knowledge of AI/ML SaaS platforms (e.g., DataRobot, H2O DriverlessAI).
Unstructured text and natural language processingo Computational tools such as R, Python, SAS, SQL, and MATLABo Anaconda, IBM Blue, and Oracle Big Data to analyze large data sets and develop automated analytics in making sense of data affecting DoD operations.
Developing machine learning, data mining, statistical network, natural language processing, text analytics, and graph-based algorithms to analyze massive data setso Supervising algorithm implementation in on-premise and cloud-based computing environments.
Developing software to generate reports and visualizations that summarize data sets and provide data-driven insights.
Developing and implementing statistical, machine learning, and heuristic techniques to create descriptive, predictive, and prescriptive analytics as well as to develop statistical tests to make data-driven recommendations and decisions.","Smart Synergies, Inc.
2.6","Chicago, IL",Consulting,Business Services
Data Scientist,"A Chicago based IOT start up with a new round of series A funding is looking to expand their engineering team to handles the uptick in sales. You will be working on an IOT enabled Saas to help take smart buildings to the next level in the commercial real estate business. This is a cloud-based platform for building managers, operators, and tenants to view data in a centralized system. Essentially the platform is a data driven tool that uses geofencing and predictive analysis to improve insights and create engagement between users.They are looking for someone who wants to get in on something from the ground up. Though the product is live you will be heavily involved in architecture and planning, as well as shaping the company culture. The tech stack over there is .Net core, Angular 8 and Azure though you will be more focused on Python, R, SQL, Spark, NLP, and some other tools that you will help drive the decision making on.Required Skills & Experience* 3+ years of professional experience in data science or machine learning* 3+ years professional experience in Python* Professional experience in Spark or similar tools* Experience in NLP* Experience leading a teamDesired Skills & Experience* Bachelor's degree in computer science or related field* Excellent written and oral communicationWhat You Will Be DoingTech Breakdown* 10% architecture/Planning* 20% Team Collaboration* 70% data scienceThe Offer* Competitive Salary: Up to $160,000You will receive the following benefits:* Medical Insurance & Health Savings Account (HSA)* 401(k)* Paid Sick Time Leave* Pre-tax Commuter BenefitApplicants must be currently authorized to work in the United States on a full-time basis now and in the future.Jobspring Partners, part of the Motion Recruitment network, provides IT Staffing Solutions (Contract, Contract-to-Hire, and Direct Hire) in major North American markets. Our unique expertise in today's highest demand tech skill sets, paired with our deep networks and knowledge of our local technology markets, results in an exemplary track record with candidates and clients.A Chicago based IOT start up with a new round of series A funding is looking to expand their engineering team to handles the uptick in sales. You will be working on an IOT enabled Saas to help take smart buildings to the next level in the commercial real estate business. This is a cloud-based platform for building managers, operators, and tenants to view data in a centralized system. Essentially the platform is a data driven tool that uses geofencing and predictive analysis to improve insights and create engagement between users.They are looking for someone who wants to get in on something from the ground up. Though the product is live you will be heavily involved in architecture and planning, as well as shaping the company culture. The tech stack over there is .Net core, Angular 8 and Azure though you will be more focused on Python, R, SQL, Spark, NLP, and some other tools that you will help drive the decision making on.Required Skills & Experience* 3+ years of professional experience in data science or machine learning* 3+ years professional experience in Python* Professional experience in Spark or similar tools* Experience in NLP* Experience leading a teamDesired Skills & Experience* Bachelor's degree in computer science or related field* Excellent written and oral communicationWhat You Will Be DoingTech Breakdown* 10% architecture/Planning* 20% Team Collaboration* 70% data scienceThe Offer* Competitive Salary: Up to $160,000You will receive the following benefits:* Medical Insurance & Health Savings Account (HSA)* 401(k)* Paid Sick Time Leave* Pre-tax Commuter BenefitApplicants must be currently authorized to work in the United States on a full-time basis now and in the future.Jobspring Partners, part of the Motion Recruitment network, provides IT Staffing Solutions (Contract, Contract-to-Hire, and Direct Hire) in major North American markets. Our unique expertise in today's highest demand tech skill sets, paired with our deep networks and knowledge of our local technology markets, results in an exemplary track record with candidates and clients.#LI-JK1","Management Decisions, Inc.
1.6","Chicago, IL",Advertising & Marketing,Business Services
Data Scientist,"Title: Data Scientist

Location: Chicago or North NJ (near Newark) (Multiple Openings)

Job Type: Full Time/ Contract to Hire

Salary: Open

Requirements:

• Minimum 5-10 years of hands-on experience with statistical software tools: SQL, R, Python

• 3+ years- experience in business analytics, forecasting or business planning with emphasis on analytical modeling, quantitative reasoning and metrics reporting

• Experience working with large data sets in order to extract business insights or build predictive models

• Proficiency in one or more statistical tools/languages - Python, Scala, R SPSS or SAS and related packages like Pandas, SciPy/Scikit-learn, NumPy etc.

• Good data intuition / analysis skills; sql, plsql knowledge must

• Banking / Financial Sectors (preferred / not a must)

Note: If interested please send your updated resume and include your rate requirement along with your contact details with a suitable time when we can reach you. If you know of anyone in your sphere of contacts, who would be a perfect match for this job then, we would appreciate if you can forward this posting to them with a copy to us.","Two95 International Inc.
4.0","Chicago, IL",Staffing & Outsourcing,Business Services
Statistician,"Address: 111 W Monroe - 115 S LaSalle Job Family Group: Data Analytics & Reporting WHY BMO? At BMO we have a shared purpose; we put the customer at the centre of everything we do - helping people is in our DNA. For 200 years we have thought about the future-the future of our customers, our communities and our people. We help our customers and our communities by working together, innovating and pushing boundaries to bring them our very best every day. Together we're changing the way people think about a bank. WHAT IS THE OPPORTUNITY? The Data Scientist works with management and business partners to support the development and implementation of statistical models & advanced analytical solutions. We are looking for a strategic thinker with the ability to dissect business problems, conduct research and advanced statistical analysis to identify trends, variations, patterns, and insights relating to branch performance and customer activities, and build end-to-end analytical solutions to drive profitable growth for the business This is an exciting opportunity that is on the forefront of a critical capability, providing thought leadership to U.S. Personal and Business Banking on the value of data and analytics. The incumbent will get to work with and support multiple lines of business around the enterprise to help them achieve their objectives. So if you have a strong statistical modeling expertise, like to work in a start-up mode and have a long term orientation, join us to make meaningful difference in the lives of our customers, the community we serve in and the company. WHAT WILL YOU DO? + Support Senior Management on analytical projects of varying sizes and complexities, including: + Participate in business partner interviews, brainstorming sessions, and workshops to capture business objectives and prioritize opportunities + Research & leverage state of art modeling techniques, participates in modeling innovation. + Identify best analytical techniques that can be effectively applied to achieve business objectives and interpret next best action through data driven insights + Building end to end automated analytic solutions that are intuitive, simple to maintain, and drive real business outcomes + Leads the development and implementation of innovative analytical solutions, including customer segmentation, optimization, prescriptive analytics and machine learning algorithm & recommendations to solve business problems. + Data gathering and cleansing, statistical transformation, feature engineering & selection + Build & deploy response models leveraging analytical techniques such as linear/logistic regression models, Gradient Boosting, Random Forest, Attribution to determine Product Propensity as well as Customer Contact Channel Preference + Conduct Model Validation & documentation including KS, Gini Coefficient, ROC Curve, PSI + Build Strategies & Design Experiment & conduct A/B testing to prove or disprove hypothesis + Evaluate & deploy new tools, techniques & technologies to advance analytical capabilities + Operates as a subject matter expert on statistical analysis, test & design of experiment analysis methodology & financial impact analysis. Minimum Qualification: At a minimum, here's what we need from you: + Bachelor's degree in Mathematics, Statistics, Analytics, Computer Science And/Or Physics or other quantitative disciplines + 4+ years of experience in credit risk, fraud risk, marketing analytics, optimization, operation analytics, Modeling/Data Science or related. + Advanced skills in SQL or SAS a must, including relevant packages and statistical methodologies + Deep understanding of statistical modeling techniques like Regression, Decision Trees, Segmentation & Classification Preferred Qualification: If we had our say, we'd also look for: + Master's degree or Ph.D. in Mathematics, Statistics, Analytics, Computer Science and/or Physics, preferably in banking & financial services industry + 2+ years of experience in credit risk, fraud risk, marketing analytics, optimization, operation analytics, Modeling/Data Science or related. + Experience in building response models & propensity scores. + Knowledge of Python, R, Spark or HiveQL will be preferred + Knowledge of machine learning techniques like Gradient Boosting, Random Forest, SVM, Pathing & Attribution etc. a strong plus + Experience in building and presenting data driven insights through business intelligence tools Qualitative skills: + Exhibits advanced critical thinking skills, integrative skills and creativity to drive innovation + Demonstrates ability to build a good fact base, apply sound reasoning, and generate relevant recommendations that get implemented and lead to business success + Able to work highly independently and manage multiple priorities in an agile fast paced environment + Demonstrates strong attention to detail and a high level of due diligence We're here to helpAt BMO Harris Bank we are driven by a shared Purpose: Boldly Grow the Good in business and life. It calls on us to create lasting, positive change for our customers, our communities and our people. By working together, innovating and pushing boundaries, we transform lives and businesses, and power economic growth around the world.As a member of the BMO Harris Bank team you are valued, respected and heard, and you have more ways to grow and make an impact. We strive to help you make an impact from day one - for yourself and our customers. We'll support you with the tools and resources you need to reach new milestones, as you help our customers reach theirs. From in-depth training and coaching, to manager support and network-building opportunities, we'll help you gain valuable experience, and broaden your skillset.To find out more visit us at https://bmoharriscareers.com. BMO Harris Bank is committed to an inclusive, equitable and accessible workplace. By learning from each other's differences, we gain strength through our people and our perspectives. BMO Harris Bank N.A. is an equal opportunity/affirmative action employer. All qualified applicants will receive consideration for employment without regard to sex, gender identity, sexual orientation, race, color, religion, national origin, disability, protected Veteran status, age, or any other characteristic protected by law. Accommodations are available on request for candidates taking part in all aspects of the selection process. To request accommodation, please contact your recruiter. BMO Financial GroupServing customers for 200 years and counting, BMO is a highly diversified financial services provider - the 8th largest bank, by assets, in North America. With total assets of $728 billion as of October 31, 2018, and a team of diverse and highly engaged employees, BMO provides a broad range of personal and commercial banking, wealth management and investment banking products and services to more than 12 million customers and conducts business through three operating groups: Personal and Commercial Banking, BMO Wealth Management and BMO Capital Markets.We serve Canadian clients through BMO Bank of Montreal®, our personal and commercial banking business, BMO Nesbitt Burns®*, one of Canada's leading wealth management firms, and BMO Capital Markets, our North American investment and corporate banking division.In the United States, clients are served through BMO Harris Bank, a major U.S. Midwest personal and commercial bank, and BMO Private Bank, with wealth management offices across the United States, as well as BMO Capital Markets, our North American investment and corporate banking division.We help our customers make money make sense by delivering the broadest range of financial services through a single point of contact. Our financial service professionals provide access to any services our customers require across the entire enterprise.","BMO Financial Group
3.7","Chicago, IL",Banks & Credit Unions,Finance
Data Scientist,"Domain Experience:

3+ years-experience in machine learning and predictive analytics

Strong knowledge of statistics and predictive methods such as SEM, multiple and logistic regression, Bayesian modeling, support vector machines, neural net training, tree induction techniques like CHAID, CART, random forest, random tree, etc.

Able to translate complexÂdataÂinto actionable insights and recommendations.

Strong understanding of the Financial Services is required.

Experience with financial models, risk models, marketing cross-sell, up-sell, retention, and customer lifetime value models preferred.

15 years plus Real world experience in monetizing models and making money (Retail or Distribution industry)

Expert in R, Vanatge etc (Sri you know our environment, some one who can coach our team)

Â

Soft Skills:

Multi-tasking and priority setting â ability to effectively manage multiple projects of varying complexity.

Ability to work independently and as part of a team.

Excellent communication skills, both written and verbal.

Technical Skills/Experience:

Experience with statistical modeling

Practical experience in preparingÂdataÂfor machine learning

Practical experience in using and designing regression, SVM, clustering, and other classification models.

Nice to have experience in optimization

Nice to have experience in Spark, Tensorflow, parallel computation

Experience with largeÂdataÂstores, both SQL and noSQL (e.g. Hadoop)

Python, R, Matlab

Node.js, Scala for services, Postgres for theÂdatabase

Kubernetes, for deployment and Devops

AWS for infrastructure, leveraging EC2, S3, SWF, CloudFront, Route53, and much more

Proven capabilities in presenting technical findings to non-technical audiences

Â

Â","Unicom Technologies INC
4.7","Chicago, IL",IT Services,Information Technology
Data Scientist,"Who We Are!

At Maven Wave, an Atos Company, we are relentless in hiring the industrys top talent. Each employee is hand-picked not only for their skills, but for their personality and broad expertise. We are looking for this rare combination of talent that sets us apart in the industry.

Maven Wave helps leading companies make the shift to digital and shorten the fuse to innovation. We combine the expertise of top-tier consulting with the agility of a cutting-edge technology firm. This multidisciplinary blend of skills allows us to create unique digital advantages for our clients. Maven Waves digital solutions are agile, mobile, rooted in analytics, and built in the cloud.


Maven Wave, Google, and YOU: Drive and deliver business results with data-based insights.

We are looking for a Data Scientist who will utilize their analytical, statistical, and programming skills to develop data-driven solutions to complex business challenges.


Your Life As a Maven:
Leverage company data to drive business solutions for enterprise clients using R and Python.
Perform data collection for Data Science operations including Machine Learning.
Develop custom data models and algorithms to apply to data sets.
Use predictive modeling to increase and optimize customer experiences, revenue generation, ad targeting, and other business outcomes.
Assess Model accuracy using common metrics (AUC, F1, etc.) and explain the results to client stakeholders.

Your Expertise:
3-5 years of experience manipulating data sets and building statistical models.
Cloud experience in a major platform, such as AWS, GCP, or Azure.
Experience using Data Science languages (R, Python) to manipulate data and draw insights.
Knowledge of a variety of Machine Learning and advanced analytical techniques and their real world advantages/drawbacks.
Familiarity with the following software/tools: Python, C, Java, Jupyter Notebooks, SQL, ML platforms (H2O, DataRobot), distributed data (Map/Reduce, Hadoop), and visualization (Tableau, qlikview)
Must have a Bachelors degree in Computer Science, Technology, Computer Information Systems, Computer Applications, Engineering, or a related field.
Your X-Factor:
Aptitude - You have an innate capacity to transition from project to project without skipping a beat.
Communication - You have excellent written and verbal communication skills for coordination across projects and teams.
Impact - You are a critical thinker with an emphasis on creativity and innovation.
Passion - You have the drive to succeed paired with a continuous hunger to learn.
Leadership - You are trusted, empathetic, accountable, and empower others around you.
Why Were Proud To Be Mavens!
Google Cloud North America Services Partner of the Year 2019, 2018, 2017
#21 Best Workplaces in Chicago, FORTUNE
Great Place To Work Certification, Great Place to Work
Fast Fifty, Crain's Chicago Business
101 Best and Brightest Companies to Work For, National Association for Business Resources (NABR)
Top Google Cloud Partner, Clutch
Fastest Growing Consulting Firms in North America (#11, #37), Consulting Magazine
Top IT Services Companies, Clutch
Google Global Rising Star Partner of the Year
Ready to Learn More?
Digital Transformation at Maven Wave
Check out the Data Team
See what Glassdoor has to say
Real Customer Stories","Maven Wave Partners
4.5","Chicago, IL",Consulting,Business Services
Data Scientist,"Careers | UL | Data Scientist in Northbrook, Illinois | Careers at United States - Northbrook
Please Enable Cookies to Continue

Please enable cookies in your browser to experience all the personalized features of this site, including the ability to apply for a job.

Welcome page

Returning Candidate?

Log back in!


Data Scientist

Location

US-IL-Northbrook

Job ID

2020-17946

# of Openings

1

Job Category

Information Technology



What you’ll learn & achieve:



Use advanced mathematical and statistical concepts and theories to collect and analyze data and construct solutions to complex business problems. Identify what data is available and relevant, including internal and external data sources, leveraging new data collection processes such as sensors, open data, and social media feeds. Perform advanced statistical analysis on experimental or business data to identify, validate and quantify trends or patterns. Design experiments, test hypotheses, and build models to explore complex business and safety science systems. Construct advanced predictive models, algorithms and probability engines to support data analysis or product functions. Write methodology, analysis and data insights for research papers, proposals and presentations. Synthesize all aspects of a data science project to lead non-technical audiences through the goals, methods and implications of the project. Leverage knowledge in machine learning, natural language processing, mathematical and statistical analyses, and technologies such as R, MongoDB, Elastic Search and open source analysis tools. Work with business leaders and researchers to suggest other projects and initiatives that will advance the organizations goals. *This position qualifies for Underwriters Laboratories Inc.’s employee referral policy program.



What makes you a great fit:



Master’s degree in data science, predictive analytics, mathematics or statistics and 3 years of experience in data analytics or data science.

Must have work experience with each of the following: 1.) predictive modeling using machine learning including neural networks Bayesian, k-means and related algorithms; 2.) implement natural language processing algorithms to detect patterns in large volumes of unstructured data using BERT, Spark, scikit learn, NLTK and SpaCy; 3.) conduct mathematical and statistical analyses to uncover relationships between variables using R, multivariate, logistic and other regression methods; and 4.) aggregate, prepare and pre-process large volumes of unrelated data for use in Data Lakes that implement MongoDB, Elastic Search and open source analysis tools.



What you’ll experience working at UL:



.

Options

Apply for this job onlineApply
Share
Email this job to a friendRefer

Sorry the Share function is not working properly at this moment. Please refresh the page and try again later.

Share on your newsfeed


Connect With Us!

Not ready to apply? Connect with us for general consideration.

EEO is the Law
E-Verify Poster (English)
Right to Work Poster (English)

UL is committed to hiring and retaining a qualified diverse workforce. We are proud to be an Equal Opportunity/Affirmative Action Employer, making decisions without regard to race, color, religion, creed, sex, sexual orientation, gender identity, marital status, national origin, age, veteran status, disability, or any other protected class U.S. Citizenship is required for most positions.

If you experience technical difficulties during the application process, please click here

Software Powered by iCIMS
www.icims.com","Underwriters Laboratories
3.3","Northbrook, IL",Consulting,Business Services
Data Analyst,"Undertone stands alone among AdTech and ad network businesses in its ability to address marketing objectives through Synchronized Digital Branding and extraordinarily creative treatments. We drive best in class results for clients through Undertones expansive rich media and video capabilities that are expressed across multiple channels and platforms, matching the consumer journey.

Undertones Data Management Service (UDMS) is a big data, cloud-based data-warehouse, dashboard and reporting environment. Do you want to help enable a data-driven organization? This is your opportunity to join a mission critical team, at an innovative company in an industry just beginning to harness the power of data.

As member of the Undertones UDMS Team, the Data Analyst drives value by providing provocative, differentiating analytics and insights. This position will support a wide variety of business intelligence efforts across Undertone while working in a highly collaborative manner within multiple large, cloud-based data sources to identify insights and spearhead our next generation product offerings. Most importantly, you should love the data, working with data, finding the nuance that leads to key differentiation for the business and our customers. This is a high visibility analytics and consulting position requiring daily interaction with business users, data scientists, engineers and key stakeholders.

Job Responsibilities:
Work with business teams to understand their analytical needs, including identifying critical metrics and KPIs
Use analytical and problem-solving skills to deliver actionable insights to relevant decision makers
Develop rich interactive visualizations integrating various reporting components from multiple data sources
Use SQL, Tableau and other technologies to pull data from different backend systems and product meaningful information and visualizations
Take complicated problems and build simple frameworks
Work directly with users and management to gather requirements, provide status updates, and build good relationships and rapport
Profile and Experience:
A minimum of 2 year of a full-time data analytics experience, ideally in an Ad-tech company
A minimum of a Bachelors degree in Engineering, Mathematics, Business, or related field
Expert SQL coding skills against large data sets
Strong analytical skills, including the ability to mine data in order to draw meaningful conclusions
Strong oral and written communications skills
Knowledge of Business Intelligence tools such as Tableau
Powered by JazzHR","Undertone
3.8","Chicago, IL",Advertising & Marketing,Business Services
Data Scientist,"The Data Scientist (Senior Manager level) will be part of the Enterprise BI team at 1-800-Flowers.com, Inc. This individual will manage one or more analysts and focus on customer-level advanced analytics for the direct-to-consumer and business-to-business channels.

Responsibilities include, but are not limited to:
As a hands-on analytics leader, deliver actionable insights while prioritizing and managing the workload of junior analysts
Collaborate with business owners and propose appropriate analytics solutions to address critical business questions
Create Tableau dashboards to empower business owners
Develop advanced analytics solutions to address some open business questions, e.g.,
Multi-Brand Customer Segmentation
Next Best Offer/ Next Best Brand
Channel Attribution
Customer Retention
Key Competencies:
Strong analytical mind, problem-solving skills and foundation in Statistics
Ability to collaborate well with individuals on-site and in remote offices
Intermediate to advanced level of expertise using SAS, SQL, Tableau, Python
Outstanding analytical skill set: a clear expert in the Analytics/ Data Science field
Experience working with large volumes of data, combining and reconciling data from different sources
Experience in MS Office applications with very strong Excel skills
Requirements:
Minimum B.S. in Mathematics, Statistics, Data Analytics or related quant field
5+ years in a similar analytical role generating insights through data analytics
Strong communication skills: both written and verbal
Ability to work independently on multiple concurrent assignments
Self-driven for continual learning and ongoing training/development
Highly organized, detail-oriented
Equal Opportunity Employer Minorities/Women/Protected Veterans/Disabled","1-800-Flowers.com
2.8","Melrose Park, IL",Wholesale,Business Services
Data Scientist,"What’s significantly better than working on a typical data science team? How about working on a data science team in which you’re directly making an impact in the revolutionary field of artificial intelligence even as an entry level team member? (well, statistically significant that is). Pardon the pun, but at Spectrum we’re certain that our team is pumped up to work not only with like-minded data-savvy and fun loving professionals, but also to work with cutting edge new tools like our predictive, artificially intelligent proprietary software. So, if your confident that you want to make a direct impact in your next job today, then please keep on reading.

Responsibilities

Beyond working with state of the art technology you will have many different fantastic projects to work on as a Data Scientist at Spectrum. Here are just a few different responsibilities you can expect off the bat:
Work with IT teams, management and/or data scientists to determine organizational goals
Mine data from primary and secondary sources
Clean and prune data to discard irrelevant information
Analyze and interpret results using standard statistical tools and techniques
Pinpoint trends, correlations and patterns in complicated data sets
Identify new opportunities for process improvement
Provide concise data reports and clear data visualizations for management
Some Characteristics That Define You

We understand that as a Data Scientist for Spectrum, you have many different professional goals and personal interests. As such here are just a few different things that typically define our team members on the Data Science team:
Analytical. In order to solve problems and build innovative new digital marketing campaigns, it is essential that you know how to take an idea and analyze it from all of its angles.
Patient. As a data scientist, you know that you work with extremely large data sets on a daily basis. As such we are looking for someone who is not only meticulous, but patient enough to sit and sift through that data in a thorough way.
Creative. Beyond just analyzing data sets, you are an explorer and a puzzle solver. Pulling insights out of your data and understanding how those insights can better shape our tools is something that you live to do.
Student. More so than most industries, the field of data science is always changing and evolving. As such, you are always looking to learn new things and gain new skills.
Business-Savvy. Beyond the wicked data science skills you bring to the table, we also want you to consider the business implications of our data tools. From the ways our team will use them to how our customers will use them, we always want you to keep the user and the business application in mind.
Required Skills and Experience

On top of the many intangible skills you bring to the table, there are many skills that can help improve the efficiency and success of your work at Spectrum. Here are a few of those required skills and experience that you will come in with as a Data Scientist on our team:
A bachelor’s degree/pursuing a bachelor's degree in computer science, mathematics, statistics, information systems, or a related field
Experience with statistical modeling
Fundamental knowledge of R and/or SAS languages
Experience with SQL databases and database querying languages
Experience with data mining and data cleaning
Experience with data visualization and reporting techniques
Written and verbal expression
Benefits

As a Data Scientist at Spectrum there are a ton of fantastic perks and benefits that come along with your work. Here are just a few of the benefits you can expect when joining the Spectrum family:
Comprehensive medical & dental insurance
Retirement planning & company matching
Generous PTO, including sick days & holidays
A state-of-the-art office environment
Nintendo Switch in-office gaming such as FIFA, Arms, Mario Kart, and Rocket League
Year-round gym memberships
Paid continuing education
Casual dress code
Flexible scheduling
Free-Lunch-Friday
Company sponsored parties and group activities outside of the office","Spectrum Communications and Consulting
3.4","Chicago, IL",Advertising & Marketing,Business Services
Data Scientist,"Data Scientist
6 Month Contract to hire
Elmhurst, IL
Not able to provide sponsorship for now or in the future
One of Medix's top ranked clients is one of the leading healthcare systems within the Chicagoland area. Our client is looking to add a Data Scientist to their team due to growth. This individual will be responsible for collecting, cleansing, and creating models and reports of company's data. This individual will work out of their western suburbs location.

This opportunity includes a competitive compensation package including medical, dental, visual benefits, remote capability, 401k and PTO options. This also includes free parking and a business casual environment.

Responsibilities include:

Perform highly strategic and complex analysis and develop tools to support company's goals
Collect, cleanse, and distribute data to optimize company future growth
Provide new insights into businesses through statistical analysis, data mining, data visualization, and to create solutions
Work heavily within SQL
Work with SAS, ETL, data processing, programming and data analytics
Work with BI tools including PowerBI or Tableau
Utilize Python programming language
Research and develop statistical learning models for data analysis
Collaborate with product management and engineering departments to understand company needs and devise possible solutions
Communicate results and ideas to key decision makers
Implement new statistical or other mathematical methodologies as needed for specific models or analysis
Requirements:

Minimum of 7 years of experience working as a Data Scientist extracting data, processing, and performing data analytics
Strong data capturing experience with SQL
Previous exposure in PowerBI or Tableau
Previous SAS, Python, R, or Java programming language experience
Healthcare exposure (Bonus)
Ability to present findings, models, tables, presentations to stakeholders, executives, upper management","Medix
3.5","Elmhurst, IL",Staffing & Outsourcing,Business Services
Data Analyst,"Address:111 W Monroe - 115 S LaSalleJob Family Group:Data Analytics & ReportingData AnalystThe Data Analyst will partner with management and business partners to support the development, and implementation of advanced data and analytical solutions that drive measurable business outcomes and create a distinctive customer experience. In this role, you will collaborate with senior management to dissect business problems, conduct research and analysis, structure data and build end-to-end analytical solutions working with multiple groups.This role will also assist to design, develop, and maintain analytical dashboards and adhoc solutions to support business driven decisions. This includes preparation and investigation of data working closely with the Data Governance and Technology teams and supporting multiple lines of business across the enterprise to help them achieve their objectives. This role also needs to take ownership of data, act as SME and developing automated data quality checks to make sure quality data is provided for business consumption.Key Responsibilities* Collect business partner requirements, data gathering, integration and enrichment* Import/Clean/Transform/Validate/Model data with the purpose of understanding and drawing conclusions from data* Build/design data input and data collection mechanisms* Perform data related activities, including data extraction/profiling/ cleansing/deduplication/ standardization/conversion/ transformation/data mining/reporting;* Conduct research/data analysis/ implementation for projects* Lead projects to work with technology teams to implement the solutionsBasic Qualifications:* University degree in Computer Science, Computer Applications, Information Technology, Information Systems, Engineering (any) or at least 2 years of experience in the job offered, as Software Engineer, Programmer, Data Modeler, Data Architect, Reporting Analyst, Application Developer, Systems Analyst, or related IT position* Experience conducting data analysis, configuration, and report solutions* Experience designing, implementing, and supporting data management solutions including building curated datasets for analytics and reporting* Experience working with technologies including Hadoop, Tableau, Spotfire, ETL, Talend, Datameer, Netezza or AWS* Experience in Software development and Data Management* Strong skills in programming using SQL, Datameer, ETL tools, Python and/or R preferred* Knowledge of Data quality and Metadata tools and processes with exposure to Data GovernanceSkills* Demonstrates solid communication skills (both written and verbal)* Shows strong knowledge technical skills, with proven record of building solutions to complex problems* Exhibits advanced critical thinking skills, integrative skills and creativity to drive innovation* Demonstrates ability to build a good fact base, apply sound reasoning, and generate relevant recommendations that get implemented and lead to business success* Able to work highly independently and manage multiple priorities in an agile fast paced environment* Demonstrates strong attention to detail and a high level of due diligenceConsults on analytical solutions to understand, analyze, and synthesize requirements, goals and objectives relative to data and business intelligence needs and to enable high-quality, fact-based business decisions to drive better business outcomes. Provides advice on the configuration, functionality, applicability, and usability of data management, data analytics, and data visualization technology solutions. Supports the development of the strategy and roadmap for data quality and data analytics, data modeling, reporting, business intelligence, and the design and development of sophisticated decision support tools.Qualifications:* Builds effective relationships with internal/external stakeholders.* Leads/participates in the design, implementation and management of new analytics & reporting solutions.* Designs, develops, and implements innovative analytical solutions.* Designs and produces regular and ad-hoc reports, and dashboards.* Breaks down strategic problems, and analyses data and information to provide subject matter insights and recommendations.* Structures and assembles data into multi-dimensions with various granularities (e.g., demographics, customers, products, transactions).* Monitors and tracks tool performance, user acceptance testing, and addresses any issues.* Integrates information from multiple sources to enable more efficient processes, enhanced analysis and/or streamlined reporting.* Designs, develops, and implements innovative analytical solutions.* Designs and produces regular and ad-hoc reports, and dashboards.* Builds reports and visualizations to effectively communicate data driven insights to users for a variety of audiences e.g. visualization solutions of data into reports, graphics, dashboards to illustrate facts, trends, and insights.* Develops solutions and makes recommendations based on an understanding of the business strategy and stakeholder needs.* Supports development and execution of strategic analytics & reporting initiatives in collaboration with internal and external stakeholders.* Analyzes data and information to provide subject-matter insights and recommendations.* Develops tools and delivers training programs for use of reporting tools and self-serve analytics by non-analytical end users; may include delivery of training to audiences.* Documents and maintain operational procedures and processes relating to analytical and reporting processes.* Builds effective relationships with internal/external stakeholders.* Collaborates with internal and external stakeholders in order to deliver on business objectives.* Focus is primarily on business/group within BMO; may have broader, enterprise-wide focus.* Exercises judgment to identify, diagnose, and solve problems within given rules.* Works independently on a range of complex tasks, which may include unique situations.* Broader work or accountabilities may be assigned as needed.* Typically between 4 - 6 years of relevant experience and post-secondary degree in related field of study or an equivalent combination of education and experience.* Knowledge and experience in data preparation, data analysis, and statistical tool sets including but not limited to Spotfire, Tableau, SQL, SAS, R, Python, ETL tools, JIRA- Very good.* Technical proficiency gained through education and/or business experience.* Verbal & written communication skills - In-depth.* Collaboration & team skills - In-depth.* Analytical and problem solving skills - In-depth.* Influence skills - In-depth.* Data driven decision making - In-depth.We're here to helpAt BMO Harris Bank we are driven by a shared Purpose: Boldly Grow the Good in business and life. It calls on us to create lasting, positive change for our customers, our communities and our people. By working together, innovating and pushing boundaries, we transform lives and businesses, and power economic growth around the world.As a member of the BMO Harris Bank team you are valued, respected and heard, and you have more ways to grow and make an impact. We strive to help you make an impact from day one - for yourself and our customers. We'll support you with the tools and resources you need to reach new milestones, as you help our customers reach theirs. From in-depth training and coaching, to manager support and network-building opportunities, we'll help you gain valuable experience, and broaden your skillset.To find out more visit us at https://bmoharriscareers.com.BMO Harris Bank is committed to an inclusive, equitable and accessible workplace. By learning from each other's differences, we gain strength through our people and our perspectives. BMO Harris Bank N.A. is an equal opportunity/affirmative action employer. All qualified applicants will receive consideration for employment without regard to sex, gender identity, sexual orientation, race, color, religion, national origin, disability, protected Veteran status, age, or any other characteristic protected by law. Accommodations are available on request for candidates taking part in all aspects of the selection process. To request accommodation, please contact your recruiter.","BMO
3.2","Chicago, IL",Banks & Credit Unions,Finance
Data Analyst,"Client is seeking to add a Data Analyst to staff the Enterprise Data Services team reporting to the Life and Health Enterprise Services Delivery Leader. This position is responsible for the development and maintenance of data warehouse and analytical environments to support financial, management and statutory reporting requirements along with enhancing and facilitating corporate decision-making capabilities. Position Responsibilities middot Independently work with business customers and members of the EDS team to create solutions that support reporting, analytic and warehouse needs using the appropriate platforms and tools. middot Analyze business requirements and work with client areas to produce functional specifications for use as reference in creation of reporting and analytical solutions. middot Perform the first level of testing for a new andor enhanced functionality and provide support for user acceptance testing. middot Analyze source data to understand relationships and determine business rules. middot Assist in designing the data warehouse and assure that data is stored and maintained in consistent formats. middot Create source to target mapping documents to transform the source data into the target warehouse and test final transformations. middot Develop andor maintain relationships with business customers to identify and acquire additional data sources to incorporate into the warehouse. middot Train and assist users with retrieving data from the warehouse. middot Provide guidance in the creation of reporting and analytical solutions. Position Qualifications middot Requires a bachelorrsquos degree or equivalent certifications in technical system design. middot 4+ years of experience developing data warehouse solutions preferably within the insurance industry. middot Sound understanding of data warehouse best practices, relational data structures and dimensional data modeling. middot Strong knowledge of current relational database and big data software and query concepts middot Advanced SQL skills middot Experience supporting large scale Enterprise Data Warehouses middot Ability to analyze and solve complex problems and to work independently on multiple tasks middot Must be able to communicate effectively verbally and in writing with technical and non-technical associates About the Company Peterson Technology Partners (PTP) httpptechpartners.com has been Chicago's premier Information Technology (IT) staffing, consulting, and recruiting firm for over 22+ years. Named after Chicago's historic Peterson Avenue, PTP has built its reputation by developing lasting relationships, leading digital transformation, and inspiring technical innovation throughout Chicagoland. Based in Park Ridge, IL, PTP's 250+ employees have a narrow focus on a single market (Chicago) and expertise in 4 innovative technical areas Artificial IntelligenceMachine LearningData Science RoboticsRobotic Process Automation (RPA) CyberDataInformation Security DevOpsDevSecOps PTP httpswww.ptechpartners.comblog exists to ensure that all of our partners (clients and candidates alike) make the best hiring and career decisions. Connect LinkedIn httpslinkedin.comcompanypeterson-technology-partners Facebook httpswww.facebook.comPetersonTechnologyPartners Twitter httpstwitter.comPTPChicago YouTube httpswww.youtube.comchannelUC2RbatuBB1G86fmD1wp8KPA All Social Links httpsallmylinks.comptpchicago Review Google httpsgoo.glmapsWAM3m8YPxtn Glassdoor httpswww.glassdoor.comOverviewWorking-at-Peterson-Technology-Partners-EIIE714978.11,39.htm Yelp httpswww.yelp.combizpeterson-technology-partners-park-ridge All Review Links httpsallmylinks.comptpchicago Listen iTunes httpspodcasts.apple.comuspodcastrecruiters-get-real-it-career-questions-tech-job-tipsid1486245664 Spotify httpsopen.spotify.comshow1YneryOs3bQEjsH8JGh374 Stitcher httpswww.stitcher.compodcastmatty-bv3recruiters-get-real-it-career-questions-tech-job-tips-and All Podcast Links httpsallmylinks.comrecruitersgetrealpodcast Apply Stack Overflow httpsstackoverflow.comjobscompaniespeterson-technology-partners Dice ..company10123255 LinkedIn httpswww.linkedin.comcompanypeterson-technology-partnersjobs?viewAsMembertrue Glassdoor httpswww.glassdoor.comJobsPeterson-Technology-Partners-Jobs-E714978.htm All Job Openings httpbit.lyPTPChicagoJobs","Peterson Technology Partners
4.1","Chicago, IL",Computer Hardware & Software,Information Technology
Data Analyst,"Please make sure to read the job posting in its entirety as it reflects both the University roles and responsibilities, followed by the specific description.

Department

20123 Obstetrics & Gynecology

About the Unit

The Lindau Laboratory at the University of Chicago is an interdisciplinary, fast-paced laboratory performing human-level observational, interventional, health services, geospatial and agent-based modeling research motivated by a fundamental concern for the principle of justice in health and health care. Over the last three years, the lab has grown rapidly in the number, complexity and size of our data assets; the number and span of our internal and external collaborations; and in our primary data sharing activities, including dissemination of and technical support for more than 100 custom datasets created for consumers of our urban built asset data. The Lab, funded predominantly by agencies of the U.S. Department of Health and Human Services along with private philanthropy currently employs about 15 full and part-time researchers across disciplines including epidemiology, gerontology, anthropology, public health, and health care communications. The lab routinely collaborates across disciplines, University of Chicago units, and with investigators at other institutions including experts in the fields of computer science, design, architecture, psychology, public health and other medical and social science fields. In addition to her scholarly work, Dr. Lindau is a practicing gynecologist with specialized expertise in prevalence, prevention and treatment of sexual disorders in women. The work of the lab focuses in two main areas: 1) urban health and population health improvement, with a particular concern for people living in high-poverty communities and; 2) preservation and treatment of female sexuality in the context of aging, cancer and other common diseases. The two main areas of work include the South Side Health and Vitality Studies (SSHVS) and the Program in Integrative Sexual Medicine (PRISM). SSHVS is a well-established collaborative effort between university researchers and community members that aims to understand how community assets and information and communication technologies can be used to improve health and vitality.

Job Family

Research

Responsible for all aspects of research projects and research facilities. Plans and conducts clinical and non-clinical research; facilitates and monitors daily activities of clinical trials or research projects. Directs engineering and technical support activities to develop and maintain tools and computational methods needed to gather and analyze data.

Career Track and Job Level

Bioinformatics

Responsible for developing methods and software tools to analyze and interpret biological data.

P2: Requires knowledge and experience in own discipline; still acquiring higher-level knowledge and skills. Builds knowledge of the organization, processes and customers. Solves a range of straightforward problems. Analyzes possible solutions using standard procedures. Receives a moderate level of guidance and direction.

Role Impact

Individual Contributor

Responsibilities

The job administers programs and support all phases of bioinformatics activities by helping devise or modify procedures to solve complex problems.

1) Participates in creating data algorithms and specialized computer software to identify and classify components of a biological system (i.e. DNA and protein sequences)., 2) Applies basic application of computational tools and information technology to gather, analyze and visualize data in biology and biomedical research, 3) Interprets data analysis of high throughput genomics, proteomics and genetic data., 4) Plans own resources to implement or modify existing web-based bioinformatics tools, 5) Performs other related work as needed.

Unit-specific Responsibilities

1) Data analysis and data management: Perform, with support of a team of PhD and masters-level analysts, advanced analytic tasks to accomplish the scientific aims of the lab's research.

2) Conduct statistical analyses; demonstrated proficiency in descriptive, multivariable, and/or other advanced analyses using large datasets (experience with longitudinal data an asset); duplicate analyses as part of the lab's quality assurance protocol.

3) Independently create, prepare, and manage databases and prepare datasets for analysis.

4) Draft presentations and manuscripts for the purposes of presentation at scientific meetings and publication in peer-reviewed literature.

5) Research support: Support ongoing research projects in the lab.

6) Assist with ongoing data monitoring tasks, including data preparation and reporting, through creation of reports.

7) Contribute to survey development tasks, including questionnaire design and logic, and protocol development.

8) Perform literature reviews.

Unit-preferred competencies

1) Organization Skills.

2) Problem-solving.

3)Collaboration Skills.

4) Attention to detail.

5) Ability to work autonomously.

Education, Experience, and Certifications

Minimum requirements include a college or university degree in related field.

Minimum requirements include knowledge and skills developed through 2-5 years of work experience in a related job discipline.

Preferred Qualifications

Education

1) Advanced degree in related field (Research, Data Analysis, Public Health)

Experience

1) 2+ years of relevant research experience

2) Critical thinking/problem solving experience

3) Strong analytic and data management experience

4) Proficiency in STATA or R required; GIS experience a plus

5) Expertise in epidemiology, social science, populations studies, and/or community health

6) Experience in NIH grant-writing, manuscript writing, oral presentation at scientific meetings and implementing human subjects protocols

7) Proven expert level proficiency in Microsoft Word, Excel, PowerPoint, and scientific search engines

8) Experience working in a fast-paced, multidisciplinary environment

9) Excellent organization and verbal and written communication experience, as well as past ability to work effectively with people from many backgrounds

10) Experience in working with sensitive subject matter and maintaining strict confidentiality regarding research subjects and patients

Required Documents

1) Cover Letter

2) Resume

NOTE: When applying, all required documents MUST be uploaded under the Resume/CV section of the application

FLSA Status

Exempt

Pay Frequency

Monthly

Pay Grade

Depends on Qualifications

Scheduled Weekly Hours

40

Benefits Eligible

Yes

Drug Test Required

No

Health Screen Required

No

Motor Vehicle Record Inquiry Required

No

Posting Date

2020-05-04-07:00

Remove from Posting On or Before

2020-11-04-08:00

Posting Statement

The University of Chicago is an Affirmative Action/Equal Opportunity/Disabled/Veterans Employer and does not discriminate on the basis of race, color, religion, sex, sexual orientation, gender identity, national or ethnic origin, age, status as an individual with a disability, protected veteran status, genetic information, or other protected classes under the law. For additional information please see the University's Notice of Nondiscrimination.

Staff Job seekers in need of a reasonable accommodation to complete the application process should call 773-702-5800 or submit a request via Applicant Inquiry Form.

The University of Chicago's Annual Security & Fire Safety Report (Report) provides information about University offices and programs that provide safety support, crime and fire statistics, emergency response and communications plans, and other policies and information. The Report can be accessed online at: http://securityreport.uchicago.edu. Paper copies of the Report are available, upon request, from the University of Chicago Police Department, 850 E. 61st Street, Chicago, IL 60637.","University of Chicago
4.0","Chicago, IL",Colleges & Universities,Education
Data Scientist,"Data Scientist Azure Deep Learning Azure Machine Learning GC or Contract-to-hire 70-80 an hour on a W2 W2 Only Important Role This candidate must be sharp and communication skills must be exceptional Deep Learning and machine learning Microsoft Azure (Cloud) ndash must be strong with 2+ years of experience Azure Machine Learning Data Science and Big Data - Statistics, Market Research, Market Analysis, Analytics, Data Visualization, Statistical Modeling SQL, workflow management tools Microsoft Azure Python (programming) Claim Management experience (insurance) Advanced analytics ndash technologies T-SQL, SQL Server, SSIS, Data Factory , Power BI, Hybernate, C","Encore Consulting Services
1.0","Rolling Meadows, IL",-1,-1
Data Scientist,"Overview

Good people, working with good people, for our common good.

Sound good?

KeHE-a natural, organic, specialty and fresh food distributor-is all about ""good"" and is growing, so there's never been a more exciting time to join our team. If you're enthusiastic about working in an environment with a people-first culture and an organization committed to good living, good food and good service, we'd love to talk to you!

Primary Responsibilities

The Data Scientist will be at the forefront of KeHE's movement towards being a technological leader in the food distribution industry. This role will help shape the future by utilizing their knowledge and expertise of machine learning and big data to challenge the status quo and provide creative solutions to business problems. We are looking for an experienced data professional to employ data science approaches to a variety of business problem throughout the data life cycle including data acquisition, ETL, analysis and final product development.

Essential Functions
Research, build and maintain machine learning applications including structured and unstructured data, regression, classification, dimensionality reduction, and clustering
Collect, structure and analyze internal and external data sources with scalability in mind
Control data science projects from end to end with the ability to communicate results to upper management and key stakeholders
Identify and implement improvements in existing tools or processes using advanced technological approaches
Serve as the resident data expert and share best practices/approaches for machine learning techniques, big data, data modeling, and cloud computing
Minimum Requirements, Qualifications, Additional Skills, Aptitude
Bachelor's Degree in a quantitative field (Applied Mathematics, Statistics, Economics, Computer Science) or related fields
5+ years of experience in data analytics, business analytics or business intelligence
1+ years of experience designing and implementing machine learning solutions that drive business value
Excellent understanding of machine learning models such as regression, classification (logistic regression, naïve Bayes and tree-based models) and clustering (k-means and hierarchical)
Experience in feature engineering, dimensionality reduction and data manipulation to feed machine learning models
Ability to employ machine learning and predictive models to derive actionable business insights and value using data
Proven history of owning analytics projects from initial problem discovery through final solution
Proficient programing experience using Python, R or SAS with a focus on data wrangling and machine learning
Experienced in writing complex queries to extract and write data using SQL
Effectively communicate and present results of analysis using visualization tools such as Tableau, Power BI or Qlikview
Experience integrating external data via APIs or web scraping
Preferred Experience and Abilities:
Master's Degree in a quantitative field (Data Science, Applied Mathematics, Statistics, Econometrics)
Exposure to big data tools such as Spark, Scala or Hadoop
Understanding of cloud computing environments and tools (AWS/MS Azure)
Basic understanding of artificial intelligence models (neural networks, deep learning, Bayesian networks)
Understanding of Natural Language Processing (NLP) techniques
Understanding of Time Series analysis techniques
Requisition ID

2020-7576","Kehe
2.6","Naperville, IL",Wholesale,Business Services
Data Engineer,"Why VillageMD?

VillageMD is changing the trajectory of healthcare by empowering primary care physicians to make informed decisions and engage patients in meaningful ways. We work with thousands of clinicians and healthcare disruptors across the country to build and contribute to our platform to improve patient health while driving down the cost to deliver it.

We are a mission-oriented organization and are thrilled about the work that we do every day. We're transparent, collaborative, and relentless in pursuit of our mission, all while doing so with humility and a low ego. We believe that diverse backgrounds and experiences create the best opportunity for innovation and the community that we are creating is greater than any individual.

We've built our technology using the best of cloud and open-source technologies to create an open, data-first platform that is enriched with analytical models and modernly connected to internal and external apps. These apps drive clinical decision support, patient engagement, and other facilitators of innovative, information-enriched health experiences.

Data Engineers at VillageMD build distributed components, pipelines, and tools that enable our organization to make analytical, data-driven decisions. We're in a unique position to impact everyone in primary care from independent, family-owned practices to world-class health systems. We aggregate, process, and deliver rich datasets to improve the effectiveness of primary care for our doctors and patients.

What are examples of work that Data Engineers have done at VillageMD?
Built and implemented a data profiling tool to reverse engineer data schemas from new data sources facilitating normalization of the data into our data model
Created a summary data platform supporting our presentation layer that allows clinicians and operators in our practices to pinpoint interventions on-demand to patients most in need
Analyzed and designed the best ways to expand our data model to incorporate more data that's mission critical
What will make you successful here?
Strong analytical and technical skills
A real passion for problem solving and learning new technology
Vision to balance speed and maintainability in solution design
The ability to handle multiple, concurrent projects
Crafting and implementing requirements, keeping projects on track, and engaging partners
Challenging the status quo to improve our processes and tools
Communicating complex technical details in meaningful business context
A low ego and humility; an ability to gain trust by doing what you say you will do
What you might do in your first year:
Own ten projects to design and implement best-in-class data processing enabling clean data flow directly to our data model and on to our presentation layer
Work with analytics, engineering and operations to design and implement a new analytics product that supports improving patient health
Design a new concept within our data model to meet a new operational or analytical need
The following experience is relevant to us:
5+ years of full-time experience including extensive experience with healthcare data
Ability to understand and design relational data structures required
Very strong capabilities manipulating data using SQL
Knowledge of, and/or willingness to learn, non-relational data structures and other technologies (e.g. Postgres, Redshift, Cassandra, MongoDB, Neo4j, S3, etc.)
Experience or willingness to learn building information pipelines utilizing Python or Java a plus
BS/MS in computer science, math, engineering, or other related fields is required.
Track record of successfully executing projects with multiple partners
What can we offer you?
Competitive salary, bonus, and health benefits
Paid gym membership
Fun, fast-paced, startup environment (with snacks)
Pre-tax savings on commute expenses
Remote flexibility
A highly-collaborative, conscientious, forward-thinking environment that welcomes the impact you can make from Day 1.
A clear link between our daily work on products and services and the improved quality of healthcare that this work facilitates for patients.
At VillageMD, we see diversity and inclusion as a source of strength in transforming healthcare. We believe building trust and innovation are best achieved through diverse perspectives. To us, acceptance and respect are rooted in an understanding that people do not experience things in the same way, including our healthcare system. Individuals seeking employment at VillageMD are considered without regard to race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status.","VillageMD
4.1","Chicago, IL",Health Care Services & Hospitals,Health Care
Data Analyst,"Analyze sequencing data from RNA-seq, RNA methylation (m6A)-seq, m6A RNA RIP-seq, RNA-CLIP-seq, and metabolome studies, and develop new analyzing tools using R, Python and other coding programs when necessary. Review and revise existing analysis tools and protocols. Perform statistical analysis of large sets of sequencing and metabolome data, maintain a high standard managing complex data, and prepare figures for presentation, grant application and publication.

Analyze sequencing data from RNA-seq, RNA methylation (m6A)-seq, m6A RNA RIP-seq, RNA-CLIP-seq, and metabolome studies.
Use, review, revise and develop new computer programs for data analysis.
Purify experimental samples and build sequencing libraries.
Perform statistical analysis of large sets of sequencing and metabolome data.
Prepare figures for presentation, grant application and publication.
Present and discuss research work at lab group meetings.
Discuss ongoing work regularly with advisor.
Willingness to learn and improve/develop techniques.

Master’s degree in computer science and Bachelor’s degree in industrial engineering or applied mathematics, with background and experience in biomedical research.
Demonstrated computational, statistical and mathematical abilities for sequencing and other data analysis.
Previous laboratory experience preferred.
Strong analytical, computational and organizational skills with consistent attention to detail.
Strong verbal and written communication skills
The candidate will be skilled in designing and executing data analysis.
The candidate will be diligent with documentation, detail oriented and well organized.
The candidate will have the ability to work independently and under supervision, and function as a research team member
Proficient in Microsoft Word and PowerPoint, with advanced skills in Excel (or similar) for data curation, analysis and visualization.
Experience with database or statistical tools such as R, SASS or SPSS required","Ann & Robert H. Lurie Children's Hospital of Chicago
3.8","Chicago, IL",Health Care Services & Hospitals,Health Care
Data Analyst,"Address:111 W Monroe - 115 S LaSalleJob Family Group:Data Analytics & ReportingData AnalystThe Data Analyst will partner with management and business partners to support the development, and implementation of advanced data and analytical solutions that drive measurable business outcomes and create a distinctive customer experience. In this role, you will collaborate with senior management to dissect business problems, conduct research and analysis, structure data and build end-to-end analytical solutions working with multiple groups.This role will also assist to design, develop, and maintain analytical dashboards and adhoc solutions to support business driven decisions. This includes preparation and investigation of data working closely with the Data Governance and Technology teams and supporting multiple lines of business across the enterprise to help them achieve their objectives. This role also needs to take ownership of data, act as SME and developing automated data quality checks to make sure quality data is provided for business consumption.Key Responsibilities+ Collect business partner requirements, data gathering, integration and enrichment+ Import/Clean/Transform/Validate/Model data with the purpose of understanding and drawing conclusions from data+ Build/design data input and data collection mechanisms+ Perform data related activities, including data extraction/profiling/ cleansing/deduplication/ standardization/conversion/ transformation/data mining/reporting;+ Conduct research/data analysis/ implementation for projects+ Lead projects to work with technology teams to implement the solutionsBasic Qualifications:+ University degree in Computer Science, Computer Applications, Information Technology, Information Systems, Engineering (any) or at least 2 years of experience in the job offered, as Software Engineer, Programmer, Data Modeler, Data Architect, Reporting Analyst, Application Developer, Systems Analyst, or related IT position+ Experience conducting data analysis, configuration, and report solutions+ Experience designing, implementing, and supporting data management solutions including building curated datasets for analytics and reporting + Experience working with technologies including Hadoop, Tableau, Spotfire, ETL, Talend, Datameer, Netezza or AWS+ Experience in Software development and Data Management+ Strong skills in programming using SQL, Datameer, ETL tools, Python and/or R preferred+ Knowledge of Data quality and Metadata tools and processes with exposure to Data GovernanceSkills+ Demonstrates solid communication skills (both written and verbal)+ Shows strong knowledge technical skills, with proven record of building solutions to complex problems+ Exhibits advanced critical thinking skills, integrative skills and creativity to drive innovation+ Demonstrates ability to build a good fact base, apply sound reasoning, and generate relevant recommendations that get implemented and lead to business success+ Able to work highly independently and manage multiple priorities in an agile fast paced environment+ Demonstrates strong attention to detail and a high level of due diligenceConsults on analytical solutions to understand, analyze, and synthesize requirements, goals and objectives relative to data and business intelligence needs and to enable high-quality, fact-based business decisions to drive better business outcomes. Provides advice on the configuration, functionality, applicability, and usability of data management, data analytics, and data visualization technology solutions. Supports the development of the strategy and roadmap for data quality and data analytics, data modeling, reporting, business intelligence, and the design and development of sophisticated decision support tools.Qualifications:+ Builds effective relationships with internal/external stakeholders.+ Leads/participates in the design, implementation and management of new analytics & reporting solutions.+ Designs, develops, and implements innovative analytical solutions.+ Designs and produces regular and ad-hoc reports, and dashboards.+ Breaks down strategic problems, and analyses data and information to provide subject matter insights and recommendations.+ Structures and assembles data into multi-dimensions with various granularities (e.g., demographics, customers, products, transactions).+ Monitors and tracks tool performance, user acceptance testing, and addresses any issues.+ Integrates information from multiple sources to enable more efficient processes, enhanced analysis and/or streamlined reporting.+ Designs, develops, and implements innovative analytical solutions.+ Designs and produces regular and ad-hoc reports, and dashboards.+ Builds reports and visualizations to effectively communicate data driven insights to users for a variety of audiences e.g. visualization solutions of data into reports, graphics, dashboards to illustrate facts, trends, and insights.+ Develops solutions and makes recommendations based on an understanding of the business strategy and stakeholder needs.+ Supports development and execution of strategic analytics & reporting initiatives in collaboration with internal and external stakeholders.+ Analyzes data and information to provide subject-matter insights and recommendations.+ Develops tools and delivers training programs for use of reporting tools and self-serve analytics by non-analytical end users; may include delivery of training to audiences.+ Documents and maintain operational procedures and processes relating to analytical and reporting processes.+ Builds effective relationships with internal/external stakeholders.+ Collaborates with internal and external stakeholders in order to deliver on business objectives.+ Focus is primarily on business/group within BMO; may have broader, enterprise-wide focus.+ Exercises judgment to identify, diagnose, and solve problems within given rules.+ Works independently on a range of complex tasks, which may include unique situations.+ Broader work or accountabilities may be assigned as needed.+ Typically between 4 - 6 years of relevant experience and post-secondary degree in related field of study or an equivalent combination of education and experience.+ Knowledge and experience in data preparation, data analysis, and statistical tool sets including but not limited to Spotfire, Tableau, SQL, SAS, R, Python, ETL tools, JIRA- Very good.+ Technical proficiency gained through education and/or business experience.+ Verbal & written communication skills - In-depth.+ Collaboration & team skills - In-depth.+ Analytical and problem solving skills - In-depth.+ Influence skills - In-depth.+ Data driven decision making - In-depth.We're here to helpAt BMO Harris Bank we are driven by a shared Purpose: Boldly Grow the Good in business and life. It calls on us to create lasting, positive change for our customers, our communities and our people. By working together, innovating and pushing boundaries, we transform lives and businesses, and power economic growth around the world.As a member of the BMO Harris Bank team you are valued, respected and heard, and you have more ways to grow and make an impact. We strive to help you make an impact from day one - for yourself and our customers. We'll support you with the tools and resources you need to reach new milestones, as you help our customers reach theirs. From in-depth training and coaching, to manager support and network-building opportunities, we'll help you gain valuable experience, and broaden your skillset.To find out more visit us at https://bmoharriscareers.com.BMO Harris Bank is committed to an inclusive, equitable and accessible workplace. By learning from each other's differences, we gain strength through our people and our perspectives. BMO Harris Bank N.A. is an equal opportunity/affirmative action employer. All qualified applicants will receive consideration for employment without regard to sex, gender identity, sexual orientation, race, color, religion, national origin, disability, protected Veteran status, age, or any other characteristic protected by law. Accommodations are available on request for candidates taking part in all aspects of the selection process. To request accommodation, please contact your recruiter.BMO Financial GroupServing customers for 200 years and counting, BMO is a highly diversified financial services provider - the 8th largest bank, by assets, in North America. With total assets of $728 billion as of October 31, 2018, and a team of diverse and highly engaged employees, BMO provides a broad range of personal and commercial banking, wealth management and investment banking products and services to more than 12 million customers and conducts business through three operating groups: Personal and Commercial Banking, BMO Wealth Management and BMO Capital Markets.We serve Canadian clients through BMO Bank of Montreal®, our personal and commercial banking business, BMO Nesbitt Burns®*, one of Canada's leading wealth management firms, and BMO Capital Markets, our North American investment and corporate banking division.In the United States, clients are served through BMO Harris Bank, a major U.S. Midwest personal and commercial bank, and BMO Private Bank, with wealth management offices across the United States, as well as BMO Capital Markets, our North American investment and corporate banking division.We help our customers make money make sense by delivering the broadest range of financial services through a single point of contact. Our financial service professionals provide access to any services our customers require across the entire enterprise.","BMO Financial Group
3.7","Chicago, IL",Banks & Credit Unions,Finance
Data Analyst,"Collaborate with the Data Governance capabilities and roadmaps, standards and processes. Track the improvement and adoption.* Provide leadership and mentoring to both accounts and service lines by providing coaching, training, and awareness of data governance and data quality policies.
Adhere to processes by which proper data governance approval is obtained for information exchange between services lines, accounts and regions.
Provide input to existing and new data standards
Develop and document process documentation regarding account data quality auditing
Manage data related tasks to support accounts in data clean up and standardization activities.
Update/modify project plans, provide status reports, and track tasks to completion to meet timeline deliverables for internal projects
Ensure that key business terms and metrics are inventoried and maintained centrally for timely access electronically
Apply project management skills to manage multiple tracks of data governance activities based on an overall project plan.
Support account data stewardship program. Provide guidance and fulfill requests from data owners, data stewards and other stakeholders.
Perform additional job duties and support special projects as assigned
Required
Must handle multiple tasks, manage time effectively, and establish priorities to meet deadlines in a fast-paced and changing team environment
Excellent oral, written, and presentation communication skills. Strong negotiation and group facilitation skills; ability to move a process forward, while meeting the needs of a variety of internal customers.
Relationship management skills that include: (1) excellent listening and consultative capability, (2) the ability to influence and negotiate with business and technology partners to drive change and resolve conflicts at the lowest level and (3) the ability to take a broad perspective and make key connections
Build trust with large project teams through effective communication, conflict management and professional rapport
Superior project management/consulting and leadership skills. Demonstrated ability to facilitate complex, mission critical projects and to develop, participate in and guide multi-disciplinary work teams. Manage task time lines and deliverable schedules and share concerns about deliverables, time lines, and issues with Data Governance, PMOs, account leadership, and partners.
Strong attention to detail when dealing with data and multiple work streams
Excellent time management skills
Comfortable working remote and being conscience of carefully communicating via email, instant messaging, and webex meetings.
Sound judgment, initiative, resourcefulness, tenacity and the flexibility to operate independently in a fast-paced environment.
Knowledge of Data Governance, Data Quality and Data Management projects.
Ability to quickly develop an understanding of business processes and how data is used.
Experience in dealing with internal and external customers. Must be able to deal with strong personalities and people who have competing priorities. Needs to be resilient; resolving conflicts quickly to achieve desired business results.
High level of energy and enthusiasm
Experience in remediating data issues is recommended.
Customer focused; ability to interpret customer requirements
Expert level skills in Microsoft Suite including Excel, Word, Powerpoint, Access, and Visio
4+ years data related experience
Bachelor's degree or 4 years of related industry experience required
About TEKsystems:

We're partners in transformation. We help clients activate ideas and solutions to take advantage of a new world of opportunity. We are a team of 80,000 strong, working with over 6,000 clients, including 80% of the Fortune 500, across North America, Europe and Asia. As an industry leader in Full-Stack Technology Services, Talent Services, and real-world application, we work with progressive leaders to drive change. That's the power of true partnership. TEKsystems is an Allegis Group company.

The company is an equal opportunity employer and will consider all applications without regards to race, sex, age, color, religion, national origin, veteran status, disability, sexual orientation, gender identity, genetic information or any characteristic protected by law.

If you would like to request a reasonable accommodation, such as the modification or adjustment of the job application process or interviewing process due to a disability, please call 888 472-3411 or email accommodation@teksystems .com for other accommodation options.

Job Requirements:","TEKsystems, Inc
3.9","Chicago, IL",Staffing & Outsourcing,Business Services
Machine Learning Engineer,"Role Description
Triplebyte screens and evaluates thousands of engineers per month to find the best candidates for our partner companies. Human decision making doesn't work at our scale; our marketplace is powered by automated assessment and decision making. Triplebyte has three cornerstone ML products: our quiz, our interview, and our matchmaking. As a machine learning engineer, you'll be responsible for the end-to-end process of designing and running experiments to serving production models at scale. Some of our pipelines use off the shelf components, but we're also implementing custom models and techniques from the latest research papers. We're also building forecasting tools for internal teams to measure and predict outcomes. This is an ideal role for an engineer or data scientist who wants the scope and responsibility to own features/products from the inception and research phase through to measuring real-world results.
Fields your work will touch on
Psychometrics
Recommender systems
Time series analysis
Survival analysis
Bayesian inference
Probabilistic programming
Requirements
Robust exploratory/experimental skills. We have a novel dataset of candidate profiles and interview outcomes from our candidate screening process and our hiring marketplace. You'll be responsible for designing and evaluating experiments to predict downstream outcomes.
Ability to implement models from research. Some of our best improvements in both speed and predictiveness has come from doing literature surveys and implementing novel techniques from research papers.
Engineering skills. This is a hybrid research/engineering role. You'll be responsible for productionizing your pipelines/models and integrating against our back-end services.
About Triplebyte
Triplebyte is a hiring marketplace used by companies like Apple, Dropbox, Stripe, and Instacart to hire the best technical talent. We are on a mission to build a meritocratic hiring process, and we do all our evaluation background blind. Our ultimate goal is to collect the largest dataset and use this to build the world's best technical hiring process. No other company has successfully done what we're doing in this field.
We are growing extremely quickly, working on a problem that is fundamental, sitting at the crossroads between the workforce and employers. Ten years from now, it'll look silly to use anything other than Triplebyte for technical hiring.
Company Culture
We have a laid-back, friendly office culture. Over lunch you'll often find us discussing the latest in technology, books, and pop culture, and then maybe getting in a quick game of chess or babyfoot (foosball).
Since we're an early-stage company, we move fast, and it's important that each member of our team is able to take ownership of projects by defining problems, brainstorming solutions, and running experiments.","Triplebyte
3.2","Chicago, IL",Computer Hardware & Software,Information Technology
Data Analyst,"Job Description
Data Analyst

Duration: 6+ month contract

Location: Chicago, IL

***MUST HAVE STRONG TABLEAU AND SQL SKILLS***

Duties and Responsibilities:
Creates specifications for reports and analysis based on business needs and required or available data elements.
May provide consultation to users and lead cross-functional teams to address business issues.
Produces datasets and reports for analysis using system reporting tools.
May perform research and assists in analyzing financial and health data, including medical algorithms to determine health care expenditures, medical and economic outcomes, and cost containment strategies.
Analyzes complex business problems and issues using data from internal and external sources to provide insight to decision-makers.
Identifies and interprets trends and patterns in datasets to locate influences.
Qualifications:
Bachelor’s Degree and 5 years’ experience in health care data statistical analysis OR 7 years’ experience in healthcare data statistical analysis.
3 years’ experience in data analysis and information reporting relating to healthcare data
Ability to query and analyze large sets of complex healthcare data and 4 years’ experience using Structured Query Language (SQL)
Ability to derive insights from complex data for presentation and decision making
Experience with data visualization tools Tableau, MicroStategy or similar
Verify accuracy of reports and provide insights.
Demonstrated best practices and knowledge of internal or external business issues to improve products or services
Ability to independently solve complex problems
Ability to work independently with minimal guidance
Ability to serve as a resource for colleagues with less experience; may direct the work of other staff members.
Experience with visualization tool Tableau or similar highly preferred
Experience authoring/maintaining SAS for complex reporting purposes
Experience or exposure to clinical data integration
Ability to provide subject matter expertise on healthcare/insurance industry
Expertise in business analysis process flows, facilitation, requirements gathering, testing software systems, etc.
Proficient creating and leveraging complex pivot tables
Financial analysis related to provider and facility data

Company Description
Founded in 1994 as Computer Resource Solutions, The CRS Group is a privately held company with offices in Itasca, IL and downtown Chicago. CRSG provides staffing solutions to Fortune 500 companies by successfully managing their IT contingent workforce needs. We expanded our offerings to extend that same high-quality service to other business needs, including creative, marketing, finance, legal and HR.","CRS Group
4.7","Chicago, IL",Staffing & Outsourcing,Business Services
Software Engineer,"The Job Details are as follows:

ROLE OVERVIEW

The Software Engineer will be a key member of a small, focused product team working to create new platforms that BAM’s data analysts, data scientists, quantitative investors, and researchers can rely on for sourcing data sets. The ideal candidate is obsessed with creating high quality software, loves working with data in all its myriad forms, enjoys thinking and debating about the best solutions to complex problems, and has the ability to push forward and get things done. If you’re the kind of person who gets excited by the prospect of wrapping your mind around a different problem each day, we’d love to chat with you.

Among other things, the Software Engineer will:
Devise and develop data solutions leveraging various cloud-based data, database, and distributed computing technologies.
Gain a deep understanding of data requirements and utilization for quantitative investment, in order to help drive prioritization and design decisions.
Help in partnering with end users in order to understand and flesh out requirements as well as provide occasional first level support.
Apply creativity and lateral thinking in order to craft high performance solutions to loading and serving large amounts of investment data.
Work and collaborate as part of a globally distributed engineering team.
Create software that is well commented, well understood, well tested, and well documented – quality above all!
QUALIFICATIONS & REQUIREMENTS:
Degree in Computer Science or closely related field
A passion for data and experience in applying that passion to high quality data products
Strong knowledge of software engineering best practices, object oriented concepts, and the ins and outs of data-focused development
Data-oriented experience with languages such as Python, Rust, Scala, Java, C#, etc. (We work primarily in Python, but feel that the right candidate can come from any language background.)
Intermediate or better knowledge of SQL and experience writing production queries against one or more SQL DBMS
Experience with basic DevOps techniques, including CI/CD and infrastructure-as-code
Experience working in at least one cloud environment. Familiarity with AWS a big plus
5+ years of professional software development experience. Financial industry exposure a plus but not at all required
Self-starter who is not afraid to ask questions and who can thrive in a fast-paced and agile environment where a one-line email can morph into a weeks-long project
Humble, team-player who wants to win","Balyasny Asset Management
3.9","Chicago, IL",Investment Banking & Asset Management,Finance
Data Scientist,"What you'll learn & achieve:Use advanced mathematical and statistical concepts and theories to collect and analyze data and construct solutions to complex business problems. Identify what data is available and relevant, including internal and external data sources, leveraging new data collection processes such as sensors, open data, and social media feeds. Perform advanced statistical analysis on experimental or business data to identify, validate and quantify trends or patterns. Design experiments, test hypotheses, and build models to explore complex business and safety science systems. Construct advanced predictive models, algorithms and probability engines to support data analysis or product functions. Write methodology, analysis and data insights for research papers, proposals and presentations. Synthesize all aspects of a data science project to lead non-technical audiences through the goals, methods and implications of the project. Leverage knowledge in machine learning, natural language processing, mathematical and statistical analyses, and technologies such as R, MongoDB, Elastic Search and open source analysis tools. Work with business leaders and researchers to suggest other projects and initiatives that will advance the organizations goals. *This position qualifies for Underwriters Laboratories Inc.'s employee referral policy program.What makes you a great fit:Master's degree in data science, predictive analytics, mathematics or statistics and 3 years of experience in data analytics or data science.Must have work experience with each of the following: 1.) predictive modeling using machine learning including neural networks Bayesian, k-means and related algorithms; 2.) implement natural language processing algorithms to detect patterns in large volumes of unstructured data using BERT, Spark, scikit learn, NLTK and SpaCy; 3.) conduct mathematical and statistical analyses to uncover relationships between variables using R, multivariate, logistic and other regression methods; and 4.) aggregate, prepare and pre-process large volumes of unrelated data for use in Data Lakes that implement MongoDB, Elastic Search and open source analysis tools.What you'll experience working at UL:.Connect With Us!Not ready to apply?for general consideration.UL is committed to hiring and retaining a qualified diverse workforce. We are proud to be an Equal Opportunity/Affirmative Action Employer, making decisions without regard to race, color, religion, creed, sex, sexual orientation, gender identity, marital status, national origin, age, veteran status, disability, or any other protected class U.S. Citizenship is required for most positions.LocationUS-IL-NorthbrookJob ID2020-17946# of Openings1Job CategoryInformation Technology","UL, LLC","Northbrook, IL",-1,-1
Data Analyst,"Senior AWS Developer

UST Global is looking for a highly energetic and collaborative AWS developer who
Possesses extensive business analyst skills with experience of working projects in both Agile SAFe and Waterfall methodologies. Possesses expertise in handling cross vendor client teams across different geographic locations. End to end project management encompassing all project lifecycle stages including conceptualization, initiation, execution and closure. The candidate should be a proven self starter with demonstrated ability to make decisions and accept responsibility and risk. Excellent written and verbal communication skills with the ability to collaborate effectively with domain experts and IT leadership team is key to be successful in this role.

Representative Duties and Tasks
Configures, and administers Amazon Web Services AWS cloud computing technologies, infrastructure, and applications to meet the organizations requirements.
Assists and supports the design, deployment, management, and operation of scalable, highly available, and fault tolerant systems in the AWS cloud by working directly with the stakeholders.
Lead and perform the installation and configuration of AWS cloud management applications by leading medium to large sized efforts.
Develops, and designs software automation and scripts to orchestrate AWS cloud and virtualization technologies with defined scope, schedule and expectations.
Views and analyzes summary data on AWS cloud resource deployment and takes appropriate action.
Monitors requests and key metrics for AWS cloud resources, as well as the performance of systems in the cloud and directs remediation.
Troubleshoots issues and plans for future AWS cloud capacity requirements. Develops roadmap and business case for capacity growth.
Identifies, manages and resolves AWS cloud computing security risks and implements best practices as applied within a cloud environment.
Provides subject matter expert technical support to customers using AWS products, solutions and APIs.
Identifies and documents product bugs and feature requests and works with internal support teams, external providers, as well as customers to implement effective solutions.
Supports and leads the evaluation of new service offerings from AWS to determine potential usage by GDMS.
May provide work direction to other employees as a technical lead
Knowledge Skills and Abilities
Proficient understanding of the AWS platform
Proficient understanding of AWS service offerings
Proficient understanding of virtualization technologies Server, Storage, Networking
Proficient understanding of computer programming languages C, C Sharp, C , Perl, PHP, and Python.
Proficient understanding with scripting languages, and software and infrastructure automation skills
Detailed and fully proficient knowledge of technology trends and champions new ideas and product and process improvements.
Strong understanding of security, risk and compliance frameworks, disaster recovery, high availability architectures, hardware, operating systems and networking connectivity.
Experience creating templates with CloudFormation, and similar technologies.
Shows initiative on assignments, and professionally executes projects with very little direction, or can provide direction and leadership to technical teams.
Fully proficient ability to handle significant responsibility, leadership and accountability while executing complex assignments.
Effective communication skills written and verbal .
Knowledge of systems architecture.
Able to accept integrate constructive feedback
Proficient ability to work collaboratively and effectively with a wide range of individuals
Proficient ability to learn and apply GDMS culture, policies and processes
Location This position can be based in Chicago","UST Global
4.1","Chicago, IL",IT Services,Information Technology
Data Analyst,"Chicago Public Schools (CPS) is the third largest school district in the United States, serving over 350,000 students in 600 schools and employing nearly 36,000 people, most of them teachers. CPS has set ambitious goals to ensure that every student, in every school and every neighborhood, has access to a world-class learning experience that prepares each for success in college, career and civic life. In order to fulfill this mission we make three commitments to our students, their families and all Chicagoans: academic progress, financial stability and integrity. Six core values are embedded within these commitments - student centered, whole child, equity, academic excellence, community partnership and continuous learning.Reporting to the Director of Compliance & Training in the Office of Student Protections and Title IX, which now includes the Equal Opportunity Compliance Office, the Data Analyst is responsible for managing the collection, evaluation, and reporting of data to ensure that our protection processes and responses are in line with district compliance standards.The Data Analyst will be held accountable for the following responsibilities:* Understand data to extract information aligned to business requirements;* Perform analysis on complex data sets to provide relevant and actionable information;* Evaluate data for integrity and consistency;* Identify anomalies in data to trace the source of inaccuracies;* Identify data trends to recommend best practices and process improvements;* Summarize data to provide topline reports and graphic representation through dashboards and presentations;* Develop, implement, and manage data collection systems and other strategies to optimize data collection efficiency and data quality;* Continuously locate and define new process improvement opportunities for the collection and reporting of data;* Partner with subject matter experts to identify additional data needs; and* Performs additional ad hoc duties as assigned.Type of Education Required:* Bachelor's degree from an accredited college or university.* Master's degree a plus.Type of Experience Required:* Minimum of 3-5 years of data mining and data analysis experienceKnowledge, Skills and Abilities:* Expertise in applying a variety of statistical techniques to interpret and analyze data;* Expert user of Microsoft and Google office suites;* Ability to write advanced queries and produce reports;* Ability to acquire data from primary or secondary data sources;* Ability to maintain databases;* Ability to create pivot tables;* Strong analytical, organizational, and communication skills;* Refined judgement with the ability to manage highly sensitive and confidential information.* Ability to bring projects to a close with minimal supervision;* Ability to work in a fast paced environment, respond immediately to multiple constituencies, and meet continuous critical deadlines;* Ability to build relationships, establish collaborative partnerships, and work with a wide range of constituencies with diplomacy and tact;* Skilled multi-tasker and excellent time manager;* Ability to simultaneously achieve multiple goals and manage multiple projects; and* Excellent attention to detail and the ability to produce consistent high-quality work;Residency Requirement:As a condition of employment with the Chicago Public Schools (CPS), employees are required to live within the geographic boundaries of the City of Chicago within six months of their CPS hire date and maintain residency throughout their employment with the district.'255951","Chicago Public Schools
3.5","Chicago, IL",K-12 Education,Education
Data Analyst,"Role: Data Analyst
Location: Chicago, IL(Local Only)
Job Type: Permanent / Fulltime

Roles and responsibilities:
Data Analysts with expertise in Python for data analysis is a must
Cloud Experience Setting up AWS, Google Cloud
Experience with Google BigQuery, Apache Spark, Hadoop, Hive, and other Big Data technologies","Diverse Lynx
3.9","Chicago, IL",IT Services,Information Technology
Data Analyst,"JOB TITLE: Data Management Aide

FLSA STATUS: Non-Exempt

REPORTS TO: Program Director

POSITION SUMMARY:
Under the supervision of the Quality Assurance and Compliance Coordinator, the Data Management Aide will work closely with the Program Director to support the overall functions of Programs. The Data Management Aide is responsible for ensuring the accuracy of monthly and quarterly reports related to classrooms data that supports teachers center-based, home based and family child care homes in individualizing instruction and enhance program design.

ESSENTIAL FUNCTIONS AND RESPONSIBILITIES:
• Reviewing child-level progress data such as, observations, and outcomes data.

• Provides support to the Managing Director & Operations and IT Manager in grant-specific and agency-wide data needs.

• Data entry; developing and maintaining procedures for data collection, input, management and quality control.

• Developing statistical reports for grant reporting and program evaluation/development.

• Ensure that information is accurately entered in the system and follow proper procedures for formatting and securing data

• Examine data for errors related to formatting, locate and eliminate duplicate entries

• Update the COPA data management system at the program level.

• Adhere to the HIPPA privacy rules to protect personal information regarding staff, families and children s records

• Responsible for Food Meal Report and communicates with teaching staff about findings.

• Responsible for Attendance Report and communicates with teaching staff about findings.

• Performs other duties as assigned

POSITION REQUIREMENTS:
• High School Diploma and or GED Equivalent.

• Associates Degree in Administration preferred.

• Computer literate (Microsoft, social media, outlook, etc.); COPA software is a plus.

• An understanding of database functionality and structure

• Experience with database management and knowledge of basic statistics

• At least one year of direct experience in data collection, data analysis and statistical reporting

• Excellent written, oral, interpersonal skills

• Must be self-motivated, detail-oriented, highly organized, and able to meet deadlines

• Ability to work well in a team environment

• Experience with federal grant requirements is a plus

ACKNOWLEDGEMENT:
Verification of eligibility to work in the U.S will be required within the first 3-days of employment.

Upon offer of employment, applicants must complete all forms related to hiring, including El Hogars application and employment status and 3 letters of recommendation. In addition, applicants must be able to pass a Criminal Background Check, Fingerprinting and a Child Abuse and Neglect Background Check, which are required by DCFS. All qualified applicants will be considered for employment without regard to race, ethnicity, religion, gender, sexual orientation, national origin or disability.",El Hogar del Nino - The Home of the Child,"Chicago, IL",-1,-1
Data Analyst,"Level Ex is transforming the way medical professionals hone their skills by practicing high-risk procedures and earning training credit with the latest medical devices and diagnostic treatments in our industry-leading 3D mobile games. In less than four years, Level Ex has exponentially grown, hiring top talent from the video games industry, the digital health ecosystem, and leading medical institutions. Our clients include top 20 pharmaceutical, biotech, and medical device companies including Baxter, Pfizer, Merck, and Medtronic, as well as leading medical associations.

We’re looking for an experienced Data Analyst who can discover ways to improve our genre-bending mobile games, can lead roadmap projects that will boost the company’s analytics & data science capabilities, can build and support data pipelines for business intelligence and can deliver ad hoc analytics requests to internal partners and external clients.

What You’ll Be Doing with Us
Writing SQL queries for analysis and ETL details (views, dimensional/factual tables, aggregate tables, etc.)
Leading larger projects in a data & analytics roadmap.
Authoring and presenting data analyses that answer business questions and identify recommendations.
Delivering ad-hoc reports for multiple departments.
Building compelling, useful data visualizations and dashboards that track important KPIs related to player behavior, games development, marketing, operations, etc.
Defining telemetry details to add or change existing event data. Identifying data and structure needed in order to analyze mobile games with different design patterns.
Discovering and fixing data quality, structure and integrity issues.
Validating data and to ensure availability across live apps, client projects, and future projects, and collaborating with Quality Assurance to ensure telemetry is correct.
Performing statistical analysis in areas like marketing campaigns, AB tests for product improvements, client project analysis, and more.
Training and deploying predictive models to optimize marketing, operations, etc.
Documenting pipeline details, changes to telemetry, and other important information. Support in maintaining metadata files and data models.
Writing and monitoring JIRA/development tickets.
Provide guidance and peer review to staff on a growing team.

Who We Want To Meet
3+ years of experience working in data & analytics, business intelligence, data science or data engineering.
3+ years of experience with SQL.
3+ years of experience with one or more open-source data science languages - R, Python, etc.
3+ years of experience with Tableau or other data visualization tools.
B.S. or M.S. in Computer Science, Mathematics, Statistics, Economics, Analytics, Engineering or equivalent combination of education and experience.
Passion for using data, analytics, statistics, and predictive modeling to solve problems.
Attention to detail.
Excellent verbal and written communication skills.
Ability to collaborate effectively and work as part of a team at a growing start-up.

Bonus Points Awarded For
M.S. or Ph.D. in Computer Science, Mathematics, Statistics, Economics, Analytics, Engineering or equivalent combination of education and experience.
Experience working on mobile game analytics and/or on medical analytics.

How We Make You Happy
Multiple health insurance plans with 100% company-paid premiums
401(k) with company-paid match
Dental and vision insurance
Pre-tax flex spending and commuter accounts
Paid vacation, sick days and holidays
Downtown Loop location convenient to public transportation, and plenty of nearby food options
Unlimited cold brew and gourmet coffee, kombucha, Bevi sparkling water, and craft beer
Full kitchen and food options including breakfast, and both healthy and comfort snacks
Team after-hours events, like Board Game Night

Interested?
For the fastest consideration please send us your resume along with a cover letter detailing why you’re a fit for this important role. We look forward to hearing from you and exploring the possibilities.

Level Ex is an Equal Opportunity Employer (EOE).

No Agencies or Recruiters, please.
Legal authorization to work in the U.S. is required. We will not sponsor individuals for employment visas, now or in the future, for this job.","Level Ex, Inc.
3.6","Chicago, IL",Video Games,Media
Data Engineer,"Job Description
Our Mission

With wasteful healthcare spending in the U.S. estimated at $935 billion, we take our role as a healthcare innovator very seriously. Simply put, Apervita is on a mission to change the face of healthcare. We intend to do this by continuously improving the value of healthcare delivery through performance, measurements and insights.
Recognized as the trusted source for performance measurement through our proprietary cloud-based rules engine, we address the complexities of an industry transitioning to accountable-based care arrangements. Serving one of the nation’s largest regulatory organizations, more than 1-in-2 U.S. hospitals and several nationally recognized health plans, Apervita conducts more than 10 billion value-based computations annually, providing vital insights that enable collaboration, build trust and advance value-centric care.

As we move into our next phase of growth, we’re looking for smart, passionate and fearless professionals to help us pursue our mission. We’ve earned the trust of our investors, including Optum Ventures, Baird Capital, Pritzker Group Venture Capital and Math Venture Partners, to further grow and scale our business in 2020. We’ve also been recognized as an industry leader by Gartner, CIOReview, Healthcare Tech Outlook, and Healthcare Informatics. Always in search of the next “first,” Apervita was recently named the first company to certify electronic clinical quality measures from the National Committee for Quality Assurance (NCQA) using our proprietary clinical quality language (CQL) ingestion engine. This is a huge step forward in healthcare quality innovation and an indication of where we’re headed. We’re clearly on the cusp of something big and bold and can’t wait to see what happens next.

Are you up to the challenge?

Data Engineer

About the role
The Data Engineer is responsible for deploying and managing ETL/ELT pipelines, jobs, orchestration frameworks, and ensuring data quality. The charter of the data engineering team is to optimize how our customers data turn into insights as fast as possible meeting customer SLA’s. The data engineer can expect to work closely with business analysts, data scientists, analytics experts and developers to build the ETL/RLT pipelines, and data models. The data engineer will also have the opportunity to inform the design, implementation, and best practices or this system including deployment of modern tools.

Responsibilities
Build cloud-based data warehousing environments, data processing pipelines, and data models that support a variety of business needs
Support a variety of data processing pipelines, integrate new data sources into our data warehouse, and create jobs to load, transform, and QA vital datasets
Work with analysts and developers in the product development process to ensure that newly designed data models meet analytics requirements and follow best practices
Share your expertise on scalable data processing with analysts and data scientists to further our goal of being a truly data driven organization
About you
5+ years of experience as a data engineer using data warehousing technologies like, Amazon Redshift, RDS, S3, Athena, EMR, and Hadoop/Hive/Spark
Proficient in SQL including one or more relational databases like MySQL, Oracle, Postgres, or similar
5+ years experience with ETL and job scheduling or orchestration using tools like Airflow, Luigi, Oozie, or similar
5+ years experience programming in python and familiarity with AWS and git
Excellent communication skills and ability to work on a growing team
Bonus points if you have
Experience with web-scale data or working with healthcare data in a HIPAA-compliant environment
Experience with Healthcare Payer data as well as Optum Impact Intelligence tool.
Experience with data modeling, data visualization, and/or BI tools like Looker, Metabase, or Tableau
Experience with AB Testing
Benefits
Stock Options
PTO
Unlimited sick and sanity days
Commuter benefits
Medical, Dental, Vision
401K with matching
Unlimited snacks in office
Powered by JazzHR

17RCjfuDup","Apervita
4.8","Chicago, IL",Enterprise Software & Network Solutions,Information Technology
Data Analyst,"Riskonnect, Inc. is the leading integrated risk management software solution provider that empowers organizations to anticipate, manage and respond in real-time to strategic and operational risks across the extended enterprise. Riskonnect is the only provider ranked in the leadership and visionary quadrants by world renowned industry analysts Gartner and Forrester. We employ more than 500 risk professionals in the Americas, EMEA and Asia Pacific and serve over 900 customers across 6 continents. The combination of innovative risk technology, a customer success mindset, and employee-first belief makes Riskonnect a sought after place to work.

Primary Role Responsibilities:
Support, maintain, and streamline data interfaces.
Troubleshoot data interface issues. Analyze data (claims data, client databases) to find issues and anomalies and provide quality assurance.
Enable automation; add efficiencies to coding. Clean up data/codes.
Act as first level client contact for data-related issues.
Assist clients; interface with internal colleagues (e.g., Support) to resolve client issues.
Coordinate with colleagues globally to ensure seamless support.
Required Qualifications:
Minimum 1 year of experience working in a SQL Server Management Studio environment
Working knowledge of query-writing, stored procedures, and views
Strong analytical skills and ability for problem-solving
Detail-oriented, organized, and self-motivated
Within Role Promotion Considerations Hiring of/promotion to Data Analyst, Senior Data Analyst, or Lead Data Analyst is based on a combination of:
Years of experience
Ability to meet or exceed key performance metrics
Superior display of relevant competencies
Knowledge of platform / technical expertise
Complexity of projects handled; ability to solve complex/escalated problems
Successful execution of project responsibilities from start to finish
Scope of work performed
Ability to lead/mentor less experienced analysts on larger projects
Key Performance Indicators
On-time delivery of data
Integrity of data
Turnaround of cases/issues
Successful automation
Timely communication
Number of accounts processed
Client satisfaction
Client relationship
Solid documentation
Helpful Qualifications:
ARMS certification
Microsoft SQL certification(s)
Database tools (e.g., Oracle)
Experience with Salesforce
Experience with Financial data sets, involving financial validation.","Riskonnect Inc
3.7","Chicago, IL",Enterprise Software & Network Solutions,Information Technology
Data Engineer,"Job Description
Job Overview

We are looking for a Data Engineer to join our growing team of analytics experts, where you will have the opportunity to author and manage data pipelines from ingest to insights and all the plumbing in between. The Data Engineer will support our data scientists with both existing and net new projects, ensuring that data delivery is consistent and optimized. The right candidate will be excited by the prospect of optimizing or even re-designing our company’s data architecture to support our next generation of products and data initiatives.

Responsibilities for Data Engineer
Create and maintain optimal data pipeline architecture.
Assemble large, complex data sets to meet functional and non-functional business requirements.
Author the pipeline code required for optimal extraction, transformation, and loading of data from a wide variety of data sources.
Work with Data Scientists and Systems Engineers to design data delivery architecture.
Work with stakeholders including the Executive and Product teams to assist with data-related technical issues and support their data insight needs.
Create data tools for team members that assist them in building and optimizing our products.
Qualifications for Data Engineer
Advanced working SQL knowledge and experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases. PostgreSQL administration familiarity a plus.
Strong Python scripting skills. Ruby a plus.
Familiarity with API endpoint interactions and techniques for handling query complications.
Understanding of Containerization, Micro-Service, and Server-less a strong plus.
Strong analytic skills related to working with unstructured datasets.
Build processes supporting data transformation, data structures, metadata, dependency and workload management.
Working knowledge of message queuing, stream processing, and highly scalable data stores.
Experience supporting and working with cross-functional teams in a dynamic environment.
The ideal candidate would have 3+ years of experience in a Data Engineer role, or 5+ years in any Software Engineering role with demonstrable familiarity of the Data Engineering/Science space. Work experience, academic instruction, and/or code portfolio will all considered.
Powered by JazzHR

sEaphUQBLW","Strike Social
4.3","Chicago, IL",Advertising & Marketing,Business Services
Data Engineer,"ob Title Data Engineer Location Chicago, IL Duration 12+ Months Required Skills Responsibilities At least 3+ years experience as a Data Engineer Experience and expertise in using Spark in combination with pySpark, Scala or Java, either on-premise or Cloud Experience of software engineering in pythonScalaJavaC++ Experience with relational database and SQL (Postgres, Redshift, Snowflake, SQL Server) Expert knowledge of distributed computing, RDD and optimization techniques Experience with NoSQL and streaming platforms, e.g. Kafka, MongoDB, Neo4j is a plus Experience with developing software products for cloud platform, e.g. AWS. Experience in creating and customizing Reports and Dashboards Experience working on Large enterprise level data sets and ETL Experience in Data analysis, data consolidation and normalization Comfortable on Linux for both development and operations Experience with advanced analytics and modern machine learning techniques is a plus Experience with cloud native services such as AWS EMR","Involgix
4.5","Chicago, IL",IT Services,Information Technology
Data Analyst,"Role Type: Data Analyst

Reports To: Chief Technology Officer

*
About Us

CareAdvisors is a technology company that helps patients get access to healthcare and social service benefits they need by automating the manual enrollment role taken on by hospitals.

Many patients who receive care at hospitals are eligible for Medicaid and other social service benefits, but some have barriers to enroll or re-enroll in their benefits. Using technology focused on automation, CareAdvisors remove barriers so that patients can get access to the benefits they need.

Our Customer Relationship Management tool empowers care navigators and social workers with a platform that is connected to a network of community resources and hospitals. We use the data gathered across our network to power our analytics engine. Join us in building out our platform so we can connect people to the care they need!

About the Role

As a Data Analyst, you will research and develop predictive models for population health. Overall, you will support our enterprise strategy and delivery of analytic services by performing various analyses and interpretations to support business needs for assigned functions. The analyst will collaborate across analytic teams, business partners, and customers to ensure a coordinated flow of information, documentation, and relationships to support the delivery of leading-edge analytics. Due to the dynamic nature of this role, we are looking for entrepreneurial candidates with the ability to derive analytical insights from a variety of business contexts.

Responsibilities
Compile analytical and statistical reports.
Formulate, define, and recommend scope of reports.
Review information for accuracy and reconcile data.
Provide support and education to staff on how to access reports and interpret the data.
Synthesize raw data into digestible and actionable information.
Identify trends and make recommendations for quality and operational improvement.
Collaborate with leaders to understand key value drivers and challenges within their business units and determine the key metrics and insights that can help improve performance as a result.
Continually think of new ways that data-driven insights can help support Care Advisors.
We are looking for a team member with the following background
Currently based in the Chicagoland area (REQUIRED!)
BS or BA degree in business, economics, finance, accounting, marketing analytics, MIS, computer science, engineering, or equivalent work experience.
2 years of related experience in an internship or full-time role guiding strategic decision making using data and analytics.
Experience working in a healthcare or startup environment, preferred.
Experience with topics in public health, population health, social determinants of health, data science, or social science, preferred.
Experience with report/dashboard development, data/report automation, self-service capabilities, data design and integration, data quality and governance, preferred.
SQL, Python, and/or Tableau skills are preferred.
Familiar with predictive programming in R and/or Python.
Proficiency in Microsoft Excel, Powerpoint and Word.
Ability to take insights and turn them into actionable steps that can drive business value.
At Care Advisors we value diversity and endeavor to treat everyone with respect, no matter their age, gender, race, ethnicity, or sexual, cultural or ideological preferences.

Due to the unprecedented situation of COVID-19, CareAdvisors has decided to protect our current and future employees by managing our business remotely. This is inclusive of interviewing, onboarding, and daily operations. Please consider that our roles will not be remote long-term and we will return to an office environment once it is deemed safe to do so following the guidance of local health authorities and the Centers for Disease Control.

*

Job Type: Full-time

Schedule:
Monday to Friday
Experience:
healthcare or startup environment: 1 year (Preferred)
data and analytics: 2 years (Required)
Education:
Bachelor's (Required)
Location:
Chicago, IL 60654 (Required)
Work Location:
One location
Benefit Conditions:
Waiting period may apply
Work Remotely:
No","Care Advisors Inc
3.5","Chicago, IL",Computer Hardware & Software,Information Technology
Data Engineer,"Position: Data Engineer
Location: Bristol, CT
Type: Permanent/Direct-hire*
Start: ASAP

*Sorry, this client is unable to sponsor or work with 3rd party vendors*

Requirements:
Experience on Apache Airflow tool.
Must have hands on experience implementing AWS Big data lake using EMR and Spark.
Working experience on AWS platform.
Experience in using CI/CD pipeline (Gitlab)
Experience in Code Quality implementation (Used Pep8/Pylint) tools or any other code quality tool.
Experience of Python Plugins /operators like FTP Sensor, Oracle Operator etc.
Implement Industry Standards /Best Practices.
Excellent analytical and problem-solving skills
Business acumen to work directly with clients. Excellent verbal and written communication skills","Mondo
3.8","Chicago, IL",Staffing & Outsourcing,Business Services
Data Engineer,"Job Description
What We Do
Kalderos delivers technology that solves the challenges facing the US healthcare system. At Kalderos, we develop technology solutions with a focus on simplifying the complex coordination of drug discount programs from exhaustive data services to intelligent reporting to issue resolution.

To learn more: https://www.kalderos.com/company/about

What Data Engineers Do

The Data team’s mission at Kalderos is to provide data modeling expertise to internal teams, and build data storage and processing platforms that can scale as Kalderos scales. They can work within the Ledger and Master Data team, the Data Science team, or others as needs arise. Below are some possible day to day tasks for a data engineer at Kalderos.
Work with product teams to understand and develop data models that can meet requirements and operationalize well
Build out automated ETL jobs that reliably process large amounts of data, and ensure these jobs runs consistently and well
Build tools that enable other data engineers to work more efficiently
Try out new data storage and processing technologies in proof of concepts and make recommendations to the broader team
Tune existing implementations to run more efficiently as they become bottlenecks, or migrate existing implementations to new paradigms as needed
Learn and apply knowledge about the drug discount space, and become a subject matter expert for internal teams to draw upon
What We Are Looking For
4+ years work experience as a Data Engineer in a full-time role
Candidates must be authorized to work in the US and be able to work in Chicago/Milwaukee
Excellent project managements skills, and familiarity working in an agile environment
Some ways you may demonstrate this are:
Describing a time in which you had a large project you needed to manage
Relevant work experience on a Agile team
Proven data engineering experience that involved creating, and maintaining a database and implementing data processing pipelines
Some ways you may demonstrate this are:
Professional experience described on your resume
Open source implementations of data intensive applications
A personal side project that involved maintaining a database like a website
Online course completion in relevant areas
Vendor certification in a relevant field
Programming experience with a modern computing language that supports data engineering work (Python, C#, JVM-languages like Scala)
Some ways you may demonstrate this are:
Professional project descriptions on your resume
GitHub repositories that have working code that you created
Sending a code snippet that exemplifies your work
Advanced SQL skills and understanding performance trade-offs of various SQL implementations
Some ways you may demonstrate this are:
Professional project descriptions on your resume
SQL Certifications you have earned
Answering SQL questions in a phone interview
Advanced SQL queries you wrote in your Github repository
What May Set You Apart
Experience with SQL databases like MS SQL Server
Experience with Azure cloud computing such as hosted databases
Experience with streaming technologies such as Kafka or Event Hubs
Experience with orchestration frameworks like Azure Data Factory or Airflow
Experience with NoSQL data stores such as MongoDB and CosmosDB
Experience in the healthcare or pharmaceutical industries
Experience with large scale migrations of databases
Experience creating RESTful APIs to service data needs for web applications
Experience with implementing Software Development Lifecycle approaches to database work, such as Testing, CI/CD and other automation

If you think you meet some of the list of the above, but not everything, that’s perfectly fine! We encourage you to apply regardless. At Kalderos, we know talent comes in many forms, and we’re willing to look beyond a set of rigid criteria to find the right teammate.

Company Perks
401K plan with matching
Healthcare benefits
Flexible schedule and a fair PTO system that allows for a healthy work-life balance
Opportunity to work on new technologies and learn new skills
Celebration, and education stipends

To learn more: https://www.kalderos.com/company/culture

Kalderos is an equal opportunity workplace. We are committed to equal opportunity regardless of race, color, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, or veteran status.

Due to the circumstances of the COVID-19 pandemic, Kalderos has decided to protect our current and future employees by shifting to an entirely remote workforce. We will continue to operate, interview, onboard, and work remotely. Please be aware that some of our roles will not be remote long-term and will return to an office setting once we're safe to do so following the guidance of local health authorities and the CDC.","Kalderos
5.0","Chicago, IL",Enterprise Software & Network Solutions,Information Technology
Data Engineer,"5+ years of experience in a Data Engineer role Experience with big data tools Hadoop, Spark, Kafka and relational SQL and NoSQL databases,","Zai Global
5.0","Chicago, IL",-1,-1
Data Engineer,"Job Title: Data EngineerCompanyWork matters. It's where we spend a third of our lives. And the workplace of the future is going to be a great place. We're dedicated to bringing that to life for people everywhere. That's why we put people at the heart of everything we do.People matter. Our people have a passion for learning, building, and innovating. Whether you're an engineer, a sales professional, a finance professional, or anything in-between, our roles aim to provide each person with meaningful impact and plenty of space to grow.TeamThis is a new team within the Data and Analytics organization. The team is fast-paced while managing highly accurate detailed information. We collaborate and support every business unit within ServiceNow.RoleWe are looking for a dynamic, perennially curious, self-motivated and data centric individual to drive Business Intelligence endeavors for the Business. A candidate to nurture, execute and deploy BI projects to direct our investments, manage business levers, track progress against guidance, predict and prescribe targeted opportunities. The role entails collaborative engagements with Field & Product Line Sales Teams, Global Services, Alliances & Channels and FP&A to deploy insightful analytic products, establish alignment on processes teams and deliver strategic metrics for current and future business initiatives.What you get to do in this role:* You will provide insights and deep analysis being sought by users/business stakeholders* Work with Cross Functional Analytics team members to curate and assimilate insights* Grow into being SME on business functions* Gather business requirements from stakeholders on various analytics initiatives* Analyze requirements, determine optimal solutions and determine gap from current state, dependencies and ways to mitigate risks* Develop business requirements documentation, process workflow diagrams, functional specifications, user acceptance test scripts and other supporting documentation for Business Intelligence and Analytics initiatives* Assist stakeholders with data analysis, design data models & develop DB Views, procs, models in SAP HANA to meet business need* Develop dashboard and report prototypes and mockups with respect to the UX/UI Best Practices and have impactful UI Design* Communicate status regularly with stakeholders* Define required data integration requirements between various systems and work with extended team to get them created* Collaborate with India Development Center BI team to translate business requirements and get appropriate data solutions developed to meet business need* Partner with Global BI team to help implement solutions for end user adoptionIn order to be successful in this role, we need someone who has:* Bachelor's Degree in Information System, Analytics, Business Intelligence or related field required* 1 to 3+ years of documented experience in writing strong SQL, PLSQL in data warehouse technologies (Hana, Snowflake or any modern database).* Ability to analyze data coming from myriad data sources, mine and analyze and derive value from it to improve business SQL and other computer programs (Python, R is preferred)* Ability to visualize the results in the previous step by putting together simple and easily consumable dashboards using reporting tools* Working knowledge Tableau, Power BI is a plus* Strong analytical and problem-solving ability and be able dive into technical details and design analytics solutions* Expertise in database design & development, writing optimized queries, handling Facts, dimension data effectively* Must have good communication, presentation, and documentation skills* Capable of using Microsoft Project, Excel, Word, PowerPoint, and Visio or similar products* Business process design, project management, and/or Agile SDLC experience a plus* 1-2 years of SAP HANA experience is a plus","ServiceNow
3.7","Chicago, IL",Enterprise Software & Network Solutions,Information Technology
Data Engineer,"Data Engineering is the foundational layer of our Data & Analytics stack at Arrive. Data Engineers not only build and optimize data pipelines that transform and store data in a way that allows the rest of the organization (analysts, data scientists, other stakeholders) analyze and consume data. They are also in charge of building the systems and establishing the processes to enable the rest of the data team to develop, test, and deploy analyses and code in an efficient and scalable way.

We’re looking for an experienced Data Engineer to help us grow our data infrastructure and platform. If you're seeking a role that is high impact and full of ownership....please read on.

Please note...we are fully open to remote candidates for this position! Being in Chicago would be great, but not necessary.
What you'll tackle
Design new enterprise data models and ETL processes to populate them
Extract and transform data from production databases and 3rd party services to provide consumable data and support functions across the organization
Detect quality issues, track them to their root source, and implement fixes and preventative audits
Manage and optimize Redshift clusters/data lake to ensure current health and performance and future scaling needs
Help maintain the process we use to develop, test, and deploy good code
Become the “go to” expert of our data. Work closely with staff to understand all data from our core systems, partner services, and any other platforms we rely on
What you bring to the table
Experience with AWS; expertise in Redshift, Postgres or other RDBSs (preferably column-oriented)
Expertise in SQL and ability to write and optimize complex queries
Experience with Docker, Elastic Container Service, Lambda a plus
Ability to write customized software in Python, Bash, Go or other common open source languages. Experience with Airflow or similar scheduling service a plus
Experience with CI/CD tools like Jenkins or Drone
Creativity in approaching data organization challenges with an understanding of the end goal
A collaborative nature and entrepreneurial spirit. Prior startup experience a huge plus",Arrive,"Chicago, IL",-1,-1
Data Analyst,"This position is responsible for working on multiple project tasks in support of the technical requirements and analysis to develop and validate a solution design in the data, information and ETL domains in support of an end-to-end analysis development, management, and delivery; intensive data analysis from a documentation, investigation and technical profiling (queries) perspective; interfacing between various business and technical teams to compile requirements and design solutions; providing technical leadership to the team; work closely with customers to build relationships; and continuously gaining a deeper understanding of relevant data and processes to build analytic solutions to meet business needs. Responsible for gathering and assessing business information needs and preparing system and data requirements. Performs analyses and profiling of the data, create detailed mapping documentation including transformation rules. Requirements: Has an understanding of healthcare / payor data, subject areas, and source systems. Must understand data, data relationships at the table and attribute level. Able to interpret measurement definitions, and perform data decomposition. Perform Gap analysis and impact analysis on any changes that are being suggested. Possesses working knowledge of Relational Database Management Systems (RDBMS) and data warehouse, including full reference architecture from data integration, through semantic layer and reporting. Strong knowledge of data and dimensional modeling. Experienced in group facilitation with participants from diverse business functions and work skills Qualifications: -3 plus years of experience with Online Transactional Processing (OLTP), data warehouse and dimensional modeling -3 plus years of experience with data modeling experience (conceptual, logical and physical) using a data modeling case tool -3 plus years of professional experience working in IT -Experience with canonical and industry models -Experience with Teradata or Oracle warehousing -Experience with Data Warehouse Measure calculation frameworks -Experience with ERWin -Experience with DB2 -Healthcare experience is a plus","TechUSA
2.7","Chicago, IL",Staffing & Outsourcing,Business Services
Data Engineer,"Role Data Engineer Location Richmond, VA Chicago, IL Duration 7+Months (will extended to 1 year) Job description Required Technologies Strong Programming experience with object-orientedobject function scripting languages Python. Experience with big data tools Hadoop, Apache Spark Experience with AWS cloud services S3, EC2, EMR, RDS, Redshift Experience with stream-processing systems Storm, Spark-Streaming, etc. (Nice to have) Experience with relational SQL, Snowflake and NoSQL databases Detailed overview of functional and technical role expectations Candidate with 5+ years of experience in a Data Engineer role, who has attained a Graduate degree in Computer Science, Statistics, Informatics, Information Systems or another quantitative field. They should also have working experience using the following softwaretools 3+ years of experience (Mid-level) Strong Programming experience with object-orientedobject function scripting languages Python 3+ years of experience (Mid-level) Experience with big data tools Hadoop, Apache Spark, Kafka, etc 1+ years of experience with AWS cloud services S3, EC2, EMR, RDS, Redshift. Experience with stream-processing systems Storm, Spark-Streaming, etc. (Nice to have). 1+ Years of experience with relational SQL, Snowflake and NoSQL databases, including Postgres and Cassandra. Responsibilities for Data Engineer Create and maintain optimal data pipeline architecture, Assemble large, complex data sets that meet functional non-functional business requirements. Identify, design, and implement internal process improvements automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability etc. Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using SQL and AWS 'Big data' technologies. Build analytics tools that utilize the data pipeline to provide actionable insights into customer acquisition, operational efficiency and other key business performance metrics. Work with stakeholders including the Executive, Product, Data and Design teams to assist with data-related technical issues and support their data infrastructure needs. Create data tools for analytics and data scientist team members that assist them in building and optimizing our product into an innovative industry leader. Required Skills Python, Hadoop, Apache Spark, AWS, SnowflakeSQL knowledge. -- Thanks Regards, G. Naga Tarun US IT Recruiter Email tarunkeylent.com Direct 407-801-8682 linkedin.cominnaga-tarun-b741b7140 Keylent Inc 1000 N West Street, Suite 1200 Wilmington,DE,19801 www.keylent.com httpwww.keylent.com","Keylent
3.1","Chicago, IL",-1,-1
Data Analyst,"Job Description
We are seeking a Data Analyst to become an integral part of our enterprise fortune 500 team! You will perform data collection, analysis, validation and reporting. Designs, tests, and documents processes, SQL queries, and stored procedures. Strong analytical and organizational skills also essential. 0 - 2 years experience

Responsibilities:
Excel Wizard (Advanced to Expert level
Low level Data Analyst, no SQL required
Possible contract to hire, no guarantees
Able to perform pivot tables, functions, formulas, v-lookups, pivot reporting, macros, micros
This individual will be organizing, comparing, analyzing data.
They will receive a report from a 3rd party and then compare that report to Univar's internal reports to see where the data differs, understand why it differs, and communicate this to the manager.
This report has over 50,000 cells each report.
The hiring manager will need this individual to also add data, upload, edit, and change data as he sees errors and inconsistencies.
SQL is not required and this is a relatively low level Data Analyst role
First day start details:
They must appear onsite for the first duration of their training and then will discuss remote work once they get started due to COVID-19.

Company Description
SkySource Solutions believes in attaining success. We know success is important to our clients, applicants, candidates, and our internal staff and want to be an integral part of that process.

The SkySource Difference: We are not just another staffing firm! We truly care about our candidates long-term success and how we get there together. So the BIG Question is... How do we get there?
Our team of Recruiters come with 5 plus years of industry experience and are not looking to just find you a job. We truly care about your short-term and long-term career goals and understand what's important in making that next career move. We want to understand what you are looking for from a cultural, compensation and benefits perspective.

Apply today and experience the SkySource difference!","SkySource Solutions
4.1","Downers Grove, IL",Staffing & Outsourcing,Business Services
Data Analyst,"Teradata/Datastage/Unix
Requirement Elicitation - Business Requirements,Technical specification,System/Data Requirements
Business Analysis, Data profiling, Source to Target Data Mapping,Gap Analysis,Impact Analysis,Root cause Analysis
Agile methodology - Jira
Experience in TDM","Lorven Technologies Inc
4.0","Chicago, IL",Accounting,Accounting & Legal
Machine Learning Engineer,"Job Description
Responsibilities

We are looking for a Machine Learning Engineer to build world-class machine learning platform solutions. You will be responsible for empowering data scientists and AI scientists by developing a collection of industry-strength platform services to greatly improve scientists productivity and facilitate innovation. Your responsibilities include, but not limited to:

? Build Stats Perform’ s Machine Learning platform and services to support major AI and Data Science use cases

? Manage the ML lifecycle, including data prep, training data generation, feature engineering, optimization, experimentation, reproducibility, deployment and end-to-end workflow management

? Enable ML and Deep Learning capabilities at vast scale by developing the necessary systems, tools, technologies and integrations as part of the ML Platform offering

? Help accelerate the velocity from idea to interference in production

? Contribute to capabilities around data programming, data augmentation (transformation function), active learning (slicing function) for training data, and transfer learning

? Engineer the de-bias, ethics, security and compliance aspects of ML pipelines, centralized feature store, model metastore, and inference metrics store etc.

? Work with partners and stakeholders to identify data acquisition opportunities, create requirements, transform large volume data into AI ready high quality relevant datasets

? Achieve quality ML data using a triad of people, process & technology

? Identify, assess and implement 3rd party technologies that may complement Stats Perform capabilities, and accelerate advancement of critical features; maintain strong collaborative relationships with 3rd party technology providers",TalentCraft,"Chicago, IL",Staffing & Outsourcing,Business Services
Machine Learning Engineer,"Multiple OpeningsWE ARE OPEN TO CHICAGO AND REMOTEStats Perform is the market leader for Sports AI. We bring the deepest breadth of data, sports research, news and video content, and unrivaled AI-powered solutions to media and broadcasters, technology companies, global brands, sportsbooks, fantasy providers, teams and leagues. Stats Perform powers storytelling through natural language generation for broadcasters and tech companies, unlocks boundless player props and precise projections for sportsbooks, and generates predictions to improve team performance and player evaluation. With more than 20 AI patents issued or submitted, Stats Perform is the leading innovator in sports. We are committed to revolutionizing sports through AI.Stats Perform's extensive list of customers includes four of the top-five most popular global sports broadcast companies, seven of the top-10 global tech companies, all of the top-10 sportsbooks and seven of the top-10 football (soccer) franchises. We collect more than 30 million unique data points and distributes them to more than 1,800 customers, reaching over three billion fans a year. Stats Perform employs more than 1,600 full-time employees across 25 countries and is home to the largest sport-focused AI team with more than 40 artificial intelligence scientists collaborating with over 100 engineers creating AI solutions. These innovations will be the foundation of the future strategy of the new entity allowing rights-holders, leagues, media, and gaming partners to derive the most value and develop the richest experiences for over 3 billions sports fans.As you can imagine, such an ambitious vision takes a great team with a strong desire to explore and innovate. We are growing our AI teams to improve and expand our core technologies and help solve many unique and interesting problems around sensing, tracking, understanding and predictions. And, in building new products that never existed before, we are redefining how fans worldwide experience sports.ResponsibilitiesWe are looking for a Machine Learning Engineer to build world-class machine learning platform solutions. You will be responsible for empowering data scientists and AI scientists by developing a collection of industry-strength platform services to greatly improve scientists productivity and facilitate innovation. Your responsibilities include, but not limited to:? Build Stats Perform's Machine Learning platform and services to support major AI and Data Science use cases? Manage the ML lifecycle, including data prep, training data generation, feature engineering, optimization, experimentation, reproducibility, deployment and end-to-end workflow management? Enable ML and Deep Learning capabilities at vast scale by developing the necessary systems, tools, technologies and integrations as part of the ML Platform offering? Help accelerate the velocity from idea to interference in production? Contribute to capabilities around data programming, data augmentation (transformation function), active learning (slicing function) for training data, and transfer learning? Engineer the de-bias, ethics, security and compliance aspects of ML pipelines, centralized feature store, model metastore, and inference metrics store etc.? Work with partners and stakeholders to identify data acquisition opportunities, create requirements, transform large volume data into AI ready high quality relevant datasets? Achieve quality ML data using a triad of people, process & technology? Identify, assess and implement 3rd party technologies that may complement Stats Perform capabilities, and accelerate advancement of critical features; maintain strong collaborative relationships with 3rd party technology providersQualifications? 3+ years of relevant industry experience in Data & analytics platform or machine learning and data science? Bachelor's degree in Engineering, Computer Science, Mathematics, Computational Statistics, Machine Learning or related STEM fields? Verbal/written communication and presentation skills, including an ability to effectively communicate with both business and technical teams, and both internal and external stakeholders? An open minded, structured thinker? A team player and consensus builder? Intellectual curiosity and excellent problem-solving skills, including the ability to structure and prioritize an approach for maximum impact? Experience in projects involving large scale multi-dimensional datastore, complex business infrastructure, and cross-functional teams, and track-record of successfully launched ML projects in production? Hands on experience with building enterprise grade machine learning and data platforms? Familiarity with common machine learning algorithms (random forest, XGBoost, etc.)? Familiarity with advanced ML techniques (neural networks/deep learning, reinforcement learning, active learning, data augmentation and GAN etc.)? Experience with high-level programming languages and big data tools and ecosystems? In-depth working knowledge of cloud infrastructure such as AWS or Google Cloud? Experience in integrating with internal and external complex systems that are able to scale and demonstrate security, reliability, scalability, and cost efficiency","STATS PERFORM
2.7","Chicago, IL",TV Broadcast & Cable Networks,Media
Data Engineer,"We are looking for a talented, passionate Data Engineer with the skill and desire to contribute to our team. In simplest terms, you'll be building the foundation upon which we grow our business.

If you have experience working to extract knowledge and actionable information from multiple data sources, then we would love to talk with you. If you are the type of person who comes to work every day expecting to learn, contribute, teach, and have fun, then we think you will fit right in.

About our Team

We aim to derive meaning from our data, enabling us to run our business better, and also equip our clients to do the same. We believe in agile software development (lowercase 'a') and use elements from Scrum and Lean as a base for how we manage our work. 'Inspect & Adapt' is more than just a catchphrase to us. Most of our development work is done in Python and we use Airflow for orchestration of our data pipelines. We pair as-needed, but not as a rule. We are willing to have every problem under the sun exactly once, in exchange for never having the same problem twice.

Core Responsibilities & Qualifications
In this role, you will focus on the design, implementation, operation, and refactoring of data management systems to meet the Brads Deal's business needs. This includes designing how the data will be stored, consumed, and integrated into our systems.
You will take business requirements, transform them into data models, and develop ETL processes to populate those models. We are a small (and growing) team so it's important that you enjoy working a project from end-to-end.
You will identify, design, and implement internal improvements to how we process data. This could include automating manual processes, optimizing data delivery, and re-designing infrastructure for greater scalability.
You should have hands-on experience with a variety of the data warehousing concepts and practices, covering both technical development as well as 'not-necessarily technical practices' such as data governance. This list of experiences includes data manipulation, database partitioning, data structures, data management, and best engineering practices.
You should have advanced working SQL knowledge and experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of database platforms.
You have a successful history of manipulating, processing and extracting value from large disconnected datasets.
You have experience with scripting languages (We use Python).
In addition to developing and implementing ETL processes, you have experience dealing with performance and scaling issues.
You have at least 3+ years of end-to-end experience with data warehousing and BI systems. This includes data modeling, ETL architectures, OLAP, and Big Data tools (such as Hive).
You have hands-on experience with AWS and the different data tools that are offered on that platform (Redshift, EMR, Kinesis, S3, etc).
About Us

Shop Smart, one of Forbes' 100 Most Promising Companies and a 101 Chicago Best and Brightest Organization, publishes deals and coupons from national retailers across a network of sites. The flagship, Brad's Deals, is the largest editorial-driven deal site with over 5m monthly unique visitors.

Launched in 2002, the rapidly growing company has changed the way millions of consumers shop and is a leader in our space and in the Chicago technology community. We have relationships with over 2,500 top retailers (Amazon, Target, Dell, etc.), exposure to over 50M consumers a year and a consistent national media presence (USA Today, Today Show, WSJ, MSNBC).
Please note: Due to the potential personal and business impacts of Covid-19, Brad's Deals is taking a proactive approach by allowing our employees to work from home. As such, our hiring teams will be conducting virtual interviews with potential candidates as we continue to monitor the effects of the pandemic across our local community.","Brad's Deals
4.1","Chicago, IL",Internet,Information Technology
Data Engineer,"Riskonnect is the leading integrated risk management software solution provider that empowers organizations to anticipate, manage and respond in real-time to strategic and operational risks across the extended enterprise.Riskonnect is the only provider ranked in the leadership and visionary quadrants by world renowned industry analysts - Gartner, Forrester and Advisen RMIS Review.We employ more than 500 risk professionals in the Americas, EMEA and Asia Pacific and serve over 900 customers across 6 continents.The combination of innovative risk technology, a customer success mindset, and employee-first belief makes Riskonnect a sought after place to work.

Responsibilities:
Develop strategy for new multi-platform data integration and analytics.
Develop strategy for new multi-platform-sourced data lake.
Contribute to API strategy to facilitate application connectivity and analytics.
Contribute to the maintenance and evolution of best practices.
Contribute to process documentation.
Perform multiple proofs of concept (POCs).
Contribute to implementation plan for decided-upon solution(s).
Required Qualifications:
Experience with JavaScript/Java/ Python or Jitterbit and other developer languages.
Experience with Data Analytics.
Experience with Web Services and APIs.
Experience in the development of batch and real-time data integration and data consolidation processes.
Experience with machine learning, AI, and data lakes.
Proficiency in TSQL/PLSQL query-writing, stored procedure development, and views.
Strong analytical skills with ability for problem-solving.
Understands the importance of data provenance and the ability to demonstrate it to clients.
Detail oriented, organized, self-motivated.
Preferred Qualifications:
Experience with Salesforce.
Experience in the Risk Management, Healthcare, Financial, and/or Insurance industries is recommended.
Experience with Financial data sets, involving financial validation.","Riskonnect
3.7","Chicago, IL",Enterprise Software & Network Solutions,Information Technology
Data Analyst,"Show expertise in data quality assurance

Establish data quality reporting procedures and analyze data quality reports Identify potential irregularities across several internal/external data sources

Investigate data variances at their root source and resolve issues as appropriate

Liaise between management, technical staff and subject matter advisors Understand business matters, troubleshoot problems and develop responses

Establish & manage a database focused risk prototype customization platform","Green Key Resources
4.5","Chicago, IL",Staffing & Outsourcing,Business Services
Data Engineer,"Level Ex is transforming the way medical professionals hone their skills by practicing high-risk procedures and earning training credit with the latest medical devices and diagnostic treatments in our industry-leading 3D mobile games. In less than four years, Level Ex has exponentially grown, hiring top talent from the video games industry, the digital health ecosystem, and leading medical institutions. Our clients include top 20 pharmaceutical, biotech, and medical device companies including Baxter, Pfizer, Merck, and Medtronic, as well as leading medical associations.

We're now looking for an experienced Data Engineer who can build and refine a centralized data warehouse that is efficient, flexible, and scalable in a pioneering domain that combines mobile games data with healthcare provider data. We need a self-starter that will marshall the company’s data and surface it to business users and data scientists, and that will develop data pipelines to fuel data applications and business intelligence.

What You’ll Be Doing with Us
Architect, build and refine data warehouse that is scalable, efficient, and flexible, as new games and features are introduced.
Develop and maintain ETL pipelines from multiple data sources -- telemetry, sales, product cost, marketing, etc -- to fuel data applications and business intelligence.
Implement best-practices with metadata files and data models. Documenting pipeline details, changes to telemetry, and other important information.
Load new data sources into a centralized data warehouse.
Discovering and fixing data quality, structure and integrity issues.
Defining telemetry details to add or change existing event data. Identifying data and structure needed in order to analyze mobile games with different design patterns.
Leading large projects on a data & analytics roadmap.
Deploying and supporting predictive models to optimize marketing or operations.
Writing and monitoring JIRA/development tickets.

Who We Want to Meet
3+ years of experience working as a data architect or engineer.
3+ years of experience in building data pipelines.
3+ years of writing SQL.
B.S. or M.S. in Computer Science, Mathematics, Statistics, Economics, Analytics, Engineering or equivalent combination of education and experience.
Strong working knowledge of one or more of the following tools -- Python, Scala, R, Spark, AWS.
Ability to collaborate effectively and work as part of a team at a growing start-up.

Bonus Points Awarded For
M.S. or Ph.D. in Computer Science, Mathematics, Statistics, Economics, Analytics, Engineering or equivalent combination of education and experience.
Experience working on mobile game analytics and/or on medical analytics.
Experience in AWS and Snowflake.
Experience in architecting data structures for business intelligence.

How We Make You Happy
Multiple health insurance plans with 100% company-paid premiums
401(k) with company-paid match
Dental and vision insurance
Pre-tax flex spending and commuter accounts
Paid vacation, sick days and holidays
Downtown Loop location convenient to public transportation, and plenty of nearby food options
Unlimited cold brew and gourmet coffee, kombucha, Bevi sparkling water, and craft beer
Full kitchen and food options including breakfast, and both healthy and comfort snacks
Team after-hours events, like Board Game Night

Interested?
Just upload your resume or LinkedIn profile PDF below to apply. We look forward to hearing from you and exploring the possibilities.

Level Ex is an Equal Opportunity Employer (EOE).

No Agencies or Recruiters, please.
Legal authorization to work in the U.S. is required. We will not sponsor individuals for employment visas, now or in the future, for this job.","Level Ex, Inc.
3.6","Chicago, IL",Video Games,Media
Data Engineer,"Job Description
We have partnered with a large Healthcare provider the Chicago, IL area to provide them with a Data Engineer.

Please review the below description and if you are interested please contact:
Rhondolyn Kilgore at rkilgore@relevante.com
Responsible for expanding and optimizing our data and data pipeline architecture, as well as optimizing data flow and collection for cross functional teams. The ideal candidate is an experienced data pipeline builder and data wrangler who enjoys optimizing data systems and building them from the ground up. The right candidate will be excited by the prospect of optimizing or even re-designing our company’s data architecture to support our next generation of products and data initiatives.

Responsibilities of the Data Engineer:
Create and maintain optimal data pipeline architecture,
Assemble large, complex data sets that meet functional / non-functional business requirements.
Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc.
Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using SQL and AWS ‘big data’ technologies.
Build analytics tools that utilize the data pipeline to provide actionable insights into customer acquisition, operational efficiency and other key business performance metrics.
Work with stakeholders including the Executive, Product, Data and Design teams to assist with data-related technical issues and support their data infrastructure needs.
Keep our data separated and secure across national boundaries through multiple data centers and AWS regions.
Create data tools for analytics and data scientist team members that assist them in building and optimizing our product into an innovative industry leader
Work with data and analytics experts to strive for greater functionality in our data systems.
Requirements of the Data Engineer:
Bachelor’s degree in Computer Science, Statistics, Informatics, Information Systems or another quantitative field (Masters Preferred).
5+ years of experience in a Data Engineer role
Advanced working SQL knowledge and experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases.
Experience building and optimizing ‘big data’ data pipelines, architectures and data sets.
Experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement.
Strong analytic skills related to working with unstructured datasets.
Build processes supporting data transformation, data structures, metadata, dependency and workload management.
A successful history of manipulating, processing and extracting value from large disconnected datasets.
Working knowledge of message queuing, stream processing, and highly scalable ‘big data’ data stores.
Experience supporting and working with cross-functional teams in a dynamic environment.
Experience with health care datasets, clinical data, payer/claims data, SDOH data, etc.
Experience with big data tools: Hadoop, Spark, Kafka, etc. (Preferred)
Experience with relational SQL and NoSQL databases, including Postgres and Cassandra.
Experience with data pipeline and workflow management tools: Azkaban, Luigi, Airflow, etc
Experience with AWS cloud services: EC2, EMR, RDS, Redshift
Experience with stream-processing systems: Storm, Spark-Streaming, etc.
Experience with object-oriented/object function scripting languages: Python, Java, C++, Scala, etc.
Skilled in problem-solving with strong attention to detail.
Excellent customer service skills and the ability to react diplomatically and patiently to internal and external customers.
Excellent follow-up skills paired with the ability to multi-task and determine root causes.
Strong written and verbal communication skills coupled with the ability to read, analyze and interpret technical procedures.
Benefits of the Data Engineer:
Health Insurance
Dental Insurance
Life Insurance
Long Term Disability
Join our Talent Network - https://relevante.jobs.net/en-US/join","Relevante, Inc
3.1","Chicago, IL",Consulting,Business Services
Data Analyst,"Job Description
Job description
Interpret data, analyze results using statistical techniques and provide ongoing reports
Develop and implement databases, data collection systems, data analytics and other strategies that optimize statistical efficiency and quality
Acquire data from primary or secondary data sources and maintain databases/data systems
Identify, analyze, and interpret trends or patterns in complex data sets
Filter and “clean” data by reviewing computer reports, printouts, and performance indicators to locate and correct code problems
Work with management to prioritize business and information needs
Locate and define new process improvement opportunities
Requirements
Proven work experience as a data analyst or business data analyst
Technical expertise regarding data models, database design development, data mining and segmentation techniques
Strong knowledge of and experience with reporting packages (Business Objects etc), databases (SQL etc), programming (XML, Javascript, or ETL frameworks)
Knowledge of statistics and experience using statistical packages for analyzing datasets (Excel, SPSS, SAS etc)
Strong analytical skills with the ability to collect, organize, analyze, and disseminate significant amounts of information with attention to detail and accuracy
Adept at queries, report writing and presenting findings
Master's in Computer Science or Engineering Management or Project Management or Information Systems/Technology (Preferred)
Powered by JazzHR

6WAotTamka","Staffigo Technical Services, LLC
5.0","Chicago, IL",IT Services,Information Technology
Data Engineer,"Concurrency, Inc. is seeking a Data Engineer which requires both broad and deep technology knowledge and the ability to develop data solutions by mapping customer business requirements to end-to-end technology solutions. Demonstrated ability to engage and deliver in technical projects related to agility, business value, data warehousing, and cloud-oriented data solutions is also a must. Data & AI Engineers are key enablers for other consultants and partner staff by sharing knowledge in large enterprise implementations, best practices, and frameworks or patterns.
Responsibilities
Assist and author functional requirements and technical design documentation
Participate in milestone meetings and planning discussions for aligned client projects
Work with BA and PM teams to plan project sprints, scope and resource allocation
Manage at project milestones to ensure successful solution delivery and client satisfaction
Continuous learning and research on modern data solutions, and relevant technologies
Promote service offerings through blogs posts, industry groups, and speaking events
Qualifications
Bachelor's Degree in Computer Science or related fields, or the equivalent in work experience
Three or more years of experience in enterprise systems and warehouse architecture design, development, testing, deployment, and operational support
Experience with advanced integration scenarios such as hybrid cloud architectures
Experience with enterprise architecture, server topologies, and distributed systems
Knowledge of Agile methodologies
Demonstrated verbal and written communication skills
Demonstrated technical documentation skills
Prior consulting experience is a plus
Skill Requirements
Azure ETL tools such as Synapse, Databricks or Data Factory
Azure Data Platform experience required
Data Modeling (Tabular)
Data security monitoring and data governance
Power BI
SQL Server and T-SQL Development
Up to 15% travel required
Machine Learning languages such as R or Python a plus
IoT experience a plus
Spark experience a plus

Encouraging a healthy work/life balance and providing our colleagues great benefits are just part of what makes Concurrency a great place to work. Concurrency full-time employees receive complete and competitive benefits. We offer a collaborative work environment, competitive compensation, generous work/life opportunities and a comprehensive benefits package that includes paid time off plus holidays. In addition, all colleagues are eligible for a number of rewards and recognition programs, excellent training program and bonus opportunities.","Concurrency
3.8","Chicago, IL",IT Services,Information Technology
Data Engineer,"Job Description
Hello,

Kani Solutions, Inc. A New Jersey based Technology Consulting and Staffing services company. Our Industry focus is Health & Life Sciences, Energy & Utilities, Financial Services, Public Services and Retail. Our team is Dynamic and is focused to our Client needs. Our Team is geared to work with Consultants and our Clients to achieve higher performance. We want to work with you and want to welcome Candidates who are Talented, Passionate, Dedicated and have Ambition to grow.

Job Title: Data Engineer

Location: Chicago, IL

Duration: 6+ Months

Required Skills:
Experience with Spark, Hive and Yarn.
Experience with AWS cloud services: EMR and Redshift.
Must have hands-on S3
Thanks and regards

Sai Kumar

Sr. Executive- Recruitment

Kani Solutions, Inc.

P: (609)-952-6461

F: (609) 751 5067

sai@kanisol.com","Kani Solutions
4.6","Chicago, IL",Staffing & Outsourcing,Business Services
Data Engineer,"Chicago, Illinois
Skills : AWS (s3, redshift, EMR, EC2, lambda, SNS), unix shell scripting,python spark,scala
Description : MUST HAVE

AWS (s3, redshift, EMR, EC2, lambda, SNS),
unix shell scripting,python

spark,scala


PREFER TO HAVE

snowflake,presto,
arrow,Airflow,Hadoop,Hive

AWS (s3, redshift, EMR, EC2, lambda, SNS), unix shell scripting,python spark,scala","Collabera
4.1","Chicago, IL",IT Services,Information Technology
Data Engineer,"The Business

GradTests.com is a leading provider of practice psychometric tests to graduates, students and young professionals.

The Role

The core purpose of the role is to make high quality, high availability, accurate data available for our data analysts and data scientists to do their analysis, derive their insights and build their models. You are the Scotty Pippin to the Michael Jordans. You are the Xavi to the Messis.

You'll do things like:
Ensure our data warehouse is well structured, running smoothly and efficiently for all business intelligence
Set up and maintain various data pipelines used for customer analytics, marketing analytics and product analytics
Skills and experience

Non negotiables:
SQL
Python
Strong knowledge of traditional relational databases - we don't mind which
Some experience with cloud technologies - again we don't mind if it's AWS, GCP or Azure
Experience in any streaming technology
Great experience in using third party APIs at scale
Some web scraping experience
An obsession with data quality
Strong communication skills
Nice to haves:
Experience in working with analysts
Any basic knowledge of advanced analytics techniques
Experience in a visualisation tool like Tableau
Job Types: Full-time, Contract

Salary: $100,000.00 /year

Work Remotely:
Yes",GradTests (gradtests.com.au),"Chicago, IL",-1,-1
Data Engineer,"RAPP Chicago is looking for a Data Engineer

to join our rapidly growing Technology Team.


ABOUT RAPP

Our purpose

We are the agency absolutely, utterly, fiercely focused on the individual. We use our data, technology and creative smarts to make meaningful, connections with every single person a brand knows.

Our family

We are part of the OPMG group, which is in turn a part of Omnicom. This group also includes Critical Mass, Targetbase, Proximity, Credera, and sparks&honey and other well-known agencies.

Our clients

From national defense, to buying a sweet new ride, to biting into a Big Mac®, we provide smart solutions for companies like Army, Toyota, McDonald's, and more.

We are looking for people who want to strategically and functionally lead a business that is based in database marketing principles, anchored in data and insights at the core, and understand the need to create a connected experience through traditional and emerging channels, across all disciplines-data-driven creativity at its finest.

ABOUT YOU

As a data engineer, you define solutions for the use, extraction and manipulation of data - driven by the balanced combination of business needs and consumer preferences. You work in close collaboration with multidisciplinary teams to provide the data needed, in the optimal format for making critical, real-time decision.

You can communicate through a project with ease and understanding and you know your tools like the back of your hand.

You are experienced with writing complex SQL statements and mapping relational database structure. You strive in designing & continuously improving data workflows using enterprise campaign management solutions such as Adobe Campaign, Unica, Eloqua, Marketo and/or Salesforce Marketing Cloud.

You may have experimented in the past with BI tools such as Tableau, Domo or QlikView, and have R/Python in your radar

Most importantly not only can you do the job, you can explain it to a relative and they actually understand. You are self-directed, highly motivated and have fun while working hard in a fast-paced environment.","RAPP
3.2","Chicago, IL",Advertising & Marketing,Business Services
Data Engineer,"Trident Consulting is seeking a "" Data Engineer with one of our clients inMcLean,VA ""A global leader in business and technology services
Exact Job Location/Work Address Richmond, VA/Chicago, IL
Project Duration (relevant for CWR) 7+ Months
Required Technologies
Strong Programming experience with object-oriented/object function scripting languages: Python/Scala, Spark.
Experience with big data tools: Hadoop, Apache Spark etc.
Experience with AWS cloud services: S3, EC2, EMR, RDS, Redshift
Experience with stream-processing systems: Storm, Spark-Streaming, etc. (Nice to have)
Experience with relational SQL, Snowflake and NoSQL databases

Job Description: Detailed overview of functional and technical role expectations Candidate with 5+ years of experience in a Data Engineer role, who has attained a Graduate degree in Computer Science, Statistics, Informatics, Information Systems or another quantitative field. They should also have working experience using the following software/tools:
3+ years of experience (Mid-level) Strong Programming experience with object-oriented/object function scripting languages: Python/Scala, Spark.
3+ years of experience (Mid-level) Experience with big data tools: Hadoop, Apache Spark, Kafka, etc
1+ years of experience Experience with AWS cloud services: S3, EC2, EMR, RDS, Redshift
Experience with stream-processing systems: Storm, Spark-Streaming, etc. (Nice to have)
1+ Years of experience Experience with relational SQL, Snowflake and NoSQL databases, including Postgres and Cassandra.
Responsibilities for Data Engineer:
Create and maintain optimal data pipeline architecture, Assemble large, complex data sets that meet functional / non-functional business requirements.
Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability etc.
Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using SQL and AWS 'Big data' technologies.
Build analytics tools that utilize the data pipeline to provide actionable insights into customer acquisition, operational efficiency and other key business performance metrics.
Work with stakeholders including the Executive, Product, Data and Design teams to assist with data-related technical issues and support their data infrastructure needs.
Create data tools for analytics and data scientist team members that assist them in building and optimizing our product into an innovative industry leader.

Preferred Skills Python/Scala, Hadoop, Apache Spark, AWS, Snowflake/SQL knowledge
Years of Experience Required 5+

Trident Consulting handles the staffing and management of part all of the recruitment process for our customers wishing to outsource their staffing requirements. From job profiling, providing new staff, technology, to onboarding a new hire we support our customers in their future business needs.

Our Client is one of the world's leading professional services companies, transforming clients' business, operating and technology models for the digital era. Our unique industry-based, the consultative approach helps clients envision, build and run more innovative and efficient businesses. Headquartered in the U.S., a member of the NASDAQ-100 is ranked 205 on the Fortune 500 and is consistently listed among the most admired companies in the world.","Trident Consulting
4.2","Chicago, IL",-1,-1
Data Analyst,"Job Description
We are seeking a resource who loves data, analytics, and putting the two together to help drive accountability and innovation. We are a financial services firm based in the loop offering a great opportunity for growth, development, and the chance to work with the executive team to drive change.

PROJECT: Analytics for cost of business for IT services

WORK TO BE PERFORMED:
Gather functional and business requirements and rapidly translate information into a working set of operational and financial models, dashboards and management reports
Import, transform and rationalize data from systems of record into selected Technology Business Mgmt (TBM) tool
Operationalize data monthly by loading, validation and reviewing on a timely basis
Participates in collaborative efforts with domain leads, finance, and service lines to drive improved communication and shared direction.
Identifies cost / benefit of IT portfolio to properly identify gaps in bottom line
Perform other duties as assigned.
SKILL AND EXPERIENCE REQUIRED:
Previous work experience in a highly regulated, capital markets company preferred
Understanding of IT infrastructure domains
Knowledge of IT services and financial management process and best practices such as budgeting, cost allocations, capital and operating expense handling
Strong analytical, problem solving and troubleshooting skills with the ability to exercise mature judgment.
Demonstrated verbal/written communication skills to be able to articulate ideas clearly and concisely.
Ability to provide solutions that meet the business objectives and deliver on time, on budget, with a high degree of quality
Experience with TBM tools such as Apptio
Strong data transformation skills using MS Excel
Bachelor’s Degree in Information Systems, Business Management, Finance, or related field
MBA or related graduate level course work a plus
Minimum of 4 years of relevant work experience
Powered by JazzHR

vSZc0T9hpB",TalentDash,"Chicago, IL",Enterprise Software & Network Solutions,Information Technology
Data Engineer,"Requisition Number: 75536

We arewww.Insight.com (NSIT).

As a Fortune 500-ranked global provider of digital innovation, cloud/data center transformation, connected workforce, and supply chain optimization solutions and services, we help clients successfully manage their IT today while transforming for tomorrow.

From IT strategy and design to implementation and management, our employees help clients innovate and optimize their operations to run smarter.
Microsoft Worldwide AI Partner of the Year, 2018
Microsoft Worldwide Modern Desktop Partner of the Year, 2018
Microsoft US Partner Award for Intelligent Cloud - Application Innovation, 2019
Microsoft US Azure Team Partner Choice Award - Data and Artificial Intelligence, 2019
Our Insight Digital Innovation team is searching for an experienced, passionate and professional Data Engineer to join our team.

You’ll utilize the most cutting edge technology such as machine learning, artificial intelligence, big data, IoT, and azure. Here you will have practical, hands-on knowledge of modern data architectures and tools such as data warehousing, ETL/ELT, analytics, and the Azure cloud platform. You should be driven to provide quality solutions to challenging problems. You will work closely with client stakeholders and an award-winning team of engineers, architects and thought leaders to design, build and implement next-generation solutions in advanced analytics, Big Data, BI and the cloud.

What you’ll do at Insight:
You will build enterprise-grade data solutions for a variety of external clients.
Design and code solutions to tough data challenges and provide feedback on others’ work.
Work directly with client stakeholders to develop technical solutions for business cases.
Aggressively grow your skillset and expertise to meet the emerging needs of our clients.
What you’ll need to join Insight:
4+ years of experience working with data and data analytics development within the Microsoft data platform and an excellent grasp of some of following technologies:
SQL Server, Azure SQL Database, and Azure SQL Data Warehouse
Power BI
Tableau
Analysis Services and DAX
Reporting Services
Integration Services
Azure Data Factory
PowerShell scripting
Azure Automation
2 year of experience in some of the following:
Big Data technologies such as Hadoop or HDInsight, Hive, Pig, Python, Spark, Oozie, or any of the other tools with the Hadoop ecosystem
Azure Data Lake and Azure Data Lake Analytics
Predictive analytics: R, Azure Machine Learning
Strong analytical and reasoning skills that result in clear technical execution.
Skill at translating requirements into clean, efficient, quality code
Proven ability to prioritize, self-direct and execute at velocity
Passion to deliver craftsman-quality work both individually and as part of a team
Solid communication skills with both technical and non-technical stakeholders
Desire to learn new skills and grow competencies
Bachelor’s degree in Computer Science or related discipline
Requires travel to Chicago Area client sites (local only).
In the News

•https://searchitchannel.techtarget.com/feature/Data-center-infrastructure-spending-gets-AI-boost

•https://www.insight.com/en_US/about/newsroom/press-releases/2019/07012019-insight-recognized-at-no14-on-crns-2019-solution-provider-500-list.html

•https://investor.insight.com/press-release/insight-enterprises-acquire-pcm-inc

•https://insight.hqprod.businesswire.com/press-release/insight-hosts-global-ai-competition-healthcare-innovation-cincinnati

•https://investor.insight.com/press-release/houston-schools-deploying-iot-enabled-building-safety-platform-improve-emergency
https://investor.insight.com/press-release/insight-recognized-magic-quadrant-managed-workplace-services-north-america
Today's talent leads tomorrow's success. Learn about careers at Insight: jobs.insight.com.

Insight is an equal opportunity employer, and all qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, disability status, protected veteran status, sexual orientation or any other characteristic protected by law.



The position described above provides a summary of some the job duties required and what it would be like to work at Insight. For a comprehensive list of physical demands and work environment for this position, click here.

Today, every business is a technology business. Insight Enterprises, Inc. empowers organizations of all sizes with Insight Intelligent Technology Solutions™ and services to maximize the business value of IT. As a Fortune 500-ranked global provider of digital innovation, cloud/data center transformation, connected workforce, and supply chain optimization solutions and services, we help clients successfully manage their IT today while transforming for tomorrow. From IT strategy and design to implementation and management, our 6,800 employees help clients innovate and optimize their operations to run smarter. Discover more at insight.com.
Founded in 1988 in Tempe, Arizona
7,400+ teammates in 19 countries providing Intelligent Technology Solutions for organizations across the globe
$7.1 billion in revenue in 2018
Ranked #417 on the 2018 Fortune 500, #12 on the 2018 CRN Solution Provider 500
2018 Dell EMC Server Partner of the Year, 2018 Intel Retail Solution Partner of the Year, 2018 Microsoft Worldwide Artificial Intelligence Partner of the Year
Ranked #23 on the 2019 Fortune 50 Best Workplaces in Technology and #5 on the Phoenix Business Journal 2018 list of Best Places to Work (Extra Large Business)
Signatory of the United Nations (UN) Global Compact and Affiliate Member of the Responsible Business Alliance
Today's talent leads tomorrow's success. Learn about careers at Insight: jobs.insight.com.

Insight is an equal opportunity employer, and all qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, disability status, protected veteran status, sexual orientation or any other characteristic protected by law.

Posting Notes: Chicago || Illinois (US-IL) || United States (US) || MSOP-SC; None || None || US - Chicago, IL ||","Insight Enterprises, Inc.
4.0","Chicago, IL",Enterprise Software & Network Solutions,Information Technology
Data Engineer,"Description


At our heart, we are technologists with a keen understanding of business environments, challenges, and initiatives. Our team of experts bring decades of technical and consulting knowledge, project leadership, and an understanding of complex problem-solving. We have an established track record in all things Microsoft Azure and Microsoft 365 including Application Services, Azure Infrastructure, Data Platform Services, Machine Learning, User Experience, and IoT.

We are seeking Data Engineers as a critical part of our Azure Cloud Enablement (ACE) team.
Location: Chicago IL
Travel: Up to 30%
ACE in a nutshell


The ACE team sits at the intersection of technology, innovation, creativity, and blended learning. At our core, we are obsessed with providing customers with the best solutions to their biggest challenges.

We build B2B enterprise software: smart vehicles, custom web apps that hit hundreds of thousands of people, and big data warehouses are just some of what you will have the opportunity to develop. We are Microsoft Gold Certified in Application Development, Cloud Platform, Data Analytics, Data Platform and many more.

You’ll work out of our bustling Chicago office, side-by-side with experts in all things Data Platform, Data Science, Application Development, User Experience, and Cloud Infrastructure. Expect rapid career growth—we preach recognition and reward those with the aptitude and attitude to get it right.

Once you’re here…


You'll have full access to our reference architecture. Our services methodology is built on reusable technology components, patterns, and processes that have been refined and proven on thousands of production solutions. You’ll learn to develop complex data architectures, solve for real-time data needs of large businesses, and navigate the changing landscape of the Azure stack.

You will collaborate regularly with our experts, work across numerous industries, clients, and technologies. You will learn something new every day and begin adding value to our team almost immediately. You’ll join our flagship Launch Program to get you up to speed as quickly as possible.

You will partner with clients across several key industries including Healthcare, Manufacturing and Industrial Products, Financial Services, Professional Services, Engineering and High Technology, Retail and more.

Beyond the tech, you'll benefit from dollar for dollar 401(k) matching (up to 6% of your salary), ongoing structured learning opportunities, subsidized healthcare, vision, and dental plans (amongst others), a fully stocked snack, coffee, and drink bar, and a laid-back team looking to disrupt the status quo.

Relevant experience


Our basic requirement is that you must have completed a relevant job, program, degree, or internship at some point in the recent past. You should have experience working with others collaboratively, thinking critically about solving problems and technically executing. You should be hungry to learn new technology, humble with your willingness to help others, and socially capable of working collaboratively.
You must be able to work with customer stakeholders to understand business and technical requirements.
You should have skill in SQL at an advanced level, including complex queries, data definition, constraint specification, coding with SQL or similar, and database modeling.
You are inherently iterative, with knowledge of Agile methodologies, estimation techniques, and (optionally) workshop and prototype techniques.
You have a strong understanding of one or more of the following:
Power BI or similar data visualization tool
Azure or similar cloud platform
Python or Spark or similar Data Engineering language
PowerShell or similar scripting language
Azure Data Warehouse (ADW) or similar MPP database platform
Azure Data Lake (ADL)
Nice to haves:

Experience with Azure Data Platform (Azure Data Factory v.2, Azure Data Warehouse, Databricks, etc.)
Knowledge of the overall internal structure of a database system including indexing, query processing, transaction management, and fault tolerance.
Ability to design a database, implement a design in a real database system, and construct user interfaces to the database via an API or 3rd party tool.
2+ internships in related roles.","Capax Global
4.7","Chicago, IL",IT Services,Information Technology
Data Engineer,"GoHealth is looking for Data Engineers who will be responsible for the design, development, and delivery of its various batch and streaming data pipelines. We are seeking candidates who have experience in building large batch pipelines, as well as experiencing building stable, high throughput streaming systems. In this role, you will work with other members of Engineering, Product and Project Management, and various business groups to ensure timely availability of usable data to all parts of the business that need it.

Due to the unprecedented situation of COVID-19, GoHealth has decided to protect our current and future employees by managing our business remotely. This is inclusive of interviewing, onboarding and each role day-to-day. Please consider that our roles will not be remote long-term and will return to an office setting once we're safe to do so following the guidance of local health authorities' and the CDC.

Responsibilities:
Design, develop and deploy batch and streaming data pipelines.
Monitor and ensure operational stability of data pipelines.
Create and maintain documentation of the technical detail design, operational support and maintenance procedures for all data pipelines.
Ensure data quality and compliance with development, architecture, reporting, and regulatory standards throughout entire data pipeline.
Collaborate with the rest of the Engineering Team, subject matter experts and department leaders to understand, analyze, build and deliver new data-related processes and/or reports.
Skills and Experience:
Bachelor's Degree in computer science or equivalent experience required.
2+ years of experience in the design and development of data pipelines and tasks.
Strong analytical and problem solving ability with strong attention to detail and accuracy.
Understanding of data warehousing concepts and dimensional data modeling.
Hands-on experience with troubleshooting performance issues and fine tuning queries.
Experience extracting data from relational and document databases.
Experience consuming data over HTTP and in formats such as HTML, XML, and JSON.
Knowledge of and experience with a version control system (such as Git, Mercurial, SVN, etc).
Proficiency in Java or Python programming languages.
Familiarity with data warehousing platforms, such as Redshift, Snowflake, SQL Server, etc.
Benefits and Perks:
Open vacation policy
401k program with company match
Medical, dental, vision, and life insurance benefits
Flexible spending accounts
Commuter and transit benefits
Professional growth opportunities
Casual dress code
Generous employee referral bonuses
Happy hours, ping-pong tournaments, and more company-sponsored events
Subsidized gym memberships
GoHealth is an Equal Opportunity Employer
#LI-JC1","GoHealth
3.2","Chicago, IL",Health Care Services & Hospitals,Health Care
Data Analyst,"Data Analyst #411045Job Description:

If you are looking for a company where you can change a life, make a dream come true, and light the way for a better tomorrow, our company is the place where you can shine. We offer a different kind of work culture. A high standard of ethics is mandatory. Quality is our pledge. Diversity is valued. Individual initiative is rewarded. Our company offers an environment where our employees can make a real difference.

The Database Analyst provides expertise in the querying of each database used by RWE Analytics team as part of the project feasibility and/or execution using real-world databases (e.g,EMR, claims, etc.) across entire value chain geographic footprint and therapeutic areas.

The deliverables of the Database Analyst are an integral part of the analytics mission and requires expertise in creation, quality control and maintenance of efficient and rapid queries typically via SQL and SAS; as well as supporting the development and optimization of the database structures of real-world data sets.

The Database Analyst will be able to:

• Recognize issues as they generate and execute queries on existing databases
• Build cohorts and create descriptive analysis summaries in support of requests
• Collaborate with colleagues to address these issues with minimal direction
• Work closely with an RWI Medical Coder to obtain appropriate drug, disease, and procedure codes in the creation of the queries

Additional Info:

At Fast Switch Great Lakes (FSGL), Our Purpose is Our People and Our Planet. We come to work each day and are reminded we are helping people find their success stories. Isnt that cool? Also, Doing the right thing is our mantra. We act responsibly, give back to the communities we serve, and have a little fun along the way.
We at FSGL, have been doing this for 22 years with pride, dedication and plain old-fashioned hard work.
We're a financially strong, privately-held company that is 100% consultant and client focused.
We've differentiated ourselves by being fast, flexible, creative and honest. Throw out everything you've heard, seen, or felt about every other IT Consulting company. We do unique things, and we do them for Fortune 10 companies, Inc. 500 companies, and technology start-ups.
Our benefits are second to none and thanks to our flexible benefit options you can choose just the benefits that you need or want, options include:

• Medical and Dental (Fast Switch pays majority of the medical program)
• Vision
• Personal Time Off (PTO) Program
• Long Term Disability (100% paid)
• Life Insurance (100% paid)
• 401(k) with immediate vesting and 3% (of salary) dollar-for-dollar match

Plus, we have a lucrative employee referral program and an employee recognition culture.
One of our pride points as that in 2013, 2014, 2015, 2016, 2017, 2018 and 2019, Fast Switch was named one of the Top Work Places in Michigan by the Detroit Free Press.
To view all of our open positions, please go to: https://clientapps.jobadder.com/45103/fast-switch
Follow us on Twitter at: https://twitter.com/FastSwitchGL
Follow us on Instagram at: https://www.instagram.com/fastswitchgl/
Find us on LinkedIn at: https://www.linkedin.com/company/fast-switch-great-lakes
And you can become a fan of Fast Switch on Facebook at: https://tinyurl.com/v4p9yy7

Job Requirements:","Fast Switch, LTD
4.3","Northbrook, IL",IT Services,Information Technology
Data Analyst,"KellyMitchell matches the best IT and business talent with premier organizations nationwide. Our clients, ranging from Fortune 500 corporations to rapidly growing high-tech companies, are exceptionally served by our 1500+ IT and business consultants. Our industry is growing rapidly, and now is a great time to launch your career with the KellyMitchell team.

Location:
Downers Grove, IL 60515

Second Optional Work Location:
Chicago, IL 60638

Description:
Performs data collection, analysis, validation and reporting.
Designs, tests, and documents processes, SQL queries, and stored procedures.
Strong analytical and organizational skills also essential.
0 - 2 years experience
Notes From the Manager:
Excel Wizard (Advanced to Expert level)
Low level Data Analyst, no SQL required
Possible contract to hire, no guarantees
Able to perform pivot tables, functions, formulas, v-lookups, pivot reporting, macros, micros
About the Job:
This individual will be organizing, comparing, analyzing data.
They will receive a report from a 3rd party and then compare that report to Univar's internal reports to see where the data differs, understand why it differs, and communicate this to the manager.
This report has over 50,000 cells each report.
The hiring manager will need this individual to also add data, upload, edit, and change data as he sees errors and inconsistencies.
SQL is not required and this is a relatively low level Data Analyst role.
They must appear onsite for the first duration of their training and then will discuss remote work once they get started due to COVID-19","Kelly Mitchell Group
3.6","Downers Grove, IL",Staffing & Outsourcing,Business Services
Data Analyst,"RESPONSIBILITIES:

Kforce has a client that is seeking a Data Analyst in Evanston, IL.

Job Summary:
This position is responsible for assisting the Project Administrator in running data load processes and Quality Control processes. Responsibilities include running data comparison reports as required.

Essential Duties:
Develop a proficient understanding of the Accuity database and the underlying data interactions as related to how the payments products are used
Assist with the preparation of reports to support the data collection effort
Assist with processing third-party data loads
Assist in running international data QC (e.g. setting up and running QC queries)
Assist with technical / data-related tasks of the department
Provide back-up for critical department tasks
Other projects as needed
REQUIREMENTS:
Bachelor's degree or equivalent required
Organized and detail-oriented with strong analytical skills
Excellent oral and written communication skills
Able to independently make decisions, solve problems and handle multiple tasks
Ability to work under pressure and meet deadlines; ability to work overtime
Self-motivated, reliable, and proficient at working independently as well as in a team
Proactive approach in research of various secondary sources
Higher knowledge of relational databases (MS Access); ability to alter, create, and run queries and macros
Technical knowledge of SQL scripting and Java a plus
Kforce is an Equal Opportunity/Affirmative Action Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, pregnancy, sexual orientation, gender identity, national origin, age, protected veteran status, or disability status.","Kforce
4.1","Evanston, IL",Staffing & Outsourcing,Business Services
Data Analyst,"Job Description
Data Analyst

The Data Analyst will be responsible for helping prepare the Company’s ongoing reporting analysis, and to support corporate initiatives, business opportunities and other special projects. Specific responsibilities could include, but are not limited to:
Validating data and ensuring high standards of data quality
Exploring and defining data elements in various systems to help build a data dictionary
Developing and running data for use in statistical models
Querying databases for development and research purposes
Discussing reporting needs with various internal and external stakeholders and developing new tools that will improve our analytics capabilities
Development and tracking of key performance indicators that will be critical in enhancing the understanding of the business to improve decision-making for various levels of internal and external stakeholders
Assisting business areas with deriving actionable insights from their data
Coordinate and facilitate participation from internal and external collaborators to ensure timely progression of analysis and reports.
Work with multiple internal departments (including IT, Sales, Accounting and Operations) and external partners (including Birch Hill) to help deliver upon the Company’s data strategy
Conduct market research analysis and monthly reporting
Perform other miscellaneous duties as required.
Build analytical models and participate in the market data analysis as required by specific initiatives using database or reports provided from external sources
Strong analytical mindset and ease of working at analyzing large quantities of data to extract the essential trends;
Ability to capture and document business and reporting requirements from multiple sources
SKILLS AND EXPERIENCE REQUIRED
Post-Secondary degree in a quantitative field such as Business Administration (Finance/Accounting), Computer Science, Statistics or Physics required
1-3 years of related work experience in an analytical role
Expert level or proficiency in handling, organizing and sorting data in Excel
Ability to perform complex analysis such as regression, forecasting, data modeling
Demonstrated strong analytical and conceptualization skills
Strong problem solving and communication skills
SQL, Python and LookML knowledge a strong asset","MRINetwork
4.0","Des Plaines, IL",-1,-1
Data Engineer,"Data Engineer Signature Consultants has an opportunity for a Data Engineer. For this position the candidate needs to have experience with Spark, Scala, and AWSCloud Infrastructure. The candidate will need to demonstrate strong attention to details, proactive thinking, the ability to adapt to change quickly, and teamwork. Responsibilities Demonstrate disciplined software development leadership Execution and deliver solutions on-time with high bar of quality Work with Product Owners to understand the desired capability, to define and prioritize work, determine deliverables, and manage workloads Lead technical discussions and be able to work and influence a large number of cross-functional teams Build reusable solutions that can be shared across teams Continuously improve software engineering practices Elevate team members to sharpen their skills and grow their careers Qualifications Bachelor's degree or military experience 2+ years of experience with SQL 2+ years of experience with Java or Python, scala, spark 2+ years of experience building applications in a cloud environment (AWS, Azure, or Google Cloud) About Signature Consultants, LLC Headquartered in Fort Lauderdale, Florida, Signature Consultants was established in 1997 with a singular focus to provide clients and consultants with superior staffing solutions. For the ninth consecutive year, Signature was voted as one of the ""Best Staffing Firms to Work For"" and is now the 14th largest IT staffing firm in the United States (source Staffing Industry Analysts). With 28 locations throughout North America, Signature annually deploys thousands of consultants to support, run, and manage their clients' technology needs. Signature offers IT staffing, consulting, managed solutions, and direct placement services. For more information on the company, please visit www.sigconsult.com httpwww.sigconsult.com . Signature Consultants is the parent company to Hunter Hollis httpswww.hunterhollis.com and Madison Gunn httpswww.madisongunn.com .","Signature Consultants
3.6","Chicago, IL",Staffing & Outsourcing,Business Services
Software Engineer,"Data and Software Engineer


The Data and Software Engineer will join the engineering team of a rapidly growing and global start-up in the Alternative Data and FinTech space. You will be responsible for developing cutting edge data analytics, and AI applications as well as onboarding new datasets to be used by our Data Showcasing and PaaS Financial Technology Businesses. You will be responsible for working on numerous innovative technologies and projects that enable date vendors to accelerate their data sales and for global fundamental and quantitative investment managers to generate a higher ROI on their data purchases.

We have developed innovative, next-generation data exploring, and algorithmic testing and trading systems. This position will have the opportunity to participate in pushing your technology and knowledge skills to the next level. The learning curve never stops at CloudQuant.

Day to Day Responsibilities


• Dataset onboarding: You will work with new datasets and internal tools to bring datasets into our data driven systems. This includes mapping data to related companies and building configurations for APIs that utilize those datasets.

• Software Development: Python and C++ development projects depending upon skill set.

Compensation & Benefits:


This is a full-time salaried position with paid time-off, medical and dental benefits, and opportunities for advancement. Bonuses are paid based upon individual and company performance.

Requirements:


• Python 3 (2+ years) with understanding of Pandas, Numpy, Asyncio

• C++ with Templates (2+ years)

• Jupyter Hub / JupyterLab / Jupyter Notebooks (1+ years)

• Bachelor’s Degree – Financial or Technical

• Debugging

• GIT

• Linux

• Continuous Building and Test Systems

• Communication skills (verbal, written)

Would be great if you also have:


• Trading industry interest and/or experience (stocks, futures, FX, crypto, etc.)

• Data science/engineering experience

• Exposure to Machine learning and Recommendation Systems

• Kubernetes

• QT experience

• Javascript

• Grafana
• Airflow

Location:


Chicago, IL

About CloudQuant


CloudQuant provides alternative data showcasing services to alternative data providers including bespoke AI, Machine Learning, and data science services. Fundamental and quantitative investors utilize the cloud-based institutional-grade analytics technology and detailed backtests to quickly research alternative datasets in a novel “try-before-you-buy” data shopping experience.

CloudQuant demonstrates the value in alternative data to accelerate data sales for vendor partners and increase ROI for data purchasers.

We are Quantitative Investors, Proprietary Traders, Machine Learning Experts, Fundamental Investors, CPAs, CFAs, MBAs, PhDs, MFMs, CIOs, Data Scientists, AI Research Consultants

We are a global crowd research network.

We use and license PaaS technology solutions for Visualization, Data Science, Advanced Data APIs, Artificial Intelligence, High-Resolution Backtesting, High-Frequency Trading Engines, Machine Learning, Natural Language Processing, and Proprietary Alpha Signal broadcasting.","Kershner Trading Group
3.2","Chicago, IL",Investment Banking & Asset Management,Finance
Data Engineer,"Are you interested in building the future of healthcare and transforming the patient experience? Are you hopeful about what data and medical research can do to improve medicine? We’re looking for a Data Engineer to ensure PatientIQ remains on the forefront of using data to drive positive healthcare outcomes.

As a core member of the Analytics department, you will be in a very dynamic environment that works cross-functionally with all other departments, such Engineering, Sales, and Product. You will work on a broad array of problems that rely heavily on solid data engineering principles being in place: business intelligence, data science, and software engineering. We heavily value diligence, curiosity, and initiative, as those are key to unlocking the value of PatientIQ's data for our users and our decision-making. Your work will be impactful across the entire organization.

Role Responsibilities
Develop and maintain ETL infrastructure to support the ingestion of external data sources
Migrate client data into PatientIQ's platform per established service level agreements (SLA)
Define and implement key metrics for PatientIQ's data warehouse
Perform data quality assurance checks
Help scale PatientIQ's data strategy as the platform and business grows
Requirements

Ideal Qualifications
BS/MS in Computer Science, Engineering, Mathematics, or related field
Deep knowledge of SQL and at least one database technology
Proficient in Python
Experience with version control systems (e.g. git) and writing reusable and extensible code
Highly self-motivated with strong analytical problem-solving skills and attention to detail
Nice to Haves
Experience with workflow management systems such as luigi or airflow
Experience designing, building, and maintaining ETL infrastructure in a production setting
Experience in machine learning and/or business intelligence
Experience with ETL tools like Apache Kafka, Logstash, Segment, Informatica
Experience with cloud technologies such as AWS, Google Cloud Platform, or Azure
Experience working in Healthcare, Finance or another regulated industry
Benefits
Great Benefits - top-notch health, dental and vision insurance. Additional perks available including 401K.
We are Mission Driven - our team is motivated to solve complex problems, drive medicine forward, and ultimately improve patient outcomes.
True Idea Meritocracy - great ideas win out. We encourage all team members to challenge the status quo because our mission demands this.
Flexible Time Off - we trust you to take the time you need when you feel it is appropriate, given your workload and responsibilities. No need to track it or save up.
World-Class Team - we’re at the top of our industry because of our employees. They’re the best investment we can make, and we never forget that.
Fast Growing - we are building the largest platform for healthcare providers, industry partners, researchers, and others to collaborate on the mission to improve patient outcomes.",PatientIQ,"Chicago, IL",-1,-1
Data Analyst,"A promotion has resulted in an opening for a sharp-thinker to join our expanding organization and build their career!

Job Title: Production Analyst

Department: Finance

Reports To: Inventory Control Manager

FLSA Status: Salaried, Exempt

Summary Responsible for reviewing production work orders for accuracy, tracking and summarizing production trends, creating and generating reports to support continuous improvement initiatives and making recommendations based on analysis of data. The ideal candidate will have strong analytical skills, be detailed oriented and have an entrepreneurial attitude.

Essential Duties and Responsibilities include but not limited to the following:
Extract/analyze inventory and production data from ERP system for various purposes, including among others, daily, weekly, monthly and annual reporting to upper management team and other departments as well external stakeholders including banks, insurance and auditing firms/institutions;
Interpret production/inventory data to identify trends;
Utilize historical production information to generate product cost estimates for the pricing of new sales commitments;
Create process flow maps for production-related processes to clarify roles, responsibilities and the flow of information;
Use data from ERP software to drive improvements and efficiency on production processes;
Analyze production data to improve yield and labor entitlements;
Responsible for analysis of raw material and finished good inventory aging and make recommendations to Inventory Control, Production and Finance teams;
Create new reports to help identify, reconcile or prevent issues;
Interface with production, purchasing and warehouse teams on material status and production planning issues;
Reconcile inventory issues with inventory control and warehouse teams;
Assist in creating production formulas and products in ERP system;
Assist in posting production entries in ERP system;
Help manage and update different databases and other shared spreadsheets used by different personnel and departments across all locations;
Responsible for analyzing and managing weight giveaway for net weight products and work with QA and Production personnel to resolve any issues;
Will be required to perform other duties as requested, directed or assigned.
Supervisory ResponsibilitiesThis job has no supervisory responsibilities.

Qualifications To perform this job successfully, an individual must be able to perform each essential duty satisfactorily. The requirements listed below are representative of the knowledge, skill, and/or ability required. Reasonable accommodations may be made to enable individuals with disabilities to perform the essential functions. Regular attendance is required.

Education and/or ExperienceBachelor's degree in Finance, Economics or similar is preferred. At least two years of analytical experience including preparation of spreadsheets and other documents.

Language SkillsAbility to read and comprehend simple instructions, short correspondence, and memos. Ability to write simple correspondence. Ability to effectively present information in one-on-one and small group situations to customers, clients, and other employees of the organization.

Mathematical SkillsAbility to add, subtract, multiply, and divide in all units of measure, using whole numbers, common fractions, and decimals. Ability to compute rates, ratios, and percentages and to draw and interpret graphs.

Reasoning AbilityAbility to apply common sense understanding to carry out instructions furnished in written, oral, or diagram form. Ability to deal with problems involving several concrete variables in standardized situations.

Computer SkillsTo perform this job successfully, an individual should have strong knowledge of Microsoft Excel and other Microsoft Office programs; Internet software; Familiarity with SQL databases is preferred.

Other Skills and AbilitiesMust have excellent communication skills and customer service skills. Excellent typing and word processing skills. Must have the ability to multi-task and think analytically.

Physical Demands The physical demands described here are representative of those that must be met by an employee to successfully perform the essential functions of this job. Reasonable accommodations may be made to enable individuals with disabilities to perform the essential functions.

While performing the duties of this job, the employee is regularly required to sit and talk or hear. Position requires heavy use of keyboard. The employee is occasionally required to stand and walk. The employee must occasionally lift and/or move up to 25 pounds. Specific vision abilities required by this job include close vision, distance vision, color vision, peripheral vision, depth perception and ability to adjust focus.

Work Environment The work environment characteristics described here are representative of those an employee encounters while performing the essential functions of this job. Reasonable accommodations may be made to enable individuals with disabilities to perform the essential functions.

The noise level in the work environment is usually moderate.

Job Posted by ApplicantPro","Stampede Meat, Inc.
3.3","Bridgeview, IL",Food & Beverage Manufacturing,Manufacturing
Data Engineer,"This is an exciting opportunity to join an innovative and growing data centric team within the Marketing department.
The Marketing Analytics team is responsible for using data to make decisions, which includes the development of frameworks and models that are leveraged to optimise marketing programs, drive efficiency and generate action from analytic insights.
This project can be seen as ""foundational "" to understand our customer's experience and journey on client and how analytics gathered from this experience can be used to make informed decisions about Marketing spend, campaigns, client journey, new client acquisition, web site organization, web site page recommendation etc.
The role involves the below listed marketing datasets that need to be extracted from respective system and transferred to EDH. The datasets are
GA 360 – Google Big Query - Web site navigation hit level data. Demandbase data also available along with
GA 360 – Google Reporting API - Web site navigation session level aggregated level data. Demandbase data also available along with
Pardot - Marketing e-mail application
Client's LDAP dataset
Responsibilities:
Use the Client's AWS, Google Cloud Platform and Client's on premise data center to:
Test and validate the Proof of Concept (POC) GA 360 – Google Big Query data to AWS S3
Complete end to end development, test and validate the POC Pardot - Marketing e-mail data to AWS S3
Operationalize the above listed items (4 data sets) in production environment with the broadly outlined tasks/steps
Set up infrastructure – Client's on premise data center (DC3)
GCP components set up
AWS set up
Streaming data from GCP through DC3 to AWS
Data transfer Network & Security - GIS
Build & Deploy Pipelines
Scheduler for daily and history runs
Production operations and support
QA - Validation of daily transfer and landed data
Education & Experience
BS/BA in Computer Science and Engineering, Mathematics, Statistics or equivalent experience utilizing a different degree
MS or progress towards MS in Computer Science and Engineering including Machine Learning, Advanced Mathematics, Applied Statistics is preferred
Certification and or experience in cloud computing or big data technologies
Programming and devops experience in an enterprise wide setting is required
Experience in enterprisewide database system is required
Experience with data analysis, data modelling is strongly prefered
Combination of technical/quantitative and business acumen are strongly preferred
Job Qualifications
Expertise in Python for data analysis is a must, other shell scripting languages
Expertise in SQL (Oracle, Postgres, etc.)
Experience with using Analytical functions in SQL
Experience with Datawarehouse is a plus
Experience with a visualization tool Tableau
Experience with Google BigQuery, Apache Spark, Hadoop, Hive, and other Big Data technologies
Experience with AWS (EMR, S3, Lambda, DynamoDB, Athena, etc.) or other similar cloud services
Experience working with version control tool – Git, Stash, Bitbucket
Experience with build and automation tools – Jenkins, Chef etc
Exposure to Google Analytics
Strong communication, organizational and multitasking skills with ability to balance competing priorities","Informatic Technologies Inc
5.0","Chicago, IL",-1,-1
Data Engineer,"As a Data Engineer, you'll join our growing team of data scientists and engineers, reporting into Operations organization but working across multiple teams throughout the company. In this role, you(TM)ll be responsible for handling the design and construction of scalable data management systems "" ensuring that all data systems meet our company requirements "" and will also research and recommend new uses for data acquisition. As a Data Engineer, you will implement the data models and data structures needed for each use case, in the most convenient format to be used by the Data Science and Business Intelligence teams. Through regular interactions with stakeholders and functional business unit leaders, you will build high-performance algorithms, predictive models, and prototypes that influence data storage, piping, and usage. Additionally, you will participate in data requirements, modeling and testing activities. Each day will be unique, requiring an ability to think strategically and on your feet, be creative, take initiative, and employ a diverse set of skills.

WHO YOU ARE

Knowledgeable, Analytical, and Solution-Oriented. Without a doubt, you(TM)ve got strong quantitative skills and are comfortable analyzing large data set, spotting trends and patterns, and synthesizing relevant observations. You use a hypothesis-driven approach to engage in analysis that will deliver on your client questions. You like thinking outside the box to come up with innovative points of view on new challenges, relying on your previous analytic work and experience to help guide you along the way.

Results-Oriented. You demonstrate an inherent sense of urgency to drive great results, while being precise in executing your work. You are facile with creating and communicating a clear project plan, tracking progress, and keeping your business partners in the loop along the way.

Intellectually Curious. You're inherently interested in the ""why"" so that you can identify opportunities that represent unconventional solutions to the problems you are trying to solve.

Strong Communicator. Your writing and speaking skills are concise, articulate, and effective, providing an ability to interact with all levels/various teams across the organization, be understood, and develop trust and rapport within the organization.

Technologically Savvy. Microsoft Excel is a basic tool to you that you know like the back of your hand. You also have a strong skill set in R, Python, ArcGIS, machine learning, neural networks and/or other advanced analytics tools and techniques.

A Trusted Team Player. You enjoy partnering with others and build constructive working relationships that foster the collaboration necessary to deliver great results. You are accountable to your teammates and follow through on commitments.

Organized and Confident. You are flexible, composed, and able to prioritize multiple tasks and deadlines simultaneously, while confidently interacting with a variety of individuals, across all levels of the organization. You handle pressure well and do so with confidence.

WHAT YOU(TM)LL DO

Create data models and data processes, providing the right format and structure for use case solutions.

Participate in early data modeling and testing for use case development, providing input on how to improve proposed solutions and implement necessary changes.

Help to build, document, and maintain best practices, including but not limited to codebase management, work and issue tracking, testing and quality control/assurance measures, data dictionaries, and a documentation hub for both production level code and ad hoc analyses.

Interact with stakeholders and functional subject matter experts to understand all data requirements in order to develop effective business insights and translate them into actionable data structures and data models.

Assemble large, complex data sets that meet both functional and non-functional business requirements.

Extract relevant data to solve analytical challenges the organization and/or functional business units may face.

Work closely with IT teams on internal data acquisition (e.g., CRM, ERP, etc.).

Partner with stakeholders to provide technical support related to data structures, data models, data management and data infrastructure needs.

Work with data and analytics experts to strive for greater functionality in our data systems. Recommend different ways to constantly improve data reliability and quality.

Research new uses for existing data.

Create data tools for Business Intelligence, Analytics and Data Scientist team members that assist them in building and optimizing our Company use of data.

Collaborate regularly with key stakeholders to support and enhance the day-to-day operations of our business.

Produce various reports for stakeholders, as requested, to highlight areas of opportunity; works with teams to develop and implement changes, as needed.

Develop and maintain formal documentation that describes data and data structures, including data modeling.

PREVIOUS EXPERIENCE & REQUIREMENTS

Bachelor's Degree required, preferably in computer science, software/computer engineering, applied mathematics, or physics statistics.

Minimum 2 years data modeling experience and working with data management systems; deep expertise in data modeling and structuring required.

2+ years experience in high volume data environments and core data engineering activities (i.e. familiarity with cloud database set up, automation scheduling using directed acyclic graph (such as Airflow) and database optimization, including but not limited to partitioning, group and sort keys, and indexes).

Familiarity with a broad base of analytical methods e.g. data modeling (variable transformation and summarization) and processing (i.e. Spark, SQL Server, Hadoop/Hive, neo4j, etc).

Strong attention to detail and ability to think critically/conceptually.

Team oriented and flexible with proven track record in collaborating with multiple stakeholders.

Effective written and verbal communication skills required. Demonstrated ability to quickly learn new technologies a must.

Ability to think creatively when problem solving for new solutions and to work on numerous projects concurrently while effectively prioritizing workload. Tolerance for ambiguity required.

Tools/software:

Familiarity with data loading and management tools (i.e. Azure Storage""BlockBlob and relational and NoSQL databases and tools such as SQL Server, MongoDB, Data Stax, etc) required.

Must have programming and/or scripting experience (Python, Java) as well as experience with version control systems (Git/GitHub), continuous integration (circleCI) and other programming frameworks/approaches.

Proficiency in MS and Google application suites.

Must be available for overnight travel (approximately 10%)

Authorization to work in the US (without need for Visa sponsorship from employer) is required.","CultureFit Technology Staffing
5.0","Chicago, IL",Advertising & Marketing,Business Services
Data Engineer,"PDI is seeking a Data Engineer to join our team working in an exciting, high volume retail data ecosystem with over $100 billion of transaction log data. The candidate will benefit from a rich knowledge of software development practices and will need to apply those practices daily. Mastering the relationship between client data and our ecosystem will be an important element for this position.

This position plays a critical role at PDI and for both the retailer and their vendor partners to realize the most value from their data. The overarching responsibilities for this role are (i) on-boarding successfully and efficiently new clients, (ii) maintaining the data and ecosystem on an ongoing basis and introducing & implementing improvements as needed. The successful applicant will be joining an open and diverse team with a ""Can Do"" attitude, and a strong desire to make an impact in a start-up organization.

RESPONSIBILITIES & TASKS
Onboard new customers' data into the PDI data warehouse and platform, writing and installing the required ETLs
Optimize and manage existing clients data pipelines
Monitor, maintain, and, if needed rectify, various clients data integrity
Develop and/or enhance automated processes to proactively identify any data related issues and/or simplify process
Gather technical requirements from multiple sources for new data-oriented features, integrating new solutions within a developed Java solution base
Participate as a key member of our agile development team
Collaborate with team members to automate queries as needed
REQUIRED QUALIFICATIONS
Bachelor's degree in Math, Statistics, Computer Science or equivalent technical field.
Working and practical knowledge of programming principles, techniques, standards and analytical ability
Strong proficiency in Java
Proven experience with complex SQL query design and optimization
Experience with Bash scripting
Experience in data cleansing, curation, parsing, integration, semantic mapping, or editing
Experience with analytics systems (data warehouses, dimensional models, etc.)
Organizational skills and ability to balance multiple priorities in a dynamic and fast-paced environment
Strong team player with a passion for data and problem solving
Excellent oral and written communication skills
PREFERRED QUALIFICATIONS
Degree in Computer Science, Computer Engineering, Management Information Systems or related field
1-3 years of applied data engineering-related experience
Strong competence in Python
Experience with Google Cloud
Experience with Linux/Unix
PDIs employee-oriented culture provides a supportive and dynamic work environment for high achievers. PDI seeks individuals who value continuous learning, hold high ethical standards, and are top performers in their respective fields. We offer competitive wages, professional development, great culture, and a competitive benefits package. For more information about PDI, please visit our website at www.pdisoftware.com. PDI is an Equal Opportunity Employer. We verify employment eligibility for all new hires using e-Verify.

Powered by JazzHR","PDI Software
3.2","Chicago, IL",Enterprise Software & Network Solutions,Information Technology
Data Engineer,"Locations Richmond VA, McLean, VA, Wilmington, DE, Chicago, IL Required Technologies Strong Programming experience with object-orientedobject function scripting languages Python, PySpark, Scala, etc. Experience with big data tools Hadoop, Apache Spark, Kafka, etc. Experience with AWS cloud services S3, EC2, EMR, RDS, Redshift Experience with stream-processing systems Storm, Spark-Streaming, etc. Experience with relational SQL, Snowflake and NoSQL databases, including Postgres and Cassandra. Job Description Detailed overview of functional and technical role expectations Candidate with 5+ years of experience in a Data Engineer role, who has attained a Graduate degree in Computer Science, Statistics, Informatics, Information Systems or another quantitative field. Should also have working experience using the following softwaretools Strong Programming experience with object-orientedobject function scripting languages Python, PySpark, Scala, etc. Experience with big data tools Hadoop, Apache Spark, Kafka, etc. Experience with AWS cloud services S3, EC2, EMR, RDS, Redshift Experience with stream-processing systems Storm, Spark-Streaming, etc. Experience with relational SQL, Snowflake and NoSQL databases, including Postgres and Cassandra. Responsibilities for Data Engineer Create and maintain optimal data pipeline architecture, Assemble large, complex data sets that meet functional non-functional business requirements. Identify, design, and implement internal process improvements automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability etc. Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using SQL and AWS Big data technologies. Build analytics tools that utilize the data pipeline to provide actionable insights into customer acquisition, operational efficiency and other key business performance metrics. Work with stakeholders including the Executive, Product, Data and Design teams to assist with data-related technical issues and support their data infrastructure needs. Create data tools for analytics and data scientist team members that assist them in building and optimizing our product into an innovative industry leader.","SIMPLIFIED IT SOLUTIONS Inc
5.0","Chicago, IL",IT Services,Information Technology
Data Engineer,"PDI is seeking a Data Engineer to join our team working in an exciting, high volume retail data ecosystem with over $100 billion of transaction log data. The candidate will benefit from a rich knowledge of software development practices and will need to apply those practices daily. Mastering the relationship between client data and our ecosystem will be an important element for this position.

This position plays a critical role at PDI and for both the retailer and their vendor partners to realize the most value from their data. The overarching responsibilities for this role are (i) on-boarding successfully and efficiently new clients, (ii) maintaining the data and ecosystem on an ongoing basis and introducing & implementing improvements as needed. The successful applicant will be joining an open and diverse team with a ""Can Do"" attitude, and a strong desire to make an impact in a start-up organization.

RESPONSIBILITIES & TASKS
Onboard new customers' data into the PDI data warehouse and platform, writing and installing the required ETLâs
Optimize and manage existing clientsâ data pipelines
Monitor, maintain, and, if needed rectify, various clientsâ data integrity
Develop and/or enhance automated processes to proactively identify any data related issues and/or simplify process
Gather technical requirements from multiple sources for new data-oriented features, integrating new solutions within a developed Java solution base
Participate as a key member of our agile development team
Collaborate with team members to automate queries as needed
REQUIRED QUALIFICATIONS
Bachelor's degree in Math, Statistics, Computer Science or equivalent technical field.
Working and practical knowledge of programming principles, techniques, standards and analytical ability
Strong proficiency in Java
Proven experience with complex SQL query design and optimization
Experience with Bash scripting
Experience in data cleansing, curation, parsing, integration, semantic mapping, or editing
Experience with analytics systems (data warehouses, dimensional models, etc.)
Organizational skills and ability to balance multiple priorities in a dynamic and fast-paced environment
Strong team player with a passion for data and problem solving
Excellent oral and written communication skills
PREFERRED QUALIFICATIONS
Degree in Computer Science, Computer Engineering, Management Information Systems or related field
1-3 years of applied data engineering-related experience
Strong competence in Python
Experience with Google Cloud
Experience with Linux/Unix
PDIâs employee-oriented culture provides a supportive and dynamic work environment for high achievers. PDI seeks individuals who value continuous learning, hold high ethical standards, and are top performers in their respective fields. We offer competitive wages, professional development, great culture, and a competitive benefits package. For more information about PDI, please visit our website at www.pdisoftware.com. PDI is an Equal Opportunity Employer. We verify employment eligibility for all new hires using e-Verify.

Powered by JazzHR","PDI
3.5","Chicago, IL",-1,-1
Data Engineer,"Data Engineer

Chicago, IL, US

Requisition Number: 75536

We are (NSIT).

As a Fortune 500-ranked global provider of digital innovation, cloud/data center transformation, connected workforce, and supply chain optimization solutions and services, we help clients successfully manage their IT today while transforming for tomorrow.

From IT strategy and design to implementation and management, our employees help clients innovate and optimize their operations to run smarter.
Microsoft Worldwide AI Partner of the Year, 2018
Microsoft Worldwide Modern Desktop Partner of the Year, 2018
Microsoft US Partner Award for Intelligent Cloud - Application Innovation, 2019
Microsoft US Azure Team Partner Choice Award - Data and Artificial Intelligence, 2019
Our Insight Digital Innovation team is searching for an experienced, passionate and professional Data Engineer to join our team.

You'll utilize the most cutting edge technology such as machine learning, artificial intelligence, big data, IoT, and azure. Here you will have practical, hands-on knowledge of modern data architectures and tools such as data warehousing, ETL/ELT, analytics, and the Azure cloud platform. You should be driven to provide quality solutions to challenging problems. You will work closely with client stakeholders and an award-winning team of engineers, architects and thought leaders to design, build and implement next-generation solutions in advanced analytics, Big Data, BI and the cloud.

What you'll do at Insight:
You will build enterprise-grade data solutions for a variety of external clients.
Design and code solutions to tough data challenges and provide feedback on others' work.
Work directly with client stakeholders to develop technical solutions for business cases.
Aggressively grow your skillset and expertise to meet the emerging needs of our clients.
What you'll need to join Insight:
4+ years of experience working with data and data analytics development within the Microsoft data platform and an excellent grasp of some of following technologies:
SQL Server, Azure SQL Database, and Azure SQL Data Warehouse
Power BI
Tableau
Analysis Services and DAX
Reporting Services
Integration Services
Azure Data Factory
PowerShell scripting
Azure Automation
2 year of experience in some of the following:
Big Data technologies such as Hadoop or HDInsight, Hive, Pig, Python, Spark, Oozie, or any of the other tools with the Hadoop ecosystem
Azure Data Lake and Azure Data Lake Analytics
Predictive analytics: R, Azure Machine Learning
Strong analytical and reasoning skills that result in clear technical execution.
Skill at translating requirements into clean, efficient, quality code
Proven ability to prioritize, self-direct and execute at velocity
Passion to deliver craftsman-quality work both individually and as part of a team
Solid communication skills with both technical and non-technical stakeholders
Desire to learn new skills and grow competencies
Bachelor's degree in Computer Science or related discipline
Requires travel to Chicago Area client sites (local only).
In the News
-
-
*
Today's talent leads tomorrow's success. Learn about careers at Insight: .

Insight is an equal opportunity employer, and all qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, disability status, protected veteran status, sexual orientation or any other characteristic protected by law.

The position described above provides a summary of some the job duties required and what it would be like to work at Insight. For a comprehensive list of physical demands and work environment for this position, click here.
Today, every business is a technology business. Insight Enterprises, Inc. empowers organizations of all sizes with Insight Intelligent Technology Solutions and services to maximize the business value of IT. As a Fortune 500-ranked global provider of digital innovation, cloud/data center transformation, connected workforce, and supply chain optimization solutions and services, we help clients successfully manage their IT today while transforming for tomorrow. From IT strategy and design to implementation and management, our 6,800 employees help clients innovate and optimize their operations to run smarter. Discover more at .
Founded in 1988 in Tempe, Arizona
7,400+ teammates in 19 countries providing Intelligent Technology Solutions for organizations across the globe
$7.1 billion in revenue in 2018
Ranked #417 on the 2018 Fortune 500, #12 on the 2018 CRN Solution Provider 500
2018 Dell EMC Server Partner of the Year, 2018 Intel Retail Solution Partner of the Year, 2018 Microsoft Worldwide Artificial Intelligence Partner of the Year
Ranked #23 on the 2019 Fortune 50 Best Workplaces in Technology and #5 on the Phoenix Business Journal 2018 list of Best Places to Work (Extra Large Business)
Signatory of the United Nations (UN) Global Compact and Affiliate Member of the Responsible Business Alliance
Today's talent leads tomorrow's success. Learn about careers at Insight: .

Insight is an equal opportunity employer, and all qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, disability status, protected veteran status, sexual orientation or any other characteristic protected by law.

Posting Notes: Chicago || Illinois (US-IL) || United States (US) || MSOP-SC; None || None || US - Chicago, IL ||

Nearest Major Market: Chicago
Job Segment: Database, Developer, Engineer, Supply, Computer Science, Technology, Engineering, Operations",Insight UK,"Chicago, IL",-1,-1
Software Engineer,"We are looking for the right people — people who want to innovate, achieve, grow and lead. We attract and retain the best talent by investing in our employees and empowering them to develop themselves and their careers. Experience the challenges, rewards and opportunity of working for one of the world’s largest providers of products and services to the global energy industry.

Overview:

As a data scientist and machine learning software engineer on Halliburton Digital Solution team, you are responsible to deliver digital solutions which can achieve measurable business results through collaborating with subject matter experts in businesses, applying common open source libraries for building data analytics models, prototyping data driven digital tools to tackle business problems. We are looking for top talents who enjoy learning and contributing to our team through creative and innovative thinking.

Job Responsibilities:
Efficiently extract large scale complex business data (time series data, structured/unstructured) from various data sources and prepare them for data analytics.
Partner with product experts, leverage common open source Machine Learning/Deep Learning packages for identifying data patterns/trends or building predictive models.
Deploy solutions to business units using software technologies to generate measurable values for businesses.
Grasp the application of the latest machine learning & artificial intelligence open source packages, cloud and distributed computing technologies to ensure the best technologies are implemented to meet businesses’ data challenges.


Required Qualifications:
Undergraduate degree in Data Science, Computer Science, or Math, or Statistics.
For candidates who hold an engineering degree, we require candidates have taken data science classes already.
7 years of experiences with a minimum of 2 years experiences in extracting the data, using common classification or regression open source packages through R or Python.
Has basic knowledge with big data platforms like Hadoop, Hive, or Phoenix, as well as knowledge in parallel programming, and distributed computing frameworks like Spark.
Preferred Qualifications:
Advanced degree in in Data Science, Math, Statistics, Computer Science, or Engineering:
5 years of experiences with a Master’s degree
2 years of experiences with a PhD degree.
Has experience with open source machine learning packages and deep learning packages provided by Microsoft Azure, Amazon AWS, or Google GCP (such as Scikit-learn, Azure ML, TensorFlow, Sagemaker).
Interview process:

Potential candidates are required to pass a data challenge test before on-site interview can be scheduled.

Halliburton is an Equal Opportunity Employer. Employment decisions are made without regard to race, color, religion, disability, genetic information, pregnancy, citizenship, marital status, sex/gender, sexual preference/ orientation, gender identity, age, veteran status, national origin, or any other status protected by law or regulation.

Location

3000 N. Sam Houston Parkway E., Houston, Texas, 77032, United States

Job Details

Requisition Number: 87825
Experience Level: Experienced Hire
Job Family: Engineering/Science/Technology
Product Service Line: Global R&D
Full Time / Part Time: Full Time

Additional Locations for this position:

Compensation Information
Compensation is competitive and commensurate with experience.","Halliburton
3.5","Houston, TX",Oil & Gas Services,"Oil, Gas, Energy & Utilities"
Data Scientist,"Home » New Job from Competentia
Data Scientist

Vacancy Number: 26111

Location: Houston, TX

Date Posted: May 18, 2020

Data Scientist

About the role

Our client’s Petroleum Innovation Team enables the discovery, prioritization, de-risking and delivery of step change and disruptive innovation opportunities in support of Petroleum growth and value. We are seeking unique and diverse skills to inject new thoughts and perspectives into our Innovation efforts. Our client is excited to bring together passionate and creative individuals with diverse Petroleum, Technology and Innovation backgrounds to join our team.

The Innovation Data Scientist role will be part of an agile team responsible for de-risking and reducing uncertainty around how new technologies can be used to solve our most challenging problems. This role is responsible for executing data science tasks designed to make better use of company’s vast amounts of data and develop insights that have business value. This role requires a unique skillset with the ability to merge the rapid developments of computer science and machine learning with the rich depth of disparate and complex data sets such as 3D spatial geoscience data, time series operations data, and legacy unstructured data. We need out of the box thinkers, unafraid to try new things and learn from how other industries work with data. This is individual contributor role in which you will be developing algorithms to integrate and analyse data sets as part of a multi-disciplinary team and building Proofs of Concepts and Minimum Viable Products proving out new and innovative concepts.

In this role you will:
Work under the supervision of senior data scientists, geoscientists and engineers.
Develop machine learning and artificial intelligence algorithms to extract insights from complex, disparate and sometimes sparse data sets.
Develop Proofs of Concepts and Minimum Viable Products capable of delivering analytic insights to end users.
Collaborate with other team members and the business to understand problem statements and formulate approaches for solving specific business challenges
Assist with the build out and maintenance of an AWS development environment.
Research and identify potential technology solutions from external partners
Attend relevant industry and technology conferences/seminars and bring back learnings for sharing to the broader Innovation Team and Petroleum Business.
Foster attitude that value and promote innovation.
About you
Bachelors (Master is preferred) degree in STEM major from accredited institution.
Excellent problem solving and critical thinking skills with a thirst to learn new areas.
3+ years’ experience in","Competentia Holding
4.9","Houston, TX",-1,-1
Data Scientist,"Our Houston Research Center focuses on research and innovation in geology, geophysics, reservoir engineering, production technology, drilling, and sensors development to advance the discovery and recovery of oil and gas. Located in Houstons Energy Corridor, the center neighbors the nations leading petroleum engineering universities, labs, manufacturers, and service companies.

Basic Function

Develop algorithms, models and prototype solutions to address challenging scientific and engineering problems for exploration and production (E&P) applications. Serve as a bridge between machine learning (ML), data science and subject matter applications.

Duties & Responsibilities
Develop machine learning algorithms and perform advanced statistical analyses of engineering data to obtain insights into trends and opportunities
Develop and maintain appropriate databases
In close collaboration with research and business partners in the US and in the Kingdom of Saudi Arabia, offer mathematical, computational and statistical models from the collected data to automate, augment, improve or speed up human decisions
Research and deliver proof of concepts solutions, responding to clear and specific business needs
Serve as a bridge between machine learning/data science and subject matter applications
Bridge the gap between prototype development and scalable production applications when needed
Develop proper unit test frameworks for artificial intelligence (AI) and ML and provides high level documentation
Communicate appropriate algorithm research and prototype development best practices back to the machine learning group, to improve learning and future capabilities
Publish and present work in journals and at conferences
Develop and maintain statistical reports and visual presentations for management
Perform other duties and participate in special projects as assigned
Education & Experience
Bachelor's degree in Computer Science, Computer Engineering, Electrical Engineering, Applied Mathematics & Statistics, Machine Learning and Artificial Intelligence, or Geosciences required; Masters degree and/or Ph.D. strongly preferred
Must have at least three (3) years of relevant experience in data science including at least two (2) years in AI or ML
Strong fundamental understanding of various modern machine-learning methods or computational physics/geosciences/chemistry background, along with significant machine learning knowledge is desirable
Ability to:
compile, correlate, and compute results from large data sets
develop machine learning algorithms and perform advanced statistical analyses
effectively collaborate with research and business partners across disciplines and cultures
demonstrate technical writing skills and develop logical and clearly defined reports and presentations
make oral/graphic presentations to collaboration partners
show a history of active participation in technical society activities preferred
Proficient with business software applications
Experience in a few of the following areas: deep neural networks, reinforcement learning, Markov Random Fields, Bayesian networks, semi-supervised learning, computer vision, image processing, signal processing, distributed computing, and/or numerical optimization
Substantial programming experience is expected, preferably in Python
Experiences with one or more of the following is highly desirable: familiarity with ML frameworks such as Tensorflow, Keras, Pytorch, MXNet, operationalizing ML models, cloud computing (e.g. Google Cloud, AWS, etc.), GPU computing environment
Experience with big-data technologies such as Hadoop/Spark is a plus
Experience in oil and gas application is a plus.
Must be able to comprehend and communicate accurately, clearly and concisely in English
NO THIRD PARTY CANDIDATES ACCEPTED

Powered by JazzHR","Aramco Services Company
2.2","Houston, TX",Utilities,"Oil, Gas, Energy & Utilities"
Data Scientist,"Company Description

CGG is a fully integrated Geoscience company providing leading geological, geophysical and reservoir capabilities.

Job Description

CGG is currently looking for a creative and results-focused individual who enjoys working on open-ended problems. Your customers are world-class seismic imagers who strive to image the subsurface with a high degree of accuracy and resolution. Your challenge is to analyze the computational activities and demands of seismic imaging and, with your insights, propose solutions and applications for realms widely ranging from resource scheduling and allocations to automation of imaging-related computations in our HPC environment. In a nutshell, we expect you to propose solutions to known problems and also identify new areas where you can add value with your expertise.

We want people who can work with a team to decide what to look for, and who also have the technical ability to go get it. Interest in data mining and machine learning is key, since these are the two areas where you may specialize. You will participate as an engineer on a development team, writing, testing, and deploying code to achieve your goals. We want you if you are an independent thinker and capable of analyzing requirements, extracting data for analysis, and developing algorithms and tools. We process seismic data at the petascale and warehouse information at the terascale. The stakes are high, but your impact can be higher.

Must have current U.S. work authorization or qualify for sponsorship

Qualifications
Ph.D.in Computer Science, Math, Statistics, Physics or a closely related field but an equivalent combination of educationand experience will be considered
Proven Machine Learning experience
Professional experience with Deep Learning Neural Network building
Demonstrated experience with Deep Learning Framework such as Tensorflow and Keras
Experience and/or education in at least one of the fields of Big Data, Data Mining, Predictive/Prescriptive Analytics, Optimization, Exploratory Analysis & Visualization
Knowledge of relational databases, data modeling, and schema normalization techniques
Familiar with SQL
Passion for solving complex data engineering and modeling tasks
Ability to perform testing based on different hypotheses to determine the impact on key performance indicators
Excellent analytical skills and the ability to work in a collaborative team environment
Preferred:
Experience in programming (high performance computing is a plus) and developing databases
Knowledge and experience with UNIX (Linux), Java, and XML
Knowledge of Perl, R, and Spark
Expertise in designing and implementing efficient algorithms
We wish to thank all applicants for their interest; however, only those candidates selected for an interview will be contacted. EOE

Our focus on performance and passion for innovation are powered by people

Our greatest resource is you

Additional Information

All your information will be kept confidential according to EEO guidelines.",CGG Veritas,"Houston, TX",-1,-1
Data Scientist,"About National Oilwell Varco
Every single day, we put the oil and gas industry’s best minds and more than 150 years of experience to work to help our customers achieve lasting success. We have the people, capabilities, and vision to serve the needs of a significant and evolving industry. One the world can’t live without.

Throughout every region in the world, and across every area of drilling and production, our company provides the technical expertise, advanced equipment and operational support necessary for success – now and in the future.

At NOV, we power the people who power the world.

Job Description

We are currently searching for a data scientist / senior data scientist who has a proven record of designing and implementing predictive analytics solutions. We collaborate in a corporate group that develops, researches, and conducts strategic analytics projects that have a companywide impact on engineering practices and field operations.

Your Responsibilities:
You will have the opportunity to develop data driven predictive models that will lay the foundation for our Predictive Maintenance, Condition Based Maintenance, and Optimized Operations.
You will use past experience in implementing data analytics solutions for challenging engineering and reliability problems on NOV’s product lines.
Working with Big Data infrastructure, Engineering, and Operations, you will develop a scalable and sustainable analytics process.
Your Data Science responsibilities will include Data mining, Feature Extractions, Model Selection, Model Optimization, Validation, and Model Deployment.
You will engage in knowledge management and effective solution delivery.
You will assess risk, benefit, and cost of pre-existing and suggested engineering practices.
Requirements and Preferences:
Are you a motivated self-starter with the dedication to work independently and as part of a team, and an ability to multi-task? Do you have the flexibility and adaptability, to make decisions quickly? Do you thrive in dynamic environments with multiple changing priorities, where prioritization and time management are necessary tools? You may be a good fit for our team, if you also meet the following requirements:
You have 2-5 years of successful technical experience in the domain of predictive analytics (e.g. machine learning, data mining, distributed computing, and statistics related work); preferably in the Oil & Gas industry.
Your strong academic qualifications include an advanced degree in a quantitative discipline (Computer Science, Engineering, Statistics, Mathematics, etc.); preferably a PhD.
A consistent track record in data driven reliability and operation efficiency is a plus.
You have programming experience with Python or R, and experience with big data.
Having background with industrial equipment is a large plus. (Rotating machinery, reciprocating machinery, hydraulic systems, structural components, etc...)
Experience with commercial cloud services are also a plus. (AWS, Azure, and/or Google)
You have proven technical, analytical, and empirical skills.
You have a proven history of conducting research and producing viable solutions for engineering problems.
You are skilled in problem analysis and resolution, impact verification, troubleshooting, coaching, facilitation experience, and diagnosing problems across multiple disciplines.
You excel in organizational and analytical skills; you're able to focus and deliver precise results, yet understand impacts across multiple projects and systems.
You have spent time developing with machine learning and statistical models.
You communicate well in English and have good interpersonal skills, with the ability to build trust and integrity in your relationships with our business partners.
We are an equal opportunity employer.
National Oilwell Varco is committed to building a diverse environment and is proud to be an equal opportunity employer. We do not discriminate on the basis of race, color, religion, sex, national origin, disability status, protected veteran status, sexual orientation or any other characteristic protected by law.

We offer a comprehensive employee benefit package including health, life, and disability insurance; a retirement plan; and paid time off. Our company is committed to crafting a lasting impact for ourselves, our customers, and the communities where we live and work.","National Oilwell Varco
3.4","Houston, TX",Oil & Gas Services,"Oil, Gas, Energy & Utilities"
Data Scientist,"Company Description

CGG is a fully integrated Geoscience company providing leading geological, geophysical and reservoir capabilities.

Job Description

CGG is currently looking for a creative and results-focused individual who enjoys working on open-ended problems. Your customers are world-class seismic imagers who strive to image the subsurface with a high degree of accuracy and resolution. Your challenge is to analyze the computational activities and demands of seismic imaging and, with your insights, propose solutions and applications for realms widely ranging from resource scheduling and allocations to automation of imaging-related computations in our HPC environment. In a nutshell, we expect you to propose solutions to known problems and also identify new areas where you can add value with your expertise.

We want people who can work with a team to decide what to look for, and who also have the technical ability to go get it. Interest in data mining and machine learning is key, since these are the two areas where you may specialize. You will participate as an engineer on a development team, writing, testing, and deploying code to achieve your goals. We want you if you are an independent thinker and capable of analyzing requirements, extracting data for analysis, and developing algorithms and tools. We process seismic data at the petascale and warehouse information at the terascale. The stakes are high, but your impact can be higher.

Must have current U.S. work authorization or qualify for sponsorship

Qualifications
Ph.D.in Computer Science, Math, Statistics, Physics or a closely related field but an equivalent combination of educationand experience will be considered
Proven Machine Learning experience
Professional experience with Deep Learning Neural Network building
Demonstrated experience with Deep Learning Framework such as Tensorflow and Keras
Experience and/or education in at least one of the fields of Big Data, Data Mining, Predictive/Prescriptive Analytics, Optimization, Exploratory Analysis & Visualization
Knowledge of relational databases, data modeling, and schema normalization techniques
Familiar with SQL
Passion for solving complex data engineering and modeling tasks
Ability to perform testing based on different hypotheses to determine the impact on key performance indicators
Excellent analytical skills and the ability to work in a collaborative team environment
Preferred:
Experience in programming (high performance computing is a plus) and developing databases
Knowledge and experience with UNIX (Linux), Java, and XML
Knowledge of Perl, R, and Spark
Expertise in designing and implementing efficient algorithms
We wish to thank all applicants for their interest; however, only those candidates selected for an interview will be contacted. EOE

Our focus on performance and passion for innovation are powered by people

Our greatest resource is you

Additional Information

All your information will be kept confidential according to EEO guidelines.","Sercel
3.4","Houston, TX",Utilities,"Oil, Gas, Energy & Utilities"
Data Scientist,"Company Description

CGG is a fully integrated Geoscience company providing leading geological, geophysical and reservoir capabilities.

Job Description

CGG is currently looking for a creative and results-focused individual who enjoys working on open-ended problems. Your customers are world-class seismic imagers who strive to image the subsurface with a high degree of accuracy and resolution. Your challenge is to analyze the computational activities and demands of seismic imaging and, with your insights, propose solutions and applications for realms widely ranging from resource scheduling and allocations to automation of imaging-related computations in our HPC environment. In a nutshell, we expect you to propose solutions to known problems and also identify new areas where you can add value with your expertise.

We want people who can work with a team to decide what to look for, and who also have the technical ability to go get it. Interest in data mining and machine learning is key, since these are the two areas where you may specialize. You will participate as an engineer on a development team, writing, testing, and deploying code to achieve your goals. We want you if you are an independent thinker and capable of analyzing requirements, extracting data for analysis, and developing algorithms and tools. We process seismic data at the petascale and warehouse information at the terascale. The stakes are high, but your impact can be higher.

Must have current U.S. work authorization or qualify for sponsorship

Qualifications
Ph.D.in Computer Science, Math, Statistics, Physics or a closely related field but an equivalent combination of educationand experience will be considered
Proven Machine Learning experience
Professional experience with Deep Learning Neural Network building
Demonstrated experience with Deep Learning Framework such as Tensorflow and Keras
Experience and/or education in at least one of the fields of Big Data, Data Mining, Predictive/Prescriptive Analytics, Optimization, Exploratory Analysis & Visualization
Knowledge of relational databases, data modeling, and schema normalization techniques
Familiar with SQL
Passion for solving complex data engineering and modeling tasks
Ability to perform testing based on different hypotheses to determine the impact on key performance indicators
Excellent analytical skills and the ability to work in a collaborative team environment
Preferred:
Experience in programming (high performance computing is a plus) and developing databases
Knowledge and experience with UNIX (Linux), Java, and XML
Knowledge of Perl, R, and Spark
Expertise in designing and implementing efficient algorithms
We wish to thank all applicants for their interest; however, only those candidates selected for an interview will be contacted. EOE

Our focus on performance and passion for innovation are powered by people

Our greatest resource is you

Additional Information

All your information will be kept confidential according to EEO guidelines.","CGG
3.7","Houston, TX",Oil & Gas Services,"Oil, Gas, Energy & Utilities"
Data Scientist,"Tokio Marine HCC is a leading specialty insurance group with offices in the United States, the United Kingdom, and Continental Europe, transacting business in approximately 180 countries and underwriting more than 100 classes of specialty insurance. Tokio Marine HCC products and capabilities set the standard for the industry, and many of the Company's almost 3,000 employees are industry-leading experts.Are you currently seeking a challenging Data Scientist opportunity to help develop text analytics capabilities? At TMHCC, we have an exciting opportunity for a Data Scientist in our corporate office in Houston, TX. In this role, you will be a key member of the actuarial team to provide analytical support for the various underwriting units including, but not limited to, pricing and claims support, budget support, and providing key statistics on results to underwriting units. The work will be technical and analytical. The individual will be doing predictive and data analytics.Performance Objective:* Apply your expertise to prepare internal and external, structured and unstructured data* Collaborate with the actuarial team to develop text analytics capabilities* Design, build and validate models using simple and advanced modeling techniques to help business leaders quantify risks and make better decisions* Support cross-functional teams to implement models* Effectively collaborate with business stakeholders across the organization to understand business processes and problems to develop effective analytical solutions* Develop monitoring solutions for business stakeholders after model implementations to monitor the accuracy of predictions, proper usage, and business impactExpectations:* Within the first 30 days, become familiar with TMHCC's policies and procedures* Within the first 60 days, take ownership to develop text analytics capabilitiesQualifications:* Experience with Natural Language Processing (Text Analytics)* Experience with Python or ""R"" or similar data analysis programming language* Ability to handle sensitive and/or confidential material strictly in accordance with company policy and legal requirements* Flexibility to work outside of normal business hours and a willingness to learn* Sound analytical skills as well as problem-solving aptitude* Must be an exceptional communicator and able to make connections across the organization* Educational requirements: the ideal candidate will have a Master's degree in Data Science, Computer Science, Actuarial Science, Mathematics, Statistics or related field, or the equivalent education and/or experience. A Ph.D. would be preferred.The Tokio Marine HCC Group of Companies offer a competitive salary and employee benefit package. We are a successful, dynamic organization experiencing rapid growth and are seeking an energetic and confident individual to join our team of professionals. The Tokio Marine HCC Group of Companies are equal-opportunity employers. Please visit www.tmhcc.com for more information about our companies.#LI#GD#CB",HCC Life Insurance,"Houston, TX",-1,-1
Data Scientist,"Job Description


Company:

US6469 Sysco Payroll, Division of Sysco Resources Services, LLC

Zip Code:

77077

Minimum Level of Education:

Bachelor’s Degree

Minimum Years of Experience:

10+ Years

Employment Type:

Full Time

Travel Percentage:

OVERVIEW:

We offer our associates the opportunity to grow personally and professionally, to contribute to the success of a dynamic organization, and to serve others in a manner that exceeds their expectations. We’re looking for talented, hard-working individuals to join our team. Come grow with us and let us show you why Sysco is at the heart of food and service.

JOB SUMMARY

Overtime, this role will own one of the five core predictive\prescriptive engines for Sysco. Each engine will have multiple models as components. To lead the development of this engine, the role will require expert ability in mathematical modeling; analytical and heuristic solution methods; the ability to synthesize, visualize and communicate results; and create a tool at scale to drive the recommended course of action. This role will require close collaboration (with functions, operating companies, specialty companies or geographies and technology teams) to align around the sequencing of priorities and ensure the appropriate path to value. This role is expected to help create models in addition to coaching team members in model creation.

RESPONSIBILITIES
Ensure the data mined, cleansed and engineered for models is accurate and appropriate.
Able to bring forward new and different data sets to help solve problems.
Own the multiple models associated with one of the five predictive\perspective engines of Sysco.
Identify and use appropriate advanced analytic tools, technologies and platforms to solve business problems, create the roadmap for the engine- sequencing models overtime, create or direct the creation of the models\algorithms needed, tune the models to ensure the appropriate business outcome.
Ensure the performance scorecards and dashboards created to monitor adoption, implementation, and impact of models and strategies are adequate and are being shared throughout the enterprise
Work cross-functionally with other roles within the Enterprise Analytics Team and the Sysco broadly to tune models and ensure value created from models.
Work with LABS and Business Technology resources on API and front end integration.
Collaborate with business process owners to validate model outputs and construct an appropriate training
Work with data scientists and associate data scientists to ensure the correct data sets, calculations and analytic method being employed to solve a given problem.
Act as a magnet for data science talent.
Publish a paper and speak ~1 a year at a conference to ensure Sysco is top of mind of emerging data science talent.
QUALIFICATIONS

Education
Master’s or Ph.D. degree in Computer Science, Engineering, Mathematics, Statistics, Engineering, Neuroscience or another technical field, OR
Bachelors with 7+ years of relevant job experience
Experience:
4+ years of experience accessing and manipulating data in SQL or NoSQL database environments
2+ years of experience with scientific scripting languages (e.g., Python, R, SAS) and/or object-oriented programming (e.g., C++, Java)
3+ years of experience with Bayesian statistics, regression analysis (beyond linear regression), supervised learning, unsupervised learning or time-series analysis required
7-10 years of overall analytics experience can be inclusive of post-graduate work
Professional Skills
Excellent listening, written, and verbal communication skills, with the ability to create alignment across a diverse set of stakeholders
Executive-level presentation skills, with the ability to tailor communication for specific audiences and the ability to motivate and empower team
Excellent problem-solving skills, using an analytical and logical approach to solve complex problems
Self-starter that thrives in a fast-paced environment while delivering high quality and service levels
Strong business and technical acumen
Applicants must be currently authorized to work in the United States.

We are proud to be an Equal Opportunity and Affirmative Action employer, and considers qualified applicants without regard to race, color, creed, religion, ancestry, national origin, sex, sexual orientation, gender identity, age, disability, veteran status or any other protected factor under federal, state or local law.

This opportunity is available through Sysco Corporation, its subsidiaries and affiliates.","Sysco
3.3","Houston, TX",Wholesale,Business Services
Data Engineer,"This position is for April Health, Alphascript's parent company.

Innovative, adaptable, results-driven. If these are words that you would use to describe yourself, our Data Engineer role might be right for you. We’re looking for someone who can resolve routine problems promptly and efficiently, and who can come up with creative solutions for problems that aren’t so routine.
The role of the Data Engineer is to work with Data Architect to build Enterprise Data Management system from the ground up. The Data Engineer also works as a liaison between the subject matter experts in other departments and the Information Systems Department to understand the business requirements, needs and gaps in order to identify the appropriate datasets to perform analysis and develop insightful reports and dashboards.
You should be open to new and different ways to accomplish your work and be comfortable with new processes, initiatives and changes in priorities. This role requires a lot of collaboration with the Alphascript team, so you should be able to convey facts and information clearly (both verbally and written) and be comfortable sharing your ideas and proactively contributing to group objectives.
Responsibilities
Work with Data Architect to develop a data lake, data warehouse in local and/or Azure cloud environment
Integrate disparate data models into coherent enterprise data models
Develop ETL data pipelines to populate data lake and warehouse
Actively participate in Data Governance Program to maintain metadata and data definitions
Work in a team environment with other departments to develop reports, KPIs and dashboards (very strong communication skills)
Interpret business requirements to identify proper tools and methods to analyze, identify and report data trends and variances
Education and Experience
Bachelor’s Degree in Computer Science, Computer Engineering or Information Systems with university level programming courses
3+ years of data engineer experience
3+ years of recent experience in ETL and data warehouse development or maintenance
3+ years of experience in KPI, reports and dashboard development
Experience in healthcare company is a plus
Experience in Azure and SharePoint is a plus
Experience in agile software development environment is a plus
Skills and Abilities
Proficiency in Power BI, Azure Cloud, C#, ETL (SSIS preferred), T-SQL, Excel
Ability to develop data dictionaries of an existing database
Ability to write, analyze and debug SQL queries
Ability to develop dashboards and data models in Power BI; must be familiar with DAX and Power Pivot, and be willing to get proficient at them
Ability to develop business models and perform analysis in MS Excel
Proficiency in R and Python preferred
Working at April Health
We’re a growing team driven by a culture of passion and a commitment to excellence. You’ll work in a modern office alongside dedicated colleagues who work to consistently provide a superior patient experience. We offer a variety of competitive benefits like fully paid health insurance premiums, 401k matching and financial planning assistance, ongoing training and more.","Alphascript Pharmacy
3.2","Houston, TX",Biotech & Pharmaceuticals,Biotech & Pharmaceuticals
Data Analyst,"Smith is an entrepreneurial company with global reach, a casual environment, and limitless paths for success. For over 35 years, we’ve offered a place for driven, creative people to set and achieve ambitious goals in sales, procurement, and our supporting departments.

Opportunities await around the world. If you’re curious to see how you can help Smith grow while pursuing the next step in your own growth and development, apply today.

This Data Analyst will be responsible for data mining and building mining data tables, along with researching external methods, processes and software to provide business solutions tailored to new trends, demands and concepts. This person will need to have experience with the ETL process and strong experience with working with data coming from various sources, channels and in different formats. The candidate will also need to have the ability to structure the data for a software architect, correspond directly with clients, project or department managers, and/or business leaders to identify analytical requirements. This person will also be working with Project Managers, Architects, DBA, and Data Scientists. He or she must be comfortable utilizing both quantitative data, and qualitative knowledge. Other typical functions include but are not limited to:
Perform routine trend analyses and evaluations.
Analyze audit findings, identify trends and assist in the development of programs.
Brainstorm and form effective solutions to business problems.
Develop, maintain and assist in the implementation of programs and business solutions.
Monitor correction action follow-up from audits in business units.
Provide status reports to management, identify problem areas and verify compliance.
Clean, update and aggregate the data into more operable formatting.
Required Skills:
Bachelors Degree in MIS and/or CS.
Experience with tools such as SQL, Oracle & MongoDB.
Any ETL too experience (ex: Informatica, Oracle Data Integrator or Warehouse Builder)
Ability to work with relational and non-relational databases.
Ability to handle multiple tasks simultaneously and switch between tasks quickly.
Ability to facilitate discussion, drive consensus and build partnerships.
Detail oriented and able to work in group projects and take direction.
Excellent verbal and written communication skill is a must.
Experience as a Business Analysis is preferable.
If you like wild growth and working with happy, enthusiastic over-achievers, you'll enjoy your career with us!","N.F. Smith & Associates
4.1","Houston, TX",Wholesale,Business Services
Data Scientist,"Tokio Marine HCC is a leading specialty insurance group with offices in the United States, the United Kingdom, and Continental Europe, transacting business in approximately 180 countries and underwriting more than 100 classes of specialty insurance. Tokio Marine HCC products and capabilities set the standard for the industry, and many of the Company’s almost 3,000 employees are industry-leading experts.

Are you currently seeking a challenging Data Scientist opportunity to help develop text analytics capabilities? At TMHCC, we have an exciting opportunity for a Data Scientist in our corporate office in Houston, TX. In this role, you will be a key member of the actuarial team to provide analytical support for the various underwriting units including, but not limited to, pricing and claims support, budget support, and providing key statistics on results to underwriting units. The work will be technical and analytical. The individual will be doing predictive and data analytics.

Performance Objective:
Apply your expertise to prepare internal and external, structured and unstructured data
Collaborate with the actuarial team to develop text analytics capabilities
Design, build and validate models using simple and advanced modeling techniques to help business leaders quantify risks and make better decisions
Support cross-functional teams to implement models
Effectively collaborate with business stakeholders across the organization to understand business processes and problems to develop effective analytical solutions
Develop monitoring solutions for business stakeholders after model implementations to monitor the accuracy of predictions, proper usage, and business impact
Expectations:
Within the first 30 days, become familiar with TMHCC’s policies and procedures
Within the first 60 days, take ownership to develop text analytics capabilities
Qualifications:
Experience with Natural Language Processing (Text Analytics)
Experience with Python or “R” or similar data analysis programming language
Ability to handle sensitive and/or confidential material strictly in accordance with company policy and legal requirements
Flexibility to work outside of normal business hours and a willingness to learn
Sound analytical skills as well as problem-solving aptitude
Must be an exceptional communicator and able to make connections across the organization
Educational requirements: the ideal candidate will have a Master’s degree in Data Science, Computer Science, Actuarial Science, Mathematics, Statistics or related field, or the equivalent education and/or experience. A Ph.D. would be preferred.
The Tokio Marine HCC Group of Companies offer a competitive salary and employee benefit package. We are a successful, dynamic organization experiencing rapid growth and are seeking an energetic and confident individual to join our team of professionals. The Tokio Marine HCC Group of Companies are equal-opportunity employers. Please visit www.tmhcc.com for more information about our companies.

#LI
#GD
#CB","Tokio Marine HCC
3.4","Houston, TX",Insurance Carriers,Insurance
Data Scientist,"Company Description

Infotree’s approach to every employee and customer is based around making a positive impact. We focus on over-servicing, continuous improvement and a high-quality culture. We’re passionate about making successful matches for our employees and customers across the globe. Infotree prides itself in our proven track record and innovative culture with 100% focus on the employees and customers

Job Description

Reach out to me on 734-400-0958 OR abbas@infotreeglobal.com
W2 Candidates Only

Job Title: Data Scientist
Location: Houston, TX
Duration: 6 Months Contract

Job Description:

• 10-12 years of Hands-on experience in NLP, Machine Learning (ML) and Deep Learning (DL)
• Identify, retrieve, manipulate, relate and/or exploit multiple structured data and unstructured data sets from various sources, including building or generating new data sets as appropriate
• Should be hands on with text classification, document similarity, information retrieval (using ML and DL)
• Must have built production ready systems for data science
• Must have experience in creating and hosting scalable Restful APIs using python
• Interpret and evaluate the results of data science models and/or algorithms, understanding the meaning, limitation and scope of the results,
• A good understanding of NLP- ML-DL and the ability to build models quickly using the appropriate framework
• Understanding the right evaluation metrics for the NLP problems
• Ability to scale the DL/ML Models for the production
• Ability to containerize the ML models","Infotree Service Inc
3.7","Houston, TX",Advertising & Marketing,Business Services
Data Scientist,"The RiceTec Data Scientist will need to Design strategies and implement algorithms to analyze and leverage data; assessing the effectiveness and accuracy of data sources to be used as inputs in data analysis; to implement visualization systems that make data readily available and simplify how insights are communicated.

This analysis will be used for detection of crop response to sync management techniques, fertilizers and other crop production inputs; development of crop and pest management aids based on aerial images in large production fields; validation of small plot data collected by aerial sensors with established ground-based information.

Analysis will also focus on identifying opportunities for new and existing weather models to create value in supply reliability; parent line production; crop management.

Results should translate production problems into data-driven analytics / machine-learning tasks and building related products which automate the operational functions in production and manufacturing areas.

Candidates should have experience in building advanced analytics models across one or more areas of Predictive/Prescriptive Analytics, and Image Processing; Expertise in analytical packages such as Python, R, Statistical packages like Statistica, Minitab; applied experience in various machine learning techniques (e.g. Neural Networks).

Requirements: Masters in Statistics, Mathematics, Machine Learning, Agricultural Statistics or Climatology. PhD is Preferred.","RiceTec
2.9","Alvin, TX",Food & Beverage Manufacturing,Manufacturing
Data Scientist,"The Business

GradTests.com is a leading provider of practice psychometric tests to graduates, students and young professionals.

The Role

A data science all rounder role. The core purpose of the role is to build models to improve the product, the customer experience and ultimately the business. We're looking for someone with a nice blend of technical skills, and softer skills like business acumen, decision making and communication skills.

You'll do things like:
Conceive, devise, create, implement and fine tune data science models to solve a range of business problems, from customer churn through to
Set up, run and analyse A/B experiments for the website and email marketing campaigns
Help devise and layout a high quality infrastructure, upon which future data science can flourish
Help up skill other analytical team members into advanced data science techniques
Produce ad hoc analyses
And let's be honest, a whole load of data wrangling!
Skills and experience

Non negotiables:
SQL
Python or R
Data science models (K-means, random Forrest, neural nets etc.)
Strong foundational knowledge in stats and maths
Experience in actually productionising models and exposing to real customers
Business acumen
Strong communication skills, both written and verbal
Nice to haves:
Experience in working with developers, especially on experimentation
Some kind of cloud based experience (AWS preferred)
Some basic knowledge of source control with Git
Our application process consists of some online testing with Alooba, video call interview and then a case study. We expect the process to take about 10 business days end to end.

Job Types: Full-time, Contract

Salary: $120,000.00 /year

Experience:
Analytics: 1 year (Preferred)
Work Remotely:
Yes",GradTests (gradtests.com),"Houston, TX",-1,-1
Statistician,"The U.S. Department of the Treasury has a distinguished history dating back to the founding of our nation. As the steward of U.S. economic and financial systems, Treasury is a major and influential leader in today's global economy. We have over 100,000 employees across the country and around the world. Come Join the Department of the Treasury and Invest in Tomorrow.
See Other Information for Locations
Positions are to be filled in the Large Business & International (LB&I), Data Solutions division.
Eight (8) positions are to be filled in any of the following locations:
Birmingham, AL
Fayetteville, AR
Little Rock, AR
Phoenix, AZ
El Monte, CA
Glendale, CA
Laguna Niguel, CA
Los Angeles, CA
Long Beach, CA
Oakland, CA
Sacramento, CA
San Diego, CA
San Francisco, CA
San Jose, CA
Santa Ana, CA
Lakewood, CO
Hartford, CT
New Haven, CT
Norwalk, CT
Washington, DC
Newark, DE
Miami, FL
Ft. Myers, FL
Jacksonville, FL
Maitland, FL
Plantation, FL
Tampa, FL
West Palm Beach, FL
Atlanta, GA
Honolulu, HI
Des Moines, IA
Chicago, IL
Downers Grove, IL
Schiller Park, IL
Springfield, IL
Indianapolis, IN
Wichita, KS
Louisville, KY
New Orleans, LA
Boston, MA
Brockton, MA
Stoneham, MA
Southborough, MA
Baltimore, MD
Lanham-Seabrook, MD
Rockville, MD
Ann Arbor, MI
Clinton Township, MI
Detroit, MI
Farmington Hills, MI
Flint, MI
Grand Rapids, MI
Pontiac, MI
Bloomington, MN
Chesterfield, MO
Lee's Summit, MO
Charlotte, NC
Greensboro, NC
Raleigh, NC
Omaha, NE
Edison, NJ
Iselin, NJ
Mountainside, NJ
Paterson, NJ
Las Vegas, NV
Albany, NY
Bethpage, NY
Buffalo, NY
New York, NY
Rochester, NY
Cincinnati, OH
Columbus, OH
Independence, OH
Oklahoma City, OK
Tulsa, OK
Portland, OR
Philadelphia, PA
Pittsburgh, PA
King Of Prussia, PA
Guaynabo, PR
Warwick, RI
Franklin, TN
Memphis, TN
Nashville, TN
Austin, TX
Farmers Branch, TX
Fort Worth, TX
Houston, TX
San Antonio, TX
Ogden, UT
Salt Lake City, UT
Norfolk, VA
Richmond, VA
Vienna, VA
Seattle, WA
Milwaukee, WI
Waukesha, WI
Kearneysville, WV
Martinsburg, WV
WHAT DOES A DATA SCIENTIST DO? The Data Scientist utilizes advanced analytical, statistical, and computer programming skills to develop data- driven solutions to difficult business challenges. As a data scientist, you are responsible for conducting data-centric projects to provide insight and informed decisions for mission- oriented programs of the Internal Revenue Service (IRS), which may impact multiple program segments, divisions, the Service, or segments of the taxpayer population. This is accomplished by utilizing a wide range of technical competencies such as statistics and machine learning, coding languages, data wrangling, and reporting and visualization techniques. The Data Scientist may lead team or cross functional projects, and will apply critical thinking, problem solving and ability to communicate complex analysis to advance the use of data-driven decision making in IRS operations.

WHAT IS THE LARGE BUSINESS AND INTERNATIONAL (LB&I) DIVISION OF THE INTERNAL REVENUE SERVICE? The Large Business and International (LB&I) business unit provides service and enforcement activities to support tax compliance of businesses and related entities with assets of $10 million or more, as well as small U.S. businesses engaged in international, U.S. citizens abroad, and foreign persons and businesses with a U.S. tax requirement.
As a Data Scientist, you will:
Serve as a technical expert with responsibility for the initiation, planning, implementation, controlling, modifying and executing of all or part of an entire project, including such tasks as formulation of workload estimates for program segments, specification of the methodology to be used, preparation of appropriate specifications and procedures, and review of computer systems specifications and materials and instructions needed for assuring the adequacy of the project’s design and objectives.
Explore novel methods of retrieving data and develop innovative recommendations to management and senior leadership as a means for making data driven decisions such as modification of processes and policies. Review, evaluate, validate, and document the results of the findings.
Assist the supervisor in determining the scope, goals and schedules for future programs in the Office. Collaborate with business or technology partners to understand business needs, identify opportunities, and develop and implement analytical solutions.
Identify and assess relevant data sources’ validity and reliability to meet project needs. Collate, clean, transform, analyze, and integrate structured and unstructured data from various sources in preparation for analysis.
Apply statistical methods and concepts including data mining, statistical theory and research procedures to test hypotheses using structured and unstructured data. Develop data product solutions to improve customer experiences, anomaly detection, and business outcomes. Develop proofs of concept or demonstrations to evaluate feasibility of project solutions and recommend visualization strategies.
Document project work and review deliverables for validity, reliability and timeliness. Communicate analytic solutions to technical and non-technical stakeholders, including during executive- level and/or cross-agency meetings, in a clear and effective manner using oral and written communications.
Maintain knowledge of state-of-the-art innovations in data science from both academic and industry sources and identify opportunities for implementation. Engage in general professional development to improve knowledge of IRS processes/programs.
Apply computer based mathematical/statistical techniques using software. Lead or participate in statistical projects or studies in survey sampling (design and estimation), modeling, or statistical research. Apply knowledge of programming/coding language (i.e., SQL, SAS, SPSS, RStudio) to develop scripts or applications.
Act as a troubleshooter in resolving bottlenecks at any step in a project by identifying and proposing solutions; this may include coordination with other project team members or stakeholders to mitigate issues.

WHERE CAN I FIND OUT MORE ABOUT OTHER IRS CAREERS? If you want to find out more about IRS careers, visit us on the web at www.jobs.irs.gov
#LI-POST
You must meet the following requirements by the closing date of this announcement
BASIC QUALIFICATION REQUIREMENTS:

GS-1530 Statistician All Grades:
You must have a Bachelor's degree that included 15 semester hours in statistics (or in mathematics and statistics, provided at least 6 semester hours were in statistics), and 9 additional semester hours in one or more of the following: physical or biological sciences, medicine, education, or engineering; or in the social sciences including demography, history, economics, social welfare, geography, international relations, social or cultural anthropology, health sociology, political science, public administration, psychology, etc. Credit toward meeting statistical course requirements should be given for courses in which 50 percent of the course content appears to be statistical methods, e.g., courses that included studies in research methods in psychology or economics such as tests and measurements or business cycles, or courses in methods of processing mass statistical data such as tabulating methods or electronic data processing. OR
Combination of education and experience -- courses as shown above, plus appropriate experience or additional education. The experience should have included a full range of professional statistical work such as (a) sampling, (b) collecting, computing, and analyzing statistical data, and (c) applying statistical techniques such as measurement of central tendency, dispersion, skewness, sampling error, simple and multiple correlation, analysis of variance, and tests of significance.
GS-13 LEVEL: You must have one year of specialized experience at a level of difficulty and responsibility equivalent to the GS-12 grade level in the Federal service. Specialized experience for this position includes all of the following:
Experience applying project management principles on a data science project
Experience planning and executing a variety of data science and/or analytics projects.
Experience using data mining process models (such as CRISP-DM, SEMMA, etc.,) to design and execute data science project.
Experience preparing and analyzing structured and unstructured datasets to explorations and evaluating data science centric models.
Experience working with multiple data types and formats as a part of a data science project.
Experience applying a range of analytic approaches, including (but not limited to) machine learning, text analytics, and natural language processing; graph theory, link analysis and optimization models; complex adaptive systems; and/or deep learning neural networks that are part of the exploration.
Experience coding in various programming languages (such as R, Python, SQL, or JAVA) to conduct various phases of data science projects.
Experience creating and querying different datastores and architectures (such as Sybase, Oracle, and open-source databases) to work with various types of data as part of the data science project.
Experience using tools for data visualization (graphs, tables, charts, etc.,) and end-user business intelligence.
-The experience may have been gained in the public sector, private sector or Volunteer Service. One year of experience refers to full-time work; part-time work is considered on a prorated basis.
-To ensure full credit for your work experience, please indicate dates of employment by month/year, and indicate number of hours worked per week, on your resume.","Internal Revenue Service
3.5","Houston, TX",Federal Agencies,Government
Data Engineer,"Who is Trace3?

Trace3 is a leading Transformative IT Authority, providing unique technology solutions and consulting services to our clients. Equipped with elite engineering and dynamic innovation, we empower IT executives and their organizations to achieve competitive advantage through a process of Integrate, Automate, Innovate.

Our culture at Trace3 embodies the spirit of a startup with the advantage of a scalable business. Employees can grow their career and have fun while doing it!

Trace3 is headquartered in Irvine, California. We employ more than 850 people all over the United States. Our major field office locations include Atlanta, Denver, Detroit, Indianapolis, Grand Rapids, Lexington, Los Angeles, Louisville, San Diego, San Francisco, and Scottsdale.

Ready to discover the possibilities that live in technology?

Come Join Us!

Street-Smart - Thriving in Dynamic Times

We are flexible and resilient in a fast-changing environment. We continuously innovate and drive constructive change while keeping a focus on the ""big picture."" We exercise sound business judgment in making high-quality decisions in a timely and cost-effective manner. We are highly creative and can dig deep within ourselves to find positive solutions to different problems.

Juice - The ""Stuff"" it takes to be a Needle Mover

We get things done and drive results. We lead without a title, empowering others through a can-do attitude. We look forward to the goal, mentally mapping out every checkpoint on the pathway to success, and visualizing what the final destination looks and feels like.

Teamwork - Humble, Hungry and Smart

We are humble individuals who understand how our job impacts the company's mission. We treat others with respect, admit mistakes, give credit where it's due and demonstrate transparency. We ""bring the weather"" by exhibiting positive leadership and solution-focused thinking. We hug people in their trials, struggles, and failures – not just their success. We appreciate the individuality of the people around us.

About the Role:

What You'll Do:

The Data Engineer will be responsible for leveraging new and emerging technologies to solve key technical challenges for our clients. The Data Engineer will act as an expert and trusted advisor who develops, implements, troubleshoots, and optimizes data solutions across many platforms. This role will work closely with clients, partners and other business units to ensure consulting engagements are successful.

SUMMARY OF ESSENTIAL JOB FUNCTIONS:
Understand customers' overall data estate, IT and business priorities and success measures to design implementation architectures and solutions using advanced analytics and artificial intelligence
Develop deep relationships with key customer IT decision makers, who drive long-term cloud adoption within their company to enable them to be cloud advocates
Maintain and advance deep technical skills and knowledge, keeping up to date with market trends and competitive insights, and share within the technical community
Be a Voice of Customer to share insights and best practices, connect with Engineering team to remove key blockers
Assess the Customers' knowledge of Azure platform and overall cloud readiness to support customers through a structured learning plan and ensure its delivery through partners
Responsible for design, development, and hands-on implementation of data intelligence solutions including data platform build-up, proof of concepts or pilot implementation, software development, software integration, and documentation
Perform hands on development of apache, big data technologies, and framework
Serve as a data intelligence technical resource in team's efforts to determine the needs of our client's businesses that will simplify and automate the applications as well as make them more efficient
Align solutions with standards and best practices working with cross-functional engineering and consulting teams
Collaborate and communicate with Sales and Account Management team to ensure smooth and successful delivery and assist with the identification of additional Advanced Services and Sales opportunities within the customer's environment
Establish strong and lasting relationships with key stakeholders and decision makers in client organizations
Contribute to the development of internal best practices as well as new innovative consulting services offerings that we can take to market
Build a community and following around our company solutions and brand awareness
REQUIRED SKILLS AND EXPERIENCE:
Bachelor's degree from an accredited university required
Understanding and hands on experience with modern distributed data systems(Hadoop ecosystem, public cloud, etc).
Experience building applications in c# or java.
Understanding of BI technologies from traditional data warehousing to SaaS solutions in the cloud.
Experience in designing data and analytics architectures in Microsoft Azure cloud.
Well informed on cloud native technologies that enable batch and streaming data ingestion into cloud (For example: Azure Data Factory, Azure Event Hubs, Azure IoT Hubs etc)
Experienced in designing data lakes in Azure cloud for serving big data analytical workloads.
Proven track record of driving decisions collaboratively, resolving conflicts and ensuring follow through with exceptional verbal and written communication skills
Microsoft Certified Azure Solutions Architect Expert certification a plus.
Previous experience working for a consulting or services organization strongly preferred
5+ years of software development experience in distributed systems and building large-scale applications
5+ years of experience in building large scale, high performance, high availability systems and Strong Computer Science fundamentals (algorithms, data structures)
Hadoop, NoSQL or other Big Data certifications are a huge plus
Experience with Big Data technologies (SPARK, HDFS, HBase, Cloudera, MAPR, Hadoop and other frameworks in Hadoop ecosystem
Deep knowledge of Hadoop tools (MapReduce, SPARK, Oozie, ELK, KAFKA, HUE, HBase)
Fluency in several programming languages such as Python, Scala, or Java, with the ability to pick up new languages and technologies quickly
Intermediate knowledge with software engineering best practices
Must be able to quickly understand technical and business requirements and be able to translate them into technical implementations
Ability to mix deep technical expertise with simple, everyday language to deliver a story that is memorable, educational and useful
Highly organized, detail-oriented, excellent time management skills and able to effectively prioritize tasks in a fast-paced, high-volume, and evolving work environment
Ability to approach customer and sales requests with a proactive and consultative manner; listen and understand user requests and needs and effectively deliver
Comfortable managing multiple and changing priorities, and meeting deadlines in an entrepreneurial environment
Motivated self-starter who loves to troubleshoot and solve challenging problems and feels comfortable working directly with customers
The Perks:
Comprehensive medical, dental and vision plans for you and your dependents
401(k) Retirement Plan with Employer Match, 529 College Savings Plan, Health Savings Account, Life Insurance, and Long-Term Disability
Competitive Compensation
Training and development programs
Stocked kitchen with snacks and beverages
Collaborative and cool office culture
Work-life balance and generous paid time off
***To all recruitment agencies: Trace3 does not accept unsolicited agency resumes/CVs. Please do not forward resumes/CVs to our careers email addresses, Trace3 employees or any other company location. Trace3 is not responsible for any fees related to unsolicited resumes/CVs.","Trace3
3.3","Houston, TX",IT Services,Information Technology
Data Engineer,"Data EngineerSlalom is a modern consulting firm focused on strategy, technology, and business transformation. We believe in what's possible and shape what's next.At Slalom, personal connection meets global scale. We build deep relationships with our clients in cities across the U.S., U.K., and Canada, while sharing insights across markets to bring the full breadth of Slalom's expertise to every engagement. Our seven regional Build Centers are hubs for innovation, attracting top talent to rapidly co-create the technology products of tomorrow. We also nurture strong partnerships with over 200 leading technology providers, including Amazon Web Services, Google Cloud, Microsoft, Salesforce, and Tableau.Founded in 2001 and headquartered in Seattle, Slalom has organically grown to over 6,500 employees. We were named one of Fortune's 100 Best Companies to Work For in 2019 and are regularly recognized by our employees as a best place to work. Learn more at slalom.com.About the RoleAs a Data Engineer, you'll work in small teams to deliver innovative solutions on Amazon Web Services, Azure, and Google Cloud using core cloud data warehouse tools, Hadoop, Spark, Event Stream platforms, and other Big Data related technologies. In addition to building the next generation of data platforms, you'll be working with some of the most forward-thinking organizations in data and analytics.Responsibilities* Work as part of a team to develop Cloud Data and Analytics solutions* Participate in development of cloud data warehouses and business intelligence solutions* Data wrangling of heterogeneous data and explore and discover new insights* Gain hands-on experience with new data platforms and programming languages (e.g. Python, Hive, Spark)Qualifications* 3+ years of related work experience in Data Engineering or Data Warehousing* Hands-on experience with leading commercial Cloud platforms, including AWS, Azure, and Google* Proven experience with data warehousing, data ingestion, and data profiling* Proficient in SQL* Strong aptitude for learning new technologies and analytics techniques* Highly self-motivated and able to work independently as well as in a team environment* Understanding of agile project approaches and methodologies* Proficient in a source code control system, such as Git* Proficient in the Linux shell, including utilities such as SSHPreferred Experience* Familiarity with implementing analytics solutions with one or more Hadoop distributions (Cloudera, Hortonworks, MapR, HDInsight, EMR)* Familiarity with streaming data ingestion* Proficient in Python and/or Java* Consulting experience* Familiarity or strong desire to learn quantitative analysis techniques (e.g., predictive modeling, machine learning, segmentation, optimization, clustering, regression)Slalom is an equal opportunity employer and all qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, disability status, protected veteran status, or any other characteristic protected by law.","Slalom
4.1","Houston, TX",Consulting,Business Services
Data Scientist,"Data Scientist North America CoE

The Data Scientist is responsible for providing the delivery of Data and Analytics solutions to Techwave clients as part of our Data & Analytics CoE. The role will create solutions to business challenges through the use of advanced statistical analysis, data mining, and data visualization techniques.

Responsibilities:

Identifies the data the business should be collecting, devises methods of instrumenting the businesss system in order to extract this information
Designs, implements, and evaluates advanced statistical models and approaches for application in the businesss most complex issues
Conduct software development, software integration, statistical analysis, modeling, and simulations in a rapid DevOps environment.
Deploy new data science capabilities through existing toolsets.
Cleansing of large unstructured data and enabling analytical capability in order to query the data and address various business needs
Takes initiative to experiment with various technologies and tools with vision of creating innovative data driven insights for the business at the quickest pace possible.
Staying on top of the industrys trends, in order to provide forward-thinking recommendations
.

Requirements:

Ph.D. or Masters with experience in any mathematical sciences
Strong programming skills and experience working with tools such as R, Python Programming, Open Source, visualizations, and so forth.
Demonstrated skills in SQL server reporting services, analysis services, integration services, Tableau, or other data visualization tools.
Strong skill in statistical techniques inclusive of cluster-analysis test design, regressions, and forecasting methodologies as well as substantial familiarity in big data and standardizing and A/B testing.
Experience cleaning labeled data in preparation for use in machine learning
Ability to create parallel processing operations by managing the number of processors used in an operation given memory limitations
Knowledge of cloud based data platforms such as Snowflake, Redshift, BigQuery etc..","Techwave Consulting Inc.
3.9","Houston, TX",IT Services,Information Technology
Data Analyst,"Smith is an entrepreneurial company with global reach, a casual environment, and limitless paths for success. For over 35 years, we've offered a place for driven, creative people to set and achieve ambitious goals in sales, procurement, and our supporting departments.Opportunities await around the world. If you're curious to see how you can help Smith grow while pursuing the next step in your own growth and development, apply today.This Data Analyst will be responsible for data mining and building mining data tables, along with researching external methods, processes and software to provide business solutions tailored to new trends, demands and concepts. This person will need to have experience with the ETL process and strong experience with working with data coming from various sources, channels and in different formats. The candidate will also need to have the ability to structure the data for a software architect, correspond directly with clients, project or department managers, and/or business leaders to identify analytical requirements. This person will also be working with Project Managers, Architects, DBA, and Data Scientists. He or she must be comfortable utilizing both quantitative data, and qualitative knowledge. Other typical functions include but are not limited to:* Perform routine trend analyses and evaluations.* Analyze audit findings, identify trends and assist in the development of programs.* Brainstorm and form effective solutions to business problems.* Develop, maintain and assist in the implementation of programs and business solutions.* Monitor correction action follow-up from audits in business units.* Provide status reports to management, identify problem areas and verify compliance.* Clean, update and aggregate the data into more operable formatting.Required Skills:* Bachelors Degree in MIS and/or CS.* Experience with tools such as SQL, Oracle & MongoDB.* Any ETL too experience (ex: Informatica, Oracle Data Integrator or Warehouse Builder)* Ability to work with relational and non-relational databases.* Ability to handle multiple tasks simultaneously and switch between tasks quickly.* Ability to facilitate discussion, drive consensus and build partnerships.* Detail oriented and able to work in group projects and take direction.* Excellent verbal and written communication skill is a must.* Experience as a Business Analysis is preferable.If you like wild growth and working with happy, enthusiastic over-achievers, you'll enjoy your career with us!","Smith and Associates
3.0","Houston, TX",Legal,Accounting & Legal
Data Analyst,"Data Analyst (Internal Systems)
Location - Houston, TX
Type - Regular, full time
Pay Rate - Commensurate with experience
Travel - Periodic local and overnight travel
About cPanel

With over two decades of growth and experience under our belts, cPanel knows our industry, and we're looking for more people who are spirited, intelligent, friendly, and innovative to help us create more amazing things. We are a tight-knit team that constantly encourages and challenges each other, and above all of that, we sincerely believe in the value of the work that we do.

Because cPanel management cares deeply about helping our employees thrive we offer:
A workplace committed to the cPanel's core values of Integrity, Respect, Collaboration, and Follow-Through
Robust development teams that are practicing Agile Scrum and have everything you need to take a project from start to finish: Product Owners, Scrum Masters, Developers, QA, and Documentation writers all working with the same end goal.
A mid-sized company where your success will have a real impact on the company's success
Free catered onsite lunch every day, snacks, a gym, a flexible work schedule, and all the caffeine you can handle.
A dog-friendly office
Investments in our people by providing professional training, lunch and learns, conferences, and college reimbursement
1st-class work environment utilizing a pod concept: each team has a centralized collaboration area surrounded by a private office for each team member.
Fantastic coworkers who are passionate about creating great software.
An open-door policy to come by and talk about professional topics or just chit chat while you work through an issue.
About the role:

The Data Scientist is innovative, experienced, and highly trained; passionate about moving our company to the next level of being data-driven and advancing our purpose. The Data Scientist will drive internal data analytics projects serving all areas of the company.

The Mission (what you'll be responsible for): The Tools (what knowledge, skills, abilities, and experiences we're looking for)
Utilize reporting/analytics to assist teams in building alternative business models and projections
Identify trends and correlation between business actions and business performance on different customer segments
Understand business context, identify critical business problems, and translate them into actionable information for stakeholders.
Provide customer insights to drive changes across Marketing, Product and various teams and ultimately to improve customer value and key business metrics
Identify business opportunities, conduct financial/ROI assessment and develop projection metrics for sales and opportunities
Work with Marketing research and UX team to understand customer segments and their needs, profile our customer base and monitor the base composition change
Analyze fraud data and make recommendations that decreases fraud/abuse
Create & maintain dashboards with a variety of internal/external data sources
Adhere to the policies and procedures of the company
Exemplify the Core Values of Integrity, Respect, Collaboration and Follow-through
Eligibility Requirements
Advanced knowledge of SQL syntax and usage
Advanced knowledge of relational database design
Strong knowledge of report generation tools such as Jasper, Crystal Reports, or similar
Familiarity with Perl including database-driven web development
Familiarity with web development technologies including JavaScript, Ajax, and jQuery
Familiarity with Linux and underlying components
Education/Experience - Bachelor of Science in Computer Science required or equivalent experience
Four plus years of experience working with SQL and Relational Databases
Two plus years of experience working with report generation tools.
Two plus years experience in relevant business domains, including business intelligence tools, techniques and technology or experience in analytics, business analysis or comparable analytics solutions
At least one year of Perl development experience
In return for all the above, we offer the following:
Competitive Salary
Full Health, Vision, and Dental coverage
Flexible Spending Account
Free on-site lunch
Paid Vacation
Tuition Reimbursement
Casual Working Environment
401K Matching
EEO Statement

At our company, we take great pride in our diverse and talented workforce. We recognize that our continued success as a company depends largely on the collective strengths of our employees.

cPanel provides equal employment opportunities to all employees and applicants without regard to race, color, religious creed, sex, national origin, ancestry, citizenship status, pregnancy, childbirth, physical disability, mental disability, age, military status or status as a Vietnam-era or special disabled veteran, marital status, registered domestic partner or civil union status, gender (including sex stereotyping and gender identity or expression), medical condition (including, but not limited to, cancer-related or HIV/AIDS-related) or sexual orientation in accordance with applicable federal, state and local law. This policy applies to all terms and conditions of employment, including, but not limited to hiring, placement, termination, layoff, recall, transfer, leaves of absence, compensation and training. Privacy is taken seriously at cPanel, Inc. Information submitted is kept internally and not shared with third parties.

If this description fits you, apply below. It's relatively easy and painless.","cPanel
3.9","Houston, TX",Computer Hardware & Software,Information Technology
Data Analyst,"We are seeking a talented data specialist to join our highly motivated and innovative Data Engineering team, your efforts will be critical to the success of our client's global trading businesses. You will be responsible for the following:
Curate massive amounts of data for thousands of different tradable instruments, including stocks, bonds, futures, contracts, commodities, and more;
Perform manual steps and develop programs and processes to ensure the completeness and integrity of financial reference datasets;
Collaborate with team members to design and develop reliable data pipelines that produce high quality datasets;
Help drive continuous improvements to data quality procedures and a consistent approach to how data quality is measured, monitored and reported;
Create systematic and automated processes and tools that allow the team to scale and rapidly onboard new datasets;
Be part of a team to support the data used by production trading algorithms.
Basic Qualifications:
A bachelor's degree with a strong academic record, which includes university coursework in programming and computing systems
Prior professional experience in an environment that prioritized data quality
Experience in UNIX/LINUX and Windows environments.
An understanding of the software development process and exposure to hands-on coding in a professional environment
Experience with SQL and working with a relational database system, such as Microsoft SQL Server.
Proven problem-solving and analytical abilities including pattern detection, root cause analysis, and issue resolution
Strong communication skills
Able to work in an evolving and fast-paced environment and adjust to multiple priorities and timelines
Preferred Qualifications:
While financial industry experience is a plus, we are open-minded in our search for critical thinkers who are passionate about technology and data.
Experience with Python (and/or Java)
An understanding of how to design and develop effective data quality tests and measures
Relevant experience in data operations, with proven process improvement skills
Experience documenting business processes and workflows
Andiamo is an Equal Opportunity Employer

Andiamo provides equal employment opportunities to all employees and applicants for employment without regard to race, color, religion, sex, national origin, age, disability or genetics. In addition to federal law requirements, Andiamo complies with applicable state and local laws governing nondiscrimination in employment in every location in which the company has facilities. This policy applies to all terms and conditions of employment, including recruiting, hiring, placement, promotion, termination, layoff, recall, transfer, leaves of absence, compensation and training.

All qualified candidates are encouraged to apply by submitting their resume as an MS word document including a cover letter with a summary of relevant qualifications, highlighting clearly any special or relevant experience.","Andiamo
3.5","Houston, TX",Casual Restaurants,"Restaurants, Bars & Food Services"
Data Scientist,"One of the world’s leading financial consultative service providers are looking for Data Sceintists to join their team. The Company provides financial advisory and consultations to more than 4,500 clients in more than 35 countries, worldwide.

Job Description

Maintaining business excellence for us means the acquisition of new talent that are experts in new technologies and sciences.

We are looking for an experienced Data Scientist to join our team of technologists and data scientists to help us deliver data-driven solutions to our clients.

We are looking for someone with experience in using machine learning and natural language processing technologies to isolate, identify and utilize relevant data and help in designing and implementing new technologies and solutions to both simple and complex financial problems.

Roles & Responsibilities
Liaise with clients and our senior management team to understand client needs
Identify and process various sources of client/third-party financial data
Analyse sets of data to identify structures, patterns and trends
Use patterns in data to propose solutions and strategies for client problems
Create and present findings to senior management team and other stakeholders, as and when required
Collaborate with our technical team to design and implement automated data collection tools/processes, using predictive analytics and machine learning algorithms
Collaborate with our product development team to make recommendations for service improvements
Essential Requirements
5+ years of relevant experience (e.g. Data Scientist, Data Analyst, Statistician, Economist, etc.)
Working knowledge of machine learning algorithms and technologies
A great knowledge and/or experience of business intelligence tools (e.g. VBA, SQL, Tableau, etc.)
MSc or higher in Data Science, Statistics, Economics or a related field
Experience delivering agile solutions to various small and large clients
Strong problem-solving skills
Excellent attention to detail
Impeccable listening skills
Excellent verbal and written communication skills
Able to create and maintain strong working relationships with both internal and external colleagues and clients
Great planning and organisational skills
A desire for continuous learning and professional improvement
Desirable Skills
Experience working within the financial services (or similar) sector
Knowledge of cloud computing technologies (MS Azure, Amazon AWS, etc.)
A working knowledge of Python programming
Experience providing advisory or consultation services to client
Apply directly at: https://prolancer.com/jobs/send-proposal/298

Benefits:
Work from home opportunities
Job Types: Full-time, Contract

Salary: $50,000.00 - $75,000.00 per year","Pro Lancer
5.0","Houston, TX",-1,-1
Data Analyst,"Data Analysts, Stafford, TX: Analyze, architect, design & dev data warehouse & BI Reporting solutions using Microsoft BI Stack including SQL Server, Oracle, SSIS, SSRS, SSAS(MDX & DAX) and Power BI. Convert functional reqs to high & low level design documents. Bach degree or foreign equiv degree in Info Sys, Comp Sci or related+ 24 mos rel exp. 2 years of experience developing data warehousing, BI projects, w/Power BI, in SSPS Statistics & Rapid Minor. Microsoft SQL Server Certification is required. Travel/relocate to various unanticipated locations.

Send res to Pareto Systems LLC

4434 Bluebonnet Dr, Ste 158, Stafford, TX 77477.","Pareto Systems
4.3","Stafford, TX",IT Services,Information Technology
Data Analyst,"HORNE is an industry leading provider of disaster recovery solutions for states, territories, and municipalities in the wake of natural and man-made disasters. We currently provide services from 13 locations across the US, Puerto Rico, and the US Virgin Islands. We are looking for a Data Analyst who will collaborate with program managers and our technology team to deliver world class reporting solutions that help us improve the delivery of federal assistance after a disaster. Your work will help our clients gain meaningful insight into their rebuilding efforts and provide actionable intelligence that helps communities recover faster. With guidance from senior team members, you will be responsible for designing and building data visualization tools in response to client needs, program management requests, and internal practice management needs.

Primary Duties& Responsibilities:
Design, develop, implement and maintain reporting solutions
Utilize reporting software (Power BI, Tableau, etc.) to automate and standardize report delivery tailored to the client’s needs
Anticipate program reporting needs and collaborate with our systems design team
Ensure data quality and integrity in databases
Work with program managers to identify team training needs or process improvements that will improve reporting reliability and accuracy
Create complex functions, scripts, stored procedures and triggers to support reporting development and maintenance
Evaluate existing reporting solutions, collaborate with program managers and partners, implement improvements
Troubleshoot reporting accuracy or completeness issues
Work with appropriate urgency and an attention to detail
Work with the team to deliver world-class work on time and within budget
Continuously enhance your skills and ultimately our capabilities through professional development, skills learning, and self-instruction
Work Complexity:
Custom development of reporting solutions for complex disaster recovery programs including housing recovery operations, infrastructure rebuilding programs, economic development programs, financial management and oversight programs, and monitoring programs
Install, configure, and integrate solutions into the customer environment
Work on multiple, small to large projects as a team member, or independently on small projects
Work within aggressive timelines to deliver accurate and impactful reporting solutions
Work may require limited travel
Qualifications and Requirements:
Bachelor’s degree in computer science or a related information technology field
Knowledge of MS SQL programming with ability to design and implement complex reporting solutions
Experience with SQL Server
Good understanding of data and schema standards and concepts
Critical thinking and problem-solving skills
Bonus:
Experience with Power BI or Tableau
Experience with data warehouse/ETL implementation and/or management
Experience with OnBase
Experience with low code development environments such as OutSystems or Appian
Experience with SSRS, Crystal Reports and/or Business Intelligence tools
Experience with cloud computing environments such as Azure, AWS or Google Cloud","Horne LLP
3.1","Houston, TX",Accounting,Accounting & Legal
Machine Learning Engineer,"Job Description
Training machine learning models over billions of data points.
Quantifying predictive uncertainty using probabilistic and Bayesian methods.
Creating models that quickly generalize to new tasks using few-shot and meta- learning.
Training agents that execute decisions to optimize a reward over time.
Implementing state-of-the-art model-based planning and reinforcement learning algorithms, including offline and off-policy methods that learn from human demonstrations.
Scaling machine learning systems to massive datasets using big data technologies such as Spark and Hadoop.
Building visualization and data exploration tools that automate the analysis and debugging of machine learning models.
Experience Required
Masters or PhD in computer science, or equivalent.
4+ years of work experience.
Strong programming and problem-solving skills.
Deep knowledge of machine learning, including both supervised and reinforcement learning.
Specific subfields include deep learning, probabilistic and Bayesian methods, few-shot and meta- learning, model-based planning, and imitation learning.
Proficiency with the Python machine learning stack, including numpy, scipy, pandas, scikit-learn, matplotlib, tensorflow, keras, pytorch.
Experience with reinforcement learning, model-based planning, and/or control theory is a plus.",Microagility,"Houston, TX",Consulting,Business Services
Data Analyst,"Search ResultsPreviousNextAbout-HGACClose MenuHouston-Galveston Area CouncilAbout H-GACFinancial ReportsH-GAC BylawsH-GAC Contact InformationStaff RosterProgram Staff ContactAdvisory CommitteesAgendasBoard of DirectorsCalendarCareersH-GAC Contact FormH-GAC EventsH-GAC News & MediaOpen RecordsRegional DirectoryRFP / RFQHouston-Galveston Area CouncilResidentsBusinessGovernmentSearchH-GAC Job ListingDescriptionJob Title: Data AnalystJob ID: CE14054Full/Part Time: Full TimeRegular/Temporary: RegularHouston-Galveston Area Council OverviewHome to more than 7 million people, the Houston-Galveston region is one of the fastest growing and most diverse regions in the country. Making sure the region remains one of the nation's leading places to live, work, and prosper doesn't just happen-it takes planning and partnerships.The Houston-Galveston Area Council serves as a forum where the region's leaders and decision-makers come together to address local and regional issues related to transportation, the environment, public safety, aging, community planning, workforce training, and economic development. To support these efforts, the Houston-Galveston Area Council employs a robust team whose members are highly qualified, resourceful, and passionate about enhancing the region's quality of life.If you are looking for a career where you can help make a difference in urban, suburban, and rural communities, the Houston-Galveston Area Council has exciting opportunities for you. Learn more about why the Houston-Galveston Area Council is the right place for you to learn, grow, and excel.OpportunityH-GAC's Community & Environmental Socio-Economic team has an exciting opportunity for a Data Analyst. H-GAC's Socio-Economic Modeling program produces a regional growth forecast, an essential tool used by local governments in transportation and other long-range planning. The program conducts the ongoing collection and analysis of employment, population, and land use data, and provides tools for local governments to access US Census Data.In this role, you will be responsible for developing and managing regional growth forecasting models with large data sets from various sources. The Data Analyst will provide complex analytical support and serve as a point of contact for internal and external requests for data. Quality control to ensure the accuracy and integrity of data and providing innovative solutions to improve forecasting efforts is an integral part of this job. Strong experience reading and writing SAS code for data processing and management is crucial for success in this role.RequirementsThe successful candidate will have at a minimum:Bachelor's degree in Economics, Sociology, Planning, Statistics or a related field of study.Three (3)-Five (5) years of experience in data frames, data set designs, maintaining large volumes of data, producing forecasting models and reporting.Master's thesis, doctoral dissertation or research work relevant to this position may substitute for some work experience.Experience in reading and writing SAS code for data processing and management.Strong background in demographic and economic theory and models.Exposure and understanding of various theories, principles and presentation techniques.Preferred qualifications include:Five (5)-Eight (8) years of experience in a previous data analytics role.Strong hands on experience in BASE SAS, SAS SQL, and SAS MACRO.Proven experience with population, employment and land use forecast modeling.Apply online via: https://h-gac.com/careersH-GAC is an equal opportunity/AA employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, gender, national origin, or protected veteran status.Are you a returning applicant?Previous Applicants:Email:Password:If you do not remember your password click here .Back to Search ResultsNew SearchH-GAC CareersEmployee BenefitsJob ListingsCareersLegal DisclaimerPrivacy PolicySite FeedbackIntranet©2020Houston-Galveston Area Council",H-GAC,"Houston, TX",-1,-1
Data Engineer,"Location Houston, TX W2 role, Looking for USC, GC and H1B Transfer. Must Have Skills Python Spark SQL Responsibilities Architect end to end data solutions including data collection and storage, data modeling, and data consumption Work independently on data projects for multiple business functions Implement data flows connecting operational systems, BI systems, and the big data platform Design and implement an Enterprise Data Warehouse Automate manual data flows for repeated use and scalability Develop data-intensive applications with API and streaming data pipelines Prepare and transform data into a usable state for analytics Document and maintain source-to-target mappings and data lineage Productionize mathematical models and machine learning models Assists data analysts and data scientists with query optimization, performance tuning, and data processing Identify opportunities for data improvements and presents recommendations to management","TelligenTech, Inc
2.5","Houston, TX",-1,-1
Data Engineer,"Data Engineer

ETL automation tools such as Informatica, Mulesoft, SSIS, Alooma, or Apache Airflow

Experience with traditional RDBMS solutions such as Microsoft SQL Server and Oracle

Experience with cloud-based platforms and tools

Familiarity with DevOps tools and practices such as Git, Jenkins, JIRA, Azure DevOps

Experience with integrating to both database systems and APIs

Experience with documenting technical requirements, designs and systems

Extensive experience building scalable and resilient data pipelines

Extensive experience writing SQL

Experience with a procedural, functional or object-oriented programming language such as Python, Java, Scala, R

Additionally, candidates should be able to perform at a high level in at least two of the following technology categories:
Big Data tools such as Apache Hadoop, Spark, and Hive including managed solutions such as Databricks, Amazon EMR, Azure HD Insight, and Google Cloud Dataproc
Cloud data storage solutions such as Amazon S3, Azure Blob Storage, or Google Cloud Storage
Data warehousing solutions such as Redshift, BigQuery, and Snowflake
Message broker solutions such as Kafka, Google Pub/Sub, Amazon Kinesis
Stream processing solutions such as Flume, Storm, Spark Streaming
NoSQL Databases such as HBase, Cassandra, Redis
3-5+ years of experience in technology and/or consulting

Bachelor's Degree in CS, MIS, CIS, or a comparable technical degree

US Citizen or GC Holder

Sense Corp powers insight-driven organizations.

We turn data into actionable insights and transform organizations for the digital era.

Our people, culture, and how we engage with our clients are differentiators. Brilliant, Creative, Human, and Fun exemplify who we are. We are regularly recognized as a Best Place to Work by Austin, Houston, Dallas, and St. Louis Business Journals. With operations in Austin, Atlanta, Columbus, Dallas, Houston, San Antonio, and St. Louis we serve mid-market to Fortune 50 companies.

The Sense Corp Compass

We may be the only management consulting firm in the country where being brilliant isn't enough to land you a job. Sense Corp people must be brilliant, creative, human, and fun all at once. In other words, we hire terrific, well-rounded people. It's one reason clients love working with us. And it's why we enjoy working with each other. We may not sound like typical consultants but that's OK. We don't think like them either.

Visit us at www.sensecorp.com.","Sense Corp
3.8","Houston, TX",Accounting,Accounting & Legal
Data Analyst,"Job Title: Data Analyst

Job ID: CE14054

Full/Part Time: Full Time

Regular/Temporary: Regular

Houston-Galveston Area Council Overview

Home to more than 7 million people, the Houston-Galveston region is one of the fastest growing and most diverse regions in the country. Making sure the region remains one of the nation’s leading places to live, work, and prosper doesn’t just happen—it takes planning and partnerships.

The Houston-Galveston Area Council serves as a forum where the region’s leaders and decision-makers come together to address local and regional issues related to transportation, the environment, public safety, aging, community planning, workforce training, and economic development. To support these efforts, the Houston-Galveston Area Council employs a robust team whose members are highly qualified, resourceful, and passionate about enhancing the region’s quality of life.

If you are looking for a career where you can help make a difference in urban, suburban, and rural communities, the Houston-Galveston Area Council has exciting opportunities for you. Learn more about why the Houston-Galveston Area Council is the right place for you to learn, grow, and excel.

Opportunity

H-GAC’s Community & Environmental Socio-Economic team has an exciting opportunity for a Data Analyst. H-GAC’s Socio-Economic Modeling program produces a regional growth forecast, an essential tool used by local governments in transportation and other long-range planning. The program conducts the ongoing collection and analysis of employment, population, and land use data, and provides tools for local governments to access US Census Data.

In this role, you will be responsible for developing and managing regional growth forecasting models with large data sets from various sources. The Data Analyst will provide complex analytical support and serve as a point of contact for internal and external requests for data. Quality control to ensure the accuracy and integrity of data and providing innovative solutions to improve forecasting efforts is an integral part of this job. Strong experience reading and writing SAS code for data processing and management is crucial for success in this role.

Requirements

The successful candidate will have at a minimum:
Bachelor’s degree in Economics, Sociology, Planning, Statistics or a related field of study.
Three (3)-Five (5) years of experience in data frames, data set designs, maintaining large volumes of data, producing forecasting models and reporting.
Master’s thesis, doctoral dissertation or research work relevant to this position may substitute for some work experience.
Experience in reading and writing SAS code for data processing and management.
Strong background in demographic and economic theory and models.
Exposure and understanding of various theories, principles and presentation techniques.

Preferred qualifications include:
Five (5)-Eight (8) years of experience in a previous data analytics role.
Strong hands on experience in BASE SAS, SAS SQL, and SAS MACRO.
Proven experience with population, employment and land use forecast modeling.

Apply online via: https://h-gac.com/careers

H-GAC is an equal opportunity/AA employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, gender, national origin, or protected veteran status.","Houston-Galveston Area Council
2.5","Houston, TX",Municipal Governments,Government
Data Analyst,"Research emerging tech. Find new trends. Create amazing content.

If you are interested in following the growth of the Houston tech economy and packaging those insights into readable and understandable research content, then keep reading.

The role you'll play:

As HX's BI Manager, you will be given the opportunity to produce digestible and actionable insights into the emerging technologies and the market trends of tomorrow. In this role you will help influence city-wide programming, policy, and initiatives to accelerate the growth of our ecosystem.

Encouraged to apply: Candidates with startup experience or those who exhibit a hunger to learn and grow their domain knowledge. Brownie points for candidates with experience (tangentially or otherwise) in Venture Capital.

About the BI Team:

Working on BI efforts at Houston Exponential is like having a front row seat to the future of Houston. There is no team quite like ours anywhere, inside or outside of tech. It's a unique opportunity to both work at an agile, exciting startup and spend your day analyzing the technologies, startups, funding data and market trends of tomorrow in the local Houston landscape. To do so, you will have full access to millions of data points across multiple platforms. You will be surrounded by some of the most curious and driven people you will ever meet and held up to the highest standards every day. Our team members come from backgrounds as diverse as VC, consulting, economic development, product management, and medical research. Each member of the team has a voice in the development of strategic initiatives and are encouraged to do so!

Your main tasks:
Manage a small data team to provide oversight and management of a proprietary database.
Write data-driven research and reports that combine our proprietary data with outside data sets to identify key trends and analyze the momentum of startups, large enterprises, investors, and startup development organizations
Assist with internal reports and dashboards.
Understand and develop forward-looking analyses and insights for top industrial areas.
Develop and give presentations to discuss trends and needs
Support PR requests with data and category knowledge
Must be passionate and knowledgeable about technology and related disciplines such as venture capital and M&A
What you bring to the table:
You consider yourself to have high EQ, are intrinsically curious, and are not afraid to challenge data points in order to drive to the right answers.
Must be a startup / tech geek passionate about all things tech
Ability to synthesize data and develop meaningful conclusions and predictive insights
Strong communication/presentation skills and leadership abilities. You should feel comfortable speaking to stakeholders as an authority on the business and the category
Ability to multi-task and manage the details while keeping an eye on the big picture
Strong MS Excel and Powerpoint skills
Experience with relational databases and dashboarding technologies such as Chart.io or Power BI
What Houston Exponential is All About:

Houston is at an inflection point emerging as one of the nation's key technology innovation hubs. Houston Exponential (HX) plays a pivotal role in that success. HX is an independent 501c3 nonprofit that works to accelerate the growth of Houston's rapidly expanding technology innovation ecosystem.

We know that diversity makes for the best problem-solving and creative thinking. We are dedicated to adding new perspectives to the team and encourage everyone to apply if your experience is close to what we are looking for.

Equal Opportunity Employer: HX is committed to creating a diverse environment and is proud to be an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, gender, gender identity or expression, sexual orientation, national origin, genetics, disability, age, or veteran status.",Houston Exponential,"Houston, TX",-1,-1
Data Engineer,"Innovative, adaptable, results-driven. If these are words that you would use to describe yourself, our Data Engineer role might be right for you. We’re looking for someone who can resolve routine problems promptly and efficiently, and who can come up with creative solutions for problems that aren’t so routine.

The role of the Data Engineer is to work with Data Architect to build Enterprise Data Management system from the ground up. The Data Engineer also works as a liaison between the subject matter experts in other departments and the Information Systems Department to understand the business requirements, needs and gaps in order to identify the appropriate datasets to perform analysis and develop insightful reports and dashboards.

You should be open to new and different ways to accomplish your work and be comfortable with new processes, initiatives and changes in priorities. This role requires a lot of collaboration with the Alphascript team, so you should be able to convey facts and information clearly (both verbally and written) and be comfortable sharing your ideas and proactively contributing to group objectives.

Responsibilities
Work with Data Architect to develop a data lake, data warehouse in local and/or Azure cloud environment
Integrate disparate data models into coherent enterprise data models
Develop ETL data pipelines to populate data lake and warehouse
Actively participate in Data Governance Program to maintain metadata and data definitions
Work in a team environment with other departments to develop reports, KPIs and dashboards (very strong communication skills)
Interpret business requirements to identify proper tools and methods to analyze, identify and report data trends and variances

Education and Experience
Bachelor’s Degree in Computer Science, Computer Engineering or Information Systems with university level programming courses
3+ years of data engineer experience
3+ years of recent experience in ETL and data warehouse development or maintenance
3+ years of experience in KPI, reports and dashboard development
Experience in healthcare company a plus
Experience in Azure and Sharepoint a plus
Experience in agile software development is a plus

Skills and Abilities
Proficiency in Power BI, Azure Cloud, C#, ETL (SSIS preferred), T-SQL, Excel
Ability to develop data dictionaries of an existing database
Ability to write, analyze and debug SQL queries
Ability to develop dashboards and data models in Power BI; must be familiar with DAX and Power Pivot, and be willing to get proficient at them
Ability to develop business models and perform analysis in MS Excel
Proficiency in R and Python preferred

Location

This position is based at our Houston, TX office. Occasional travel is required.

Availability

This is a full-time position.",April Health,"Houston, TX",Health Care Services & Hospitals,Health Care
Data Engineer,"Home » New Job from Competentia
Data Engineer

Vacancy Number: 26110

Location: Houston, TX

Date Posted: May 18, 2020

Data Engineer

About the role

Our client’s Petroleum Innovation Team enables the discovery, prioritization, de-risking and delivery of step change and disruptive innovation opportunities in support of Petroleum growth and value. We are seeking unique and diverse skills to inject new thoughts and perspectives into our Innovation efforts. Our client is excited to bring together passionate and creative individuals with diverse Petroleum, Technology and Innovation backgrounds to join our team.

The Innovation Data Engineer role will be part of an agile team responsible for de-risking and reducing uncertainty around how new technologies can be used to solve our most challenging problems. This role is responsible for the extraction, collection warehousing and preparation of diverse data sets to support building data science pipelines. In this role, you will be helping our client make a better use of its vast amounts of data and develop insights that have business value. This role requires the ability to quickly build and deploy data collection, ingestion and delivery pipelines to facilitate data use by analytics and advanced machine learning/AI engines. We need out of the box thinkers, unafraid to try new things and learn from how other industries work with data. This is individual contributor role in which you will deliver data engineering solutions to support a multi-disciplinary team in their quest to build scalable, deployable innovative solutions with maximum benefits to the company.

In this role you will:
Work under the supervision of data science lead, geoscientists and subject matter experts.
Collect, aggregate and wrangle large volumes of data from multiple sources using advanced methodologies in data engineering.
Develop data ingestion and preparation workflows for data science pipelines for high and low velocity data.
Perform descriptive analytics on large heterogeneous data sets and create metrics to measure data quality and readiness for analytics.
Collaborate with other team members and the business to improve data models that feed BI tools and data science pipelines.
Assist with the build out and maintenance of an AWS development environment
Research and identify potential data engineering solutions from external partners
Attend relevant industry and technology conferences/seminars and bring back learnings for sharing to the broader Innovation Team and Petroleum Business
Help to build and personally model capabilities and behaviours that value and promote innovation
About you
Bachelors (Master is preferred) degree in STEM major from accredited institution.
5+ years’ experience in data engineering and managing large, complex, disparate data sets.
Good understanding of descriptive analytics and data engineering techniques for data science.
Demonstrated skills in data collection, cleansing, visualization, data quality assessment, and the use of analytics to build minimum viable data (MVD)
Demonstrated expertise in the development of data engineering pipelines for machine learning and artificial intelligence applications using structured, unstructured and semi-structured data sets.
Must have experience building data models to integrate diverse and high dimensional data sets.
Excellent problem solving and critical thinking skills with a thirst to learn new areas.
Experience with real-time data ingestion.
Good understanding of analytics and machine learning project lifecycle.
Interdisciplinary mind, i.e. demonstrated ability to map experiences across different domains.
Demonstrated skills in the use of one or more analytics software tools and languages (e.g. Python, R, Matlab, Java, Scala)
Experience in working with and analysing complex geospatial data sets, and knowledgeable in Geospatial analytic tools such as ArcGIS, ArcPRO, ArcPy, etc.
Good understanding of distributed computing, virtualization, and cloud technologies.
Excellent oral and written communication skills, able to effectively explain technical information to various audiences
Experience in Oil & Gas is a plus

Competentia is an Equal Opportunity / Affirmative Action employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability or protected veteran status, or other status protected by law or regulation.

Competentia, participates in E-Verify as required by law.","Competentia Holding
4.9","Houston, TX",-1,-1
Data Analyst,"McLane Global, based in Houston, TX, is a US based international and domestic food manufacturer, marketer, and supply chain expert. The McLane history spans over 125+ years of food sales and distribution experience. The company is in an impressive growth mode with 400%+ in the last 3 years. McLane Global has an aggressive plan for continued double digit growth over the next decade with a complex business model that includes revenue streams in several complementary lines of business. In the next 5 years, the company has aggressive location expansion plans.

The Opportunity:

Data Analyst is a member of the Logistics Team and reports directly to the Director of Logistics & IT. The Data Analyst is responsible for developing and supporting company-wide information reporting, support customer EDI onboarding and production, and assisting the Business Application Owners for Dynamics AX. Using Power BI and other reporting applications, the individual will quickly and accurately develop, administer and support data reports and dashboards. This position understands the fundamentals of SQL databases and; also, the nuance of visual presentation of data to non-technical customers. We seek candidates who are highly motivated, value teamwork, and possess strong business process skills. At McLane Global we value honesty, integrity, and high ethical principles. Our expectation is that all team members value the same.

The Responsibilities:
Responsible for the production and support of management and operational reporting from Dynamix AX as well as other custom and package application databases that require reporting.
Assist and support to Dynamics AX Application Owner for AX system administration and release management planning/testing.
Provide application direction and release management for other peripheral applications such as Voxware, Vendor-specific shipping software portals, and customized Precision Forms configurations.
Collaborate with Application Owner and the Dynamics AX Architect to build and support data reports and dashboards while assisting in gathering requirements from end users and validating report integrity.
Operate, manage and support the EDI system integrated with Dynamics AX as the EDI Application Owner
Daily operate, monitor and support the functionality and data quality of customer portals including Custom 3PL customer portal for accuracy and reporting of data
Collaborate with all departments to improve data quality, process and reports
Learn the importance of company culture, policies, and safety procedures to develop and maintain a clean, safe, and productive workplace.
What You Bring:
Information Systems Degree and/or equivalent experience
Two years or more of Microsoft Dynamics AX experience
Two years or more of Electronic Data Interchange (EDI) knowledge and experience
Working knowledge of SQL database and query reporting tools
Skills and experience with Power BI and other reporting tools within a predominantly Dynamics AX environment
Experience preferred in Voxware, PDF Editor, Bartender Label, Precision Forms, CargoWise, Internet Truck Stop (ITS), and shipping software – FedEx, UPS, USPS
Adept at working independently, but also in a team environment
Must be willing to travel up to 10%
McLane Global is a high energy and fast paced team environment. Our team wins every day, week, month, and year. Come be a part of a dynamic and inspiring team. Looking for a fun internship, in a collaborative and supportive environment? Our interns gain real world, hands-on experience in the world of logistics and supply chain.

Local Candidates Only

Job Type: Full-time

Pay: $65,000.00 - $85,000.00 per year

Experience:
Electronic Data Interchange (EDI): 2 years (Required)
Microsoft Dynamics AX: 2 years (Required)
Bartender Label: 1 year (Preferred)
Precision Forms: 1 year (Preferred)
CargoWise: 1 year (Preferred)
Internet Truck Stop (ITS): 1 year (Preferred)
PDF Editor: 1 year (Preferred)
Voxware: 1 year (Preferred)
Location:
Houston, TX 77090 (Required)
Language:
English (Required)
Work authorization:
United States (Required)
Application Question:
Are you able to work in the United States without employer visa sponsorship?
Benefits:
Health insurance
Dental insurance
Vision insurance
Retirement plan
Paid time off
This Company Describes Its Culture as:
Detail-oriented -- quality and precision-focused
People-oriented -- supportive and fairness-focused
Team-oriented -- cooperative and collaborative
Schedule:
Monday to Friday
On call
Other
Work Remotely:
No","McLane Global
4.0","Houston, TX",Wholesale,Business Services
Data Engineer,"Job Description
Walker Elliott has partnered with an exciting Energy Technology firm! Our client is in a great strategic position to not only grow but thrive in this changing market. They are looking for a talented Data Engineer to be a key player in building their next generation, artificial intelligence platform, serving as their core product!

In this role you will immediately have the opportunity to work on key product features for this energy related SaaS offering.

Other responsibilities will include:
Working with big data and artificial intelligence
Architecting and implementing data solutions across the entire platform
Working in a cloud-centric environment
Required Skills:
Experience working with the Azure stack
Database experience using MongoDB and SQL
Python scripting is a PLUS
Do not apply unless you are authorized to work in the United States for any employer as client company cannot sponsor or transfer visas at this time.

Walker Elliott is an Equal Opportunity Employer.

For additional information, please email your resume to resumes@walker-elliott.com or apply online.

http://www.walkerelliott.com/candidates/jobs/jobDetail/default.aspx?GUID=11321&Apply=true",Walker Elliott,"Houston, TX",-1,-1
Data Engineer,"Job Description
Senior Data Engineer

IMMEDIATE NEED for a Senior Data Engineer to join an amazing company at their Houston, TX location regarding Direct Hire employment.

Responsibilities:
Collaborate with data scientists, product management, and web engineers to deliver value and project outcomes
Convert prototype models and data pipelines built by data scientists for use in production.
Evaluation and debugging of model performance to ensure parity with prototype (Spark/Java/Python).
Develop low-latency, real-time predictive models in a microservice environment (Java).
Balance long-term code health and maintainability with business needs.
Profiling and performance tuning of production code.
ML Ops: support of Dataproc, Zeppelin, Gitlab, continuous integration systems, monitoring, alerting, etc.
Qualifications:
Experience and interest in Big Data technologies (Hadoop/ Spark/ NoSQL DB)
Experience working on projects within the cloud ideally Azure/AWS
Strong development background with experience in at least two scripting, object oriented, or functional programming language, etc. SQL Python, Java, Scala, R
Experience in at least one ETL tool
Ability to work across structured, semi-structured, and unstructured data, extracting information and identifying linkages across disparate data sets
Please send your resume to Andrew Butler, Senior Technical Recruiter for immediate consideration. Let us help you secure an interview!

ABOUT US

Irvine Technology Corporation (ITC) is a leading provider of technology and staffing solutions for IT, Security, Engineering, and Interactive Design disciplines servicing startups to enterprise clients, nationally. We pride ourselves in the ability to introduce you to our intimate network of business and technology leaders – bringing you opportunity coupled with personal growth, and professional development! Join us. Let us catapult your career!

Irvine Technology Corporation provides equal employment opportunities (EEO) to all employees and applicants for employment without regard to race, color, religion, sex, national origin, age, disability or genetics. In addition to federal law requirements, Irvine Technology Corporation complies with applicable state and local laws governing non-discrimination in employment in every location in which the company has facilities.","Irvine Technology Corporation
4.0","Houston, TX",Staffing & Outsourcing,Business Services
Data Analyst,"Job Description
Job description
Interpret data, analyze results using statistical techniques and provide ongoing reports
Develop and implement databases, data collection systems, data analytics and other strategies that optimize statistical efficiency and quality
Acquire data from primary or secondary data sources and maintain databases/data systems
Identify, analyze, and interpret trends or patterns in complex data sets
Filter and “clean” data by reviewing computer reports, printouts, and performance indicators to locate and correct code problems
Work with management to prioritize business and information needs
Locate and define new process improvement opportunities
Requirements
Proven work experience as a data analyst or business data analyst
Technical expertise regarding data models, database design development, data mining and segmentation techniques
Strong knowledge of and experience with reporting packages (Business Objects etc), databases (SQL etc), programming (XML, Javascript, or ETL frameworks)
Knowledge of statistics and experience using statistical packages for analyzing datasets (Excel, SPSS, SAS etc)
Strong analytical skills with the ability to collect, organize, analyze, and disseminate significant amounts of information with attention to detail and accuracy
Adept at queries, report writing and presenting findings
Master's in Computer Science or Engineering Management or Project Management or Information Systems/Technology (Preferred)
Powered by JazzHR

AdTmuEFqP5","Staffigo Technical Services, LLC
5.0","Houston, TX",IT Services,Information Technology
Data Engineer,"Position: Data EngineerLocation: Houston, TX 77002

Duration: 6+ months contract

Job Description:

We are currently seeking a Data Platform Engineer with 5+ years experience to join the Big Data and Advanced Analytics department. As part of the Data Engineering team, the Data Platform Engineer will work closely with Data Engineers and IT Infrastructure team to ensure the data platform is highly available, reliable, and stable. This individual will provide technical and thought leadership to the team to streamline the delivery of analytics to the business.

Must Have:

Kubernetes

Linux

MapR

Responsibilities

Implementation and ongoing administration of the platform
Perform incident investigation, diagnosis and provide resolution
Manage cluster provisioning, performance tuning, and security configuration
System monitoring and remediation of any production issues
Identify recurring problems and perform root cause analysis
Provide and implement sustainable solutions
Collaborate with the application teams to install updates, fixes, and patches
Coordinate and perform version upgrades
File system management and monitoring
Act as a primary contact for the platform
Point of contact for hardware and vendor escalation
Document all service levels
Perform application deployments acting as a gatekeeper to the production environment.

Regards,

Hari Haran.S

Wise Men Consultants

O: (281) 957-5888 Ext: 192

C: (754) 205-1604

Email: hari.haran@wisemen.com

www.wisemen.com","Wise Men Consultants
3.2","Houston, TX",IT Services,Information Technology
Data Engineer,"As a member of our Software Engineering Group, we look first and foremost for people who are passionate around solving business problems through innovation and engineering practices. You'll be required to apply your depth of knowledge and expertise to all aspects of the software development lifecycle, as well as partner continuously with your many stakeholders on a daily basis to stay focused on common goals. We embrace a culture of experimentation and constantly strive for improvement and learning. You'll work in a collaborative, trusting, thought-provoking environment-one that encourages diversity of thought and creative solutions that are in the best interests of our customers globally.This Data Engineer position will be primarily responsible for Data & Analytics development within JP Morgan's Legal Technology. This position will be an integral part of building and maintaining a net new data streaming platform to unify and govern reporting and data access across various products. Additional responsibilities may include design, construction, testing, optimization, and deployment of Data Engineering & Analytics technologies including but not limited to Relational Databases (Oracle), Kafka, Python as well as AI/ML & advanced analytics skills like Regression & Classification modeling in R or Python.The Data Engineer will need to work effectively with a globally distributed team of developers & product owners/stakeholders to implement reporting & analytics solutions leveraging the JPMC Legal generated data. Overall, the ideal candidate for this position will be highly skilled in data warehouse, streaming data, data manipulation & advanced analytics tools and have knowledge of visualization and presentation of enterprise data.This role requires a wide variety of strengths and capabilities, including:* BS/BA degree or equivalent experience* Advanced knowledge of application, data, and infrastructure architecture disciplines* Understanding of architecture and design across all systems* Working proficiency in developmental toolsets* Knowledge of industry-wide technology trends and best practices* Ability to work in large, collaborative teams to achieve organizational goals* Passionate about building an innovative culture* Proficiency in one or more modern programming languages* Understanding of software skills such as business analysis, development, maintenance, and software improvement* 6+ years of experience in a Data Engineering role, with a focus on data & analytics technologies* Experience delivering product with Agile / Scrum methodologies* Ability to communicate cross-functionally, derive requirements and architect shared datasets; ability to synthesize, simplify and explain complex problems to different types of audiences* Applied experience with Kafka streaming, JMS and other messaging technologies* Familiar with Docker, Kubernetes and other container technologies* Knowledge and applied experience in Java with Spring Framework, Spring Boot and other Spring technologies* Proficient in data analytics skills for more than one data engineering & analytics technologies including data warehouse (Oracle) and advanced analytics tools & methodologies (NLP, Classification models) Comprehensive analysis & design experience with demonstrated knowledge of Oracle based data warehouse / database structures.* Experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement.* Previous working experience in SQL, PL/SQL a must.* Proficiency in one or more modern programming languages- experience in Python, R etc.* Experience with Tableau & similar visualization tools a plus.* Strong data analysis skills and problem solving ability* Working proficiency in a selection of software engineering disciplines and demonstrates understanding of overall software skills including business analysis, development, testing, deployment, maintenance and improvement of software.* Knowledge of industry wide technology strategies and best practices* Ability to work in large, collaborative teams to achieve organizational goals, and passionate about building an innovative cultureOur Corporate Technology team relies on smart, driven people like you to develop applications and provide tech support for all our corporate functions across our network. Your efforts will touch lives all over the financial spectrum and across all our divisions: Global Finance, Corporate Treasury, Risk Management, Human Resources, Compliance, Legal, and within the Corporate Administrative Office. You'll be part of a team specifically built to meet and exceed our evolving technology needs, as well as our technology controls agenda.When you work at JPMorgan Chase & Co., you're not just working at a global financial institution. You're an integral part of one of the world's biggest tech companies. In 14 technology hubs worldwide, our team of 40,000+ technologists design, build and deploy everything from enterprise technology initiatives to big data and mobile solutions, as well as innovations in electronic payments, cybersecurity, machine learning, and cloud development. Our $9.5B+ annual investment in technology enables us to hire people to create innovative solutions that will not only transform the financial services industry, but also change the world.At JPMorgan Chase & Co. we value the unique skills of every employee, and we're building a technology organization that thrives on diversity. We encourage professional growth and career development, and offer competitive benefits and compensation. If you're looking to build your career as part of a global technology team tackling big challenges that impact the lives of people and companies all around the world, we want to meet you","JPMorgan Chase & Co.
3.9","Houston, TX",Investment Banking & Asset Management,Finance
Data Engineer,"The Business

GradTests.com is a leading provider of practice psychometric tests to graduates, students and young professionals.

The Role

The core purpose of the role is to make high quality, high availability, accurate data available for our data analysts and data scientists to do their analysis, derive their insights and build their models. You are the Scotty Pippin to the Michael Jordans. You are the Xavi to the Messis.

You'll do things like:
Ensure our data warehouse is well structured, running smoothly and efficiently for all business intelligence
Set up and maintain various data pipelines used for customer analytics, marketing analytics and product analytics
Skills and experience

Non negotiables:
SQL
Python
Strong knowledge of traditional relational databases - we don't mind which
Some experience with cloud technologies - again we don't mind if it's AWS, GCP or Azure
Experience in any streaming technology
Great experience in using third party APIs at scale
Some web scraping experience
An obsession with data quality
Strong communication skills
Nice to haves:
Experience in working with analysts
Any basic knowledge of advanced analytics techniques
Experience in a visualisation tool like Tableau
Job Types: Full-time, Contract

Salary: $100,000.00 /year

Work Remotely:
Yes",GradTests (gradtests.com.au),"Houston, TX",-1,-1
Machine Learning Engineer,"One of the world’s leading financial service providers are looking for experts in Machine Learning to help them with development of predictive financial algorithms.

The company has more than 1,500 employees and 30+ years of experience, they are the perfect destination for the best and the brightest analytical minds in the world.

Job Description

Work with the Data Science team and the wider R&D teams to design and implement a new predictive data and information analytics system.

Key Responsibilities
Design and develop a new ML and deep learning system according to requirements
Implement ML algorithms and tools, as appropriate
Run ML tests and experiments to ensure everything runs smoothly
Ensure the new system runs in parallel with the new dashboard application
Extend our existing ML libraries, and migrate data to the library as and when required
Keep up to date with the latest developments and best practices in the ML field and implement new changes where appropriate
Education, Experience and Skills
An Advanced Degree/PhD in a related subject (such as Data Science, ML, Statistics, Mathematics, Computer Science etc.)
4+ years experience working with ML/deep learning systems
Expertise in coding/developing algorithms for ML/deep learning systems
Proven experience using deep learning, analytical, NLP, classifications or predictive modelling
Proficiency in Python, R, RStudios
A working knowledge of SQL/Postgresql servers
Familiarity with open source systems such as Linux, Unix or Shell
Excellent attention to detail
Ability to work as part of a team, as well as independently with minimal supervision
Great time management and organisational skills
Desirable Knowledge & Skills
Knowledge and/or experience using AWS cloud system and applications
Proficiency or a good understanding of Java programming
Great knowledge of statistical modelling
Benefits Package
Competitive pay
Remote-working opportunities
Company laptop
Apply directly at: https://prolancer.com/jobs/send-proposal/301

Benefits:
Work from home opportunities
Job Types: Full-time, Contract

Salary: $70,000.00 - $95,000.00 per year

Experience:
Machine Learning: 2 years (Preferred)","Pro Lancer
5.0","Houston, TX",-1,-1
Data Engineer,"Data Engineer

Share

Job ID: FA-0100-322

Open Since: 2019-05-28

City: Houston
State: Texas
Country: United States of America

Job Description:


Need for a well-demonstrated Data Engineer who will work with the Data Science team to complete a major data project.

Mode of Interview : Telephonic/F2F

Job Skills:
Experience working on Hadoop platform components
Knowledge of Big Data tools, such as zookeeper, Kafka Streaming.
Shell scripting experience
Experience with integration of data from multiple data sources (NoSQL, Mongo, SQL)
Experience working with Structured/Unstructured data.
Experience creating ETL pipelines
Experience in Docker builds and Git file versioning
Demonstrated ability to quickly learn new tools and paradigms to deploy cutting edge solutions.
Knowledge of programming in Python
Knowledge of MapR
Knowledge of Scala framework
Experience with Spark, Storm or Flink
Minimum Experience: 8 Yrs

Roles & Responsibilities:
Integrate Data from multiple data sources
Create ETL Pipelines
Work under the guidance of Lead to develop based on design/architecture.
Education:

Bachelor’s Degree in Computer Science or equivalent work experience. Masters preferred","Frontend Arts
4.5","Houston, TX",Enterprise Software & Network Solutions,Information Technology
Data Engineer,"Responsibilities for Data Engineer:

â Create and maintain optimal data pipeline.

â Assemble large, complex data sets that meet functional / non-functional business requirements.

â Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, etc.

â Build analytics tools/dashboards that utilize the data pipeline to provide actionable insights into operational efficiency and other key business performance metrics using Tableau.

â Work with stakeholders including the business owners, Data and Design teams to assist with data-related technical issues and support their data needs.

â Create data tools for analytics and data scientist team members that assist them in building and optimizing models/visualizations.

Required Qualifications for Data Engineer

We are looking for a candidate with 2+ years of experience in a Data Engineer role, who has attained a bachelor's degree in Computer Science, Statistics, Informatics, Information Systems or another quantitative field. They should also have experience in following:

â Advanced working SQL knowledge and experience working with relational databases, query authoring (SQL).

â Experience building and optimizing 'big data' data pipelines, architectures and data sets.

â knowledge with data visualization best practices.

â Minimum 1-year experience in Tableau development

â Experience with various data prep/pipeline/integration tools like Alteryx, Azure Data Factory etc.

â In-depth knowledge of relational databases (e.g. Oracle and SQL Server), including data warehousing concepts and best practices

â Proficient is SQL

â Experience in at least one the following languages â R, Python, SCALA

â Experience working in an agile or Scrum based environment

â Ability to test and document end-to-end processes.

Experience working with Microsoft Azure or AWS platform will be preferred","Alpha Net Consulting, LLC
3.1","Houston, TX",IT Services,Information Technology
Data Engineer,"DATA ENGINEER – HOUSTON, TX

Who We Are

At m1neral, we are building the next evolution of mineral and royalty investing. Our built-for-purpose Mineral Intelligence Platform is an industry first, and provides enriched data, actionable AI insights, and transaction automation to buyers, operators, and sellers. Our data ingestion pipelines, processing power, and geospatial displays allow investors to target, research, and track the mineral marketplace trends across the United States.

In short, we are disrupting the status quo and are looking for hard-working, top-tier individuals to join our high-powered team.

Role Description

As a Data Engineer, you will be building out the back-end of our core product. You will be responsible work with our team to architect how we ingest, store, and query data across the entire platform. You will be making pivotal decisions on how we manage large datasets and how to make the data easily available in real-time across our platform. This will require close communication with product, design, and other engineers on the team to coordinate deliverables and navigate changes in priorities. Our team is committed to constantly improving, and as a key team member, you will have the opportunity to grow individually, and be expected to contribute to our engineering practices and culture.

The ideal candidate will have experience working with a early-stage SaaS start-ups and/or in fluid, dynamic, and fast-paced environments.

What will you be doing?
Architecting, implementing and deploying data solutions and pipelines
Working with business team members to understand problems and propose technical solutions
Developing expertise with our product, tech stack, and overall architecture
Automating solutions to improve data quality and improve overall productivity of end users
Delivering on-time release of well-tested and reliable code
Development of ETL logic, logging, monitoring, and maintenance of the central database
Integrating multiple data storage solutions using databases such as SQL Server, Mongo DB, and Azure Cognitive Search
Most importantly

We move fast, constantly innovate and you will thrive if you are someone who learns quickly, works well independently (and with others), and above all gets stuff done.

Job Requirements
BS/BA in Computer Science, Engineering, or equivalent preferred
3+ years of experience in Azure cloud architecture and relational database management (SQL Server)
Experience on Azure Data Factory (creating pipelines, loading and moving data) , Logic Apps, and Kusto preferred
Familiarity with Python and Jupyter notebooks a plus
Experience building large scale applications within oil and gas sector preferred
Familiarity with build systems, such as Github/Gitlab, Azure DevOps
Experience implementing, testing, and deploying code to a production environment
Ability to work effectively in a team environment
Capable of knowledgeably discussing performance trade-offs when evaluating different approaches
Great at solving problems, debugging, troubleshooting, and designing & implementing solutions to complex technical issues
Ability and eagerness to independently learn new technologies, prototype and propose solutions to the team
What We Offer
Competitive package (salary & equity)
Flexible work environment
Unlimited PTO
Volunteer time off
Vacation stipend (after 1yr)
High growth potential with an enterprising and energetic team

Notes
For the purposes of the interviewing process, you can expect to be rated on the results of a coding challenge that will be sent to you and both technical and team oriented in-person interviews.
Job Type: Full-time

Pay: $70,000.00 - $90,000.00 per year

Schedule:
Monday to Friday
Education:
Bachelor's (Preferred)
Work Location:
One location
Visa Sponsorship Potentially Available:
No: Not providing sponsorship for this job",m1neral,"Houston, TX",-1,-1
Software Engineer,"Job Description
Our client is a leading full-service provider of cost-effective management solutions for used healthcare materials and unused dispensed medications generated outside the hospital and large healthcare facility setting.

The Company seeks a Jr. Software Developer to join our focused IT team. In this role, you will make an impact by combining traditional development with user-centric design and research skills. Our fast-moving multi-disciplinary team balances their time between supporting users and listening to their evolving needs to adjust the systems that support the business. You will help integrate existing accounting and warehouse operations systems that are the backbone of the company with modern web services and develop new solutions that allow the business to continue to grow. You are a great creator, collaborator, and communicator with a curious mind and an ability to work both within and outside a strict production timeline. As part of a fast-moving team, you can work across multiple groups and successfully uncover critical insights that can be level up the business. In return, you will end up with a clear understanding of each facet of the business, be able to watch your projects grow, know how you are making an impact, and build your career.

Responsibilities:
• Work across multi-disciplinary teams from operations, accounting, and warehouse to understand how to evolve and support our current ERP systems
• Partner with a senior developer to support current development projects
• Understand the array of technical constraints, user goals, and business requirements that shape relevant current and future products

Requirements:
• 1+ years of experience in Web Development
• 3+ years of experience in relevant development experience
• BS/BA in Computer Science or equivalent education or experience
• Experience with the following technologies: SQL Server or other RDBMS, Python, C#, and .Net Core
• Familiar with accounting and terminology: AR, AP, GL, Financial reporting, Audits and documentation
• Strong coding, debugging, and problem-solving skills
• Independent, with internal drive and self-motivated to make an impact as part of a team
• Self-learner with a passion for technologies

Preferred:
• Experience with the following technologies: Sage 500 ERP, MS SQL Server, Salesforce, IIS, web APIs
We offer a comprehensive benefits package including medical, dental, vision, short- and long-term disability, 401K with match, paid holidays and vacations.","Crawford Thomas Recruiting
5.0","Houston, TX",Staffing & Outsourcing,Business Services
Data Engineer,"No need to be in Houston or relocate! Wersquore looking for an enthusiastic Data Engineers with MapR skills to provide brilliant solutions for our clients. Herersquos the deal The Data Engineer will be responsible for transforming data into a format that can be easily analyzed. Principle Accountabilities Installation of clusters across multiple nodes Security assessment and guidance. Skills Needed MapR cluster administration (preferably with the latest version of MapR + MapR 5.2) MapR security, monitoring, DB and Hbase administration MapR ES and Kafka administration MapR Data Governance story Hive, Drill, Spark, Sqoop, Oozie installation, administration, and tuning Automationscripting using Ansible, Puppet, Chef or Salt Experience with NFS or FUSE Basic ETL experience Cloud experience Docker and Kubernetes experience a big plus Qualifications and Requirements Strong work ethic, attitude and follow through ability. Excellent communicative, presentation and interpersonal skills. Makes compelling presentations to a variety of audiences using visual aids, PowerPoint presentations and software demos. Is adept at getting the attention and involvement of the most sophisticated and difficult audiences. Takes initiative and pursues opportunities. Self-motivated and excellent multi-tasking skills. Prioritizes and performs a variety of concurrent tasks with minimal direction. Projects a professional and polished image that inspires confidence and trust. PREDICTif Solutions is an Equal Opportunity Employer. This company does not discriminate in employment and personnel practices on the basis of race, sex, age, handicap, religion, national origin or any other basis prohibited by applicable law.","PREDICTif Solutions
3.1","Houston, TX",Accounting,Accounting & Legal
Statistician,"* Thesis/Dissertation statistical advising
* Get paid for prep time (when approved by client)
* College tutoring
* High School tutoring (not mandatory)
* Tutor required to have Statistics Degree or closely related field (or college student)
* Choose your own hours
* Introductory session before deciding to work with a client
* Meet clients online during COVID
* Meet clients both in-person and online after COVID
* Independent contractor (we refer clients to you)
* $100 referral bonuses
Job Type: Contract
Pay: $36.00 - $39.00 per hour
Benefits:
Flexible Schedule
COVID-19 considerations:
Work online during COVID
Experience:
Statistical Analysis: 1 year (Required)
Education:
Master's (Preferred)
License:
U. S. Citizen (Required)
Contract Renewal:
Likely
Full Time Opportunity:
No
Additional Compensation:
Bonuses
Company's website:
https://mobilemathlab.com/
Work Remotely:
Temporarily due to COVID-19","Mobile Math, LLC","Houston, TX",-1,-1
Data Scientist,"Data Scientist
If you are a Data Scientist with experience, please read on!
What You Will Be Doing
Developing algorithms for building information for example, spatial and natural language
Develop data analysis algorithms for Facility Operations
Develop data collection and management modules
Develop low maintenance code
Be a technical authority to drive best practices for critical programs
Work with facility managers to assess applications
What You Need for this Position
Bachelors in Computer Science or equivalent experience
3+ years of Software Development using Python, Matlab or similar
Scripting using JavaScript/AJAX
Passion for investigative product insight
Machine Learning, NLP, pattern recognition
MS Windows Server or similar
Relational database management systems, MYSQL
Agile Project Management
Great communication and quality teamwork.
So, if you are a Data Scientist with experience, please apply today!
-
Applicants must be authorized to work in the U.S.


CyberCoders, Inc is proud to be an Equal Opportunity Employer

All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, disability, protected veteran status, or any other characteristic protected by law.

Your Right to Work In compliance with federal law, all persons hired will be required to verify identity and eligibility to work in the United States and to complete the required employment eligibility verification document form upon hire.","CyberCoders
4.2","Phoenix, AZ",Staffing & Outsourcing,Business Services
Data Analyst,"Description


Do you want your voice heard and your actions to count?

Discover your opportunity with Mitsubishi UFJ Financial Group (MUFG), the 5th largest financial group in the world (as ranked by S&P Global, April 2018). In the Americas, were 14,000 colleagues, striving to make a difference for every client, organization, and community we serve. We stand for our values, developing positive relationships built on integrity and respect. Its part of our culture to put people first, listen to new and diverse ideas and collaborate toward greater innovation, speed and agility. Were a team that accepts responsibility for the future by asking the tough questions and owning the solutions. Join MUFG and be empowered to make your voice heard and your actions count.

Job Summary

We're seeking a Data Engineer to support the Core Banking Transformation (CBT) Program. This is a multi-year effort to modernize our deposits platform with a digitally-led and simplified ecosystem for consumer, small business, commercial, and transaction banking to deliver exceptional customer experience.

As the Data Engineer, you need to be collaborative and passionate about solving complex data engineering problems. You will be responsible for the design, build, implementation, monitoring, and management of the MUFG Core Banking data services gateway that provides the foundations for the technology modernization and digital transformation.

You will focus on building the firms next-generation data environment and be a key player in creating a data services platform that drives real-time decision-making in service of our customers. You will develop, build, and operate the platform using DevSecOps and System Reliability Engineering (SRE) methods.

Major Responsibilities:
Gather and process large, complex, raw data sets at scale.
Build processes to support data transformation, data structures, metadata, dependency, and workload management.
Build the infrastructure required for optimal extraction, transformation, and loading of data.
Partner with risk management and security teams to identify the standards and lead the design, build, and rollout of secured and compliant data services.
Embrace Infrastructure-as-Code, and use Continuous Integration / Continuous Delivery Pipelines to handle the full data service lifecycle.
Write infrastructure, application, and data automated test cases and participate in code review sessions.
Provide Level 3 support for troubleshooting and services restoration in Production.

Qualifications


The right candidate will have:
8+ years of technical experience with data services solution design and implementation in a cloud-native environment, possessing expert-level skills in four or more of the following areas:
Data field encryption, tokenization and metadata management
SQL and NoSQL databases, including Postgres, DynamoDB etc.
Experience with data pipeline and workflow tools: Wherescape Streaming, Wherescape RED, StreamSets Data Collector etc.
Experience with stream-processing systems: Kafka, AWS Kinesis, Apache Storm, Spark-Streaming, etc.
History of manipulating, processing and extracting value from large disconnected datasets with ETL and Data engineering
Know-how of SQL, Informatica PowerCenter or similar.
Experience with secure cloud services for data management and integration
Developing automation with python, bash, java, powershell or similar languages
Familiar with DevOps toolchain, i.e. BitBucket, JIRA, Jenkins Pipeline, Artifactory or Nexus, and experienced in deploying n-tier application stacks in AWS
Excellent data and system analysis, data mapping, and data profiling skills
Good understanding of cloud-native application models and patterns
Able to work alternative coverage schedules when necessary
Ability to find a solution with limited guidance
Bachelor's degree in computer science or related field, or equivalent professional experience
Desired Knowledge, Skills, and Experience:

Experience with container orchestration technologies such as Docker, Kubernetes, Openshift
AWS professional level certifications is preferred but not required
The above statements are intended to describe the general nature and level of the work being performed. They are not intended to be construed as an exhaustive list of all responsibilities, duties, and skills required of personnel so classified.

We are proud to be an Equal Opportunity / Affirmative Action Employer and committed to leveraging the diverse backgrounds, perspectives, and experience of our workforce to create opportunities for our colleagues and our business. We do not discriminate in employment decisions on the basis of any protected category.

A conviction is not an absolute bar to employment. Factors such as the age of the offense, evidence of rehabilitation, seriousness of violation, and job relatedness are considered in all employment decisions. Additionally, its the banks policy to only inquire into a candidates criminal history after an offer has been made. Federal law prohibits banks from employing individuals who have been convicted of, or received a pretrial diversion for, certain offenses.","MUFG
3.1","Tempe, AZ",Banks & Credit Unions,Finance
Data Scientist,"Job Description
We are looking to expand our Data Science team and looking for individuals with a passion for Data! You will collect, clean and interpret data to meet the company's overall purpose of changing how we buy and sell homes!

Position Summary

The Data Scientist uses real estate industry consumer data, statistical and financial concepts, and open source tools to uncover trends, stories and business insights. The role will be responsible to drive data-informed decisions for the business and guide our product direction with analytical insights. Day to day, the role will understand business impact, product decisions; use a combination of statistical modeling and business intuition to uncover insights from our data and build processes to generate robust metrics for teams to track to.

Essential Functions
Use consumer data, statistical and financial concepts, and open source tools to uncover trends, stories and business insights.
Dive deep into Offerpad’s internal and third-party data (SQL Server, Databricks, Power BI, Google Analytics, R) to solve complex, analytical problems.
Have a deep understanding of Machine Learning models and help create performance reporting around those models.
Partner with Finance/Marketing/Product teams to find opportunities and suggest data driven solutions.
Craft statistical/ machine learning models to gain insights from data and communicate results to partners.
Tell stories that describe analytical results and insights in meetings of all sizes with diverse audiences.
Performing ad-hoc analysis using SQL/R and presenting results in a clear manner.
Provide thought leadership across a variety of technical and non-technical audiences to ensure that all levels of the company make decisions with an analytical foundation.
Identify, research, and analyze new data sources to improve model accuracy.
Contributes to market share growth and profitability by recommending changes to products, pricing, risk management.
Become a domain expert in real-estate and Offerpad products & services.
Performs all functions according to established policies, procedures, regulatory and accreditation requirements, as well as applicable professional standards. Provides all internal/external customers of Offerpad with an excellent service experience.

Note: The essential functions are intended to describe the general content of and requirements of this position and are not intended to be an exhaustive statement of duties. Specific tasks or responsibilities will be documented as outlined by the incumbent's immediate manager.

Scope and Complexity
Interacts with all levels of leadership and employees, often relaying sensitive and/or confidential information.

Physical Demands/Environment Factors (Examples Listed)
Requires extensive sitting with periodic standing and walking.
May be required to lift up to 20 pounds.
Requires significant use of personal computer, phone and general office equipment.
Needs adequate visual acuity, ability to grasp and handle objects.
Needs ability to communicate effectively through reading, writing, and speaking in person or on telephone.
May require off-site travel; possible out-of-state travel
Minimum Qualifications
Bachelor’s degree with 5 years of work experience, involving quantitative data analysis and complex problem solving.
Deep understanding of statistics (e.g. Hypothesis testing, Regression trees etc.)
Have complete command of SQL, and either Python or R, along with some experience with visualization software like Power BI or libraries in R.
Have extensive experience directly querying multi-terabyte-sized data sets (with Azure Data Warehouse) including clickstream data (like Google Analytics) and raw data from non-standard platforms.
Have practice with terminology, and measurement issues related to experimentation, along with a history of applying advanced analytical approaches to derive insights from the data.
Have a strong written, verbal, and visual communication skills to concisely communicate in a way that provides context, offers insights, and minimizes misinterpretation.
Self-motivated to stay on top of new tools, technologies and concepts
Truth seeking, dispassionate in analysis of data, and able to follow the story and conclusion to where the evidence leads
Must be able to work on multiple projects concurrently, have a bias towards driving actions and results, and maintain a healthy balance between aggressive delivery and analytical rigor
Preferred Qualifications

Master's degree or higher in a quantitative field (e.g. science, engineering, economics, finance, statistics, or similar) and have 2 years of work experience involving quantitative data analysis and complex problem solving.

Previous real estate experience a plus","Offerpad
4.4","Chandler, AZ",Real Estate,Real Estate
Data Scientist,"Job Description
The ideal candidate's favorite words are learning, data, scale, and agility. You will leverage your strong collaboration skills and ability to extract valuable insights from highly complex data sets to ask the right questions and find the right answers.

Responsibilities
Analyze raw data: assessing quality, cleansing, structuring for downstream processing
Design accurate and scalable prediction algorithms
Collaborate with engineering team to bring analytical prototypes to production
Generate actionable insights for business improvements
Qualifications
Bachelor's degree or equivalent experience in quantitative field (Statistics, Mathematics, Computer Science, Engineering, etc.)
At least 1 - 2 years' of experience in quantitative analytics or data modeling
Deep understanding of predictive modeling, machine-learning, clustering and classification techniques, and algorithms
Fluency in a programming language (Python, C,C++, Java, SQL)
Familiarity with Big Data frameworks and visualization tools (Cassandra, Hadoop, Spark, Tableau)

Company Description
Headfarmer is a boutique recruiting firm specializing in the permanent and contract placement of the upper echelon of talent in the greater Phoenix area. We offer a unique process of ""headfarming"" which provides a level of professional support to both candidates and clients that exceeds recruiting industry standards.","Headfarmer
4.6","Phoenix, AZ",-1,-1
Data Scientist,"About Freestar:

Freestar engineers cutting-edge monetization solutions for websites. By combining industry-leading technology, data, and massive scale, we enable busy site owners to seamlessly maximize revenue while freeing themselves of the hassles of ad operations. Publishers then have more time to do what they do best: create content.

Job Description:

You will be an active, hands-on leader, working closely with Data Engineering group to develop Freestar's expanding ad services platform. This will be the lead role with primary responsibility for developing strategies and algorithms aimed primarily at optimizing publisher revenue. This will include developing strategies around ad delivery, publisher content, and ad network selection to name a few. You will accomplish these goals in a data-driven manner by developing and implementing predictive algorithms and deriving insights from big data. You will also collaborate with other teams within the organization, communicate findings to key stakeholders and evangelize data-driven business decisions.

Responsibilities:
Manage multiple projects in parallel and oversee their completion from start to finish, setting goals and project milestones
Promote best practices for statistical analyses and machine learning modeling
Help determine what metrics are critical to the organization, construct predictive models to optimize those metrics, and build out those projects into useful data products
Use first/third party data sources across digital, linear and social platforms to better understand Freestar's audience and derive insights to increase the value of the brand
Communicate results to key stakeholders
Basic Qualifications:
Graduate degree in a quantitative discipline (PhD preferred)
10+ years of work experience in advanced data analytics/data science
2+ years of experience managing/leading a team of data scientists with a track record of overseeing multiple data science and machine learning projects at all stages: from idea generation to objectives formulation to implementation and deliverables
2+ years of advertising or marketing related work
Experience with data exploration, data cleaning, implementation of advanced statistical and machine learning algorithms (e.g., time-series analysis and forecasting, clustering, and advanced classification and regression techniques such as decision trees, neural networks, deep learning, and ensemble algorithms), as well as rigorous model validation and evaluation
Fluency in Python and at least 1 of the following programming languages: Java, R, C, C++, or SAS
2-5+ years of experience with design and management of relational (SQL) and data warehouse paradigms; familiarity with Google Cloud Platform a plus
Knowledge of Spark, Cassandra or Hadoop is a plus
We'd also like to see:
Excellent interpersonal and leadership skills with the ability to develop and guide team members to deliver actionable results
Excellent verbal, written and formal presentation skills
Comfortable interacting across multiple teams and management levels within the organization
Previous background in the media landscape (linear, digital, or social) is a plus
What you can expect in return:
Full-Time, Salaried Position
Medical, Dental, and Vision benefits
401K with company match, vested immediately
The opportunity to be part of something BIG
Freestar is an Equal Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, age, protected veteran or disabled status, or genetic information.

This role is not eligible for visa sponsorship","Freestar
4.9","Phoenix, AZ",Advertising & Marketing,Business Services
Data Scientist,"Scope Data Scientist to help build classification, regression ML models for predictive analytics and anomaly detection You will be responsible for transforming data and generating actionable insights into our customer behavior Communicate key results with self-serve tools (dashboards, analytics tools) for the Customer Success team Must have DS skills Data cleaning, Data wrangling, Data Visualization, Intellectual Curiosity, Business acumen, Communication Skills, Probability and Statistics, Machine Learning Experience building (from scratch) Machine Learning (ML) models that can be put to production (with the support of data engineering and S.W engineering teams) Professional experience building machine learning models (candidates will need to articulate detail project experience from research, model selection, action and results) Statistics knowledge ToolsEnvironment must haves Azure Databricks environmentenvironment experience, Python Programming skills - 3 years (In-depth knowledge of Python, Pandas and its open-source ecosystem or similar) SQL - 2- 3 years Spark ML - domain knowledge Visualization tools Power BI or similar Responsibilities Build machine-learning models Create regression, classification models Work with engineering teams to deploy robust, highly available decisioning pipelines based on your models. Analyze large amounts of information to discover trends and patterns Combine models through ensemble modeling Present information using data visualization techniques Processing, cleansing, and verifying the integrity of data used for analysis. Undertake preprocessing of structured and unstructured data Qualifications Business acumen and communication skills to gather the data requirement from the business 3+ years of related professional work experience Theoretical and execution background of Data Science with specific focus on Machine Learning Experience testing and validating models and assessing the trade-offs between different modeling techniques and specifications Comfort manipulating and analyzing complex, high-volume, high-dimensionality data from varying sources Strong analytics and problem-solving skills needed. Can take the data and come up with a solution specific to the use case Experience in applying statistical learning methods to solve business problems Experience working with complex andor large data sets Practical ability to visualize data, communicate the data, and utilize it effectively Programming skills - 2 years (In-depth knowledge of Python, Pandas and its open-source ecosystem or similar) Proficiency in using query languages such as SQL, Hive, Pig, Sqoop. Experience with NoSQL databases, such as MongoDB, Cassandra, Hbase and SQL databases and unstructured data stores Excellent understanding of machine learning techniques and algorithms, such as k-NN, Nave Bayes, SVM, Random Forests, etc. NLP NLU experience preferred.","Vaco Technology
3.3","Scottsdale, AZ",Consulting,Business Services
Data Scientist,"The Business

GradTests.com is a leading provider of practice psychometric tests to graduates, students and young professionals.

The Role

A data science all rounder role. The core purpose of the role is to build models to improve the product, the customer experience and ultimately the business. We're looking for someone with a nice blend of technical skills, and softer skills like business acumen, decision making and communication skills.

You'll do things like:
Conceive, devise, create, implement and fine tune data science models to solve a range of business problems, from customer churn through to
Set up, run and analyse A/B experiments for the website and email marketing campaigns
Help devise and layout a high quality infrastructure, upon which future data science can flourish
Help up skill other analytical team members into advanced data science techniques
Produce ad hoc analyses
And let's be honest, a whole load of data wrangling!
Skills and experience

Non negotiables:
SQL
Python or R
Data science models (K-means, random Forrest, neural nets etc.)
Strong foundational knowledge in stats and maths
Experience in actually productionising models and exposing to real customers
Business acumen
Strong communication skills, both written and verbal
Nice to haves:
Experience in working with developers, especially on experimentation
Some kind of cloud based experience (AWS preferred)
Some basic knowledge of source control with Git
Our application process consists of some online testing with Alooba, video call interview and then a case study. We expect the process to take about 10 business days end to end.

Job Types: Full-time, Contract

Salary: $120,000.00 /year

Experience:
Analytics: 1 year (Preferred)
Work Remotely:
Yes",GradTests (gradtests.com),"Phoenix, AZ",-1,-1
Data Scientist,"MULTIPLE POSITIONS AVAILABLE
Company: Amazon.Com Services, Inc
Position Title: Data Scientist III
Location: Tempe, AZ
Position Responsibilities:
Interact with various software and business groups to develop an understanding of their business requirements and operational processes. Apply the acquired knowledge and business judgment to build decision-supporting and operational tools to improve the bottom line. Build quantitative mathematical models to represent a wide range of cloud software optimization, capacity planning and logistics systems. Implement these models and tools through the use of modeling languages and by engineering code in software languages such as Python, Scala, Java, C++, C# or C. Gather data required for analysis and mathematical model building by writing ad-hoc scripts and database queries. Perform quantitative, economic, and numerical analysis of the performance of these systems under uncertainty using statistical and optimization tools. Create computer simulations to support operational decision-making. Identify areas with potential for improvement and work with internal teams to generate requirements that can realize these improvements. Design optimal or near optimal solution methodologies to be used by in-house decision support tools and software. Create software prototypes to verify and validate the devised solutions methodologies; integrate the prototypes into production systems using standard software development tools and methodologies.

Basic Qualifications

Position Requirements:
Masters or foreign equivalent in Operations Research, Engineering, Statistics, Mathematics, Economics, Computer Science, or a related technical field, and six months of research or work experience as a Research Scientist, Data Scientist, Research Assistant, Software Engineer, or a related occupation. Five years of research or work experience must include each of the following: programming with a major programming language such as Python, Java, C, C# or C++; experience with SQL and Statistical Computing tools R, SPSS, or SAS; clustering and time series modeling; experience developing and optimizing models; graph analytics; experience with the application of statistics and probability in analyzing test results; experience with design, application, and optimization of complex high dimensional models; and experience with problem solving and data analysis on large datasets.

Preferred Qualifications

Applicants must meet all of the above listed requirements for this position.","Amazon
3.9","Tempe, AZ",Internet,Information Technology
Data Scientist,"Â

Role: Data Scientist

Location â Phoenix AZ

Position â Fulltime/Permanent

Â

Details:

Job Description: Looking for Data Scientist having experience in developing and operationalizing AI/ML models. The ideal candidate should have strong programing experience in Python and Spark..

Responsibilities:
Perform data modelling using advanced statistical analysis, unstructured data processing and developing predictive models.
Implement statistical and data mining techniques e.g hypothesis testing, machine learning and retrieval processes on a large amount of data to identify trends, patterns and other retrieval information.
Implement different machine learning techniques: Generalized Linear and Non- Linear models, Time Series Analysis, Random Forest, Gradient Boosted Machines, Text Mining, Deep Learning, Neural Networks, Supervised and Unsupervised methods using python and spark.
Lead the development of high -performance algorithms for predictive analytics, Testing and implementing these algorithms in scalable, product-ready code
Work with machine learning frameworks such as Scikit-Learn, H2O, Keras, TensorFlow.
Perform model evaluation, tuning and performance and scalability of scientific techniques and communicate the findings
Technology Skillset required:
Python
Spark
Pyspark
HIVE
SQL
Good to have
Neural Networking
H2O
Keras
TensorFlow","Softcom Systems
4.4","Phoenix, AZ",IT Services,Information Technology
Data Scientist,"Job Description
Job Description

Scope:
Data Scientist to help build classification, regression ML models for predictive analytics and anomaly detection
You will be responsible for transforming data and generating actionable insights into our customer behavior
Communicate key results with self-serve tools (dashboards, analytics tools) for the Customer Success team
Must have DS skills:
Data cleaning, Data wrangling, Data Visualization, Intellectual Curiosity, Business acumen, Communication Skills, Probability and Statistics, Machine Learning
Experience building (from scratch) Machine Learning (ML) models that can be put to production (with the support of data engineering and S.W engineering teams)
Professional experience building machine learning models (candidates will need to articulate detail project experience from research, model selection, action and results)
Statistics knowledge
Tools/Environment must haves:
Azure Data-bricks environment/environment experience,
Python Programming skills – 3 years (In-depth knowledge of Python, Pandas and its open-source ecosystem or similar)
SQL – 2- 3 years
Spark ML – domain knowledge
Visualization tools: Power BI or similar
Responsibilities:
Build machine-learning models
Create regression, classification models; Work with engineering teams to deploy robust, highly available decision pipelines based on your models.
Analyze large amounts of information to discover trends and patterns
Combine models through ensemble modeling
Present information using data visualization techniques
Processing, cleansing, and verifying the integrity of data used for analysis. Undertake preprocessing of structured and unstructured data
Qualifications:
Business acumen and communication skills to gather the data requirement from the business
3+ years of related professional work experience
Theoretical and execution background of Data Science with specific focus on Machine Learning
Experience testing and validating models and assessing the trade-offs between different modeling techniques and specifications
Comfort manipulating and analyzing complex, high-volume, high-dimensionality data from varying sources
Strong analytics and problem-solving skills needed. Can take the data and come up with a solution specific to the use case
Experience in applying statistical learning methods to solve business problems
Experience working with complex and/or large data sets
Practical ability to visualize data, communicate the data, and utilize it effectively
Programming skills – 2 years (In-depth knowledge of Python, Pandas and its open-source ecosystem or similar)
Proficiency in using query languages such as SQL, Hive, Pig, Sqoop.
Experience with NoSQL databases, such as MongoDB, Cassandra, Hbase and SQL databases and unstructured data stores
Excellent understanding of machine learning techniques and algorithms, such as k-NN, Naïve Bayes, SVM, Random Forests, etc.
NLP / NLU experience preferred.

Company Description
GTN provides Scalable Technical Staffing solutions encompassing SOW, staff augmentation, and direct hire placement for Fortune 2000 companies, with niche service offerings in Cyber Security, Digital, Payroll Management, and Professional Services.","GTN Technical Staffing
4.0","Scottsdale, AZ",Staffing & Outsourcing,Business Services
Statistician,"Preventable illnesses still kill tens of thousands of people every year, however there is hope. Through vaccines, public health prevention programs and data intelligence, the impact of the flu, pneumonia, measles, whooping cough, cervical cancer, and many more diseases is diminished. The battle is fought every day to ensure that communities are prepared, proactive, and empowered for any event or outbreak from bioterrorism and newly emerging disease, such as COVID-19, to the old diseases that never left.
Make an impact and join us in this fight at the front lines.

Your Role and Impact
As our Data Scientist / Statistician, you will work within STChealth's Consumer and Analytics Division alongside our Epidemiologist to explore, interpret and explain data trends and patterns to stakeholders of all levels. You will work with the analytics team in developing machine learning algorithms to automate and scale a variety of processes and explore business use cases where machine learning algorithms can be implemented. This is a great opportunity to join a team that is on the cutting edge of healthcare analytics.

About You
• You have a Masters or PhD in Applied Mathematics, Statistics or Computer Science
• You have experience with statistical computer languages (R, Python) and can manipulate data and draw insight and conclusions from large data sets
• You have experience developing advanced quantitative models using a variety of programs and software to support predictive assessments and other advanced mathematical techniques (ex. Neural Network, Random Forest, linear regression)
• You have 5 or more years in predictive modeling and large data analysis (healthcare industry preferred)
• You can easily communicate business interpretations of data to a wide variety of audiences in easy-to-understand terms
• You enjoy working in a highly collaborative environment where bringing new ideas and fresh perspectives is part of the culture

About Us
• As one of the Phoenix Business Journal's Best Places to Work 2019 awardees, you will find that we are a highly engaged group of people, motivated and passionate about creating intelligent solutions for healthier communities all over the world.
• Located in Phoenix's Warehouse District, we are proud to be a part of the dynamic and creative PHX Core Innovation Hub. We have an open-office layout with an urban feel and lots of room for collaboration and inspiration to feed all the great ideas that start here.
• Benefits? Ours are outstanding. Some of the highlights include a 100% company-paid medical plan, 401(k) matching, work-from-home perks, casual dress code, and an amazing amount of paid time off.
• When you choose STChealth you will be choosing a small company where you can make a big contribution. You'll be choosing a long-standing industry leader who has a 32+ year history but a start-up mentality. And you'll be choosing to join a team of people determined to reduce the impact of preventable disease and empower people throughout the healthcare ecosystem worldwide.

-----
Must be a United States citizen or have authorization to work in the United States as defined by the Immigration Act of 1986.
Scientific Technologies Corporation is an equal opportunity employer and makes employment decisions without regard to race, color, religion, sex, national origin, sexual orientation, gender identity, disability or protected Veteran status.

Keywords:Predictive Analytics, Statistical Analysis, Data Analytics, Machine Learning","Scientific Technologies Corporation
2.8","Phoenix, AZ",IT Services,Information Technology
Statistician,"The U.S. Department of the Treasury has a distinguished history dating back to the founding of our nation. As the steward of U.S. economic and financial systems, Treasury is a major and influential leader in today's global economy. We have over 100,000 employees across the country and around the world. Come Join the Department of the Treasury and Invest in Tomorrow.
See Other Information for Locations
Positions are to be filled in the Large Business & International (LB&I), Data Solutions division.
Eight (8) positions are to be filled in any of the following locations:
Birmingham, AL
Fayetteville, AR
Little Rock, AR
Phoenix, AZ
El Monte, CA
Glendale, CA
Laguna Niguel, CA
Los Angeles, CA
Long Beach, CA
Oakland, CA
Sacramento, CA
San Diego, CA
San Francisco, CA
San Jose, CA
Santa Ana, CA
Lakewood, CO
Hartford, CT
New Haven, CT
Norwalk, CT
Washington, DC
Newark, DE
Miami, FL
Ft. Myers, FL
Jacksonville, FL
Maitland, FL
Plantation, FL
Tampa, FL
West Palm Beach, FL
Atlanta, GA
Honolulu, HI
Des Moines, IA
Chicago, IL
Downers Grove, IL
Schiller Park, IL
Springfield, IL
Indianapolis, IN
Wichita, KS
Louisville, KY
New Orleans, LA
Boston, MA
Brockton, MA
Stoneham, MA
Southborough, MA
Baltimore, MD
Lanham-Seabrook, MD
Rockville, MD
Ann Arbor, MI
Clinton Township, MI
Detroit, MI
Farmington Hills, MI
Flint, MI
Grand Rapids, MI
Pontiac, MI
Bloomington, MN
Chesterfield, MO
Lee's Summit, MO
Charlotte, NC
Greensboro, NC
Raleigh, NC
Omaha, NE
Edison, NJ
Iselin, NJ
Mountainside, NJ
Paterson, NJ
Las Vegas, NV
Albany, NY
Bethpage, NY
Buffalo, NY
New York, NY
Rochester, NY
Cincinnati, OH
Columbus, OH
Independence, OH
Oklahoma City, OK
Tulsa, OK
Portland, OR
Philadelphia, PA
Pittsburgh, PA
King Of Prussia, PA
Guaynabo, PR
Warwick, RI
Franklin, TN
Memphis, TN
Nashville, TN
Austin, TX
Farmers Branch, TX
Fort Worth, TX
Houston, TX
San Antonio, TX
Ogden, UT
Salt Lake City, UT
Norfolk, VA
Richmond, VA
Vienna, VA
Seattle, WA
Milwaukee, WI
Waukesha, WI
Kearneysville, WV
Martinsburg, WV
WHAT DOES A DATA SCIENTIST DO? The Data Scientist utilizes advanced analytical, statistical, and computer programming skills to develop data- driven solutions to difficult business challenges. As a data scientist, you are responsible for conducting data-centric projects to provide insight and informed decisions for mission- oriented programs of the Internal Revenue Service (IRS), which may impact multiple program segments, divisions, the Service, or segments of the taxpayer population. This is accomplished by utilizing a wide range of technical competencies such as statistics and machine learning, coding languages, data wrangling, and reporting and visualization techniques. The Data Scientist may lead team or cross functional projects, and will apply critical thinking, problem solving and ability to communicate complex analysis to advance the use of data-driven decision making in IRS operations.

WHAT IS THE LARGE BUSINESS AND INTERNATIONAL (LB&I) DIVISION OF THE INTERNAL REVENUE SERVICE? The Large Business and International (LB&I) business unit provides service and enforcement activities to support tax compliance of businesses and related entities with assets of $10 million or more, as well as small U.S. businesses engaged in international, U.S. citizens abroad, and foreign persons and businesses with a U.S. tax requirement.
As a Data Scientist, you will:
Serve as a technical expert with responsibility for the initiation, planning, implementation, controlling, modifying and executing of all or part of an entire project, including such tasks as formulation of workload estimates for program segments, specification of the methodology to be used, preparation of appropriate specifications and procedures, and review of computer systems specifications and materials and instructions needed for assuring the adequacy of the project’s design and objectives.
Explore novel methods of retrieving data and develop innovative recommendations to management and senior leadership as a means for making data driven decisions such as modification of processes and policies. Review, evaluate, validate, and document the results of the findings.
Assist the supervisor in determining the scope, goals and schedules for future programs in the Office. Collaborate with business or technology partners to understand business needs, identify opportunities, and develop and implement analytical solutions.
Identify and assess relevant data sources’ validity and reliability to meet project needs. Collate, clean, transform, analyze, and integrate structured and unstructured data from various sources in preparation for analysis.
Apply statistical methods and concepts including data mining, statistical theory and research procedures to test hypotheses using structured and unstructured data. Develop data product solutions to improve customer experiences, anomaly detection, and business outcomes. Develop proofs of concept or demonstrations to evaluate feasibility of project solutions and recommend visualization strategies.
Document project work and review deliverables for validity, reliability and timeliness. Communicate analytic solutions to technical and non-technical stakeholders, including during executive- level and/or cross-agency meetings, in a clear and effective manner using oral and written communications.
Maintain knowledge of state-of-the-art innovations in data science from both academic and industry sources and identify opportunities for implementation. Engage in general professional development to improve knowledge of IRS processes/programs.
Apply computer based mathematical/statistical techniques using software. Lead or participate in statistical projects or studies in survey sampling (design and estimation), modeling, or statistical research. Apply knowledge of programming/coding language (i.e., SQL, SAS, SPSS, RStudio) to develop scripts or applications.
Act as a troubleshooter in resolving bottlenecks at any step in a project by identifying and proposing solutions; this may include coordination with other project team members or stakeholders to mitigate issues.

WHERE CAN I FIND OUT MORE ABOUT OTHER IRS CAREERS? If you want to find out more about IRS careers, visit us on the web at www.jobs.irs.gov
#LI-POST
You must meet the following requirements by the closing date of this announcement
BASIC QUALIFICATION REQUIREMENTS:

GS-1530 Statistician All Grades:
You must have a Bachelor's degree that included 15 semester hours in statistics (or in mathematics and statistics, provided at least 6 semester hours were in statistics), and 9 additional semester hours in one or more of the following: physical or biological sciences, medicine, education, or engineering; or in the social sciences including demography, history, economics, social welfare, geography, international relations, social or cultural anthropology, health sociology, political science, public administration, psychology, etc. Credit toward meeting statistical course requirements should be given for courses in which 50 percent of the course content appears to be statistical methods, e.g., courses that included studies in research methods in psychology or economics such as tests and measurements or business cycles, or courses in methods of processing mass statistical data such as tabulating methods or electronic data processing. OR
Combination of education and experience -- courses as shown above, plus appropriate experience or additional education. The experience should have included a full range of professional statistical work such as (a) sampling, (b) collecting, computing, and analyzing statistical data, and (c) applying statistical techniques such as measurement of central tendency, dispersion, skewness, sampling error, simple and multiple correlation, analysis of variance, and tests of significance.
GS-13 LEVEL: You must have one year of specialized experience at a level of difficulty and responsibility equivalent to the GS-12 grade level in the Federal service. Specialized experience for this position includes all of the following:
Experience applying project management principles on a data science project
Experience planning and executing a variety of data science and/or analytics projects.
Experience using data mining process models (such as CRISP-DM, SEMMA, etc.,) to design and execute data science project.
Experience preparing and analyzing structured and unstructured datasets to explorations and evaluating data science centric models.
Experience working with multiple data types and formats as a part of a data science project.
Experience applying a range of analytic approaches, including (but not limited to) machine learning, text analytics, and natural language processing; graph theory, link analysis and optimization models; complex adaptive systems; and/or deep learning neural networks that are part of the exploration.
Experience coding in various programming languages (such as R, Python, SQL, or JAVA) to conduct various phases of data science projects.
Experience creating and querying different datastores and architectures (such as Sybase, Oracle, and open-source databases) to work with various types of data as part of the data science project.
Experience using tools for data visualization (graphs, tables, charts, etc.,) and end-user business intelligence.
-The experience may have been gained in the public sector, private sector or Volunteer Service. One year of experience refers to full-time work; part-time work is considered on a prorated basis.
-To ensure full credit for your work experience, please indicate dates of employment by month/year, and indicate number of hours worked per week, on your resume.","Internal Revenue Service
3.5","Phoenix, AZ",Federal Agencies,Government
Data Scientist,"Role Data Scientist Location Phoenix, AZ Client Amex Impetus JD At least 6+ years of IT experience. Experience in developing implementing data science models specifically time series experience. Proven ability to do hands-on development using Python, Hive and Spark and delivering models into production",Youth Power Technosoft LLC.,"Phoenix, AZ",-1,-1
Data Scientist,"OUR COMPANY MISSION

Soaren Management merges time-tested business practices with cutting-edge proprietary technologies to deliver reliable, efficient, and secure financial products and services. Our greatest strengths, technology and customer care, flow from the ingenuity, curiosity and integrity of our partners and employees.

VISION STATEMENT

Soaren Management works toward a future where all consumers have broad and immediate access to a range of reliable, efficient, and secure financial products and services, expedited by constantly evolving technologies.

COMMITMENT TO OUR TALENT

Soaren Management believes our success flows directly from our employees. Our employees are at the heart of our success. As such, it is in our best interest to provide all the support they need to succeed and thrive. For that reason, Soaren Management is expanding its search for fresh talent and developing our current talent. Our commitment to our team ensures value and service to our ever-growing customer base through hiring and growing our people-centric, diverse, and forward-thinking talent.

OUR BENEFITS
Competitive annual salary
Company sponsored medical/dental/vision/life insurance/AD&D
401k with company matching
Excellent work-life balance
Flexible schedule available
PTO
A small executive team with promotion opportunities
Start-up company atmosphere with an established corporate structure
A fun, casual work environment that encourages innovative thinkers
JOB DESCRIPTION

We are currently looking for an experienced Data Scientist with deep technical and statistical knowledge and a proven track record to drive business value using advanced data analysis and machine learning techniques. This position will collaborate with executives and other business departments to execute a variety of analytical projects to improve processes and create efficiencies.

PRINCIPAL DUTIES AND RESPONSIBILITIES
Analyze complex data sets to reduce costs and improve customer experience.
Create systems for gathering, extracting, preparing data from multiple sources.
Evaluate call center services and consumer experiences with measurable data points.
Understand operational key performance indicators, report trends and patterns.
Effectively communicate analysis with proper measurements and testing.
Formulate enhancements through system optimizations and continual data analysis.
Champion process improvements assessing pre-and post-process change.
Collaborate across Operations, Compliance, IT, Finance, or other departments.
Follow all company policy and procedures.
Display leadership through punctuality, professionalism while performing required duties.
Reinforce a workplace culture of positivity, inclusion, cooperation, and respect.
Embrace and promote our company mission and core values.
Other related duties as assigned.
QUALIFICATIONS
Master's or PHD in Statistics, Mathematics, Computer Science, or another quantitative field.
3+ years of experience manipulating data sets and building statistical models.
Strong written and verbal communication skills.
Proven experience solving complex business problems using Statistical and Machine Learning techniques.
Strong SQL and data-wrangling skills – experience building datasets from scratch.
Experience using statistical computer languages (Python, R) to manipulate data and draw insights from large data sets.
Experience working in a startup environment a plus.
Must meet requirements of company background check policy requirements.
MEASURE OF SUCCESS
Ability to understand business and applications, capture, organize and present data for making better decisions and creating competitive advantages.
Ability to enhance call center services and consumer applications with streamlined data components to improve services through effective measurement and analysis.
Ability to scope, manage and execute assigned projects with effective data visualization.
Hitting goals while promoting a positive attitude true to our mission and core values.
Job Type: Full-time

Benefits:
401(k)
401(k) Matching
Dental Insurance
Employee Assistance Program
Flexible Spending Account
Health Insurance
Life Insurance
Paid Time Off
Parental Leave
Professional Development Assistance
Relocation Assistance
Tuition Reimbursement
Vision Insurance
Experience:
Data Science: 3 years (Required)
Education:
Master's (Preferred)
Work Location:
One location
Fully Remote
This Company Describes Its Culture as:
Innovative -- innovative and risk-taking
Outcome-oriented -- results-focused with strong performance culture
People-oriented -- supportive and fairness-focused
Team-oriented -- cooperative and collaborative
Schedule:
Monday to Friday
No weekends
Company's website:
https://www.soarenmanagement.com/
Work Remotely:
Yes","Soaren Management
4.3","Scottsdale, AZ",Lending,Finance
Machine Learning Engineer,"Machine Learning Engineer
10835
Phoenix, AZ
7/13/2020 11:11:00 AM

IT
Contractor - W2

Job Description
Job Description – Python/ML – Senior Engineer/ Architect

Site Reliability engineering portfolio consists of several mission critical americanexpress.com applications. Web engineering enterprise applications are highly available applications, maintains high (~99.999%) availability in an extremely high throughput transactional system with strict performance requirements. Primary focus of the Site Reliability Engineering team is to conceptualize, design, develop and implement observability related frameworks/common components, instrumenting observability tools for enterprise that will ensure high application reliability, scalability, availability and performance of the Web applications. Site reliability team is embarking on a transformation journey to implement “Automation first” approach in Service Delivery and Site Reliability Engineering space.

What you will be doing:
Conceptualize and implement Machine Learning driven Site Reliability Engineering Framework/Components to improve predictive monitoring and driving SRE team’s journey towards “Automation First” approach
Research latest technology, concepts, conceptualize solution and develop proof of concept that will improve resiliency and performance of the production infrastructure. Design and implement innovative solution/framework that will improve software engineering velocity, infrastructure resiliency and security, and data availability
Develop observability related common framework components (to be leveraged by enterprise applications), define standards for configuration, monitoring, reliability and performance engineering


Qualifications:
A BS degree in Computer Science, Computer Engineering, other Technical discipline, or equivalent work experience
5 + years of experience in Python with emphasis on machine learning
Hands on experience with – Spark, Splunk, Pandas, Numpy, and Scikit-learn
Experience in designing mission critical highly available enterprise applications
Strong knowledge of Linux internals and experience managing Linux systems in high traffic environments
Strong knowledge of machine learning, mathematical modeling, R, and statistics
Strong interpersonal communication skills and the ability to work well in a diverse team-focused environment
5+ years of experience with building Rest APIs, API Integration, and Web Services is preferred
Knowledge of server-side technologies such as WebSphere, JBose, NodeJS is preferred

Job Requirements
Job Description – Python/ML – Senior Engineer/ Architect

Site Reliability engineering portfolio consists of several mission critical americanexpress.com applications. Web engineering enterprise applications are highly available applications, maintains high (~99.999%) availability in an extremely high throughput transactional system with strict performance requirements. Primary focus of the Site Reliability Engineering team is to conceptualize, design, develop and implement observability related frameworks/common components, instrumenting observability tools for enterprise that will ensure high application reliability, scalability, availability and performance of the Web applications. Site reliability team is embarking on a transformation journey to implement “Automation first” approach in Service Delivery and Site Reliability Engineering space.

What you will be doing:
Conceptualize and implement Machine Learning driven Site Reliability Engineering Framework/Components to improve predictive monitoring and driving SRE team’s journey towards “Automation First” approach
Research latest technology, concepts, conceptualize solution and develop proof of concept that will improve resiliency and performance of the production infrastructure. Design and implement innovative solution/framework that will improve software engineering velocity, infrastructure resiliency and security, and data availability
Develop observability related common framework components (to be leveraged by enterprise applications), define standards for configuration, monitoring, reliability and performance engineering


Qualifications:
A BS degree in Computer Science, Computer Engineering, other Technical discipline, or equivalent work experience
5 + years of experience in Python with emphasis on machine learning
Hands on experience with – Spark, Splunk, Pandas, Numpy, and Scikit-learn
Experience in designing mission critical highly available enterprise applications
Strong knowledge of Linux internals and experience managing Linux systems in high traffic environments
Strong knowledge of machine learning, mathematical modeling, R, and statistics
Strong interpersonal communication skills and the ability to work well in a diverse team-focused environment
5+ years of experience with building Rest APIs, API Integration, and Web Services is preferred
Knowledge of server-side technologies such as WebSphere, JBose, NodeJS is preferred","IntraEdge
3.8","Phoenix, AZ",IT Services,Information Technology
Data Scientist,"Company Description

null
Job Description

Title: Data Scientist

Location: Tempe, AZ (Remote Work initially)

Duration: Full Time

Job Description

Preferably looking for 8+ years of experience candidate.

SQL

Python

R language

Hadoop

If you are willing to apply, then please send your updated resume along with below mentioned details:

Availability to Join:

Availability for the first Telephonic Interview:

Candidate must be authorized to work in the United States

Fulcrum is an Equal Opportunity Employer and is committed to maintaining a discrimination-free workplace","fulcrum worldwide
3.3","Tempe, AZ",IT Services,Information Technology
Data Engineer,"Location: Phoenix (AZ)
Location: Pittsburgh (PA)

Zoom is an award-winning workplace. We have been recognized by Comparably as #1 CEO, Company Happiness, Benefits, Compensation, Diversity, and more! Not to mention we've been awarded by Glassdoor as the 2nd Best US workplace & Best Large Company US CEO in 2018, Wealthfront, and Business Insider. Our culture focuses on delivering happiness, our commitment to transparency, and the tangible benefits we provide our employees and our customers.

The Data Science team lies at the foundation of Zoom's success - you'll be working cross-functionally with teams of engineers, scientists, marketers, and product professionals on some of the most critical projects in the company - whether it's exploratory research to predict user behavior, or running experiments to optimize untapped areas of growth, or developing machine learning models that deliver ""happiness"" to our users more consistently and at scale. If you are passionate about data engineering and looking to join a fun and fast-moving team, we'd love to meet you! Our team is taking Zoom's data culture to the next level by integrating predictive models into our infrastructure, and we are looking for someone like you to help us get there! This role is based in Pittsburgh or Phoenix.

Responsibilities
Own and optimize Zoom's data architecture to address the data needs of our rapidly-growing business
Join a group of passionate people committed to delivering ""happiness"" to our users and to each other
Partner with data scientists, sales, marketing, operation, and product teams to build and deploy machine learning models that unlock growth
Build custom integrations between cloud-based systems using APIs
Write complex and efficient queries to transform raw data sources into easily accessible models by coding across several languages such as Java, Python, and SQL
Architect, build, and launch new data models that provide intuitive analytics to the team
Build data expertise and own data quality for the pipelines you create
Requirements
Three or more years of relevant software engineering experience (Python, Scala and Java) in a data-focused role
Passion for creating data infrastructure technologies from scratch using the right tools for the job
A knack for writing, clean, readable, maintainable code
Comfort with open source technologies like Kafka, Hadoop, Hive, Presto, and Spark
Expertise in building out data pipelines, efficient ETL design, implementation, and maintenance
Experience with AWS tools
Proven track-record of solving complex data processing and storage challenges through scalable, fault-tolerant architecture","Zoom
4.8","Phoenix, AZ",IT Services,Information Technology
Data Scientist,"Data Scientist
10558
Phoenix, AZ
2/11/2020 1:10:00 PM

IT
Contractor - W2

Job Description
Preferably a MS or a PHD degree in computer science, computer engineering, or other technical discipline
Data Science : Must have deep knowledge of Natural language processing and techniques, Voice and Text data engineering and developing models for NLP.
Capability of writing, debugging and compiling codes in multiple Machine Learning environment and not limited to Python/Pyspark, Apache Spark, R Spark etc.
At least 2-4 years of experience in the following areas.
Complete grip on Python environment and libraries (scikit, nltk, pandas and numpy). Working knowledge of R & Spark is a plus.
Proven experience of solving complex business problems using Machine Learning techniques like Regression, Classification, Supervised or Unsupervised Recommenders, Deep iterative learning, Neural Nets etc.
Deep knowledge of Statistics and Math’s, and ability to dissect problems from the first principle. Exposure to fields like Linear Algebra, Bayesian Statistics, Group theory is desirable.
Experience of working in Distributed/Cluster computing environment is desirable.
Ability to work in cross functional teams.
Excellent data presentation and visualization skills
Hands on knowledge of SQL/ Hive QL is desirable
2+ years of software development experience with be a plus
Ability to effectively interpret technical and business objectives and challenges and articulate solutions
Willingness to learn new technologies and exploit them to their optimal potential
At the core of Software Engineering

Every member of our team must be able to demonstrate the following technical, functional, leadership and business core competencies, including:
Agile Practices
Porting/Software Configuration
Programming Languages and Frameworks
Business Analysis
Analytical Thinking
Business Product Knowledge

Job Requirements","IntraEdge
3.8","Phoenix, AZ",IT Services,Information Technology
Data Analyst,"Bigger challenges. Bolder ideas. Global impact. At Viasat, we're on a mission to deliver connections with the capacity to change the world. We're the company behind the world's fastest satellite internet service, with technology that's helping to bridge the digital divide and improve life for our customers around the globe. By providing powerful new ways for people to connect with one another, gain greater access to education, entertainment, medical research, commerce, and much more, our team is empowering millions of customers worldwide. We're looking for passionate, innovative professionals to join our team and connect the world to more. You'll work in a collaborative and inclusive environment that values diverse perspectives and continuous learning, and provides industry-leading benefits with unmatched opportunities for career growth. Our team is fearless in pursuit of new ideas and uncompromising in our quest to become the world's first truly global Internet Service Provider. Interested in joining our mission? Take a look at career opportunities at Viasat today.Job ResponsibilitiesAs a Data Analyst on the Business Operations team, you will provide analytics and insights into manufacturing and business systems in support of broad program areas across Viasat. A significant amount of this role's responsibility is aggregating, cleansing, joining, and storing data from varied sources. The talented individual in this position will develop analytical models while automating reporting and bringing the data visualization to life by building dashboards for stakeholders to use. The Data Analyst will perform data analyses encompassing in a range of analytic capabilities including but not limited to: statistical analysis, regression, time-series analysis, control charting, simulation, and other mathematical techniques.Responsibilities include:Parse and manipulate raw data leveraging tools including R, Python, Tableau, Alteryx, Pentaho or Informatic with a strong preference for PythonIngest, understand, and fully synthesize large amounts of data from multiple sources to build a full comprehension of the storyAnalyze large data sets, while finding the truth in data, and develop efficient processes for data analysis and simple, elegant visualizationDevelop and automate daily, monthly, quarterly reporting for multiple business areas within ViasatIdentifies data gaps, researches methods to fill these gaps and provide recommendationsGather and analyze facts and devise solutions to administrative problems Monitor big data with Business Intelligence tools, simulation, modeling, and statisticsExperience building intuitive and actionable dashboards and data visualizations that drive business decisions (Tableau or similar) Requirements3-5 years SQL experience3-5 years data analysis experience with emphasis in reporting 2-3 years Python experience in data cleansing, statistics, and data visualization packages (i.e. pandas, scikit-learn, matplotlib, seaborn, plotly, etc.)Strong statistics/SPC background 2-3 years Tableau experience or equivalent with data visualization toolsBackground in data visualization and decision support leveraging open source libraries/packages and third-party tools (Tableau or similar)Excellent judgment, critical-thinking, and decision-making skills; can balance attention to detail with swift executionAble to identify stakeholders, build relationships, and influence others to drive progressExcellent analytical and problem solving skillsStrong oral and written communication skillsStrong statistical backgroundBachelors degree in a related fieldUp to 10% of travelUS Citizenship is requiredPreferencesStrong preference for personal projects and work in Python Data Science experienceAlteryx experience preferredOracle EBS experience desiredOracle Business Intelligence (OBIEE) highly preferredExperience in Data Science and developing machine learning algorithmsTo learn more about this site and other office locations, please click here!_______#LI-CSI
Additional requirements
Minimum education:
BA/BS
Years of experience:
3-5 years
Travel:
Up to 10%
Citizenship:
US Citizenship Required
Clearance:
None
PDN-VSAT5580-1","Viasat
4.1","Phoenix, AZ",Telecommunications Services,Telecommunications
Data Scientist,"Role : Data Scientist

Location : Phoenix, AZ

Client : Amex / Impetus

Rate : $50-$52

JD :

At least 6+ years of IT experience. Experience in developing & implementing data science models specifically time series experience. Proven ability to do hands-on development using Python, Hive and Spark and delivering models into production

Job Type: Contract

Pay: $45.00 - $50.00 per hour

Work Remotely:
Temporarily due to COVID-19",Youth Power Technosoft LLC,"Phoenix, AZ",-1,-1
Data Analyst,"The Data Analyst is responsible for providing accurate, complete and meaningful reports and analysis used for business management and decision making. The Senior Data Analyst works closely with department and/or functional managers to determine report requirements, build reports, and quality test them prior to distribution. The Senior Data Analyst also provides support with project management services for large data projects.

Essential Job Functions
• Develops and deploys reporting and analysis that is accurate, complete and properly summarized to aid in management of business and management decision making. Responsible for extracting and summarizing data from JDE and other corporate systems.
• Has expert knowledge of JDE tables and field usage. Has thorough knowledge of other corporate software, programs and data tools. Assists managers with report design and development. Tests reports and ensures that they perform as expected.
• Understands flow of data internally and in relation to the General Ledger.
• Produces weekly, monthly, and quarterly trend and activity reports as well as other operational and management reports. Ensures that reports are produced per scheduled timelines for review by functional management teams.
• Analyzes large amounts of data and investigates and researches anomalies. Works with department and/or functional teams to correct issues when identified.
• Works with IT Business Intelligence team to design, test and deploy MRE reports for general usage.
• Provides support to management to produce reports and analyze large amounts of data as part of acquisitions or other special projects.
• Produces ad-hoc reporting as assigned.

TekCom Resources, Inc. is proud to be an Equal Opportunity Employer and values diversity. All employment is decided on the basis of qualifications, merit and business need. We are compliant with the Fair Chance Ordinance as applicable, and will consider all qualified applications for employment.","TekCom Resources, Inc.
4.9","Phoenix, AZ",Staffing & Outsourcing,Business Services
Data Analyst,"Job Description
We are currently seeking an innovative, disciplined, and results-oriented Data Analyst with relevant technical, business, and influencing skills to work in the Data Strategy & Analytics group within the Corporate Finance organization.

As a Data Analyst, you will leverage Microsoft’s Power Platform to create user-friendly dashboards, analysis, visualizations, and other end-to-end data solutions that support our company initiatives. Primary support/focus will be on our Public Access Business Segment, although cross over support to other business segments will occur.

The Data Analyst will also help drive and contribute to advancing the development of our Data Platform across the entire organization and to establish a best in class Data Strategy using the latest Microsoft Products.

About the role:
Design, develop and maintain a suite of best in class Data Strategy using Microsoft Power Platform
Simplify and communicate complex concepts to our Public Access business partners to drive data-driven outcomes
Advanced Data Visualization skillset to design and deploy Power BI Dashboards and Reports
Provide necessary technical coaching, mentoring, and training across multiple stakeholder groups to drive adoption of the Data Platform across the organization
Actively engage in the research and deployment of emerging technologies (i.e. Data Lake, Power Platform, Common Data Service, Common Data Model, etc.)
Flexible and capable of prioritizing competing tasks, timelines, and work streams
Minimum Qualifications:
Bachelor's degree in Business, Computer Science, Analytics, or another quantitative discipline
3+ years of experience as a Data Analyst creating solutions using Microsoft Power Platform
Advanced MS SQL experience
Experience with designing the data flow of the entire end-to-end Data Strategy landscape (i.e. source systems, data integration, consolidation, and reporting).
Ability to break down complex problems and projects into manageable goals and align data initiatives with the overall Data Platform Strategy.
Ability to influence across all levels of the organization and to partner effectively with cross-functional teams.
Experience with Finance systems, data concepts, and business processes.
Highly motivated self-starter with ability to work efficiently with minimal supervision and direction
Must be flexible and willing to work to meet the demands of the business which may include evenings, weekend, and holidays
International travel may be required, so must possess a valid Passport and/or Travel Documentation

Company Description
About NAGRA (Kudelski Group):
NAGRA is the worldwide leader in delivering secure, end-to-end digital media technologies that service providers can rapidly deploy to generate and protect revenues. Our solutions address the entire digital media ecosystem with a focus on leveraging innovations and elevating the consumers digital entertainment experience.

120 leading service providers worldwide have entrusted us as a natural ally for generating and securing revenue from content delivered to hundreds of millions subscribers.

NAGRA has unparalleled know-how and experience in the delivery of complete, end-to-end and secure digital media solutions, with a proven track record that spans two decades. NAGRA is independent from any media group or service provider, and is part of the Kudelski Group (SIX:KUD.S), a global technology leader.","NAGRA (Kudelski Group)
3.5","Phoenix, AZ",Telecommunications Manufacturing,Telecommunications
Data Engineer,"Description


Do you want your voice heard and your actions to count?

Discover your opportunity with Mitsubishi UFJ Financial Group (MUFG), the 5th largest financial group in the world (as ranked by S&P Global, April 2018). In the Americas, were 14,000 colleagues, striving to make a difference for every client, organization, and community we serve. We stand for our values, developing positive relationships built on integrity and respect. Its part of our culture to put people first, listen to new and diverse ideas and collaborate toward greater innovation, speed and agility. Were a team that accepts responsibility for the future by asking the tough questions and owning the solutions. Join MUFG and be empowered to make your voice heard and your actions count.

Job Summary

We're seeking a Data Engineer to support the Core Banking Transformation (CBT) Program. This is a multi-year effort to modernize our deposits platform with a digitally-led and simplified ecosystem for consumer, small business, commercial, and transaction banking to deliver exceptional customer experience.

As the Data Engineer, you need to be collaborative and passionate about solving complex data engineering problems. You will be responsible for the design, build, implementation, monitoring, and management of the MUFG Core Banking data services gateway that provides the foundations for the technology modernization and digital transformation.

You will focus on building the firms next-generation data environment and be a key player in creating a data services platform that drives real-time decision-making in service of our customers. You will develop, build, and operate the platform using DevSecOps and System Reliability Engineering (SRE) methods.

Major Responsibilities:
Gather and process large, complex, raw data sets at scale.
Build processes to support data transformation, data structures, metadata, dependency, and workload management.
Build the infrastructure required for optimal extraction, transformation, and loading of data.
Partner with risk management and security teams to identify the standards and lead the design, build, and rollout of secured and compliant data services.
Embrace Infrastructure-as-Code, and use Continuous Integration / Continuous Delivery Pipelines to handle the full data service lifecycle.
Write infrastructure, application, and data automated test cases and participate in code review sessions.
Provide Level 3 support for troubleshooting and services restoration in Production.

Qualifications


The right candidate will have:
8+ years of technical experience with data services solution design and implementation in a cloud-native environment, possessing expert-level skills in four or more of the following areas:
Data field encryption, tokenization and metadata management
SQL and NoSQL databases, including Postgres, DynamoDB etc.
Experience with data pipeline and workflow tools: Wherescape Streaming, Wherescape RED, StreamSets Data Collector etc.
Experience with stream-processing systems: Kafka, AWS Kinesis, Apache Storm, Spark-Streaming, etc.
History of manipulating, processing and extracting value from large disconnected datasets with ETL and Data engineering
Know-how of SQL, Informatica PowerCenter or similar.
Experience with secure cloud services for data management and integration
Developing automation with python, bash, java, powershell or similar languages
Familiar with DevOps toolchain, i.e. BitBucket, JIRA, Jenkins Pipeline, Artifactory or Nexus, and experienced in deploying n-tier application stacks in AWS
Excellent data and system analysis, data mapping, and data profiling skills
Good understanding of cloud-native application models and patterns
Able to work alternative coverage schedules when necessary
Ability to find a solution with limited guidance
Bachelor's degree in computer science or related field, or equivalent professional experience
Desired Knowledge, Skills, and Experience:

Experience with container orchestration technologies such as Docker, Kubernetes, Openshift
AWS professional level certifications is preferred but not required
The above statements are intended to describe the general nature and level of the work being performed. They are not intended to be construed as an exhaustive list of all responsibilities, duties, and skills required of personnel so classified.

We are proud to be an Equal Opportunity / Affirmative Action Employer and committed to leveraging the diverse backgrounds, perspectives, and experience of our workforce to create opportunities for our colleagues and our business. We do not discriminate in employment decisions on the basis of any protected category.

A conviction is not an absolute bar to employment. Factors such as the age of the offense, evidence of rehabilitation, seriousness of violation, and job relatedness are considered in all employment decisions. Additionally, its the banks policy to only inquire into a candidates criminal history after an offer has been made. Federal law prohibits banks from employing individuals who have been convicted of, or received a pretrial diversion for, certain offenses.","MUFG
3.1","Tempe, AZ",Banks & Credit Unions,Finance
Data Analyst,"Job Description
Data Analyst - SQL

Modis is currently seeking a Data Analyst (not a Data Engineer or Scientist) with strong SQL experience. Our client is seeking a passionate individual for a permanent hire role. This is an exciting opportunity to work on a diverse range of projects with one of the industry's fastest growing companies. Please apply or email me directly if you feel you are the individual we are looking for.

Position Responsibilities
Review and validate customer data as it is collected
Oversee the deployment of data to the data warehouse
Will be utilizing SQL on a frequent basis
Develop policies and procedures for the collection and analysis of data
Create or discover new data procurement and processing programs
Cooperate with our IT department to deploy software and hardware upgrades that make it possible for us to leverage big data use cases
Monitor analytics and metrics results
Implement data analysis methodologies
Review customer files to ensure integrity of data collection and utilization
Perform data profiling to identify and understand anomalies
Qualifications
Bachelor’s Degree is required
3+ years’ experience in a Data Analyst role
Strong background using SQL
Experience in customer care analytics is a big plus
Ability to understand and find appropriate applications for data and analysis results
If you feel that you are a good fit for this job please apply through the link or email your resume to andrew.cooper@modis.com.","Modis
3.2","Phoenix, AZ",Staffing & Outsourcing,Business Services
Data Analyst,"Job Description
Data Analyst

Parker & Lynch is currently conducting a direct hire search for a Data Analyst in Phoenix, AZ. Our client is seeking an experienced Analyst who wants to leverage their analytical and technical skills to make an immediate and meaningful impact on the business. If you are looking for a company that has a culture including arcade games, nap pods, strong philanthropy ties, and work-life balance, this might be your dream job!

Responsibilities:
Working closely with stakeholders across the organization to best understand their reporting and analysis needs.
Help make company-wide data driven decisions.
Create powerful visualizations and dashboards in Tableau and Excel.
Collaborate with company leaders to design systems to capture data to drive future decisions and help prioritize engineering efforts around proposed technology solutions.
Qualifications:
1-5 years of data or business analyst experience.
Strong SQL knowledge.
Experience with Excel and Tableau.
Experience with R and Python is a plus.
Education:
Bachelor’s Degree required.
If you feel that you are a good fit for this position in Phoenix, AZ- apply today at www.parkerandlynch.com","Parker & Lynch
3.6","Phoenix, AZ",Staffing & Outsourcing,Business Services
Data Engineer,"Data Engineer
10513
Scottsdale, AZ
1/27/2020 2:26:00 PM

Data Science
Contractor - W2

Job Description
looking for a savvy Data Engineer to join our growing team of analytics experts. The hire will be responsible for expanding and optimizing our data and data pipeline architecture, as well as optimizing data flow and collection for cross functional teams. The ideal candidate is an experienced data pipeline builder and data wrangler who enjoys optimizing data systems and building them from the ground up. The Data Engineer will support our software developers, database architects, data analysts and data scientists on data initiatives and will ensure optimal data delivery architecture is consistent throughout ongoing projects. They must be self-directed and comfortable supporting the data needs of multiple teams, systems and products. The right candidate will be excited by the prospect of optimizing or even re-designing our company’s data architecture to support our next generation of products and data initiatives.

PRINCIPLE RESPONSIBILITIES:

• Create and maintain optimal data pipeline architecture,
• Assemble large, complex data sets that meet functional / non-functional business requirements.
• Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc.
• Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using SQL and AWS ‘big data’ technologies.
• Build analytics tools that utilize the data pipeline to provide actionable insights into customer acquisition, operational efficiency and other key business performance metrics.
• Work with stakeholders including the Executive, Product, Data and Design teams to assist with data-related technical issues and support their data infrastructure needs.
• Keep our data separated and secure across national boundaries through multiple data centers and AWS regions.
• Create data tools for analytics and data scientist team members that assist them in building and optimizing our product into an innovative industry leader.
• Work with data and analytics experts to strive for greater functionality in our data systems.
• Troubleshoots issues with minimal guidance, identifies bottlenecks in existing data workflows and provides solutions for a scalable, defect-free application
• Works with onshore/offshore team to analyze, develop and improve pipeline run times as well as produce accurate defect free code
• Complies with Company policy and practices relating to the System Development Life Cycle.
• Provides Tier 3 support and resolution of IT issues escalated by IT Customer Support.
• Support audit and compliance reporting requests.
• Support the operation of MarkLogic and Snowflake products on a 24/7 basis as needed.
• Supports production environment in the event of emergency
• Participate in on-call support 24x7 weekly rotation of the operation of Informatica.
• Performs other job-related duties as assigned or apparent.

QUALIFICATIONS:

• 2+ years’ experience working with data warehousing, ETL development and ETL architecture.
• 2+ years’ experience combined experience with any of the following database technologies (RDBMS: MSSQL, MySQL Oracle; NoSQL: MarkLogic, Snowflake, DynamoDB, Redis).
• 2 years’ experience working on large data initiatives (?5 terabytes).
• 1 years’ experience as a JavaScript
• Advanced working SQL knowledge and experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases.
• Experience building and optimizing ‘big data’ data pipelines, architectures and data sets.
• Experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement.
• Build processes supporting data transformation, data structures, metadata, dependency and workload management.
• Good knowledge and experience of working with OO Javascript, XHTML, CSS, XML, Ajax and one or more JavaScript libraries (e.g. Prototype, JQuery)
• Experience with web services (e.g. RESTful services), including the ability to programmatically interact with data formats that may include XML, JSON and RDF
• Experience with writing software for complex web-based business applications which makes use of client-side data capture, validation and presentation
• Working knowledge of version control systems (e.g. SVN, Git)

MINIMUM QUALIFICATIONS:
• 2+ years of experience in a Data Engineer role, who has attained a bachelor’s degree in Computer Science, Statistics, Informatics, Information Systems or another quantitative field.
• AWS: 1 year experience
• DevOps Practices: 1 year experience
• 2+ years’ experience working with data warehousing, ETL development and ETL architecture.
• 2+ years’ experience combined experience with any of the following database technologies (RDBMS: MSSQL, MySQL Oracle; NoSQL: MarkLogic, Snowflake, DynamoDB, Redis).
• 2 years’ experience working on large data initiatives (?5 terabytes).
• 1 years’ experience as a JavaScript

Job Requirements","IntraEdge
3.8","Scottsdale, AZ",IT Services,Information Technology
Data Engineer,"Data Engineer Emphasis on Elasticsearch / Kafka / JSON / XML

The Opportunity:

We are looking for a Data Engineer based in Phoenix Az with 2-3 years software engineering experience.

You'll be developing and deploying tools for the processing and import/export of data into and out of large scale Elasticsearch and Kafka environments.

The Day to Day:
Work to customer requirements for the import and export of data into various formats
Develop tools to automate this processing on a regular basis
Build back-end frameworks that are maintainable, flexible and scaleable
Work with the core Teraslice development and DevOps team to enhance our data processing platform
Requirements:
2-3 years of programming experience in Javascript (Node.js), Python, Ruby or Go
Experience working with any of Elasticsearch, Kafka, Hadoop (HDFS, Hive, Spark), MongoDB, MySQL or PostgreSQL
Strong preference for Elasticsearch experience
Experience working with data in JSON, XML and CSV data formats
Comfort doing development work on the Linux platform
Exposure to compute clusters and working with many terabytes of data
US Citizenship / Work Authorization
Bonus Points:
Operational experience with Hadoop, MongoDB, Redis, Cassandra, or other distributed big data systems
Mac OS X familiarity
BS or MS in a technology or scientific field of study
High energy level and pleasant, positive attitude!
Evidence of working well within a diverse team
Compensation:
Salary commensurate with experience, generally higher than competitive industries
Comprehensive benefits package
Opportunities for advancement and a clear career path
Relocation assistance provided (if required)
About Us:

Terascope provides software and technical services to assist companies deploying Elasticsearch at scale. We assist customers with design, development and operations and through our Open Source efforts are developing the Teraslice distributed processing platform for working with data stored in Elasticsearch and Kafka.

Powered by JazzHR",Terascope,"Phoenix, AZ",-1,-1
Data Engineer,"Job Summary:

As part of Daman’s Data Engineering team, you will be architecting and delivering highly scalable, high performance data integration and transformation platforms. The solutions you will work on will include cloud, hybrid and legacy environments that will require a broad and deep stack of data engineering skills. You will be using core cloud data warehouse tools, Python, spark, events streaming platforms and other data management related technologies. You will also engage in requirements and solution concept development, requiring strong analytic and communication skills.

Responsibilities:

· Function as the solution lead for building the data pipelines to support the development / enablement of Information Supply Chains within our client organizations – this could include building (1) data provisioning frameworks, (2) data integration into data warehouse, data marts and other analytical repositories (3) integration of analytical results into operational systems, (4) development of data lakes and other data archival stores.

· Optimally leverage the data integration tool components for developing efficient solutions for data management, data wrangling, data packaging and integration. Develop overall design and determine division of labor across various architectural components
Deploy and customize Daman Standard Architecture components
Mentor client personnel. Train clients on the Daman Integration Methodology and related supplemental solutions
Provide feedback and enhance Daman intellectual property related to data management technology deployments
Assist in development of task plans including schedule and effort estimation
Skills and Qualifications:

· Bachelor’s Degree or foreign equivalent in Computer Science, Electrical Engineering, Mathematics, Computer Applications, Information Systems or Engineering is required

· Experience building high-performance, and scalable distributed systems

· Good experience in migration from Netezza/ DB2 to Snowflake.

· AWS cloud experience (EC2, S3, Lambda, EMR, RDS, Redshift)

· Experience in ETL and ELT workflow management

· Familiarity with AWS Data and Analytics technologies such as Glue, Athena, Spectrum, Data Pipeline

· Experience building internal cloud to cloud integrations is ideal
Experience with streaming related technologies ex Spark streaming or other message brokers like Kafka is a plus
· 3+ years of Data Management Experience

· 3+ years of batch ETL tool experience (DataStage / Informatica / Talend)

· 3+ years’ experience developing, deploying and supporting scalable and high-performance data pipelines (leveraging distributed, data movement technologies and approaches, including but not limited to ETL and streaming ingestion and processing)

· 2+ years’ experience with Hadoop Ecosystem (HDFS/S3, Hive, Spark)

· 2+ years’ experience in a software engineering, leveraging Java, Python, Scala, etc.

· 2+ years’ advanced distributed schema and SQL development skills including partitioning for performance of ingestion and consumption patterns

· 2+ years’ experience with distributed NoSQL databases (Apache Cassandra, Graph databases, Document Store databases)
Experience in the financial services, banking and/ or Insurance industries is a nice to have
Daman Is an Equal Opportunity Employer and All Qualified Applicants Will Receive Consideration for Employment Without Regard to Race, Color, Religion, Sex, National Origin, Disability Status, Protected Veteran Status, Or Any Other Characteristic Protected by Law.

Job Type: Full-time

Pay: $100,000.00 - $130,000.00 per year

Benefits:
401(k)
Dental Insurance
Health Insurance
Paid Time Off
Vision Insurance
Additional Compensation:
Bonuses
Schedule:
Monday to Friday
Work Remotely:
Temporarily due to COVID-19","Daman, Inc.
3.9","Phoenix, AZ",-1,-1
Data Analyst,"Ref ID: 00215-0011486780Classification: Data Analyst

Compensation: $20.90 to $23.00 hourly

We are hiring for a large financial institution in North Phoenix...please apply if you meet the qualifications. Responsible for examining and analyzing programs, processes, claims, documentation and/or files of unusual, complex and/or higher risk transactions to ensure compliance with internal company requirements and/or agency or government regulations. Clearly communicates overall process or transaction quality and provides feedback to appropriate contacts regarding identified material deficiencies or issues including identification of inconsistencies. Analyzes risks and offsets and develops solutions for problems identified. Acts as mentor to lower level team members and may assist with their development. Provides support for exam management activities and any other initiatives as needed. 4+ years experience in one or more of the following: quality assurance; operations; loan documentation; loan servicing; or underwriting.

Job Requirements:
QA - Quality Assurance, Analysis

Accountemps, a Robert Half Company, matches highly skilled professionals with accounting finance jobs on a temporary and temporary-to-hire basis. From accounting clerks and bookeepers to accounts payable and staff accountants, we provide you with access to exciting career opportunities. Our personalized approach, innovative matching technology and global network with local market expertise help you find the legal opportunities that match your skills and priorities fast. By working with us, you have access to challenging opportunities, competitive compensation and benefits, and training to enhance your skill sets.

From philanthropy to environmental stewardship to employee programs, Robert Half is proud to have an active role in the communities in which we live and work. Our company has appeared on FORTUNEs Most Admired Companies list every year since 1998.

Download our mobile app to take your job search on the go!

Contact your local Accountemps office at 888.490.3195 or visit www.roberthalf.com/jobs/accountemps to apply for this job now or find out more about other job opportunities.

All applicants applying for U.S. job openings must be authorized to work in the United States. All applicants applying for Canadian job openings must be authorized to work in Canada.

© 2020 Accountemps. An Equal Opportunity Employer M/F/Disability/Veterans

By clicking 'Apply Now' you are agreeing to Robert Half Terms of Use.","Robert Half
3.5","Phoenix, AZ",Staffing & Outsourcing,Business Services
Data Analyst,"Gatestone & Co. is looking for an efficient, detail-oriented Data Analyst. The Data Analyst will be responsible for facilitating the issuance of letters and digital communications to consumers, in accordance to regulatory and client expectations.

Our ideal candidate is self-motivated and produces high-quality work. They are able to prioritize tasks appropriately and effectively, and handle multiple tasks at once, while maintaining strong follow-up skills to ensure all responsibilities are handled.

In this role you will:
Complete service requests as it relates to the creation of new letters and digital communications
Perform daily tasks relating to quality control and data validation
Demonstrate accuracy and thoroughness; look for ways to improve and promote quality; apply feedback to improve performance; monitor own work to ensure quality
Assist the Compliance Manager in the development of an effective record keeping system, including letter approvals, letter log, and inventory and regulatory requirements
Import/export data from text format into Excel and vice versa, while maintaining field-level integrity and data accuracy
Work closely with IT and other departments in regards to letter status, communications to consumers, etc.
Other duties as assigned
Skills Required:
An analytical thinker, able to synthesize complex or diverse information, collect and research data, use intuition and experience to complement data; able to manage specialized work efficiently with confidence and competence
A problem solver who identifies and resolves problems in a timely manner; gathers and analyzes information skillfully, uses reason even when dealing with emotional topics
Ability to read, analyze, and interpret corporate, compliance, and legal documentation, as needed
Detail oriented, well organized and has proven ability to work within stringent time frames
Excellent verbal, written, listening, and interpersonal skills
Efficient with troubleshooting
Familiarity with ticketing systems
Qualifications:
2+ years in an administrative role
Proficient with Microsoft Office suite
Knowledge of AS400 is required
Ability to pass a background check and drug screen
High school diploma or GED is required
Who We Are

Founded in 1926, Gatestone is an industry leader providing exceptional outsourced Customer Contact Center and Business Process Outsourcing (BPO) solutions to the world’s most respected organizations. Our clients are some of the world’s most respected organizations including Fortune 500 companies.

Started by Nicholas Wilson from humble beginnings, Gatestone has grown into a major global outsource provider with 10 fully-integrated sites located across North America, Latin American, Central America and Asia offering skill sets across multiple experience levels and languages. Still under original ownership, the company is supported by a long-tenured management team who provide unparalleled strategic leadership at all levels throughout the organization.

Benefits of Working at Gatestone

At Gatestone, we understand that our corporate success starts by attracting the right people, developing and mentoring those that show potential and taking steps to retain and promote our top performers.

We believe in our employees and invest in providing the best growth opportunities. Promotions at Gatestone are based on merit, past performance, and leadership potential. We recognize our top employees and help them succeed. We also have a full time Employee Engagement Specialist who ensures we have fun while working hard!

When you join Gatestone, you do more than join a company. You become part of a team of talented and self- driven individuals dedicated to bring success to the Company and their lives.

Be a part of an Awarding Winning Company.

Check us out in Instagram to see how much fun the Gatestone experience really is!

https://www.instagram.com/gatestonebpo

Job Type: Full-time

Pay: $14.50 per hour

Benefits:
Dental Insurance
Health Insurance
Life Insurance
Paid Time Off
Vision Insurance
Schedule:
8 Hour Shift
Monday to Friday
Experience:
Administrative: 2 years (Required)
Call Center: 2 years (Required)
As400: 2 years (Required)
Education:
Associate (Required)
Location:
Phoenix, AZ 85004 (Required)
Benefit Conditions:
Waiting period may apply
Only full-time employees eligible
Work Remotely:
Temporarily due to COVID-19","Gatestone & Co. Inc
2.9","Phoenix, AZ",Staffing & Outsourcing,Business Services
Data Analyst,"6777722
Silicon Valley Bank Banking SAS/Python Data Analyst 6+ 2 Tempe AZ AZ 85281 responsible for data requirement and insight generation for the commercial banking customer
- Able to work independently
-PL/SQL
-Knowledge on Tableau","The Accuro Group
3.0","Tempe, AZ",Staffing & Outsourcing,Business Services
Data Analyst,"Door Sales & Installation is seeking a Data Analyst to develop reports, troubleshoot data issues, and conduct full life cycle analysis.
GENERAL JOB DESCRIPTION:
Interpret data, analyze results using statistical techniques and provide ongoing reports.
Develop and implement databases, data collection systems, data analytics and other strategies that optimize statistical efficiency and quality.
Acquire data from primary or secondary data sources and maintain databases/data systems.
Identify, analyze, and interpret trends or patterns in complex data sets.
Filter and “clean” data by reviewing computer reports, printouts, and performance indicators to locate and correct code problems.
Work with management to prioritize business and information needs.
Locate and define new process improvement opportunities.
Assist in special projects or requests. Other duties as necessary.
KNOWLEDGE & EXPERIENCE:
Proven working experience (4 to 6 years) as a Data Analyst of Business Data Analyst.
Technical expertise regarding data models, database design development, data mining and segmentation techniques.
Strong knowledge of and experience with reporting packages data-bases (SQL etc.), programming (.net) SSRS
Knowledge of statistics and experience using statistical packages for analyzing datasets (Excel)
SKILLS & ABILITIES:
Strong analytical skills with the ability to collect, organize, analyze, and disseminate significant amounts of information with attention to detail and accuracy.
Adept at queries, report writing and presenting findings.
Good interpersonal skills to work with different management levels.
Strong business acumen.
Job Type: Full-time
Benefits:
401(k)
401(k) Matching
Dental Insurance
Flexible Spending Account
Health Insurance
Life Insurance
Paid Time Off
Vision Insurance
Schedule:
Monday to Friday
Experience:
SQL, (.net) SSRS: 4 years (Required)
Data Analyst: 4 years (Required)
Company's website:
www.ericksoncompanies.com
Benefit Conditions:
Only full-time employees eligible
Work Remotely:
No",Door Sales & Installations,"Tempe, AZ",-1,-1
Data Engineer,"About Freestar:

Freestar engineers cutting-edge monetization solutions for websites. By combining industry-leading technology, data, and massive scale, we enable busy site owners to seamlessly maximize revenue while freeing themselves of the hassles of ad operations. Publishers then have more time to do what they do best: create content.

Data Engineer Job Responsibilities:

Joining our data team, you will have an opportunity to learn and work with modern tools like Airflow and Druid to ensure a seamless stream of data where we need it. As we are a startup environment, you'll likely pick up some software engineering skills too, however the primary focus on the role is on data engineering. We're looking for someone who:
Develops and maintains scalable data pipelines and builds out new API integrations to support continuing increases in data volume and complexity.
Collaborates with analytics and business teams to improve data models that feed business intelligence tools, increasing data accessibility and fostering data-driven decision making across the organization.
Implements processes and systems to monitor data quality, ensuring production data is always accurate and available for key stakeholders and business processes that depend on it.
Writes unit/integration tests, contributes to engineering wiki, and documents work.
Performs data analysis required to troubleshoot data related issues and assist in the resolution of data issues.
Works closely with a team of frontend and backend engineers, product managers, and analysts.
Defines company data assets (data models), SQL, Airflow to populate data models.
Designs data integrations and data quality framework.
Build dashboards that concisely and succinctly convey business metrics.
Designs and evaluates open source and vendor tools for data lineage.
Works closely with all business units and engineering teams to develop strategy for long term data platform architecture.
Data Engineer Qualifications / Skills:
Knowledge of best practices and IT operations in an always-up, always-available service
Experience with or knowledge of Agile Software Development methodologies
Excellent problem solving and troubleshooting skills
Process oriented with great documentation skills
Excellent oral and written communication skills with a keen sense of customer service
Education, Experience
Ample relevant knowledge and experience. You either have a BS or MS degree in Computer Science or a related technical field, OR certification from a data science bootcamp + 2 years of experience in a role as a data engineer
Proficiency in Python and Java, Scala, or Go development experience
4+ years of SQL experience (Strong SQL required)
Familiarity with BI reporting tools like Tableau, Looker.
4+ years of experience with schema design and dimensional data modeling
Ability in managing and communicating data warehouse plans to internal clients
Experience designing, building, and maintaining data processing systems
Experience working with either a Map Reduce or an MPP system on any size/scale
Experience/knowledge of cloud computing platforms like AWS/GCP would be a plus
We'd also like to see:
Excellent interpersonal and problem solving skills with the ability to communicate with team members to deliver actionable results
Comfortable interacting across multiple teams and management levels within the organization
Previous background in the ad tech or media landscape (linear, digital, or social) is a plus
What you can expect in return:
Full-Time, Salaried Position
Medical, Dental, and Vision benefits
401K with company match, vested immediately
The opportunity to be part of something BIG
Freestar is an Equal Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, age, protected veteran or disabled status, or genetic information.

This role is not eligible for visa sponsorship","Freestar
4.9","Phoenix, AZ",Advertising & Marketing,Business Services
Data Analyst,"Role: Data Analyst

Location: Tempe, AZ

Contract: 6+ Months

Â

Job Description:

A driven, experienced data analyst to join the Vendor Managed Inventory team who has a passion for solving problems with data, an eye for process improvement, and the skill to execute changes.

You'll be a great fit if you have the grit to persevere through challenging or ambiguous problems, love a chance to step away from your desk to understand and improve processes, and get excited about translating data into action.

Â
Use statistical methods to analyze data and generate useful business reports to solve operational problems.
Be responsible for extracting, cleansing, and visualizing large data sets using the tools and techniques described above.
Plan and lead execution of identified process improvements and cross functional initiatives.
Proactively monitor existing reporting, identify areas of concern, and perform any additional analysis needed to understand underlying causes or nuances.
Deliver insights on urgent business challenges by performing ad hoc analysis and crafting accurate, easy to understand findings.
Forecast future performance based on impact of process improvements and changes to the business.
Work with management team to create a prioritized list of needs for each business segment.
Use data to create models that depict trends related to growth, consumption and forecast.
Work with Project managers to outline the specific data needs for each supplier negotiations.
Â
Qualifications/Experience:
Bachelor's degree in Computer Science, Engineering, Math, or similar field from an accredited undergraduate institution required.
2+ years of professional experience in data, reporting, and analytics.
Ability to collaborate effectively and work as part of a team.
Strong attention to detail.
Strong analytical skills with proficiency in Microsoft SQL Server.
Experience with visualization software; Excel, Access, Pivot Tables, V-Look Up, Tableau proficiency a big plus.
Capable of managing competing priorities.
Ability to thrive (and preference to work) in a dynamic, fast-paced environment.
Ability to communicate confidently to senior leadership.
Â","Softcom Systems
4.4","Tempe, AZ",IT Services,Information Technology
Data Analyst,"The Paragon Group is a Columbus, Ohio based Information Technology firm delivering high quality, cost effective resources to a progressive clientele. Founded in 1998, The Paragon Group has a full time staff of highly skilled, motivated professionals. The Paragon Group provides staff augmentation, temp-to-perm placements, permanent placements, and consulting services both locally and nationally. We are a full time employer and offer a full benefits package. We are currently looking for a Data Analyst for long term employment opportunity.*Must be able to work on our W2* - Advanced SQL skills. - Have worked on multiple DB technologies like Teradata, Oracle, Redshift etc. - Proficient profiling skills, using tools like IDQ would be a plus. - Proficient source to Target mapping skills. - Moderate data modeling (Relational and Dimensional) skills - Good communication skills - All necessary professional skills to work on an Agile line.","The Paragon Group
2.9","Scottsdale, AZ",Banks & Credit Unions,Finance
Data Engineer,"The Data Engineer will work on all phases of the development lifecycle. This will be considered a leader position, with responsibilities that include design, development, implementation, documentation, and optimization of an assortment of solutions. Candidates for this position will have prior experience delivering efficient, secure, high performance, and easy-to-support solutions primarily within the Microsoft suite of technologies. They will also have prior experience in providing technical leadership and direction to junior team members.

Design, document, develop, test, debug, deploy, and support a variety of custom SSIS packages, SQL databases, indexing, and performance tuning.
Provides technical leadership, creates standards for technical approaches and/or software development practices for highly performant ETL processes and database schema.
Maintains awareness of development trends, new tools, efficiencies - - shares with entire team on routine basis.
Proactive solution detection, analysis, and guidance
Gather, analyze, and document user reporting and/or data feed requirements
Code reviews
Provide escalated support for junior team members
Perform any other assigned tasks deemed necessary by management
SM123

Bachelor’s Degree in Computer Science or related field preferred
6+ years of experience with Microsoft technologies, application design, development, and administration.
3+ years of experience with cloud-based solutions and/or hybrid connectivity
Strong understanding of secure application development with the ability to perform application security reviews
Prior experience with data visualization tools, dashboard and web based reporting tools
Strong requirements gathering and documentation skills
Strong analytical and problem solving skills
Retail environment experience is preferred but not required
Technical Skills:
Databases: MS SQL Server
Languages/Libraries: T-SQL, Powershell
Operating Systems: Windows 2012 R2, Windows 10, Mac OS X
Tools: Visual Studio, VSCode, GitHub, SQL Server Management Studio, SQL Server Reporting Services, Business Intelligence Design Studio, Team Foundation Server
Other: SharePoint, Microsoft Office, Visio
Personality Traits:
Maintain high levels of integrity and dependability
Maintain a focus on results, quality and customer satisfaction
Works well in a team environment and effectively manage work activities
Project a professional demeanor and appearance
Be extremely flexible and adaptable
Demonstrates the ability to function and stay focused in a constant pressure, fast growing and ever-changing organization
Communication Skills:
Ability to competently understand, speak, read and write English.
Ability to effectively present information and respond to questions from groups of managers, project steering committees and customers.
Requires excellent interpersonal communications skills.
SM123

In addition to a rewarding career, Sprouts offers a comprehensive program to help support you and your family. These programs include:
Competitive pay
Opportunities for career growth
15% discount for you and one other family member in your household on all purchases made at Sprouts
Flexible schedules
Employee Assistance Program (EAP)
Eligibility requirements may apply for the following benefits:
401(K) Retirement savings plan with a generous company match
Affordable benefit coverage, including medical, dental vision
Pre-tax Flexible Spending Accounts for healthcare and dependent care
Company paid life insurance and short-term disability coverage

Grow with us!
If you have a passion for inspiring people and a flair for fresh food, consider applying for a job at Sprouts! With a focus on customer service, our neighborhood grocery stores offer high-quality, farm fresh produce, natural meats, plenty of scoop-your-own bulk goods and much more in a fun, friendly, old-fashioned farmer’s market setting. Come grow your career in healthy living with a fast-paced, rapidly growing company and teams that pride themselves on empowering others along their journey.
The above statements are intended to describe the general nature and level of the work being performed by people assigned to this work. This is not an exhaustive list of all duties, responsibilities, and requirements. Sprouts’ management reserves the right to amend and change duties, responsibilities, and requirements to meet business and organizational needs as necessary.
California Residents: We collect information in accordance with California law, please see here for more information.","Sprouts Farmers Market
2.9","Phoenix, AZ",Food & Beverage Stores,Retail
Data Engineer,"Senior Data Engineer

Locations: Phoenix AZ

Long term

Job Description:

Data model development and Model scoring

Work with Data Scientists and build scripts to meet their data needs

Required Qualifications

· 7+ years of overall experience

· 3+ years’ experience with Big Data ( HADOOP platforms) –Hive, Spark ( needs to be currently hands-on on Hadoop cluster)

· 5+ years of ETL (Extract, Transform, Load) - Scoop, INFA RDBMS Teradata, Oracle

· Experience in Python

· Reproduce issues faced by Data Scientists

· Knowledge of Agile is a must

Job Type: Contract

Salary: $65.00 - $70.00 per hour

Experience:
HADOOP: 5 years (Required)
Big Data: 5 years (Required)
ETL: 8 years (Required)
Education:
Bachelor's (Preferred)","Digital dhara
4.7","Phoenix, AZ",-1,-1
Data Analyst,"Data Analyst

Job Title

Data Analyst

Job
ID

26969311

Location

Phoenix,

AZ

Other Location

Description

Career Evolutions is searching for a Data Analyst for an exciting and rapidly-growing wellness company in Phoenix, Arizona. This is an excellent career opportunity with a competitive compensation.

Duties Will Include:
Perform data profiling and analysis to clarify the nature and scope of data issues.
Identify and document data-cleansing requirements.
Develop strategies for duplicate identification and merging.
Drive the definition, development, testing and application of data cleansing strategies in a hands-on fashion:
Work with Subject Matter Specialists (SMS) to identify and prioritize data quality issues
Profile data to determine scope, risk, and cleansing approaches
Present cleansing options with recommendations for addressing issues
Develop and test cleansing scripts to automate cleansing wherever possible
Coordinate cleansing using data verification services where appropriate
Coordinate the application of cleansing activities with production support staff
Coordinate data entry resources and tasks and where manual cleansing is required
Configure and manage environment for data profiling and analysis.
Qualifications:
SQL fluency required, especially SQL Server.
Experience cleansing consumer data in volume (address, phone, email, etc.)
Familiarity with profiling tools and data cleansing services is strongly desirable.
Great team player with a positive attitude.
A highly proactive, energetic, and enthusiastic approach, projecting a sense that business is being taken care of responsibly.
Ability to see the “big picture” while addressing critical details.
Problem solving and analysis skills, combined with strong business judgment.
Attention to details, consistency and reliability of performance under tight deadlines.
Excellent communication skills both written and verbal.
Superior organization and planning skills. Capable of handling multiple activities and ad-hoc requests simultaneously.
Willingness to adapt to fast-paced delivery cycles; ability to multi-task.
Local candidates in the greater Phoenix area preferred.","Career Evolutions
2.5","Scottsdale, AZ",-1,-1
Data Engineer,"Candidate Description Blue Rose Technologies (BRT) is actively seeking an experienced Data Engineer, with AWS Big Data experience. Our ideal candidate needs to have demonstrated expertise in building data pipelines and data systems at scale, using Apache Open Source stack and Hadoop ecosystem. Candidates should have strong familiarity working in an AWS cloud environment, as well as, working with other data engineers, product managers, and product delivery teams when required. Qualifications Experience Candidates with 6+ yearsrsquo experience in data engineering, who have either obtained a Graduate degree in the field of Computer Science or related field, or Bachelor's degree with 8+ years of relevant experience in the above fields. Key Responsibilities Provide technical solution leadership in data engineering team, driving technology decisions, mentoring others, and contributing significantly on an individual level Build frameworks to handle data at high scale using Apache Spark and data cataloging tools like Apache Hive, AWS Glue on top of a multi-tiered data lake storage Use exploration and analytic tools like AWS AthenaPresto to probe and validate data Build robust data processing pipelines using AWS Services and integrate with multiple data sources Collaborate with product owners and stakeholders to plan and define requirements Desired Skills AWS Services RDS, AWS Lambda, AWS Glue, Apache Spark, Kafka, Hive, etc. SQL and NoSQL databases like MySQL, Postgres, and Elasticsearch AWS EMR Familiarity with Spark programming paradigms (batch and stream-processing) Strong programming skills in at least one of the following languages Java, Scala. Familiarity with a scripting language like Python, as well as, UnixLinux shells AWS Athena Strong analytical skills and advanced SQL knowledge, indexing, query optimization techniques. Good to have ETL skills Ability to translate data needs into detailed functional and technical designs for development, testing, and implementation Ability to serve as a liaison between technical, quality assurance, and non-technical stakeholders throughout the development and deployment process Project Duration 12 months+ initiative, and All candidates will be required to work on-site at Tempe, AZ location. SalaryBenefits Details This is an hourly W2 or 1099 contracting position with Blue Rose Technologies, with optional United Health Insurance packages.","Blue Rose Technologies LLC
3.2","Tempe, AZ",IT Services,Information Technology
Data Engineer,"Job Description
Full Time Data Engineer Position

***Local Phoenix Candidates Only***

***No Sponsorship Available - Must be legally authorized to work in US without sponsorship***
Create and maintain ETL pipelines
Build complex data sets to meet business requirements
Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using SQL and NoSQL technologies

Company Description
Headfarmer is a boutique recruiting firm specializing in the permanent and contract placement of the upper echelon of talent in the greater Phoenix area. We offer a unique process of ""headfarming"" which provides a level of professional support to both candidates and clients that exceeds recruiting industry standards.","Headfarmer
4.6","Phoenix, AZ",-1,-1
Data Engineer,"Title: Data Engineer
Location: Phoenix, AZ
Duration: Contract

Job Description:
The data engineer will be primarily attached to the data management team and provide much needed support to migrate data (and reports) from an existing legacy system to a new enterprise application.
In addition, this resource will be deeply involved in the designing, development and documentation of a new enterprise data warehouse.
Roles & Responsibilities:
Reverse engineering of existing reports to retrieve and document technical specifications (data source, column definitions, etc.).
Data migration and mapping from legacy systems to a new transactional system.
Building of a new data warehouse.
Exposure to cross-functional teams to facilitate solutions to meet business needs.
Assisting in the preparation of strategic analysis and findings for department leadership and key stakeholders.
Developing metrics and creating ad-hoc reporting as needed. Assist internal customers with acceptance and adoption of implemented solutions.
Adhering to best practices for problem analysis, concept evaluation, systems design, database development, modification, testing, and evaluation to ensure quality and consistency.
Conducting training to various audiences for data related issues and technical applications as needed.
Recommending solution options for data and reporting needs, and provide technical advice where needed to support companywide objectives and goals and resolve problems.
Interact with the business to understand change in processes, data implications and potential reporting modifications.
Documenting the types and structure of the business data (logical modeling).
Analyzing and mining business data to identify correlations among the various data points.
Mapping and tracing data from source to target systems in order to solve a given business or system problem.
Designing and creating data reports and dashboards to help the business in their decision making.
Perform statistical analysis of business data.
Ability to perform root cause analysis.
Required Skills:
SQL Development
Microsoft SQL Server, Microsoft Access, Microsoft Excel
SQL Server Integration Services (SSIS)
SQL Server Reporting Services (SSRS), Tableau

Preferred Skills:
OLTP and OLAP modelling and design
Data warehousing concepts
Power BI
C#, PowerShell, DAX, MDX
About our Company:
Connecting people’s aptitude & ambitions with our opportunities to deliver results.
22nd Century Staffing is a Minority & Woman Owned Business Enterprise (MWBE) that supports demanding staffing programs for Corporations and State and Local Government Agencies. Our journey began in 1997 by supporting large Federal contracts which nudged us in the direction of creating large candidate pools across the country. Over the last 20 years, we have built a strong business model that is carefully constructed to deliver on multiple facets. We have proven past performance of providing services that exceed our clients' expectations. Today 22nd Century supports clients in all 50 states and has grown to be a company that is trusted and sought for providing a complex mix of workforce solutions.
Our Global Delivery model with over 110 recruiters, data miners and research analysts working across multiple time zones is backed by an internal database of 800,000 resources across all major industries.
With a firm grip on the entire spectrum of staffing solutions, we have placed more than 500,000 skilled resources and delivered 15 million+ man-hours.
“22nd Century Staffing is an Equal Opportunity Employer"" and “US Citizens & all other parties authorized to work in the US are encouraged to apply.","22nd Century Staffing
4.3","Phoenix, AZ",Staffing & Outsourcing,Business Services
Data Analyst,"Net Orbit Inc has openings for the position Data Analyst with Master's degree Computer Science, Engineering (any), Technology or related and 1 yr of exp to design and development of required analytic projects in response to business needs. Perform data migration tasks using SQL and HIVE queries between legacy mainframe to DB2, to Big Data (Hive, Impala) and similar enterprise RDBMS. Analyze and assess the quality and integrity of the data. Develop and implement data collection systems and other strategies that optimize statistical efficiency and data quality. Responsible for Application development using all phases of Software Development Life Cycle (SDLC) including Analysis, Design Development.
Work location is Tempe, AZ with required travel to client locations throughout the USA. Please mail resumes to 1232 E Broadway Rd, Suite 110, Tempe, AZ 85282 (OR) e-mail:","Net Orbit Inc
4.3","Tempe, AZ",-1,-1
Data Engineer,"Data Engineer ||Phoenix,AZ or San Antonio,TX, or Plano, TX

Diverse Lynx LLC is an Equal Employment Opportunity employer. All qualified applicants will receive due consideration for employment without any discrimination. All applicants will be evaluated solely on the basis of their ability, competence and their proven capability to perform the functions outlined in the corresponding role. We promote and support a diverse workforce across all levels in the company.","Diverse Lynx
3.9","Phoenix, AZ",IT Services,Information Technology
Data Engineer,"Primary Purpose and Essential Functions: Prepare and maintain data flows specific to our reporting, analysis and machine learning projects.* Collaborate with Data Science and Business Intelligence teams to identify, design, develop, and implement data applications such as truck arrival intelligence, network balance recommendations, service failure mitigation, and driver hours optimization.* Extensive elastic search development.* Provide troubleshooting, coding, and data pipeline expertise to Data Science and Business Intelligence teams.* Identify and implement outside data sources and new technologies to enhance analysis and reporting impact on business problems.* Collaborate with Data Warehouse/ ETL team to transition data sets into production/core environment and implement new data technologies for analysis and reporting use.* Maintain a positive work atmosphere by acting and communicating in a manner which facilitates the success of business operations in order to meet company demands and expectations and perform other duties as assigned by leadership.* Proactively work to assist others in achieving the organization's objectives.* Skills:Must possess excellent interpersonal skills.Must be able to collaborate with others on team and across the organization.Must be able to present recommendations and/or findings to others including senior leadership.* Education: Bachelors in computer science or related field or equivalent combination of education and experience required.* Experience Required: 3+years related hands on experience required. Previous experience with Java and SQL required. Proven problem solver, creative thinker capabilities required. Experience with Alteryx, Elastic Search, Hive/Impala, Scala, Spark, Python, HTML, Groovy preferred.","Swift Refrigerated
3.3","Phoenix, AZ",Trucking,Transportation & Logistics
Data Engineer,"RESPONSIBILITIES Kforce has a client in search of a Data Engineer in Phoenix, AZ. Summary We are looking for a Senior Software Engineer with experience as a Full stack developer skilled primarily with middleware and back end data engineering technologies with a minimum of 7+ years of experience in designing and developing enterprise solutions with cloud. Key Tasks Design, build and optimize data applications and data pipelines to extract, transform and load data from various data sources to internal and cloud targets Participate in proactively identifying issues and resolving issues concerning data pipeline jobs Identify and implement process improvements automate data processing, build frameworks, design and implement near real-time data ingestion capabilities Evaluate tools and emerging technologies and carry out POCs to identify tools that would optimize data processing and data pipelines Design and implement data sharing tools and solutions including batch sharing and API capabilities Design and implement data analytic tools and solutions that provides actionable insights to stakeholders Work with product, application and business teams to assist with ad hoc data requests, data exploration requests and building business knowledge models Work with data science teams to assist with assist with data and data processing requests Contribute by the way of your past experiences and industry knowledge to the Data Engineering function that is driving significant changes to the tool stack to drive critical initiatives for the organization REQUIREMENTS A minimum of 5 years of software development experience, covering the stages of the SDLC A minimum of 3 years of experience working with data technologies and relational (oracle, MySQL, SQL server, PostgreSQL) as well as NoSQL databases 3 years of experience developing solutions on JavaJ2EE platform 3 years of experience developing solutions with Amazon AWS data tools and technologies 2+ years of experience with Python or JavaScript (server side - node.js or other js frameworks) or R scripting 2+ years of experience with Python or JavaScript (server side - node.js or other js frameworks) or R scripting 2+ years of experience working with Hadoop and spark eco system Advanced working knowledge of current and emerging data technologies Vast knowledge of open source tools technologies Experience working with agile software development methodologies Experience with spring framework using spring boot specifically is preferable Experience working on cloud migration projects is preferable Experience in developing and consuming REST based web services and working in and integrating with microservices based environment is preferable Experience working with event driven architectures and distributed messaging broker such as Kafka Experience working with one or more data streaming technologies is preferable Experience working with Mongo DB or Elasticsearch andor Redis technologies is preferable Experience working with Informatica, HVR is preferable Kforce is an Equal OpportunityAffirmative Action Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, pregnancy, sexual orientation, gender identity, national origin, age, protected veteran status, or disability status.",Kforce Technology Staffing,"Phoenix, AZ",-1,-1
Data Engineer,"Our client in Phoenix, AZ is looking to add dynamic Data Engineer within the organization.Qualifications

• Experience building data pipelines to automate batch and real-time data delivery to the AWS data lake, warehouses, analytical and machine learning applications
• Experience building and utilizing APIs and data delivery services that support critical operational and analytical applications for our internal business operations, customers and partners
• Experience integrating and shipping code into AWS cloud Production environments
• Strong experience with all phases of the software development life cycle (SDLC) using Agile methods
• Strong experience with using Amazon Cloud services
• Experience with programming languages: including Java, Node.js, Python

Job Requirements:","VincentBenjamin
3.4","Phoenix, AZ",Staffing & Outsourcing,Business Services
Data Engineer,"RESPONSIBILITIES:

Kforce has a client in search of a Data Engineer in Phoenix, AZ.

Summary:
We are looking for a Senior Software Engineer with experience as a Full stack developer skilled primarily with middleware and back end data engineering technologies with a minimum of 7+ years of experience in designing and developing enterprise solutions with cloud.

Key Tasks:
Design, build and optimize data applications and data pipelines to extract, transform and load data from various data sources to internal and cloud targets
Participate in proactively identifying issues and resolving issues concerning data pipeline jobs
Identify and implement process improvements: automate data processing, build frameworks, design and implement near real-time data ingestion capabilities
Evaluate tools and emerging technologies and carry out POCs to identify tools that would optimize data processing and data pipelines
Design and implement data sharing tools and solutions including batch sharing and API capabilities
Design and implement data analytic tools and solutions that provides actionable insights to stakeholders
Work with product, application and business teams to assist with ad hoc data requests, data exploration requests and building business knowledge models
Work with data science teams to assist with assist with data and data processing requests
Contribute by the way of your past experiences and industry knowledge to the Data Engineering function that is driving significant changes to the tool stack to drive critical initiatives for the organization
REQUIREMENTS:
A minimum of 5 years of software development experience, covering the stages of the SDLC
A minimum of 3 years of experience working with data technologies and relational (oracle, MySQL, SQL server, PostgreSQL) as well as NoSQL databases
3 years of experience developing solutions on Java/J2EE platform
3 years of experience developing solutions with Amazon AWS data tools and technologies
2+ years of experience with Python or JavaScript (server side - node.js or other js frameworks) or R scripting
2+ years of experience with Python or JavaScript (server side - node.js or other js frameworks) or R scripting
2+ years of experience working with Hadoop and spark eco system
Advanced working knowledge of current and emerging data technologies
Vast knowledge of open source tools & technologies
Experience working with agile software development methodologies
Experience with spring framework using spring boot specifically is preferable
Experience working on cloud migration projects is preferable
Experience in developing and consuming REST based web services and working in and integrating with microservices based environment is preferable
Experience working with event driven architectures and distributed messaging broker such as Kafka
Experience working with one or more data streaming technologies is preferable
Experience working with Mongo DB or Elasticsearch and/or Redis technologies is preferable
Experience working with Informatica, HVR is preferable
Kforce is an Equal Opportunity/Affirmative Action Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, pregnancy, sexual orientation, gender identity, national origin, age, protected veteran status, or disability status.","Kforce
4.1","Phoenix, AZ",Staffing & Outsourcing,Business Services
Data Engineer,"A leading and a big data analytics software products and services organization in Deer Valley, who specializing in helping fortune 100 companies in their digital transformation journey is seeking to add to a Data Engineer their talented team of developers. This is a great opportunity for whoever wants to work on the cutting- edge technologies in the global IT industry today. This is a 12-month contracting position ending in July 2021, paying up to $55.00 per hour with benefits.In this position, you will join a team that will be enhancing and modernizing legacy technology. This team develops Big Data and batch/real-time analytical solutions, creating insights about different Members across the full spectrum of digital channels, including search, mobile, email, social, and web. If you have the desire to tell a story with data, and the talent to seamlessly integrate customer information across physical, digital, mobile, and social media, this is the team for you!Required Skills & Experience* 4+ years of IT experience* Very good experience in Hadoop, Hive, Spark Batch and streaming.* Good to have experience with 1 NoSQL - HBase/ Cassandra.* Experience with Java/J2EE & Web Services, Scala/ Python is good to have* Writing utilities/program to enhance product capability to fulfill specific customer requirementDesired Skills & Experience* Experience with Jupyter is a plus* Experience with Apache Spark or other streaming data frameworks is a plus* Experience with Talend and Talend Master Data Management* AWS CertificationsWhat You Will Be DoingTech Breakdown* Java, Scala, Python* Hadoop, Hive, Spark Batch and streaming* NoSQL - HBase/ Cassandra* AWSThe Offer* Competitive Pay: Up to $55/hour, DOE* Contract Duration: X - 12 MonthsYou will receive the following benefits:* Medical & Dental Insurance* Health Savings Account (HSA)* 401(k)* Paid Sick Time Leave* Pre-tax Commuter Benefit* A culture of empowerment where you have the opportunity to be mentored by leading tech gurus* Paid holidays* Have fun while you work in a diverse environment* Participate in summits, hackathons and ""techfest"" events; collaborate and learn from peersApplicants must be currently authorized to work in the United States on a full-time basis now and in the future.","Management Decisions, Inc.
1.6","Phoenix, AZ",Advertising & Marketing,Business Services
Data Engineer,"Role Data Engineer Location Phoenix AZ Duration 6 month contract to start, go possibility to extend longer (3 yr project) Job Description Skill set that the manager is looking for Mid ndash senior developer, at least 4-5 years exp in this space is ideal MUST HAVE STRONG Python and java Aws datalakes exp Data engineering background, Hadoop is a plus Project datalakes building in aws and building data processing technologies within aws No architecture, this is 100 engineering hands on role Must start immediately","DEREX TECHNOLOGIES INC.
4.1","Phoenix, AZ",Enterprise Software & Network Solutions,Information Technology
Data Engineer,"Position: Data Engineer
Location: currently remote ( candidate needs to move to Chandler, AZ a later point in time)
Duration: Long Term

• The ideal candidate must have a strong J2ee background (UI DEVELOPMENT USING J2EE) and currently performing a Hadoop Data Engineer role.

Job Description:
• Data model development and Model scoring
• Work with Data Scientists and build scripts to meet their data needs
Required Qualifications
• 10+ years of overall experience
• 3+ years' experience with Big Data ( HADOOP platforms) –Hive, Spark ( needs to be currently hands-on on Hadoop cluster)
• 4+ years of overall experience in UI development using J2ee","PeopleNTech LLC
4.3","Chandler, AZ",IT Services,Information Technology
Data Engineer,"Job Description
GTN is looking for a Data Engineer to expand and optimize our client's data storage and data pipeline architecture, and optimize data flow/collection for their cross functional teams. The successful candidate will design, implement, and maintain data storage and data flow solutions for structured and non-structured multi-model data in support of data science and machine learning pipelines. Additionally, the ideal candidate will be an experienced data pipeline builder and data wrangler, who enjoys optimizing data systems and building them from the ground up. They must be self-directed and comfortable supporting the data needs of multiple teams, systems and products.

Job Responsibilities:
Create and maintain optimal data pipeline architecture.
Assemble large, complex data sets that meet functional / non-functional business requirements.
Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc.
Create data tools for analytics and data science team members that assist them in building and optimizing data science products.
Build processes supporting data transformation, data structures, metadata, dependency and workload management.
Job Requirements:
Masters in Computer Science, Engineering or a related field (Specifically, with exposure to cancer biology studies/data/research/etc. being highly desired)
A successful history of manipulating, processing, and extracting value from large disconnected datasets.
Experience building and optimizing ‘big data’ data pipelines, architectures and data sets.
Experience with relational SQL and NoSQL databases, including MongoDB, Cassandra, etc.
Strong analytic skills related to working with unstructured datasets
Experience with microservices architecture
Experience with data pipeline and workflow management tools: Luigi, Airflow, etc.
Experience with AWS cloud services: EC2, EMR, RDS, Redshift
Experience with object-oriented/object function scripting languages: Python, Java, Scala, etc.
Proficiency in Python, Pandas, PySpark, Dask, Ray, etc.
Experience writing RESTful APIs
Experience with big data tools: Hadoop, Spark, Kafka, etc.
Proficient verbal and written communication skills to explain complex technical details in clear language
Commitment to the successful achievement of team and organizational goals through a desire to participate with and help other members of the team
Demonstrate a focus on listening to and understanding user needs and then delighting the customer by exceeding service and quality expectations

Company Description
GTN provides Scalable Technical Staffing solutions encompassing SOW, staff augmentation, and direct hire placement for Fortune 2000 companies, with niche service offerings in Cyber Security, Digital, Payroll Management, and Professional Services.","GTN Technical Staffing
4.0","Phoenix, AZ",Staffing & Outsourcing,Business Services
Data Engineer,"Position: Sr. Data Engg (Python)

Location: Chandler, AZ; San Francisco, CA or New Jersey

Duration: Contract

Job Description:

Required Technologies: Python, SQL Developer ,T-SQL,SSIS

5+ years' experience on programming knowledge on python and building the ETL data pipelines and data integrations.

Advanced working SQL knowledge and experience working with rotational and data warehouse databases.

Very good knowledge and understand the business requirements and user stories to create design document.

5 years very strong experience in T-SQL, stored procedures query performance tuning.

1+ years e experience in SSIS on SQL server 2104 and 2017 and SQL Server 2017 is must.

Understanding the existing architecture SQL and SSIS based and to build the new architecture using python and building the ETL data pipelines which is independently or self-service data platform to support all the systems and when ever need anything to add /new custom features can be supportable in the new architecture.

Must have to take ownership end to end development and drive the whole project independently.

Must have very strong knowledge on data analyzing and need strong analytic skills.

Must have hard core development experience, developed pipeline using python in previous projects.

Banking domain is big plus and have very good commination skills and attitude.","ESolutions Inc
4.0","Chandler, AZ",IT Services,Information Technology
Data Engineer,"Job Description
Data Engineer
Scottsdale, AZ, USA
USC, GC only
6+ months

MINIMUM QUALIFICATIONS: •
2+ years of experience in a Data Engineer role, who has attained a bachelors degree in Computer Science, Statistics, Informatics, Information Systems or another quantitative field.
• AWS: 1 year experience
• DevOps Practices: 1 year experience
• 2+ years experience working with data warehousing, ETL development and ETL architecture.
• 2+ years experience combined experience with any of the following database technologies (RDBMS: MSSQL, MySQL Oracle; NoSQL: MarkLogic, Snowflake, DynamoDB, Redis).
• 2 years experience working on large data initiatives (?5 terabytes).
• 1 years experience as a JavaScript",Vegatron Systems,"Scottsdale, AZ",-1,-1
Data Engineer,"Location: Tempe, AZDescription: Global retail partner of the Phoenix-local JUDGE delivery office is currently seeking a Data Engineer for a contract to hire role in Tempe!
This is a CONTRACT TO HIRE position; The selected individual should be fully prepared to expect conversion to a direct employee of the end client at the conclusion of the initial contract timeline. This is not a position for a career consultant; our client is seeking a background reflecting commitment to long tenure and seeking to resume in kind.
Please follow-up with Sky Donovan / sdonovan@judge.com / following submission of application and resume to coordinate a complete qualification discussion | BE ADVISED: Resumes will not be presented to the end-client without a full conversation with a JUDGE associate.

This job will have the following responsibilities:
• Build, deploy and manage data engineering pipelines.
• Contribute to design and creation of high-quality solutions.
• Work with other data engineers, business intelligence and machine learning experts to solve real-life, challenging business problems.
• Work with languages such as python and SQL.
• Handle batch and real-time data processing utilizing different tools and technologies.
Qualifications & Requirements:
• Degree in computer science or related.
• 3+ years of relevant professional experience.
• Extensive experience in Python and SQL.
• Experience with batch and real-time data processing tools and technologies (Databricks, Spark, Kafka)
• Knowledge of distributed data solutions, storage systems and columnar databases.
• Knowledge of Cloud Computing on Microsoft Azure or any other public cloud offering
• Familiarity with Continuous Integration/Continuous Deployment, Git.
• Knowledge about Agile development methods like Scrum and Kanban.
• Knowledge of key machine learning concepts & ML frameworks (like scikit-learn, H2O.ai, Keras, etc.) is a plus.
Please follow-up with Sky Donovan / sdonovan@judge.com / following submission of application and resume to coordinate a complete qualification discussion | BE ADVISED: Resumes will not be presented to the end-client without a full conversation with a JUDGE associate.

Contact: sdonovan@judge.com
This job and many more are available through The Judge Group. Find us on the web at www.judge.com

Job Requirements:","The Judge Group
3.5","Tempe, AZ",Staffing & Outsourcing,Business Services
Data Engineer,"Net2Source is a Global Workforce Solutions Company headquartered at NJ, USA with its branch offices in Asia Pacific Region.We are one of the fastest growing IT Consulting company across the USA and we are hiring "" Data Engineer for one of our clients.We offer a wide gamut of consulting solutions customized to our 450+ clients ranging from Fortune 500/1000 to Start-ups across various verticals like Technology, Financial Services, Healthcare, Life Sciences, Oil & Gas, Energy, Retail, Telecom, Utilities, Technology, Manufacturing, the Internet, and Engineering.

Company: One of Our Clients
Role: Data Engineer
Location: Phoenix AZ
Contract : 12+ months

Job Description:

Mandatory Skills: AWS Lambda, Hive, Spark and Python

Role & Responsibilities:

About Net2Source, Inc.
Net2Source is an employer-of-choice for over 2200+ consultants across the globe. We recruit top-notch talent for over 40 Fortune and Government clients coast-to-coast across the U.S. We are one of the fastest-growing companies in the U.S. and this may be your opportunity to join us!
Want to read more about Net2Source?, Visit us at

Equal Employment Opportunity Commission
The United States Government does not discriminate in employment on the basis of race, color, religion, sex (including pregnancy and gender identity), national origin, political affiliation, sexual orientation, marital status, disability, genetic information, age, membership in an employee organization, retaliation, parental status, military service, or other non-merit factor.

Net2Source Inc. is one of the fastest growing Global Workforce Solutions company with a growth of 100% YoY for last consecutive 3 years with over 2200+ employees globally and 30 locations in US and operations in 20 countries. With an experience of over a decade we offer unmatched workforce solutions to our clients by developing an in-depth understanding of their business needs. We specialize in Contingent hiring, Direct Hires, Statement of Work, Payroll Management, IC Compliance, VMS, RPO and Managed IT Services.

Fast Facts about Net2Source:
Inception in 2007, privately held, Debt free
2200+ employees globally
375+ In- house Team of Sales, Account Management and Recruitment with coast to coast COE.
30 offices in US and 50+ Offices globally
Operations in 20 countries (US, Canada, Mexico, APAC, UK, UAE, Europe, , Europe, Latin America, Japan, Australia)

Awards and Accolades:
2018 Fastest Growing IT Staffing Firm in North America by Staffing Industry Analysts
2018 Fastest-Growing Private Companies in America as a 5 times consecutive honoree Inc. 5000
2018 Fastest 50 by NJBiz
2018 Techserve Excellence Award (IT and Engineering Staffing)
2018 Best of the Best Platinum Award by Agile1
2018 40 Under 40 Award Winner by Staffing Industry Analysts
2018 CEO World Gold Award by SVUS
2017 Best of the Best Gold Award by Agile1

Stay safe and healthy!

Regards,
Divyansh Srivastava (Dave)
Net2Source Inc.
Client Delivery Manager Enterprise Business
Global HQ Address 7250 Dallas Pkwy, Suite 825 Plano, Texas 75024
Office: (201) 340-8700 x 477|Cell: (201) 479-3334|Fax: (201) 221-8131|Email: divyansh@net2source.com
https://www.linkedin.com/in/divyansh-srivastava-11563041/
Web: www.net2source.com | Social: Facebook | Twitter | LinkedIn","Net2Source
3.2","Phoenix, AZ",Staffing & Outsourcing,Business Services
Data Engineer,"Maybe youve stopped by for a coffee, fueled up your car or grabbed something to eat on the go. Then you know what Circle K is all about. Making everyday life easier for people all over the world. Weve grown into a successful global company with over 15,000 stores in 24 countries, serving more than 6 million customers each day. In all, we have more than 120,000 people working at our stores and support offices.To support our future growth ambitions we are building a global data platform and machine learning solutions. We are now looking for an experienced Data Engineer to join our Data Engineering team in the Global Tech Data and Analytics Department. For the right candidate, Circle K can offer a challenging and rewarding role in a talented, multinational and diverse team.

RESPONSIBILITIES

• Prototype, build, deploy and manage data engineering pipelines.
• Contribute to design and creation of high-quality solutions.
• Work with other data engineers, business intelligence and machine learning experts to solve real-life, challenging business problems.

REQUIRED QUALIFICATIONS

• Degree in computer science or related.
• 3+ years of relevant professional experience.
• Extensive experience in Python and SQL
• Experience with batch and real-time data processing tools and technologies (Databricks, Spark, Kafka)
• Knowledge of distributed data solutions, storage systems and columnar databases.
• Knowledge of Cloud Computing on Microsoft Azure or any other public cloud offering
• Familiarity with Continuous Integration/Continuous Deployment, Git.
• Fluent in spoken and written English.
• Knowledge about Agile development methods like Scrum and Kanban.

Technologies we use: Microsoft Azure Databricks (Spark), Azure SQL Datawarehouse, Azure Tabular, Azure Data Factory, Azure Functions, Azure Containers, Docker, DevOps, Python (3.x), PySpark, Scripting (Powershell, Bash), Git, Terraform, Power BI.

We know great companies are built from within, by great people like you. Come grow with us! We´re looking forward to reviewing your application.

Circle K is an Equal Opportunity Employer.
The Company complies with the Americans with Disabilities Act (the ADA) and all state and local disability laws. Applicants with disabilities may be entitled to a reasonable accommodation under the terms of the ADA and certain state or local laws as long as it does not impose an undue hardship on the Company. Please inform the Companys Human Resources Representative if you need assistance completing any forms or to otherwise participate in the application process.

Click below to review information about our company's use of the federal E-Verify program to check work eligibility:

In English

In Spanish

Job Requirements:","circle k
2.9","Tempe, AZ",Gas Stations,Retail
Data Engineer,"Overview

Required Skills
• Experience in building Big Data technologies and utilities is required
• Experience with MPP databases. Ability to troubleshoot issues and develop functions in an MPP environment is highly desired
• Very good knowledge of the software development life cycle, agile methodologies, and test-driven development
• Experience utilizing and extending ETL solutions in a complex, high-volume data environment is highly desired
• 2+ years of SQL experience and ETL development is required
• 2+ year of programming experience in either Spark, C, Java, Python, R and/or other functional programming skills
• Sound understanding of continuous integration & continuous deployment environments
• Experience in connecting and building application program interfaces (APIs) or messaging software and interoperability techniques and standards
• Strong analytical skills with a passion for testing
• Excellent problem solving and debugging skills
• Exposure in Data Management, Governance and Controls functions
• 4+ years of certified learning in Information Management, Computer Science, Engineering or Application/Platform Development

Preferred / Complementary Skills
• Technical and quantitative reasoning skills with regard to marketing data
• Experience in Informatica, Talend, Pentaho, Ab Initio
• Experience in Hadoop, Hive, Impala, Pig or Kafka
• Experience in Greenplum or Netezza

Required Skills • Experience in building Big Data technologies and utilities is required • Experience with MPP databases. Ability to troubleshoot issues and develop functions in an MPP environment is highly desired • Very good knowledge of the software development life cycle, agile methodologies, and test-driven development • Experience utilizing and extending ETL solutions in a complex, high-volume data environment is highly desired • 2+ years of SQL experience and ETL development is required • 2+ year of programming experience in either Spark, C, Java, Python, R and/or other functional programming skills • Sound understanding of continuous integration & continuous deployment environments • Experience in connecting and building application program interfaces (APIs) or messaging software and interoperability techniques and standards • Strong analytical skills with a passion for testing • Excellent problem solving and debugging skills • Exposure in Data Management, Governance and Controls functions • 4+ years of certified learning in Information Management, Computer Science, Engineering or Application/Platform Development Preferred / Complementary Skills • Technical and quantitative reasoning skills with regard to marketing data • Experience in Informatica, Talend, Pentaho, Ab Initio • Experience in Hadoop, Hive, Impala, Pig or Kafka • Experience in Greenplum or Netezza
This is Company overview ...

Which company? Recruiting Company or Client Company???","Maestro Technologies
5.0","Wilmington, DE",IT Services,Information Technology
Data Scientist,"Business Unit:

We are looking to hire a data scientist to join our analytics team within CTS/TPX. Our team is responsible for providing analytical support to help improve our customers' experience and products performance by identifying key trends, building new KPIs and telling stories with data. We work cross-functionally and closely with program, product and engineering teams.

The ideal candidate will be passionate about data-driven decision making, able to perform analyses on large unstructured and structured data sets and quickly grasp new technologies. The ideal candidate must be comfortable working in a dynamic team and addressing large audiences. The data scientist will be responsible for supporting our current efforts related to exploratory and predictive analytics, machine learning, and A/B testing methodologies. They will be applying data mining and modeling techniques, statistical analysis, and building high quality dashboards and presentations to provide insights to the executive leadership team. They will provide input into strategy, analysis methods, and tool selection.

Core responsibilities include but are not limited to:
Uses analytical rigor and statistical methods to analyze large amounts of data, extracting impactful insights using sophisticated statistical techniques such as data analysis, data mining, optimization tools, and machine learning techniques and statistics (
Develops and executes statistical and mathematical solutions to business problems to support larger initiatives under the direction of senior team members.
Produce analysis of historical patterns in customer behaviors and product performance from complex real-world behavioral data.
Develop and deploy predictive models based on historical data that provide future predictions about customer behavior.
Constructs forecasts, recommendations and strategic/tactical plans based on applying data science techniques to business data.
Build results and presentations that report methodology and results of analysis.
Build customer centric models and optimization tools to support large scale projects that utilize online & offline data, structured & unstructured data, set top box data, and media/behavioral/attitudinal data.
Consistent exercise of independent judgment and discretion in matters of significance.
Regular, consistent and punctual attendance. Must be able to work nights and weekends, variable schedule(s) as necessary.
Other duties and responsibilities as assigned.
Employees at all levels are expect to:
Understand our Operating Principles; make them the guidelines for how you do your job
Lead the customer experience - think and act in ways that put our customers first, give them flawless digital options at every touchpoint, and make them promoters of our products and services
Know your stuff - be hardworking learners, users and advocates of our groundbreaking technology, products and services, especially our digital tools and experiences
Win as a team - make big things happen by working together and being open to new insights
Be an active part of the Net Promoter System - a way of working that brings more employee and customer feedback into the company - by joining huddles, making call backs and helping us elevate opportunities to do better for our customers
Get results and growth
Respect and promote inclusion and diversity
Do what's right for each other, our customers, investors and our communities
We prefer candidates with the following background and skills:
At least a Bachelor's degree in analytical field (Computer Science, Applied Mathematics, Statistics, Economics, Engineering)
2 to 5 years of proven experience working as a BI/data analyst/Data scientist or similar role
Scripting and Programming skills (Spark SCALA, Python, PySpark, R)
Experience with data visualization tools such as Tableau, Quicksight, Qlick
Experience with Predictive Modeling and Machine Learning
Experience working with relational databases, SQL
Exposure to big data tools and cloud technologies such as AWS
Analytical, creative, and innovative approach to solving problems
Strong written and verbal communication
Positive and upbeat demeanor
Ability to work in a constantly evolving and fast paced environment
Proactive, highly organized, and able to prioritize and run multiple tasks
Ability to establish and maintain strong working relationships and achieve results by working collaboratively with others
Comcast is an EOE/Veterans/Disabled/LGBT employer","Comcast
3.6","Philadelphia, PA",-1,-1
Data Scientist,"University Overview

The University of Pennsylvania, the largest private employer in Philadelphia, is a world-renowned leader in education, research, and innovation. This historic, Ivy League school consistently ranks among the top 10 universities in the annual U.S. News & World Report survey. Penn has 12 highly-regarded schools that provide opportunities for undergraduate, graduate and continuing education, all influenced by Penn's distinctive interdisciplinary approach to scholarship and learning.

Penn offers a unique working environment within the city of Philadelphia. The University is situated on a beautiful urban campus, with easy access to a range of educational, cultural, and recreational activities. With its historical significance and landmarks, lively cultural offerings, and wide variety of atmospheres, Philadelphia is the perfect place to call home for work and play.

The University offers a competitive benefits package that includes excellent healthcare and tuition benefits for employees and their families, generous retirement benefits, a wide variety of professional development opportunities, supportive work and family benefits, a wealth of health and wellness programs and resources, and much more.

Posted Job Title

Data Scientist

Job Profile Title

Data Analyst C

Job Description Summary

The Perelman School of Medicine at the University of Pennsylvania is the oldest and one of the finest medical schools in the United States. Penn is rich in tradition and heritage and at the same time consistently at the forefront of new developments and innovations in medical education and research. Since its founding in 1765 the School has been a strong presence in the community and prides itself on educating the leaders of tomorrow in patient care, biomedical research, and medical education. http://www.med.upenn.edu/

Job Description

This analyst will work under the guidance of investigator in the Center for Biomedical image Computing and Analytics (http://www.cbica.upenn.edu/, CBICA), Director, Christos Davatzikos, PhD. The work involves testing, validating and extending advanced image processing algorithms, preparing and extending processing pipelines, and applying these pipelines on magnetic resonance brain imaging datasets from various studies involving both structural and functional data. The data analyst will collect and organize final quantitative and imaging results, perform quality control on the results, and communicate with clinical collaborators for the dissemination and discussion of the results. This position offers the opportunity to gain experience using advanced neuroimaging processing techniques and to apply these methods in the study of normal and pathological brain function.QualificationsA Bachelor's Degree and 2 years to 3 years of experience or equivalent combination of education and experience is required. Experience with magnetic resonance imaging (MRI) analysis is required. Strong computer skills (knowledge of Python and/or Matlab, statistical analysis packages, basic shell scripting, experience in Unix platform) will be preferred.

The job pay range encompasses the full range of employees from new hires to the salaries of Penn employees with many years of experience and seniority and is not a precise indicator of salaries of new hires when looking at the top end. Based on what we pay employees coming into this position our pay range is 50,000-70,000 based on education and experience above the minimum qualifications. Working ConditionsOffice, Library, Computer RoomPhysical EffortTypically sitting at desk or table

Job Location - City, State

Philadelphia, Pennsylvania

Department / School

Perelman School of Medicine

Pay Range

$50,684.00 - $138,391.00

Affirmative Action Statement Penn adheres to a policy that prohibits discrimination on the basis of race, color, sex, sexual orientation, gender identity, religion, creed, national or ethnic origin, citizenship status, age, disability, veteran status, or any other legally protected class.

Special Requirements Background check required after a conditional job offer is made. Consideration of the background check will be tailored to the requirements of the job.

The University of Pennsylvania's special character is reflected in the diversity of the Penn community. We seek talented faculty and staff who will constitute a vibrant community that draws on the strength that comes with a substantive institutional commitment to diversity along dimensions of race, ethnicity, gender, sexual orientation, age, religion, disability, veteran status, interests, perspectives, and socioeconomic status. Grounded in equal opportunity, nondiscrimination, and affirmative action, Penn's robust commitment to diversity is fundamental to the University's mission of advancing knowledge, educating leaders for all sectors of society, and public service. The University of Pennsylvania prohibits unlawful discrimination based on race, color, sex, sexual orientation, gender identity, religion, creed, national or ethnic origin, citizenship status, age, disability, veteran status, or any other legally protected class.","University of Pennsylvania
4.3","Philadelphia, PA",Colleges & Universities,Education
Data Scientist,"Job Title: Data Scientist

Location - Philadelphia, PA

End CustomerÂâ Comcast

Pay Rate: $80/hr C2C

***No OPT EAD***

***Non locals are fine, only WebEx Video interview

Data Scientist

Â Xfinity Mobile, available exclusively to its cable customers, allows existing Internet customers to add wireless cellphone services to their current product bundle. Comcast utilizes its vast number of Xfinity Hotspots for coverage and piggybacks on the existing wireless platform of Verizon to provide an affordable solution for wireless services to our customers.

Â The Xfinity Mobile Business Intelligence team is looking for a Data Scientist who can dive into unknown data and do deep analysis â prove causation or prove data is related and therefore one causes the other. You will support our operations and data architecture teams with insights gained from analyzing company data. You must be that person who can create value out of data.

Â The ideal candidate is adept at using large data sets to find opportunities for product and process optimization and using models to test the effectiveness of different courses of action. Such a person proactively fetches information from various sources and analyzes it for better understanding about how the business performs. Additionally, they can utilize AI tools to automate certain processes within the Xfinity Mobile.Â

This person must have strong experience using a variety of data mining/data analysis methods, using a variety of data tools, building and implementing models, using/creating algorithms and creating/running simulations. They must have a proven ability to drive business results with their data-based insights. They must be comfortable working with a wide range of stakeholders and functional teams. The right candidate will have a passion for discovering solutions hidden in large data sets and working with stakeholders to improve business outcomes. This Data Scientist must possess the skill-sets necessary to hit the ground running and must be willing to learn about the mobile phone business while solving problems quickly and efficiently.

Â

See Yourself:

Â Working with stakeholders throughout the organization to identify opportunities for leveraging company data to drive business solutions.

Â Mine and analyze data from company databases to drive optimization and improvement of product development, marketing techniques and business strategies.

Â Assess the effectiveness and accuracy of new data sources and data gathering techniques.

Â Develop custom data models and algorithms to apply to data sets.

Â Use predictive modeling to increase and optimize customer experiences, revenue generation, ad targeting and other business outcomes.

Â Coordinate with different functional teams to implement models and monitor outcomes.

Â Develop processes and tools to monitor and analyze model performance and data accuracy.

Â

Minimum Requirements

Â Four-year degree in a related Computer Science, Math or Statistical field of study.

Â 7+ continuous years of professional experience as a Data Scientist.

Â Strong problem-solving skills with an emphasis on product development.

Â Experience using statistical computer languages (R, Python, SQL, etc.) to manipulate data and draw insights from large data sets.

Â Experience working with and creating data architectures.

Â Knowledge of a variety of machine learning techniques (clustering, decision tree learning, artificial neural networks, etc.) and their real-world advantages/drawbacks.

Â Knowledge of advanced statistical techniques and concepts (regression, properties of distributions, statistical tests and proper usage, etc.) and experience with applications.

Â A drive to learn and master new technologies and techniques.

Â Coding knowledge and experience with several languages: C, C++, Java, JavaScript, etc.

Â SUPERB communication skills with an emphasis on writing and interpreting abilities

Â Excellent presentation skills. Must have the ability to confirm complex data into digestible formats for non-technical business teams.","Veritis Group
3.7","Philadelphia, PA","Health, Beauty, & Fitness",Consumer Services
Data Scientist,"Description


Do you want to work at the forefront of artificial intelligence and machine learning? CapaxGlobal has a significant data analytics and management presence across many industries. With that footprint comes massive amounts of data that can inform us about markets and ways to improve our client business practices. This position will be part of the Data Science and Machine Learning team and will bring strong quantitative skills to our data science capabilities. You work in a multidisciplinary team exploring, connecting and mining internal data sources and will develop data models using algorithms for pattern detection and forecasting. In this position you will be managing projects that use advanced analytics techniques, such as optimization, forecasting, machine learning, predictive analytics, and statistical analysis, to develop solutions that help deliver significant value to a variety of Capax’s partners and clients. Candidates will be exposed to a wide spectrum of high visibility projects ranging from sales effectiveness, competitive intelligence, fraud detection, time series forecasting, operational efficiency, sourcing and procurement, supply-chain optimization and financial analysis.
Location: Chicago IL | Philadelphia PA | Remote
Travel: Up to 30%
Responsibilities
Develop and code models by applying algorithms to large structured as well as unstructured data sets for our more complex projects. Develop visualization products to share analysis across a large group of business users.
Design strategies and propose algorithms to analyze and leverage data from existing as well as new data sources.
Continuously seek out industry best practices and develop skills to create new capabilities for data analytics at clients to improve business decisions.
Network with business stakeholders to develop a pipeline of data science projects aligned with business strategies. Translate complex and ambiguous business problems into project charters clearly identifying technical risks and project scope.
Participate on cross-disciplinary project team of database specialists, data scientists, and business subject-matter experts to complete project deliverables.
Qualifications
Bachelor’s degree from an accredited college/university in Computer Science, Computational Linguistics, Statistics, Mathematics, Engineering, Bioinformatics, Physics, Operations Research or related fields.
Master’s degree in data science, applied mathematics, or bioinformatics preferred.
Minimum 6 years relevant work experience (if Bachelor’s degree) or minimum 3 years relevant work experience (if Master’s degree) with a proven track record in driving value in a commercial setting using data science skills.
In-depth knowledge of various modeling algorithms e.g. Linear, GLMs, trees based models, neural networks, clustering, PCA, and time series models.
Proficiency in R (e.g. ggplot2, cluster, dplyr, caret), Python (e.g. pandas, scikit-learn, bokeh, nltk), Spark – MLlib, H20, or other statistical tools.
Minimum 2 years experience working in a data science or machine learning environment.
In-depth knowledge of databases, data modeling, Hadoop, and distributed computing frameworks.
Experience in software development environment, Agile, and code management/versioning (e.g. git).
Strong EDA skills and experience/knowledge.
Ability to understand complex and ambiguous business needs and applying the right tools and approaches.
Collaborative team player.
Excellent communication skills, both written and verbal.
Experience developing and testing machine learning and/or statistical projects.
Strong presentation skills. Ability to present statistical results to lay persons in an easy to understand way.
We are looking for all levels of data science experience, jr through sr.","Capax Global
4.7","Philadelphia, PA",IT Services,Information Technology
Data Scientist,"Clarivate Analytics is a global leader in providing trusted insights and analytics to accelerate the pace of innovation. We deliver critical data, information, workflow solutions, and deep domain expertise to innovators worldwide.

Our solutions cover the entire lifecycle of innovation: scientific and academic research; patent analytics and regulatory standards; pharmaceutical and biotech intelligence; trademark, domain and brand protection. Our portfolio consists of some of the world’s most trusted brands, including Web of Science, Derwent, CompuMark, Cortellis, MarkMonitor, and Techstreet.

We employ more than 4,300 colleagues in 43 countries.

Clarivate Analytics is a public company. We are listed on the New York Stock Exchange under the tickers NYSE:CCC; CCC.WS.

At Clarivate, we believe human ingenuity can transform the world and improve our future. That’s why we harness our global reach, curate our content, and invest in best-in-class technology and people.

Join the team that is improving the way the world creates, protects, and advances innovation.

As a Data scientist, you will help facilitate doing research work and identifying ML methods that could be used to solve the different problems faced by our business units and implement the solutions which will help optimize the systems and help the company to innovate.

Major responsibilities:
Researches and identifies Machine Learning (ML) and Natural Language Processing (NLP) methods and algorithms to solve specific problems to improve user experience on Clarivate data and websites
Implements these methods and devises appropriate test plans to validate and compare the different approaches
Identifies new applications of ML and NLP in the context of Clarivate extensive sets of content and data
Explores existing data for insights and recommends additional sources of data for improvements
Technical /Professional Skills & Competencies:
Excellent understanding of ML, NLP and statistical methodologies
Excellent programming skills (Java/Python/R/Sas)
Ability to test ideas and adapt methods quickly end to end from data extraction to implementation and validation
Experience with information retrieval algorithms and recommended systems a big plus
Education and Background:
Bachelor's degree in Computer Science, Engineering or similar. MS preferred
Relevant work experience preferred
Ability to work with data engineers and product teams
.

It is the policy of Clarivate to provide equal employment opportunity (EEO) to all persons regardless of age, color, national origin, citizenship status, physical or mental disability, race, religion, creed, gender, pregnancy, sex, sexual orientation, gender identity and/or expression, genetic information, marital status, status with regard to public assistance, veteran status, or any other characteristic protected by federal, state or local law. In addition, Clarivate will provide reasonable accommodations for qualified individuals with disabilities.","MarkMonitor
3.1","Philadelphia, PA",Enterprise Software & Network Solutions,Information Technology
Data Scientist,"Gryphon Technologies is a premier engineering and technical services provider supporting National Security programs. Gryphon is the federal Government’s partner working in support of mission critical systems in every phase of their lifecycle. We are proud of our ability to help shape tomorrow, while ensuring today’s U.S. and coalition forces can carry out their critical missions and tasks.
Gryphon is an Equal Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, disability status, genetics, protected veteran status, sexual orientation, gender identity or expression, or any other characteristic protected by federal, state or local laws.

• Work with Sr. Data Scientists on Digital Engineering tasks including use of Natural Language Processing (NLP), Artificial Intelligence (AI), and Machine Learning (ML) methods, techniques, and tools. This includes technically working on multiple projects in a matrix environment while creating new programs and starting new projects.
• Work with AI and big data technologist/architect to explore new or assess known technology to solve specific natural language processing (NLP) related problems
• Collect and preprocess data with hands-on work to explore, train or re-train models to solve domain specific problems and provide solution for our products
• Customize and optimize models with various techniques (quantization/binarization, pruning, etc) to reduce model size and computation cycles while keeping similar performance.

• MS or Ph.D. in CS or EE with 3+ years of experience in AI/big data algorithm development (B.S. with requisite experience will be considered)
• Solid knowledge of AI/ML and/or Deep Learning in general and experience with one or more specific fields related to NLP or NLU
• Solid theoretic knowledge with AI/ML and experience with customizing, re-training and evaluating models to solve domain specific problems
• Experience with commonly used NLP toolkits (e.g. NLTK, SpaCy, Gensim) is a big plus
• Highly Experienced in Computer Programming (Python, C, Mathematica, etc.)
• Linked Data, Triple Stores, Ontology Modeling
• Expert Systems
• Knowledge Management, Digital Libraries
• Highly proficient in Linux, High-Performance Computing
• Strong knowledge of Cybersecurity
One must have good written communication, interpersonal, problem-solving, analytical, mathematical, and organizational skills. Ability to follow directions is a must. Applicants must be able to work well alone and as part of a team. A Security Clearance or the ability to obtain one will be required. U.S. Citizenship required.","Gryphon Technologies
3.1","Philadelphia, PA",Aerospace & Defense,Aerospace & Defense
Machine Learning Engineer,"Machine Learning Engineer
Valley Forge, PAApply Now
Are you interested in supporting the ever-changing technology needs of the U.S. Government by providing services that support defense initiatives? Come look at Stratagem, where we help the U.S. Government solve some of the most challenging and interesting problems in the world.

Stratagem is hiring motivated, creative, and technically-minded individuals with a passion and skill for building state-of-the-art technologies. What is most important to us at Stratagem is candidates have exceptional problem-solving skills, are creative out-of-the-box thinkers, and are comfortable with quickly learning, evaluating, and deploying new technologies. Successful employees are self-starters, excellent communicators, and positive individuals with a passion for delivering the highest quality products.

** TS – SSBI REQUIRED**
** US CITIZENSHIP REQUIRED **

This is a Software Engineer position in Valley Forge, PA, and we are not hiring your average Java Joe’s. We are looking for the Macchiato with a double shot. You will be given substantial feature ownership, and we'll expect you to contribute product ideas as well as code. Your ideas will help shape the future of Stratagem.

Responsibilities & Skills
Our ideal candidate is a programming expert with a passion for machine learning. We need someone with prior experience designing and implementing modern machine-learning and computer-vision concepts and algorithms, and who stays up to date on all best-practice standards.
As a software engineer, your responsibilities include:
Investigating and solving exciting and difficult challenges in image recognition, classification, content analysis, and deep learning
Integrating with a diverse team to deliver in an agile-like manner
Developing new algorithms
Contributing to building aspects of a web-accessible system
Prototyping ideas/concepts to prove a solution quickly
Your core skills/experience include:
IAT Level II or III certification (i.e. Security+ or CISSP or CASP) within 90 days of hire
Expertise in one of the following: Java, Python, C++, etc.
Proficiency with containerization - Docker preferred
Proficiency with cloud Infrastructure - AWS or C2S preferred
Proficiency with PostgreSQL – or similar GIS database concepts
Experience with Hadoop, Spark, etc.
Experience developing and implementing Image Classification and Content Analysis
Experience with neural networks, K-means, etc.
Experience working with deep learning frameworks, such as Caffe, TensorFlow and Theano
3-15 years’ experience
You are the proud owner of a TS/SCI SSBI clearance
Bonus points if you have experience in any of the following:
DevSecOps experience
In-depth understanding of modern best-practices, such as Kaggle competition winners
Comfortable with statistics and data science concepts
Mission Management
SIGINT experience
About you
You are an exceptional problem solver, a quick learner, and a creative out-of-the-box thinker who values team work. You are comfortable with the pace and ever-changing requirements of a small development company while maintaining a healthy work life balance.

Who is Stratagem
Stratagem is a small and fast-growing technology company built around the idea that we can make a lasting impact for our customers and employees. We believe in a culture of innovation, fun, empowerment, and family. We want you to learn new skills so you can become more fulfilled in both your personal and professional life.

At Stratagem, our goal is to make our company the last company you work for!","Stratagem Group
4.4","Valley Forge, PA",Aerospace & Defense,Aerospace & Defense
Data Scientist,"SummaryProvide data management and statistical analysis in Big Data environment. Assist in development of tools and processes to manage, integrate and synthesize large data sets and deliver business rules and recommendations to functional business units and product managers

Responsibilities and Duties

Perform analyses, development and provide data mining in a large data warehouse environment which includes data design, database architecture, Meta data and repository creation.

Extensive use data mining and data analysis tools.

Review and validate data loaded into the data warehouse for accuracy

Provide technical consulting to users of data warehouses and advises users on conflicts and inappropriate data usage

Gather and assess business information needs and prepare system requirements

Interact with user community to develop and produce reporting requirements

Responsible for prototyping solutions, preparing test scripts, and conducting tests and for data replication, extraction, loading, cleansing, and data modeling for data warehouses

Maintain knowledge of software tools, languages, scripts, and shells that effectively support the data warehouse environment in different operating system environments

Make recommendations towards the development of new code or reuse of existing code.

Responsibilities may also include participation in component and data architecture design, performance monitoring, product evaluation and buy versus build recommendations

#LI-JS1

Requirements

7+ years of programming/systems analysis experience

5+ years of experience with business intelligence and stat tools and systems

Strong experience in Relational Database Management Systems (RDBMS) and data warehouse front-end tools

Extensive knowledge of data warehouse and data mart concepts

Experience in systems analysis and design

Solid understanding of development, quality assurance and integration methodologies

BS in Computer Science, IS, or other related field. Or equivalent work experience

Technical Skills Required

Stat & Data Tools "" Python, Machine Learning, SQL, Spark, Data Visualization
Data & Cloud Tools "" Hadoop, AWS Big Data Stack (S3, Spark, Lambda, Presto, Athena, Kinesis, Redshift)
Scripting Tools "" Linux/Unix, Shell Scripts","Numeric, LLC
3.2","Philadelphia, PA",Staffing & Outsourcing,Business Services
Data Scientist,"What You Will A Part Of:

The IT Data Science Analyst is responsible for developing and maintaining the divisional data stores needed to provide crucial business insights across the Division. CTD is looking for a business-facing Data Science Analyst that will help us discover the insights hidden in company data. The selected candidate will help the CTD division make smarter decisions to help our customers make the world healthier, cleaner and safer. The role must work closely with Business Intelligence, other IT functions, and functional analysts across Thermo Fisher scientific to drive projects focused on improvements to information to support divisional business insights and analytics. The primary focus will be in applying data mining techniques, doing statistical analysis, and generating business insights that deliver value to the company and our customers. This role will require strong partnership with regional and functional analysts to develop, and execute, various reporting, analytics, and dashboard initiatives.
What You Will Do:
Direct interaction with the business to understand and analyze business problems, derive insights and recommend solutions
Working independently, or with functional analysts, to create reports, data sets and mechanisms to provide visibility to business data
Executing ad-hoc analysis and presenting results in a clear manner
Extending company's data with third party sources of information when needed
Collaborate with IT and business partners to ensure data quality, integrity, and accuracy across the global LCD data stores
Establish good working relationships with peers in other divisions and explore joint system and process improvement opportunities.
Maintain MS SQL Server database environments (security, tables, views, packages, SQL Agent jobs, SSAS database, Integration Services)
Develop/Maintain PowerBI dashboards for sales and finance team utilization
How You Will Get Here:
Data-oriented personality
Great communication skills
Experience with data visualization tools, such as PowerBI, Tableau or Cognos
Proficiency in using query languages such as SQL
Experience with NoSQL databases
Good applied statistics skills, such as distributions, statistical testing, regression, etc.
Experience with common data science toolkits
Good scripting and programming skills
Ability to partner with management at all levels and to lead major projects and initiatives
Strong communication skills and ability to work effectively across a matrix organization
BA/BS degree in finance, mathematics, computer science or other business related disciplines
Life Sciences experience preferred
Key Success Factors:
Strong organizational and communication skills, and proven ability to adapt style to different situations and people
Must be a business partner, not merely a technical expert - this position plays an active role providing actionable insight into the Clinical Trials Division
Strong analytical skills - and ability to use those skills to influence and drive change
Excellent interpersonal and communication skills (both verbal and written).
Ability to interact professionally with a diverse group including VPs, directors, managers, subject matter experts and end-users.
Self-motivated; bias for action
Global experience
10% travel requirement
This position has not been approved for Relocation Assistance.","Thermo Fisher Scientific
3.4","Philadelphia, PA",Biotech & Pharmaceuticals,Biotech & Pharmaceuticals
Data Scientist,"Employer CSL Behring

Location King of Prussia, Pennsylvania

Posted Jun 20, 2020

Ref R-

Discipline Information Technology, Business/Data Analytics

Hotbed Pharm Country

Required Education Doctorate/PHD/MD

Position Type Full time

You need to sign in or create an account to save

About CSL

With operations in 35+ nations and ~ 22,000 employees worldwide, CSL is driven to develop and deliver a broad range of lifesaving therapies to treat disorders such as hemophilia and primary immune deficiencies, and vaccines to prevent influenza. Our therapies are also used in cardiac surgery, organ transplantation and burn treatment.

CSL is the parent company of CSL Behring and Seqirus. CSL Behring is a global leader in the protein biotherapeutics industry, focused on bringing to market biotherapies used to treat serious and often rare conditions. CSL Behring operates CSL Plasma , one of the world's largest collectors of human plasma, which is used to create CSL's therapies. Seqirus is the second largest influenza vaccine company in the world and is a transcontinental partner in pandemic preparedness and a major contributor to the prevention and control of influenza globally.

We invite you to take a look at the many career possibilities available around the globe and consider building your promising future at CSL by becoming a member of our team!

Job Description

CSL Behring, a global biopharmaceutical leader driven by our promise to save and improve lives, is looking for a full-time Data Scientist who will be expected to be responsible and accountable for all aspects of a project - data collection, data cleaning, modeling, presentation construction, presentations to management and executives, stakeholder management, moving applications and models into production, and more.

The purpose of this role is to increase the efficiency & performance of CSL business operations and, concurrently, to increase patient access to CSL therapies by working closely with subject matter experts to define operational areas to improve, data to be leveraged and business metrics to examine and analyst.

Come join a strong and collaborative team that focuses on delivering on service requests, quick wins & strategic applications of advanced analytics and artificial intelligence!

Key Responsibilities:

Planning and developing analytics projects based on business requirements, and developing and applying advanced statistical algorithms for analysis of large-scale high-dimensional data across various business domains.
Collaborates with process teams to elicit and understand requirements, challenges and potential solutions
Utilizes processes and systems to extract knowledge and insights from either structured or unstructured data
Matures project/single-site solutions to global enterprise solutions and provides documentation, training, and ongoing support
Stays current with latest research and technology ideas; evaluates technologies for design, simulation, engineering, runtime etc.
Educates and transfers technologies to other business units for implementation

Required Skills & Experience:

University degree in a technical field relevant to business process engineering; Computer Science, Statistics, Engineering (Ph.D. or MS) preferred
3+ years' experience in reporting and analytics
Demonstrated experience with the Hadoop stack (Hadoop/Spark Paradigms)
Strong background in predictive analytics, machine learning, and data mining
Strong foundation in database languages and data science languages
Experience working with real-world, large-scale and high-dimensional data sets

More searches like this
Information Technology jobs in King of Prussia
Business/Data Analytics jobs in King of Prussia","CSL Behring
3.7","King of Prussia, PA",Biotech & Pharmaceuticals,Biotech & Pharmaceuticals
Data Scientist,"About InterDigitalInterDigital develops fundamental wireless and video technologies that are at the core of mobile devices, networks, and services worldwide. We solve many of the industry's most critical and complex technical challenges, inventing solutions for more efficient broadband networks and richer multimedia experiences, years ahead of market deployment. InterDigital has licenses and strategic relationships with many of the world's leading wireless companies. Founded in 1972, InterDigital is listed on NASDAQ and is included in the S&P MidCap 400® index. For more information please visit www.interdigital.com.SummaryInterDigital is currently seeking a Data Scientist to work in our IS Department. We are looking for a Data Scientist to provide insights into the business through statistical analysis, data mining and data visualization techniques. The successful candidate will be intricately involved with our Data Management and Information Delivery team in the governance, development and maintenance of our reporting solution including the refinement of a data framework and implementation of Machine Learning and Artificial Intelligence solutions.Job Responsibilities* Coordinates and performs research and analytic activities utilizing various data sources and employ programming to clean, massage, and organize the data.* Interpret and analyze data to provide historical reporting, metrics tracking, adhoc reports and predictive models.* Generate dashboards and visualizations that can easily be interpreted.* Provide operational reporting for process and cost improvement projects and ROI evaluations.* Analyze error trends to determine root causes and implement solutions to address them.* Interact with business users across our global environment to gather requirements for reporting solutions and other data need to support decision making and business performance analysis.* Communicate results and explain advanced statistical content to key decision makers.* Develop strategy for long term data platform architecture.* Research and develop statistical learning models for data analysis* Develops and maintains technical documentation* Maintains Quality Service and Departmental Standards by* Reading, understanding and adhering to organizational Standard Operating Procedures (""SOP"")* Assisting in establishing and enforcing departmental standards* Ensuring the application of IS policies, principles, and practices in the delivery of all services* Participating in the modification of related company SOPs* Contributes to team effort by* Working with internal staff to resolve issues* Exploring new opportunities to add value to the organization and departmental processes* Helping others to achieve results* Performing other duties as assignedQualifications* Bachelor's degree in Information Technology, Computer Science, or a related field of study (10+ years relevant IS experience and training may be considered in lieu of a degree)* At least 5 years of IS experience with SQL and scripting languages such as Java/Python and Perl* At least 5 years of IS experience with statistical analysis, data visualization, and data cleansing tools and techniques such as SAS, R Programming and visualization using Power BI or equivalent.* Experience working in probability and statistics, time-series analysis, as well as experience in the use of machine learning applications and techniques.* Prior experience working with a financial organization and developing financial reporting required.* Experience with Microsoft Excel, Access, Flow, PowerPoint, OneNote and SharePoint.* Experience in managing cross functional teams a plus* Must be able to demonstrate a thorough understanding of business priorities and realizes the criticality of being a business partner* Ability to prioritize and work on several tasks simultaneously* Solid written and communication skills.* Effectively communicate and interact with both functional and technical personnel in solving complex business and technical problems* Ability to complete tasks within critical timelines and work well in a fast-paced, high-energy environment.* Able to proactively work alone and within a team environment.Location: Conshohocken, PAInterDigital is committed to a policy of Equal Employment Opportunity and will not engage in or tolerate unlawful discrimination against an applicant or employee on the basis of race, color, religion, creed, national origin, ancestry, citizenship, immigrant status, military status, veteran status, sex, sexual orientation, gender (including gender identity and/or expression), pregnancy, age, physical or mental disability, genetic information, atypical heredity cellular or blood trait, marital status, family status, domestic partner or civil union status or any other legally recognized protected basis under federal, state or local laws, regulations or ordinances. This policy applies to all terms and conditions of employment, including, but not limited to, hiring, compensation, benefits, training, assignments, evaluations, coaching, promotion, discipline, discharge and layoff.","InterDigital Communications Corporation
3.4","Conshohocken, PA",Electrical & Electronic Manufacturing,Manufacturing
Data Scientist,"Our Data Scientist is responsible for in-depth analysis of data across QVC and HSN leading to actionable insights and recommendations. This usually involves statistical and non-statistical modeling, simulations, optimization, and A/B testing.Relevant areas include consumer behavior, customer journey, e-commerce, television, marketing, and operations. Example projects include marketing mix optimization, airtime optimization, price elasticity estimation, and direct-response marketing targeting and effectiveness measurement.Job Description DetailsWhat you'll do:* Construct analytic data sets for exploration, modeling, insight generation* Conduct in-depth data analysis, data and prepare visualizations summarizing key features of the data* Develop accurate models for forecasting and inference* Develop test designs, hypotheses, success metrics, and test requirements, and execute test analysis* Work with stakeholders to define business questions and success criteria* Present results and consult the business on next steps* Conduct change management for new methodologies* Research best practices, technologies, tools, and trends* Guide and mentor other analytics team members (Center of Excellence)* Work with IT on productionalization, data accuracy* Develop novel techniques or maintain legacy codes when neededWho you are:* Advanced degree (Master's/PhD) in Statistics, Economics, Computer Science or other quantitative discipline* Expertise in various statistical methodologies such as regression analysis, cluster analysis, decision trees, factor analysis/principal component analysis, time series, survival models* 2+ years experience in data integration with SQL* 2+ years experience in statistical programming in SAS (strongly preferred) and/or R, Python* Experience in data visualization and exploration tools (Tableau preferred)* Strong statistical knowledge and knowledge of test design* Experience distilling and presenting complex concepts to a business audience* 2+ years experience using web analytics programs such as Coremetrics (preferred) or Google Analytics* 2+ years experience using A/B and Multivariate testing tools; experience with A/B testing analysis preferred* Experience at a B2C e-commerce company a plus#LI-CF1About QVC, IncQVC, Inc., exceeds the expectations of everyone we touch by delivering the joy of discovery through the power of relationships. Every day, in nine countries, QVC engages millions of shoppers in a journey of discovery through an ever-changing collection of familiar brands and fresh new products, from home and fashion to beauty, electronics and jewelry. Along the way, we connect shoppers to interesting personalities, engaging stories, and award winning customer service. Based in West Chester, Pa. and founded in 1986, QVC has more than 17,000 employees and has retail operations in the U.S., Japan, Germany, United Kingdom, Italy, France, and through a joint venture in China. Worldwide, QVC engages shoppers on 14 broadcast networks reaching approximately 370 million homes, seven websites, and 220 social pages. Visit corporate.qvc.com to learn more.QVC, Inc., is a wholly owned subsidiary of Qurate Retail, Inc. (NASDAQ : QRTEA, QRTEB), which includes QVC, HSN, zulily and the Cornerstone brands (collectively, ""Qurate Retail Group""), as well as other minority investments. Qurate Retail Group believes in a third way to shop -- beyond transactional ecommerce or traditional brick-and-mortar stores -- and is #1 in video commerce,#3 in ecommerce in North America and #3 in mobile commerce in the U.S. (according to Internet Retailer). For more information, visit www.qurateretailgroup.com. QVC, Q, and the Q Ribbon Logo are registered service marks of ER Marks, Inc.EEOAs an equal opportunity employer, Qurate Retail Group is committed to a diverse workforce and is also committed to a barrier-free employment process. In order to ensure reasonable accommodations for individuals pursuant to applicable law, individuals that require accommodation in the job application process for a posted position may contact us at CareersUS@QVC.com for assistance.Click Apply and log in with your existing account or create an account. This will allow you to check the status of your application at any time and receive the most up to date communications from our Talent Acquisition team.","QVC, Inc.
3.2","West Chester, PA","Department, Clothing, & Shoe Stores",Retail
Data Analyst,"Role Overview

Security, energy management, asset protection, and automation efficiencies...these are a few of our favorite things.

STRATIS IoT is actively seeking an experienced and passionate Data Analyst to join its engineering teams who are creating & molding the next generation of smart building technology. Our diverse family is made-up of adventurous, multifaceted individuals who bring what they've learned through various walks of life to improve our products.

As a Data Analyst, you should have at least two years of experience in the field, addressing real-world challenges. You will utilize your experience to assist in gaining user experience insights, product successes, key data opportunities, and overall scaling of the STRATIS platform.

Key Responsibilities
Love what you do & be an integral part of our family that is forging a new path in IoT technology;
Work with internal and external stakeholders to understand how they are using our product's data, align on useful metrics, and produce data representations an interpretable way;
Use creative analysis to surface opportunities across multiple databases;
Work relentlessly to ensure data findings are accessible to users at all levels through dashboards, visualizations, and reports;
Drive sales awareness, marketing efforts, program highlights when key data-points are discovered;
Actively interact with clients & partners during pilot projects to gain user insights;
Utilize data to understand user experiences in the field, as they are controlling & managing devices such as locks, thermostats, lights, shades, water metering, energy metering, & leak detection;
Innovate constantly on existing and cutting-edge technology to build new solutions;
Assist in the company's machine learning and AI goals in order to fully capitalize on our automation capabilities;
Take ownership of the company's data reporting capabilities, but work collaboratively with engineering teams to ensure you are armed with what you need;
Represent the company well as a continually client-facing team member;
This role reports directly to the Chief Innovation & Product Officer (CIPO).
Qualifications
2+ years of experience working with software engineering teams in an Agile environment as a data-oriented team-member;
Extraordinary initiative, drive, organization, and task-management skills;
Familiarity with Looker (LookML);
Ability to positively influence decision-making at all levels within an engineering organization with data insights;
Quick to learn new, complex systems and technologies;
Understanding of engineering principles, scrum practices, etc;
Excited to impact real people every day through your work.
Interview Process

PHASE 1: A member of our team will contact you to arrange a call to discuss your professional accomplishments & ambitions. You may be asked to participate in a second phone call to gauge technical capabilities as well.

PHASE 2: You will be invited to interview with the teams. This interview will include a review by multiple members of our various teams. Throughout this phase of the interview process, you will get the chance to interact with our teams in a casual, free-flowing environment.

PHASE 3: Final interview to assess our mutual culture-add, your relevant skillsets, and to answer any additional questions that may have come up throughout the process. Prior to this phase, you may be requested to contribute to a challenge of some type.

About STRATIS

Located in the former East Falls community theatre in the East Falls neighborhood of Philadelphia, STRATIS is widely considered one of the best-kept secrets in emerging technology. Since 2014, we have been the leader in smart apartments for multifamily. We were named one of Entrepreneur Magazine's ""Best Companies in America"" two years in a row, #740 on Inc. Magazine's list of 5000 ""fastest-growing companies"" in 2019, and our CEO, Felicite Moorman, was Ernst & Young's 2017 local and regional Entrepreneur of the Year.

As the only system of its kind built for the complexities of multifamily building management, we are leading the global movement for smart cities in the urban and residential sectors. To date, STRATIS has been installed in over 30,000 units in Japan and Europe, and in over 350,000 units across 46 states in the U.S.

Key Benefits
Competitive salary
401K retirement plan (matching)
Medical, dental, and vision plan
Life Insurance plan
SEPTA Transportation discounts
Dog-friendly office for people-friendly dogs
Ability to see your contributions impact lives every day
Flexible schedules and vacation/work from home policy (including maternity/paternity leave)
Sponsorship for conferences and educational events
Supportive, casual, and professional work environment for a team that focuses on creating linchpins, mentors, and experts in their field.","STRATIS IoT Inc
4.7","Philadelphia, PA",Enterprise Software & Network Solutions,Information Technology
Data Scientist,"The Device Software Product Management team is responsible for the management of software strategy & roadmap for all Comcast & Sky devices. This generally includes a broad set of responsibilities including: strategy development, product discovery of new technologies, external & internal partnerships, software roadmap definition, management and prioritization for new and existing devices.

As a data scientist, you will play a pivotal role in improving Comcast’s WiFi product! You will collaborate with a multi-disciplinary team of engineers, architects, product managers and external partners to derive key insights that will be used for decision making, producing reports for both internal consumption and TPX SLT and driving device/platform requirements and improvements!

Core Responsibilities:
Work with large, complex data sets and apply analytical and statistical methods to derive global and local trends relative to WiFi performance for both CPE & connected clients and associated operational metrics.
Synthesize trends into insights to make product recommendations with effective presentations of findings at multiple levels of partners through visual display of quantitative information
Build and prototype analysis pipeline iteratively to provide insights at scale. Develop understanding of Comcast data structures and metrics, advocating for changes where needed for both product and platform development.
Establish performance baselines, develop and deploy predictive models to forecast improvements, keep track of benefits realization as new features are developed & deployed
May serve as team leader. Mentors and trains junior team members.
Qualifications:
MS degree in a quantitative discipline (e.g., data analytics, statistics, operations research, bioinformatics, computer science, mathematics, physics, electrical engineering, industrial engineering).
3-5 years of meaningful work experience in data analysis or related field. (e.g., as an engineer, data scientist)
Strong sense of independence and intellectual curiosity.
Ability to think, communicate and execute from big picture strategy to execution details
Strong foundation in data analytics, statistics and machine learning
Experience in writing code in SQL & Python (Scala, Unix)
Experience in operating in Big Data Pipelines (Spark, Hive, SQL engines) batch and streaming
Experience in developing and deploying Machine Learning models and data story telling with visualizations
Preferred qualifications:
PhD degree in a quantitative discipline as listed in Minimum Qualifications
Applied experience with machine learning on large datasets (Spark)
Experience articulating business questions and using mathematical techniques to arrive at an answer using available data. Experience translating analysis results into business recommendations.
Demonstrated skills in selecting the right statistical tools given a data analysis problem. Proven effective written and verbal communication skills.
Displayed leadership and self-direction. Showcased willingness to both teach others and learn new techniques.","Contingent Network Services
3.1","Philadelphia, PA",Enterprise Software & Network Solutions,Information Technology
Statistician,"The U.S. Department of the Treasury has a distinguished history dating back to the founding of our nation. As the steward of U.S. economic and financial systems, Treasury is a major and influential leader in today's global economy. We have over 100,000 employees across the country and around the world. Come Join the Department of the Treasury and Invest in Tomorrow.
See Other Information for Locations
Positions are to be filled in the Large Business & International (LB&I), Data Solutions division.
Eight (8) positions are to be filled in any of the following locations:
Birmingham, AL
Fayetteville, AR
Little Rock, AR
Phoenix, AZ
El Monte, CA
Glendale, CA
Laguna Niguel, CA
Los Angeles, CA
Long Beach, CA
Oakland, CA
Sacramento, CA
San Diego, CA
San Francisco, CA
San Jose, CA
Santa Ana, CA
Lakewood, CO
Hartford, CT
New Haven, CT
Norwalk, CT
Washington, DC
Newark, DE
Miami, FL
Ft. Myers, FL
Jacksonville, FL
Maitland, FL
Plantation, FL
Tampa, FL
West Palm Beach, FL
Atlanta, GA
Honolulu, HI
Des Moines, IA
Chicago, IL
Downers Grove, IL
Schiller Park, IL
Springfield, IL
Indianapolis, IN
Wichita, KS
Louisville, KY
New Orleans, LA
Boston, MA
Brockton, MA
Stoneham, MA
Southborough, MA
Baltimore, MD
Lanham-Seabrook, MD
Rockville, MD
Ann Arbor, MI
Clinton Township, MI
Detroit, MI
Farmington Hills, MI
Flint, MI
Grand Rapids, MI
Pontiac, MI
Bloomington, MN
Chesterfield, MO
Lee's Summit, MO
Charlotte, NC
Greensboro, NC
Raleigh, NC
Omaha, NE
Edison, NJ
Iselin, NJ
Mountainside, NJ
Paterson, NJ
Las Vegas, NV
Albany, NY
Bethpage, NY
Buffalo, NY
New York, NY
Rochester, NY
Cincinnati, OH
Columbus, OH
Independence, OH
Oklahoma City, OK
Tulsa, OK
Portland, OR
Philadelphia, PA
Pittsburgh, PA
King Of Prussia, PA
Guaynabo, PR
Warwick, RI
Franklin, TN
Memphis, TN
Nashville, TN
Austin, TX
Farmers Branch, TX
Fort Worth, TX
Houston, TX
San Antonio, TX
Ogden, UT
Salt Lake City, UT
Norfolk, VA
Richmond, VA
Vienna, VA
Seattle, WA
Milwaukee, WI
Waukesha, WI
Kearneysville, WV
Martinsburg, WV
WHAT DOES A DATA SCIENTIST DO? The Data Scientist utilizes advanced analytical, statistical, and computer programming skills to develop data- driven solutions to difficult business challenges. As a data scientist, you are responsible for conducting data-centric projects to provide insight and informed decisions for mission- oriented programs of the Internal Revenue Service (IRS), which may impact multiple program segments, divisions, the Service, or segments of the taxpayer population. This is accomplished by utilizing a wide range of technical competencies such as statistics and machine learning, coding languages, data wrangling, and reporting and visualization techniques. The Data Scientist may lead team or cross functional projects, and will apply critical thinking, problem solving and ability to communicate complex analysis to advance the use of data-driven decision making in IRS operations.

WHAT IS THE LARGE BUSINESS AND INTERNATIONAL (LB&I) DIVISION OF THE INTERNAL REVENUE SERVICE? The Large Business and International (LB&I) business unit provides service and enforcement activities to support tax compliance of businesses and related entities with assets of $10 million or more, as well as small U.S. businesses engaged in international, U.S. citizens abroad, and foreign persons and businesses with a U.S. tax requirement.
As a Data Scientist, you will:
Serve as a technical expert with responsibility for the initiation, planning, implementation, controlling, modifying and executing of all or part of an entire project, including such tasks as formulation of workload estimates for program segments, specification of the methodology to be used, preparation of appropriate specifications and procedures, and review of computer systems specifications and materials and instructions needed for assuring the adequacy of the project’s design and objectives.
Explore novel methods of retrieving data and develop innovative recommendations to management and senior leadership as a means for making data driven decisions such as modification of processes and policies. Review, evaluate, validate, and document the results of the findings.
Assist the supervisor in determining the scope, goals and schedules for future programs in the Office. Collaborate with business or technology partners to understand business needs, identify opportunities, and develop and implement analytical solutions.
Identify and assess relevant data sources’ validity and reliability to meet project needs. Collate, clean, transform, analyze, and integrate structured and unstructured data from various sources in preparation for analysis.
Apply statistical methods and concepts including data mining, statistical theory and research procedures to test hypotheses using structured and unstructured data. Develop data product solutions to improve customer experiences, anomaly detection, and business outcomes. Develop proofs of concept or demonstrations to evaluate feasibility of project solutions and recommend visualization strategies.
Document project work and review deliverables for validity, reliability and timeliness. Communicate analytic solutions to technical and non-technical stakeholders, including during executive- level and/or cross-agency meetings, in a clear and effective manner using oral and written communications.
Maintain knowledge of state-of-the-art innovations in data science from both academic and industry sources and identify opportunities for implementation. Engage in general professional development to improve knowledge of IRS processes/programs.
Apply computer based mathematical/statistical techniques using software. Lead or participate in statistical projects or studies in survey sampling (design and estimation), modeling, or statistical research. Apply knowledge of programming/coding language (i.e., SQL, SAS, SPSS, RStudio) to develop scripts or applications.
Act as a troubleshooter in resolving bottlenecks at any step in a project by identifying and proposing solutions; this may include coordination with other project team members or stakeholders to mitigate issues.

WHERE CAN I FIND OUT MORE ABOUT OTHER IRS CAREERS? If you want to find out more about IRS careers, visit us on the web at www.jobs.irs.gov
#LI-POST
You must meet the following requirements by the closing date of this announcement
BASIC QUALIFICATION REQUIREMENTS:

GS-1530 Statistician All Grades:
You must have a Bachelor's degree that included 15 semester hours in statistics (or in mathematics and statistics, provided at least 6 semester hours were in statistics), and 9 additional semester hours in one or more of the following: physical or biological sciences, medicine, education, or engineering; or in the social sciences including demography, history, economics, social welfare, geography, international relations, social or cultural anthropology, health sociology, political science, public administration, psychology, etc. Credit toward meeting statistical course requirements should be given for courses in which 50 percent of the course content appears to be statistical methods, e.g., courses that included studies in research methods in psychology or economics such as tests and measurements or business cycles, or courses in methods of processing mass statistical data such as tabulating methods or electronic data processing. OR
Combination of education and experience -- courses as shown above, plus appropriate experience or additional education. The experience should have included a full range of professional statistical work such as (a) sampling, (b) collecting, computing, and analyzing statistical data, and (c) applying statistical techniques such as measurement of central tendency, dispersion, skewness, sampling error, simple and multiple correlation, analysis of variance, and tests of significance.
GS-13 LEVEL: You must have one year of specialized experience at a level of difficulty and responsibility equivalent to the GS-12 grade level in the Federal service. Specialized experience for this position includes all of the following:
Experience applying project management principles on a data science project
Experience planning and executing a variety of data science and/or analytics projects.
Experience using data mining process models (such as CRISP-DM, SEMMA, etc.,) to design and execute data science project.
Experience preparing and analyzing structured and unstructured datasets to explorations and evaluating data science centric models.
Experience working with multiple data types and formats as a part of a data science project.
Experience applying a range of analytic approaches, including (but not limited to) machine learning, text analytics, and natural language processing; graph theory, link analysis and optimization models; complex adaptive systems; and/or deep learning neural networks that are part of the exploration.
Experience coding in various programming languages (such as R, Python, SQL, or JAVA) to conduct various phases of data science projects.
Experience creating and querying different datastores and architectures (such as Sybase, Oracle, and open-source databases) to work with various types of data as part of the data science project.
Experience using tools for data visualization (graphs, tables, charts, etc.,) and end-user business intelligence.
-The experience may have been gained in the public sector, private sector or Volunteer Service. One year of experience refers to full-time work; part-time work is considered on a prorated basis.
-To ensure full credit for your work experience, please indicate dates of employment by month/year, and indicate number of hours worked per week, on your resume.","Internal Revenue Service
3.5","Philadelphia, PA",Federal Agencies,Government
Data Analyst,"Title: Data Analyst
Location: 100% remote right now, onsite in Center City Philadelphia, PA after Covid! 1 day remote down the line
Duration: FULL TIME Permanent (Must be a US Citizen or Greencard Holder)
Start: ASAP
Interview Process: Zoom Video Interviews
Must haves:
SQL
Global & enterprise background
Implementations/integrations
MarTech
Data visualization (PowerBI/Tableau, etc)
Notes
SQL Background
5+ years of experience
ERP experience
Integrations
Implementations (walking through them)
Headsdown do'er type role
highly communicative / personality is key
status updates
MarTech background
over communicative
Tableau/PowerBI (or any data visualization tool)
Data link to data visualization
Salesforce -- sales and service cloud (PLUS)
database type person- navigate between databases
magento, salesforce, PIMs, snowflake-- similar products
Coming from enterprise and global background
30/60/90- implementation on PIM, launching a project--snowflake implementation, data warehouse platform
working and guiding those tools
data needs and data issues
data architecture--future integrations, maintenance, data modeling
ground up build-- which they think will be a challenge
omnichannel- digital and offline side of things
salesforce/website -utilizing data
Python/R (Plus)
gradually growing into senior manager/data strategy lead

If qualified and interested, please send your most current resume as a word document to Jason Weinstein at jason.weinstein@mondo.com","Mondo
3.8","Philadelphia, PA",Staffing & Outsourcing,Business Services
Data Analyst,"At Seer, we pride ourselves on innovation; standing out among the rest and enabling our clients to do the same. We're a Digital Marketing Agency powered by Big Data to drive integrated, holistic strategy for our clients. We get excited at the thought of bringing together millions of data points from disparate data sets (including qualitative!) to drive empathy-fueled opportunities and insights at scale. Big Data, automation, and problem solving at scale: it's what's for breakfast. Could this be love? Maybe.

What about you? You’re a data-obsessed problem-solver. You pay attention to the details without losing sight of the big picture. You know how to think critically and turn business problems into data problems. You’re quick to pick up patterns and patient enough to identify long-term trends. You're detail-oriented, logical, and endlessly curious about how big data is used to inform digital marketing.
Here are some highlights of what you'll be doing...
You’ll be entrenched in the data; working across divisions to turn business problems into data problems through critical thinking and consulting skills
You’ll help manage Seer’s data warehouse leveraging BigQuery and SQL expertise to optimize queries and drive other cost-saving opportunities
You’ll work within our data warehouse, using BigQuery and pulling business insights out of data
You’ll create dashboards in Data Studio & Power BI to display data for greater cross-divisional analysis and crafting strategy
You’ll complete cross-divisional training, gaining a strong foundation of PPC, SEO, Analytics, and how they all work together
You'll contribute to the Seer blog, industry forums, and grow your thought leadership skills from the ground up
The skills you'll bring to the table...
You're an innovator. You're excited to work with Big Data and use your experience in SQL to problem solve and answer business questions
You've worked with data visualization tools, specifically Power BI and/or Data Studio
You have relevant internship experience or hands-on project experience working with data
You take initiative and can self-direct in the absence of detailed guidelines
You’re comfortable managing deadlines for multiple deliverables and thrive in a fast-paced, open environment
You have a strong sense of self, which means you’re able to say no, deliver feedback, have the confidence to provide input, etc.
Bonus Points...
You have experience leveraging Python and APIs to access new data sources not available in the data warehouse
You can interpret API instructions and build MVPs to transfer data from an API into a database or flat file.
You have an understanding of digital marketing data, specifically SEO and PPC. Perhaps you’ve even worked in a marketing agency!? We should definitely chat!!


Sometimes the best opportunities are hidden by self-doubt. We disqualify ourselves before we have the opportunity to be considered. Regardless of where you came from, how you identify, or the path that led you here-- you are welcome. If you read this job description with a belly full of excitement, we’re just as excited about you. You’ve gotta apply though :)","Seer Interactive
3.9","Philadelphia, PA",Internet,Information Technology
Data Scientist,"Clarivate Analytics is a global leader in providing trusted insights and analytics to accelerate the pace of innovation. We deliver critical data, information, workflow solutions, and deep domain expertise to innovators worldwide.

Our solutions cover the entire lifecycle of innovation: scientific and academic research; patent analytics and regulatory standards; pharmaceutical and biotech intelligence; trademark, domain and brand protection. Our portfolio consists of some of the worlds most trusted brands, including Web of Science, Derwent, CompuMark, Cortellis, MarkMonitor, and Techstreet.

We employ more than 4,300 colleagues in 43 countries.

Clarivate Analytics is a public company. We are listed on the New York Stock Exchange under the tickers NYSE:CCC; CCC.WS.

At Clarivate, we believe human ingenuity can transform the world and improve our future. Thats why we harness our global reach, curate our content, and invest in best-in-class technology and people.

Join the team that is improving the way the world creates, protects, and advances innovation.

As a Data scientist, you will help facilitate doing research work and identifying ML methods that could be used to solve the different problems faced by our business units and implement the solutions which will help optimize the systems and help the company to innovate.

Major responsibilities:
Researches and identifies Machine Learning (ML) and Natural Language Processing (NLP) methods and algorithms to solve specific problems to improve user experience on Clarivate data and websites
Implements these methods and devises appropriate test plans to validate and compare the different approaches
Identifies new applications of ML and NLP in the context of Clarivate extensive sets of content and data
Explores existing data for insights and recommends additional sources of data for improvements
Technical /Professional Skills & Competencies:
Excellent understanding of ML, NLP and statistical methodologies
Excellent programming skills (Java/Python/R/Sas)
Ability to test ideas and adapt methods quickly end to end from data extraction to implementation and validation
Experience with information retrieval algorithms and recommended systems a big plus
Education and Background:
Bachelor's degree in Computer Science, Engineering or similar. MS preferred
Relevant work experience preferred
Ability to work with data engineers and product teams
.

It is the policy of Clarivate to provide equal employment opportunity (EEO) to all persons regardless of age, color, national origin, citizenship status, physical or mental disability, race, religion, creed, gender, pregnancy, sex, sexual orientation, gender identity and/or expression, genetic information, marital status, status with regard to public assistance, veteran status, or any other characteristic protected by federal, state or local law. In addition, Clarivate will provide reasonable accommodations for qualified individuals with disabilities.","Clarivate Analytics
2.8","Philadelphia, PA",Research & Development,Business Services
Data Analyst,"University Overview

The University of Pennsylvania, the largest private employer in Philadelphia, is a world-renowned leader in education, research, and innovation. This historic, Ivy League school consistently ranks among the top 10 universities in the annual U.S. News & World Report survey. Penn has 12 highly-regarded schools that provide opportunities for undergraduate, graduate and continuing education, all influenced by Penn's distinctive interdisciplinary approach to scholarship and learning.

Penn offers a unique working environment within the city of Philadelphia. The University is situated on a beautiful urban campus, with easy access to a range of educational, cultural, and recreational activities. With its historical significance and landmarks, lively cultural offerings, and wide variety of atmospheres, Philadelphia is the perfect place to call home for work and play.

The University offers a competitive benefits package that includes excellent healthcare and tuition benefits for employees and their families, generous retirement benefits, a wide variety of professional development opportunities, supportive work and family benefits, a wealth of health and wellness programs and resources, and much more.

Posted Job Title

Data Analyst

Job Profile Title

Data Analyst D

Job Description Summary

Data Analyst DThe data analyst will partner with the Faculty of the Penn Dermatology Oncology Center (PennDOC) and the Skin Biology and Disease Resource Based Center (SBDRC) to design, conduct, and publish research that improves the lives of patients with skin cancer and skin diseases. The data analyst will enjoy a collegial relationship with a dynamic group of surgeons, clinicians, and basic scientists dedicated to conducting practical research about skin cancer and skin diseases. The data analyst will also collaborate with clinical research coordinators in the Department of Dermatology and work with collaborating investigators from other specialties and outside institutions to ensure compliance with regulatory research requirements. Applicants must have a strong background in creating and analyzing databases; knowledge in basic statistics; basic knowledge in regulatory requirements of the Institutional Review Board; excellent oral and written communication skills to work with a team and to draft research proposals and manuscripts; and organizational skills to prepare agendas and material for regular research team meetings. The data analyst will receive mentorship from and report to the Director of Research Operations for the Department of Dermatology. The data analyst will have regular guidance from Faculty mentors, including Principle Investigators and Subject Matter Experts.

Job Description

With general direction, performs data analysis and assists with design of complex data models based upon business or research requirements. Often as part of a team, identifies and resolves required information flows and content issues, and transforms requirements into data designs and models. May perform analyses, development and evaluation on large databases and large complex installations. May provide reporting and decision support systems consultation. May provide data analysis expertise to one or more project or support teams. May work with vendor delivered solutions

Position contingent on funding.

Responsibilities
Develops and analyzes databases as indicated for research projects including clinical trials, observational, retrospective, and prospective studies. Maintains and enhances the existing database for Mohs micrographic surgery at Penn. Collects and organizes data from patient charts and existing databases (e.g. SEER, Optum). Develop and implement quality control plans to ensure data integrity and compliance.
Performs descriptive and inferential statistics, including regression analyses, and sample size calculations. Analyses may also include simple data descriptions (e.g., prevalence and incidence of outcomes), correlations, regression modeling (e.g., linear, logistic, cox proportional hazard models, mixed effects models, latent class analysis). Uses statistical programming language, such as SAS, STATA, R, or other programing language for analysis and collaborates with biostatistical experts when appropriate. Ability to use data visualization techniques in Tableau, Power BI, Excel, or with a programming language (e.g., R or Python. The analyst may need to learn additional statistical or bioinformatics (e.g., multi-omic data analysis) techniques for existing and/or future projects.
Drafting and submission of research grant proposals and manuscripts:
Partners with Faculty to complete research grant proposals and manuscripts. Common contributions from the data analyst include: preparing tables to summarize data and figures to illustrate statistics; drafting relevant portions of research proposals and manuscripts; submitting manuscripts and proposals; and managing correspondence with authors, journal editors, and reviewers.
Mentoring pre-doctoral research fellows and organizing research meetings:
Mentors pre-doctoral student researchers in study design and basic statistical analysis. Works with faculty mentors and Principle Investigators, including Director of PennDOC and PI/co-PI of the SBDRC to organize the agenda and materials for research group meetings.
Perform additional duties as assigned
Duties

The data analyst will partner with the Faculty of the Penn Dermatology Oncology Center and the Skin Biology and Disease Resource Based Center to design, conduct, and publish research that improves the lives of patients with skin cancer and skin diseases. The data analyst will enjoy a collegial relationship with a dynamic group of surgeons, clinicians, and researchers dedicated to practical research about skin cancer and skin diseases. The data analyst will also collaborate with clinical research coordinators in the Department of Dermatology and interface with collaborating investigators and biostatisticians from other specialties and outside institutions.

The data analyst will create and analyze databases; apply basic statistics to data; design data tables and figures; assist with manuscript and grant proposal drafting; ensure compliance with research regulations; and prepare materials for regular research team meetings.

Qualifications

Required:

+ 3-5 years experience. 1-2 years of prior experience in clinical research or an equivalent combination of education and experience.

+ Bachelor's Degree or higher educational attainment in biostatistics, biomedical informatics, public health, or related field that ensures a fundamental understanding of research design considerations. Master's Degree preferred.

+ Basic knowledge of regulatory requirements and how to appropriately fulfill them, including Institutional Review Board submissions.

+ Ability to perform descriptive and basic inferential statistics, including regression analyses, and sample size calculations.

+ Proficiency with basic computer programming skills, including basic Microsoft Office applications, e.g. Access, Word, Excel, PowerPoint.

+ Experience using a statistical programming language, such as SAS, STATA, R, or other programming language.

+ Working knowledge of relational database design, query, and reporting.

+ Excellent interpersonal and communication (written and verbal) skills

+ Ability to work both independently and with a team as well as the ability to manage up.

+ Strong organizational and documentation skills.

Preferred

+ Ability to import/export data into or from various formats into standard statistical software.

+ Experience in verifying, documenting, and cleaning large data files.

+ Experience with large administrative or claims datasets (e.g Medicare, SEER, NCDB, etc)

+ Familiarity with data standards and coding conventions.

+ Experience managing multiple projects effectively and meeting deadlines.

+ Experience with data visualization techniques in Tableau, Power BI, Excel, or with a programming language (e.g., R or Python).

+ Experience with mySQL or SQL

Working ConditionsOffice, Library, Computer RoomPhysical EffortTypically sitting at desk or table

Contingent upon funding

Job Location - City, State

Philadelphia, Pennsylvania

Department / School

Perelman School of Medicine

Pay Range

$59,703.00 - $168,837.00

Affirmative Action Statement Penn adheres to a policy that prohibits discrimination on the basis of race, color, sex, sexual orientation, gender identity, religion, creed, national or ethnic origin, citizenship status, age, disability, veteran status, or any other legally protected class.

Special Requirements Background check required after a conditional job offer is made. Consideration of the background check will be tailored to the requirements of the job.

The University of Pennsylvania's special character is reflected in the diversity of the Penn community. We seek talented faculty and staff who will constitute a vibrant community that draws on the strength that comes with a substantive institutional commitment to diversity along dimensions of race, ethnicity, gender, sexual orientation, age, religion, disability, veteran status, interests, perspectives, and socioeconomic status. Grounded in equal opportunity, nondiscrimination, and affirmative action, Penn's robust commitment to diversity is fundamental to the University's mission of advancing knowledge, educating leaders for all sectors of society, and public service. The University of Pennsylvania prohibits unlawful discrimination based on race, color, sex, sexual orientation, gender identity, religion, creed, national or ethnic origin, citizenship status, age, disability, veteran status, or any other legally protected class.","University of Pennsylvania
4.3","Philadelphia, PA",Colleges & Universities,Education
Data Analyst,"Are you ready to take the next step in your career? Do you want to do meaningful work that improves quality of life? At Tetra Tech, you will work with high-performing teams who are passionate about using their expertise to find solutions to complex problems in water, environment, infrastructure, resource management, energy, and international development.Tetra Tech Inc. is currently seeking a Data Analyst located in Philadelphia, PA for its Disaster Response Division. The successful candidate will have extraordinary attention to minute detail and be responsible for executing and overseeing daily administrative, data entry, and reconciliation assigned to them, and those performed by other staff under the supervision of the Program Manager.Responsibilities:* QA/QC reconciliation, and data entry of timesheets records, invoice records, and material use records for grant-funded programs* Coordinate, review, analyze, and summarize financial data for grant-funded programs* Audit and reconciliation of force account documentation.* Assist in evaluating the fiscal administration of grant programs* Perform QA/QC review of financial documentation.* Reconcile federal and state grants, cost estimates, audits, and other initiatives that support disaster recovery effortsQualifications:The ideal candidate will have 2+ years of experience in finance, accounting, data entry and/or business administration and must be able to or have:* Bachelor's degree in business, accounting, or in public administration required. Four years additional industry experience may be substituted in lieu of degree.* Prior experience with post-disaster federal grant funding* Finance, Accounting, Business Administrative background preferred* Office suite proficiency (Excel, Outlook, SharePoint and Word experience required)* Must have proficient verbal and written communications skills with the ability to receive and execute instructions* Ability to multi-task and work under pressure to meet strict deadlines* Work attentively with minimal supervision* Work days in excess of 8 hours and/or weekend attendance may be required (Open to consider flexible schedule for the right candidate)* Have extraordinary attention to minute detail* Adaptable to work on many different deliverables and maintain composure and professionalism* Proficient verbal and written communications skills with the ability to receive and execute instructions* Exceptional client service and communication skills to maintain outstanding Client relationship* Ability to multi-task and work under pressure to meet strict deadlines (this is duplicated)* Must be available for short-term travel to support on-site client needs and extended deployment (e.g., 90+ days) to address client response and long-term recovery needs following emergencies and major disastersAbout Tetra Tech:Tetra Tech is a leading provider of high-end consulting and engineering services for projects worldwide. We combine the resources of a global, multibillion dollar company with local, client-focused delivery in more than 400 locations around the world. We are Leading with Science® to provide sustainable and resilient solutions for our clients.At Tetra Tech, we provide a collaborative environment that supports individual performance, innovation, and creativity. We are proud to offer competitive compensation and benefits. Learn more by visiting http://www.tetratech.com/en/benefits.For more information on our company, please visit our website at www.tetratech.com. To apply, please submit your resume and cover letter on the Careers portion of our website at www.tetratech.com/careers.We thank all applicants for their interest; however only those selected for an interview will be contacted. Tetra Tech is committed to creating a diverse environment and is proud to be an Equal Opportunity Employer. We invite resumes from all interested parties including women, minorities, veterans and persons with disabilities.Tetra Tech is a VEVRAA federal contractor and we request priority referral of veterans for available positions.EOE AA M/F/Vet/Disability - No calls or agenciesAdditional Information* Organization: 105 TDR","Tetra Tech, Inc.
3.7","Philadelphia, PA",Architectural & Engineering Services,Business Services
Data Analyst,"Does optimizing marketing efficiency and effectiveness get you all hot and bothered?

Do well written formulas make you all tingly inside? We are hiring a digital analyst who sees the stories and humans inside the numbers. Someone who can transform data into actionable insights to drive our clients’ websites, applications and digital/social marketing.

The Mandatories
Love of big ideas.
Assist in the design and planning of campaign/site success measurements.
Work collaboratively with the Digital Strategy, Account Management, Media, and Social departments to develop hypothesis, establish KPIs and ask pointed questions.
Collect and aggregate consumer, business, campaign and media data from a number of different sources.
Monitor and analyze performance to provide insights and recommendations for optimizations and improvements.
Help drive the creation of dashboards and periodic reports for clients as well agency-wide reporting processes and templates.
Demonstrated passion for telling stories with quantitative data.
2+ years of relevant work experience, agency side is a plus.
Extensive knowledge of performance metrics, especially within digital and emerging media.
Skilled using data tools to design and build reports.
Experience in setup & implementation of GA / GTM.
Extra Credit:
Experience in setup, implementation and maintenance of a Data Management Platform.
Media experience and working knowledge of media tools, such as, Adwords, Doubleclick, Facebook, etc.
Experience with the design and implementation of GA goal and conversion tracking.
Extra Extra Credit:
Ability to study the past, and predict the future, to act in the present.
The Perks
A competitive salary.
Solid Health Bennies.
401k and Profit Share Programs.
A stocked Kegerator with rotating brews.
The office - built into John Wanamaker’s old penthouse apartment, smack in the middle of the city. Like none you’ve ever seen.
Vacation policy: We all take them and love the refreshing feeling they offer and so our policy is unlimited vacay.
A work environment that enthusiastically encourages creativity, risk-taking and growth.
BE UNFORGETTABLE.
That's our mission. Simple to say. Nearly impossible to pull off. But when you set the bar that high, every single jump has meaning.","Red Tettemer
3.6","Philadelphia, PA",Advertising & Marketing,Business Services
Data Analyst,"The Ombudsman’s Office (OMB) is a neutral and confidential resource for member firms and their employees, public investors, and any other business or individual who interacts with FINRA to voice their concerns about operations, enforcement, or other FINRA activities or staff. The Analyst is responsible for collecting and analyzing ombudsman and other secondary data to identify patterns, trends and problematic issues. This is professional position, developing and refining skills and receives moderate supervision and regular direction from a manager.

Essential Job Functions:
Maintains strict confidence and neutrality while performing duties and responsibilities and strictly adheres to the ombudsman Standards of Practice.
Utilizing data analytics, gather and analyze Ombudsman and other FINRA data to determine significant patterns, trends, and areas that may require additional focus by Ombudsman case managers.
Partners with Ombudsman case managers to conduct research to detect underlying causes of problematic issues and trends, and develop recommendations for improvement.
Responsible for the production of management-level quarterly and annual statistical and other ad-hoc reports that identify trends, risks, recommendations, and ongoing work status.
Supports the development of recommendations where other departments’ policies, procedures, and practices should be created or improved.
Develops case documentation guidelines and the development/maintenance of a knowledge management (FAQs, topical dictionary) tool.
Acts as a point of contact in the development of the Ombudsman office case tracking and reporting system, a system used to track all inquiries and complaints received by the Office, including complaint details, progress notes, report of findings, and resolution summaries.
Acts as the lead in testing of system requirements and in system maintenance.
Other Responsibilities:
Works with the Ombudsman team on the development of departmental processes and procedures that guide the ongoing activities of the Office and primarily responsible for developing and maintaining written procedures.
Receives and manages inquiries from FINRA constituents to determine the appropriate referral department or resolution and captures detailed records of inquiries in the department’s case tracking and reporting system.
Support Ombudsman case managers by assisting with research for complex cases as needed.
Ensure all records are retained in accordance with FINRA and the office’s Information Privacy and Protection Policy and Record Retention Requirements.
Special Projects as assigned.
Education/Experience Requirements:
Bachelors in Computer Science, Engineering, Business, Finance, Economics, or Statistics and 2+ years of cumulative relevant experience; or equivalent combination of training and/or work experience.
1 - 3 years of securities, compliance or financial regulatory experience preferred.
Quantitative and qualitative analysis experience and strong analytical and critical thinking skills required.
Experience with SQL and relational database design.
Experience generating, improving and automating statistical and graphical charts.
Advanced skills utilizing Microsoft Excel, Access, and PowerPoint
Microsoft 365, and Visual Basic experience helpful.
Excellent written and verbal communication skills, including interactions with both internal and external constituents.
Strong organizational skills and excellent detail orientation are essential.
Working Conditions:
Professional office environment
Occasional travel may be required.
To be considered for this position, please submit an application.

The information provided above has been designed to indicate the general nature and level of work of the position. It is not a comprehensive inventory of all duties, responsibilities and qualifications required.

Please note: If the “Apply Now” button on a job board posting does not take you directly to the FINRA Careers site, enter www.finra.org/careers into your browser to reach our site directly.

FINRA strives to make our career site accessible to all users. If you need a disability-related accommodation for completing the application process, please contact FINRA’s accommodation help line at 240.386.4865. Please note that this number is exclusively for inquiries regarding application accommodations.

In addition to a competitive salary, comprehensive health and welfare benefits, and incentive compensation, FINRA offers immediate participation and vesting in a 401(k) plan with company match. You will also be eligible for participation in an additional FINRA-funded retirement contribution, our tuition reimbursement program and many other benefits. If you would like to contribute to our important mission and work collegially in a professional organization that values intelligence, integrity and initiative, consider a career with FINRA.

Important Information

FINRA’s Code of Conduct imposes restrictions on employees’ investments and requires financial disclosures that are uniquely related to our role as a securities regulator. FINRA employees are required to disclose to FINRA all brokerage accounts that they maintain, and those in which they control trading or have a financial interest (including any trust account of which they are a trustee or beneficiary and all accounts of a spouse, domestic partner or minor child who lives with the employee) and to authorize their broker-dealers to provide FINRA with duplicate statements for all of those accounts. All of those accounts are subject to the Code’s investment and securities account restrictions, and new employees must comply with those investment restrictions—including disposing of any security issued by a company on FINRA’s Prohibited Company List or obtaining a written waiver from their Executive Vice President—by the date they begin employment with FINRA. Employees may only maintain securities accounts that must be disclosed to FINRA at one or more securities firms that provide an electronic feed (e-feed) of data to FINRA, and must move securities accounts from other securities firms to a firm that provides an e-feed within three months of beginning employment.

You can read more about these restrictions here.

As standard practice, employees must also execute FINRA’s Employee Confidentiality and Invention Assignment Agreement without qualification or modification and comply with the company’s policy on nepotism.

Search Firm Representatives

Please be advised that FINRA is not seeking assistance or accepting unsolicited resumes from search firms for this employment opportunity. Regardless of past practice, a valid written agreement and task order must be in place before any resumes are submitted to FINRA. All resumes submitted by search firms to any employee at FINRA without a valid written agreement and task order in place will be deemed the sole property of FINRA and no fee will be paid in the event that person is hired by FINRA.

FINRA is an Equal Opportunity and Affirmative Action Employer

All qualified applicants will receive consideration for employment without regard to age, citizenship status, color, disability, marital status, national origin, race, religion, sex, sexual orientation, gender identity, veteran status or any other classification protected by federal state or local laws as appropriate, or upon the protected status of the person’s relatives, friends or associates.

FINRA abides by the requirements of 41 CFR 60-741.5(a). This regulation prohibits discrimination against qualified individuals on the basis of disability, and requires affirmative action by covered prime contractors and subcontractors to employ and advance in employment qualified individuals with disabilities.

FINRA abides by the requirements of 41 CFR 60-300.5(a). This regulation prohibits discrimination against qualified protected veterans, and requires affirmative action by covered prime contractors and subcontractors to employ and advance in employment qualified protected veterans.

©2020 FINRA. All rights reserved. FINRA is a registered trademark of the Financial Industry Regulatory Authority, Inc.","FINRA
3.5","Philadelphia, PA",Brokerage Services,Finance
Data Analyst,"Philadelphia, Pennsylvania
Skills : agile,data analysis,system analysis,sql,aws,s3,athena,redshift,glue,communication
Description : Analyze data from a particular business domain and define how best to organize it in support of Group's cloud data architecture runway

Work with stakeholders to understand the domain's functional and data requirements

Work with stakeholders to identify use cases for data consumption

Support Data Architecture by rationalizing redundant data and developing the approach building out the Group cloud data-warehouse and analytics platforms

Support broader architecture teams in defining a business domain's master data management approach

Define and document the Data Lineage for a business domain

Skills:

7+ years of experience working in the Data or Systems Analysis field

Strong SQL skills and knowledge of various database types and technologies

Familiarity with relevant data-related AWS services (S3, Athena, Redshift, Glue, etc..)

Knowledge and Experience working in a Scaled Agile Framework

Excellent collaboration and teamwork skills

Excellent written/verbal communicationsagile,data analysis,system analysis,sql,aws,s3,athena,redshift,glue,communication","Collabera
4.1","Philadelphia, PA",IT Services,Information Technology
Data Analyst,"Position Summary:

The Data Analyst will be responsible or researching, collecting data and performing statistical analysis needed to monitor trends and patterns. This position will distribute and monitor data analysis projects, support staff in overcoming barriers in their projects and review the accuracy and reliability of data analysis projects.

The Data Analyst is also required to have an advanced understanding of the function and utilization of queries and data tables. This position will take primary responsibility for getting the data right, managing and preparing data for web applications, reports, graphs, charts and Business Intelligence tools. Candidates must be able to organize raw data, produce actionable insights and effectively communicate this information through data visualizations and messaging.

The Data Analyst will work closely with the PMHCC IT Application Programmers Assigned to PMHCC Case Management and will perform several responsibilities at the request of the Programming staff.

Duties and Responsibilities:
• Consult with arid serve as the interface for the purpose of insuring coordination of information systems planning between PMHCC Case Management, the PMHCC Information Services Department, the PMHCC Finance/Administration Department and the Legal and Compliance Officer
• Gather requirements for new enhancements as needed, from the above entities as they pertain to business processes, data collection and reporting and communicating this information to the Programming team so they may code the information system application
• Perform User Acceptance Testing (UAT) of all application changes, fixes or enhancements and involve staff in the Case Management department in UAT as needed
• Act as the first point of contact for any information system application issues or problems; investigate if it is a system wide issue or specific to a user and communicate/create tickets for the Programming team to investigate and fix or provide recommendations to issues.
• Set priorities based on input and feedback from Case Management executive team on any new enhancements to the information system application and communicate/manage the priorities with the Programming team
• Organize data generated and manipulate data received through research into reports that is easily readable and demonstrates findings legibly
• Distribute and monitor data analysis projects; support staff in overcoming barriers in their projects and review the accuracy and reliability of data analysis projects
• Conduct analytical and statistical research; make recommendations on data collection and analysis methods to ensure data is reliable and understandable; synthesize and interpret information, translate quantitative and qualitative data into visuals and reports for varying audiences
• Prepare comprehensive reports, graphs and tables; track and report on key performance indicators for the department: using an array of reporting tools including business intelligence applications
• Support ad-hoc analytic requests; providing accurate and timely data, analysis and insightful interpretations
• Interpret data, analyze results using statistical techniques and provide ongoing reports
• Identify and gather appropriate information to remove gaps in data (missing, incomplete, inaccurate, etc.)
• Provide continued training to Case Management staff on the information System Application, new features and/or enhancements
• Train the executive team on the use of any ad-hoc reporting tools of business intelligence tools
• Initiate research projects that are data-driven, which directly address questions from Case Management staff and external partners

Skills Required:
• Ability to translate complicated data into useful information
• Advanced experience with SQL; authoring pipelines via SQL
• Advanced understanding of Excel
• Advanced understanding of queries and data tables
• Excellent quantitative and data analysis skills
• Advanced understanding of data management and storage infrastructures
• Ability to initiate and drive projects to completion with minimal guidance
• Ability to build key data sets to empower operation and exploratory analysis
• Strong analytical skills with the ability to collect, organize, analyze and disseminate significant amounts of information
• Extremely strong attention to detail and accuracy
• Knowledge of statistics and experience using statistical packages for analyzing large data-sets (Excel, SAS, SPSS)
• Excellent written and verbal communication skills with the ability to collaborate and work with others; share information in a clear arid concise manner
• Ability to prioritize and respond to requests with speed and agility
• Proficiency in critical thinking and usage of problem-solving skills
• Ability to perform complex statistical analysis
• Proficiency in using computer software packages to manage and produce data such as tables, maps and/or graphic displays
• Excellent written analysis and oral presentation skills
• Ability to write queries to extract data for reporting or information requests
• Experience with Microsoft Power BI is a plus

Education and Experience:
• Bachelors decree in Information Management, Statistics, or a related field of study is required
• Experience in a technical field performing data analytics, modeling and statistical analyses
• Familiarity with health data, HIPAA is a plus
• Familiarity with social work or case management organizations is a plus
• At least two (2) years or experience with SQL database queries and reporting
• At least two (2) years or experience in a technical field performing data analytics, reporting, modeling and statistical analyses

Equal Opportunity Employment:
PMHCC, Inc. is committed to equal opportunity. It is our policy to support equal employment for all employees and applicants without regard to race, religion, color, sex, sexual preferences, age, national origin, disability, behavioral health status, military status or any other characteristic protected by law.

Americans with Disabilities Act:
Employees as well as applicants who are currently, or become disabled, must be able to perform the functions of the job with either reasonable accommodation or unaided. PMHCC, Inc. will examine reasonable accommodations on a case by case basis in accordance with the law.","PMHCC Inc.
2.4","Philadelphia, PA",Health Care Services & Hospitals,Health Care
Data Analyst,"Data Analyst

Responsibilties:
Analyze data from a particular business domain and define how best to organize it in support of Group's cloud data architecture runway
Work with stakeholders to understand the domain's functional and data requirements
Work with stakeholders to identify use cases for data consumption
Support Data Architecture by rationalizing redundant data and developing the approach building out the Group cloud data-warehouse and analytics platforms
Support broader architecture teams in defining a business domain's master data management approach
Define and document the Data Lineage for a business domain
Required Skills:
7+ years of experience working in the Data or Systems Analysis field
Strong SQL skills and knowledge of various database types and technologies
Familiarity with relevant data-related AWS services (S3, Athena, Redshift, Glue, etc..)
Knowledge and Experience working in a Scaled Agile Framework
Excellent collaboration and teamwork skills
Excellent written/verbal communications
Bachelorts or higher in relevant field
For more information please contact Mark Reilly at 908-758-5602 ext 206 or mreilly@itechsolutions.com

Since 1995, iTech Solutions Inc., has been providing IT Consulting and Direct Hire Services to the Insurance, Financial, Communications, Manufacturing and Government sectors with local offices in Connecticut, Minnesota, Colorado, Massachusetts, Tennessee, North Carolina, and New Jersey / Pennsylvania area.

Our recruiting strategy is simple, if you want to find qualified IT professionals then use IT professionals to find them. So at iTech Solutions, our personnel are all career IT professionals with a wide range of IT experience. We can honestly say our staff understands the technologies, the complexities of finding and selecting the appropriate personnel and the pressures of running successful IT projects.

Employer will not sponsor applicants for any employment visas, at hiring or in the future, including but not limited to H-1B visas. Corp-to-Corp or subcontract personnel will not be considered for this position.","Ampcus Incorporated
3.9","Philadelphia, PA",Consulting,Business Services
Data Engineer,"Slyce is the market leader in the emerging technology of image recognition and visual search. Over the past few years, we've been busy raising capital, growing our team, and signing deals with 25+ of the leading retailers in the US including Home Depot, Bed Bath & Beyond, Neiman Marcus, and Macy's. We are a close-knit team with ambitious goals and we're excited to drive our cutting-edge technology further into the marketplace and have fun doing it.

Our technology allows consumers to submit a photo or scan an image using their mobile device and Slyce will recognize what it contains and match it to products sold by retailers that have integrated our technology. The focus of our approach is to take our core services and white label our technology into retailers' apps and mobile web. We also drive experiences with our core consumer apps, including SnipSnap, which reaches more than 5 million monthly users.

About the role
On a typical day, you may work on a new feature, develop a new algorithm, help construct a dataset, discover and fix a software bug, message a customer to understand the problem they're trying to solve, or improve your team's tools. PS: There is no typical day.
You will perform data and concrete analysis with human intuition, build data pipelines and develop tools to enable machine learning models to learn from data.
As you get to know our existing data streams and customer goals, you will recommend new types and methods of data collection, new ways to process data, and discover new patterns between many different types of data that provide value to customers.
As you get to know our existing data streams and customer goals, you will recommend new types and methods of data collection, new ways to process data, and discover new patterns between many different types of data that provide value to customers.
You will regularly deploy solutions to enable the team to release small, frequent iterations to customers via mobile apps, the web, and embedded systems.
Effective communication is extremely important. You will work with a diverse array of people, both inside and outside of Slyce to create the best products and solutions possible.
About You
MS in Computer Engineering, Computer Science, Electrical Engineering or equivalent practical experience.
Proficient in Python, C/C++ or Rust
Deep understanding of software systems fundamentals
You are actively interested in developing and deploying AI on a fleet of devices to improve people's shopping experience.
Experience with or exposure to creating highly available, scalable, low-latency, global systems.
A track record of pursuing self directed side projects, research, or open source projects.
Innate curiosity and a desire to explore solutions in a small, highly focused team.
You take pride in your work and ownership of the solutions you build.
Technologies we use:
Python, C++, Rust
Javascript, React, Angular-JS
TensorFlow, TensorRT
MySQL, MongoDB, Kafka, Kubernetes
AWS, GCP","Slyce
3.5","Philadelphia, PA",Enterprise Software & Network Solutions,Information Technology
Data Analyst,"Job Description


Job #: 1076450

Role: Systems Analyst

Location: Philadelphia, PA

Duties:
Analyze data from a particular business domain and define how best to organize it in support of Group's cloud data architecture runway
Work with stakeholders to understand the domain's functional and data requirements
Work with stakeholders to identify use cases for data consumption
Support Data Architecture by rationalizing redundant data and developing the approach building out the Group cloud data-warehouse and analytics platforms
Support broader architecture teams in defining a business domain's master data management approach
Define and document the Data Lineage for a business domain
Skills:
7+ years of experience working in the Data or Systems Analysis field Strong SQL skills and knowledge of various database types and technologies
Familiarity with relevant data-related AWS services (S3, Athena, Redshift, Glue, etc..)
Knowledge and Experience working in a Scaled Agile Framework
Excellent collaboration and teamwork skills
Excellent written/verbal communications
Education: Bachelors or higher in relevant field

***THIS PERSON MUST BE ABLE TO SIT ON APEX SYSTEMS W-2 WITHOUT SPONSORSHIP***

If interested, send resume to mfetterolf@apexsystems.com

EEO Employer

Apex Systems is an equal opportunity employer. We do not discriminate or allow discrimination on the basis of race, color, religion, creed, sex (including pregnancy, childbirth, breastfeeding, or related medical conditions), age, sexual orientation, gender identity, national origin, ancestry, citizenship, genetic information, registered domestic partner status, marital status, disability, status as a crime victim, protected veteran status, political affiliation, union membership, or any other characteristic protected by law. Apex will consider qualified applicants with criminal histories in a manner consistent with the requirements of applicable law. If you have visited our website in search of information on employment opportunities or to apply for a position, and you require an accommodation in using our website for a search or application, please contact our Employee Services Department at employeeservices@apexsystemsinc.com or 844-463-6178.","Apex Systems
3.8","Philadelphia, PA",Staffing & Outsourcing,Business Services
Data Analyst,"Data Analyst Job Summary

We’re looking to add a detail-oriented, methodical, and collaborative data analyst to our growing team of driven professionals. As a data analyst, you will play a key role in our organization. Your primary goal will be to leverage data and communicate your findings to help us make smarter, data-backed business decisions.

Business Analyst Duties and Responsibilities
Analyze financial and business status by collecting, monitoring, and studying data.
Identify trends in business performance and provide recommendations for improvement.
Analyze current and past business/financial data and performance and establish and evaluate profit plans.
Prepare reports and projections based on this analysis to provide financial models and forecasts
Responsible for design, development and implementation of a robust system to collect, cleanse and analyze data from various systems and databases.
Work on engineering and analytical tasks to develop statistical models to enhance business decision making and meet business KPIs
Work on business intelligence tools such as Tableau to present business insights to management through data visualization.
Big data handling and retrieving for historical purchase and sale transactions of all the cities and regions.
Develop incorporate machine learning algorithms using Python based on market trend, operational and other global factors.
Tools and technologies utilized: Python, R, SQL, Tableau, Pandas, Spyder, Jupyter Notebook, R studio, QlikView, KNIME, ETL.
Business Analyst Requirements and Qualifications
Bachelors Degree desired.
Expert-level analytical and financial modeling skills.
Strong presentation skills, and the ability to influence and persuade others. Communication skills with the ability to distill complex subjects to a wider audience.
Knowledge of ERP systems and related technologies.
Excellent time management and organizational ability.
Ability to multitask and consistently meet deadlines.
Ability to identify useful information in data sets and suggest conclusions that support decision making.
Understanding of data gathering, inspecting, cleansing, transforming, and modeling/diagramming techniques.
Excellent leadership, collaboration, and project management skills.
Keen attention to detail.
Willingness to make decisions and solve problems.
About EMR

EMR's presence in America has increased over recent years with organic growth accelerated by strategic acquisitions in key locations. We have coverage in more than 20 states with almost 2,000 employees spread across these sites. Our American operations form a crucial part of EMR's international activities.

Our core business is the recycling of metal from a range of sources such as End-of-Life vehicles/consumer products, industry, construction and demolition. We have extensive ferrous and non-ferrous operations worldwide and produce over 100 grades of high quality recycled materials which are taken to market by our substantial road, rail and shipping network.

Supporting our core activities are a range of specialist divisions including industrial clearance, total waste management, ship breaking, servicing local government service providers and cable, copper and aluminum granulation facilities. Also, through our own and our joint venture activities we are working towards becoming a zero waste company.

Job Type: Full-time

Pay: $60,000.00 - $80,000.00 per year

Benefits:
401(k)
401(k) Matching
Dental Insurance
Health Insurance
Life Insurance
Paid Time Off
Vision Insurance
Schedule:
Day shift
Monday to Friday
This Company Describes Its Culture as:
Detail-oriented -- quality and precision-focused
Aggressive -- competitive and growth-oriented
Outcome-oriented -- results-focused with strong performance culture
Company's website:
www.emrgroup.com
Benefit Conditions:
Waiting period may apply
Work Remotely:
Temporarily due to COVID-19","Eastern Metal Recycling
3.5","Camden, NJ",Metals Brokers,Mining & Metals
Data Analyst,"Tandigm Health, LLC is a value-based population health organization. We engage our physician network by aligning economics and rewarding them for the value of the care they provide rather than for the volume of services. We enable our physicians with innovative tools, actionable data, expert training and education, and clinical delivery support. We empower our physicians by building community-oriented care delivery systems that facilitate collaboration across the continuum of care.

At Tandigm, you will find a culture where all Teammates have the opportunity to collaborate in an energized, multi-disciplinary work environment focused on improving patient outcomes and enabling our staff to do some of the most rewarding work of their careers.

SUMMARY

The Tandigm Health Data Analyst works with on a variety of projects with stakeholders from across the company to help them answer critical business questions and build information assets to support their operational needs. They analyze medical and pharmaceutical claims data sets to discover pattern, test assumptions, and uncover new opportunities. The Data Analyst gathers requirements; designs new reporting packages; creates technical specification documents; helps write the necessary SQL code; and deploys and maintains these assets. They are responsible for insuring data quality and appropriate data use to comply with HIPAA (Health Insurance Portability and Accountability Act) regulations.

ESSENTIAL FUNCTIONS

· Consistently exhibits behavior and communication skills that demonstrate Tandigms commitment to superior customer service, including quality, care, and concern with each and every internal and external customer.

· Apply critical thinking skills to analyze large data sets to detect patterns and identify trends.

· Work closely with colleagues to understand their objectives, refine requirements, and design reports/dashboards that provide them the business insight to support their goals.

· Write, deploy and maintain SQL code and other database objects.

· Identify data issues and work with various partners and vendors to resolve these issues.

· Comply with HIPPA (Health Insurance Portability and Accountability Act) regulations when using and reporting PHI (Protected Health Information).

· Performs additional duties as assigned.

EDUCATION:

· Bachelors degree in Computer Science, Epidemiology, Information Management, Mathematics, Statistics or related field

EXPERIENCE:

· Demonstrated experience querying databases with SQL

· Demonstrated experience writing database stored procedures

· Demonstrated skills in SSIS, SSRS

KNOWLEDGE, SKILLS, ABILITIES:

· Health care industry background desirable

· Experience in data modeling (Enterprise Architect preferred)

· Familiarity with databases (SQL Server preferred)

· Experience designing and building charts/dashboards/reports with data visualization software (Tableau preferred)

· Experience applying statistical analysis to large datasets with BI software desirable (R preferred)

· Ability to work independently on various simultaneous initiatives.

· Ability to produce high quality work products on time.

· Excellent written and verbal communication skills.

Tandigm Health is an Equal Opportunity Employer (EOE)","Tandigm Health LLC
4.2","West Conshohocken, PA",Health Care Services & Hospitals,Health Care
Data Scientist,"Our Data Scientist is responsible for in-depth analysis of data across QVC and HSN leading to actionable insights and recommendations. This usually involves statistical and non-statistical modeling, simulations, optimization, and A/B testing.

Relevant areas include consumer behavior, customer journey, e-commerce, television, marketing, and operations. Example projects include marketing mix optimization, airtime optimization, price elasticity estimation, and direct-response marketing targeting and effectiveness measurement.

Job Description Details

What you’ll do:
Construct analytic data sets for exploration, modeling, insight generation
Conduct in-depth data analysis, data and prepare visualizations summarizing key features of the data
Develop accurate models for forecasting and inference
Develop test designs, hypotheses, success metrics, and test requirements, and execute test analysis
Work with stakeholders to define business questions and success criteria
Present results and consult the business on next steps
Conduct change management for new methodologies
Research best practices, technologies, tools, and trends
Guide and mentor other analytics team members (Center of Excellence)
Work with IT on productionalization, data accuracy
Develop novel techniques or maintain legacy codes when needed
Who you are:
Advanced degree (Master’s/PhD) in Statistics, Economics, Computer Science or other quantitative discipline
Expertise in various statistical methodologies such as regression analysis, cluster analysis, decision trees, factor analysis/principal component analysis, time series, survival models
2+ years experience in data integration with SQL
2+ years experience in statistical programming in SAS (strongly preferred) and/or R, Python
Experience in data visualization and exploration tools (Tableau preferred)
Strong statistical knowledge and knowledge of test design
Experience distilling and presenting complex concepts to a business audience
2+ years experience using web analytics programs such as Coremetrics (preferred) or Google Analytics
2+ years experience using A/B and Multivariate testing tools; experience with A/B testing analysis preferred
Experience at a B2C e-commerce company a plus
#LI-CF1

About QVC, Inc

QVC, Inc., exceeds the expectations of everyone we touch by delivering the joy of discovery through the power of relationships. Every day, in nine countries, QVC engages millions of shoppers in a journey of discovery through an ever-changing collection of familiar brands and fresh new products, from home and fashion to beauty, electronics and jewelry. Along the way, we connect shoppers to interesting personalities, engaging stories, and award winning customer service. Based in West Chester, Pa. and founded in 1986, QVC has more than 17,000 employees and has retail operations in the U.S., Japan, Germany, United Kingdom, Italy, France, and through a joint venture in China. Worldwide, QVC engages shoppers on 14 broadcast networks reaching approximately 370 million homes, seven websites, and 220 social pages. Visit corporate.qvc.com to learn more.

QVC, Inc., is a wholly owned subsidiary of Qurate Retail, Inc. (NASDAQ : QRTEA, QRTEB), which includes QVC, HSN, zulily and the Cornerstone brands (collectively, \""Qurate Retail Group\""), as well as other minority investments. Qurate Retail Group believes in a third way to shop -- beyond transactional ecommerce or traditional brick-and-mortar stores -- and is #1 in video commerce,#3 in ecommerce in North America and #3 in mobile commerce in the U.S. (according to Internet Retailer). For more information, visit www.qurateretailgroup.com. QVC, Q, and the Q Ribbon Logo are registered service marks of ER Marks, Inc.

EEO

As an equal opportunity employer, Qurate Retail Group is committed to a diverse workforce and is also committed to a barrier-free employment process. In order to ensure reasonable accommodations for individuals pursuant to applicable law, individuals that require accommodation in the job application process for a posted position may contact us at CareersUS@QVC.com for assistance.

Click Apply and log in with your existing account or create an account. This will allow you to check the status of your application at any time and receive the most up to date communications from our Talent Acquisition team.","Qurate Retail Group
3.6","West Chester, PA",Other Retail Stores,Retail
Data Analyst,"Required:
Knowledge of referential and large data formats and file structures
Knowledge of databases, including big data technologies
Knowledge of programming and SDLC
Knowledge of Metadata tagging, data classification, and defining business and technical metadata
Ability to convey complex concepts to business stakeholders in terms relevant to the business
Excellent written and verbal communications skills
Excellent data analysis skills
Organized, structured, methodical
Analytical with strong problem-solving ability
Strong prioritization and time management skills
Experience with these is a must:
Strong Python and Spark
Hadoop and/or Big data solutions
Oracle, PL/SQL, Teradata
Should have Data lineage experience
Exposure to AWS and/or Cloud environments
Should have been a developer in past
Good understanding on Code Repositories like GIT","Techligent
3.3","Philadelphia, PA",IT Services,Information Technology
Machine Learning Engineer,"Nearly one in two households in the U.S. struggles to handle an unexpected expense of $400 or more. When it comes to managing household expenses, things like a broken appliance or a growing family can be financially burdensome. We're a collaborative team of creative problem-solvers on a mission to make life's purchases more accessible and affordable. Located in the heart of vibrant Philadelphia, we're building a FinTech-enabled e-commerce marketplace that combines quality brands with sensible financing to improve the lives of our neighbors and communities.

Position Overview

We are looking for engineers to help build our machine learning platform in a fast-paced, entrepreneurial environment. As a member of the Engineering Team, you will design, implement, and ship new ML solutions at scale that will be used by data scientists and engineers within our Product Team. Applicants should be highly motivated and comfortable with taking on and adapting to a diverse array of subject matter. This opportunity is both unique and pivotal, as it provides the chance to join a rapidly-growing team that delivers software products that are experienced by millions of people.

Initial Responsibilities
Utilize deep technical knowledge of machine learning, recommendation systems, data engineering, and software engineering principles to build machine learning solutions and workflows
A passion for making these methods scalable, reproducible and easy-to-use
Providing guidance on transitioning prototypes and experiments to performant, production models
Leading architectural decisions and tool selection in order to deliver platform features
Contributing to our team's commitment to testable, readable, and well-organized code
Clearly communicate trade-offs between schedule, resources, model performance etc.
Work on projects of growing responsibility, both individually and as part of a team, to build experience and skills at a pace matched to your shown ability
Learn more about the industry and Perpay, establishing a solid foundation to be better positioned for long-term career success
Basic Qualifications
Bachelor's degree or higher in a quantitative/technical field (Computer Science, Engineering)
Creative, collaborative, and product focused
Minimum 2+ years work experience in related field required
Strong working knowledge of SQL/NoSQL, relational databases and Python is required (2+ years experience)
Industry experience in algorithm design and implementation, codebase management and code generalization
Experience delivering complex engineered features for real-time prediction systems
What We Offer:
Competitive salary + equity
Health/dental/vision insurance fully covered
401K + company match
Gym + public transportation subsidy
Relocation assistance
Centrally located in downtown Philadelphia in a beautiful loft-style office with an espresso machine and office pup (Kingsli)
We don't work with external recruiting agencies, please contact us or apply directly!",Perpay,"Philadelphia, PA",-1,-1
Data Analyst,"Location Camden, NJ Salary 50 Description Our client is currently seeking a Data Analyst Someone with a food science product development background is most preferred. Will be trained on Optiva strong data accuracy, strong in Excel Will work remote and manager and manager wants someone to be in the EST or CST timezones only. The work hours are Mon-Fri 9am-5pm This is a non-IT technical role within the Campbell Americas RD Product Data Management (PDM) group leading the product document translation for finished product commercialization and quality initiatives, managing critical product formulation information as it is transferred from the kitchen to the manufacturing facility. This position establishes and documents technical standards related to product formulation management for successful scale up and manufacture. Team members in this role are also responsible for technical documentation in systems such as the Optiva Product Lifecycle Management (PLM) system, SharePoint, and an Electronic Notebook system. Working in close collaboration with internal subject matter experts in Product Development, Packaging, Quality, Regulatory Affairs, Supply Chain and Nutrition. Projects are of moderate to high complexity and technical risk. Apply food sciencetechnical knowledge to translate Product Development kitchen batch formulations to plant-ready formatted formulations, using a set of standards dictated by type of formula (e.g. retort soup, aseptic broth, hot fill beverage), specific manufacturing location requirements and unitized plant operations. - Systematic build of formulas, procedures and specifications in the Optiva Product Lifecycle Management system as required to ensure that products can be manufactured properly and according to specifications and can integrate with SAP RMS plant floor systems. - Work collaboratively as a core member of multiple product commercialization business teams, independently managing all product documentation requirements as needed to meet project timelines. - Ensure all technical documentation is bundled to deliver the full manufacturing requirements formula, procedure, kitchen batch sheet, formula change notes, cost and extend SAP requirements, item specifications and some packaging requirements. Minimum education required BS Degree in a Science based field, Computer Science acceptable - Years of relevant experience 2-3 years - Excellent written and verbal technical communication skills, along with strong collaboration skills. - Demonstrate analytical thinking, problem solving and decision-making skills. - Proficient at independent planning and prioritization. - Strong computer skills including fluency in Microsoft Office (especially Excel), and database management. Ability to quickly become proficient in all relevant software systemsapplications such as Optiva PLM and SharePoint. Contact kzywalewskijudge.com mailtokzywalewskijudge.com?subjectData20Analyst20 This job and many more are available through The Judge Group. Find us on the web at www.judge.com httpwww.judge.com","The Judge Group, Inc.
3.5","Camden, NJ",Staffing & Outsourcing,Business Services
Data Analyst,"What if you could...

Use your refined analytical skills to interpret complex data to increase performance and engagement within multiple business lines, while also maintaining individual autonomy and flexibility?

Work with other Data Analysts, Data Scientists, Data Engineers, and DBAs to design, develop and execute high-impact analytics solutions for large, complex, structured and unstructured data sets (including big data) to help the business make better fact-based decisions?

Be a catalyst for change in helping to analyze business trends to understand and recommend optimization strategies which will effectively increase company service level and revenue?

Find opportunities to create new reporting methods and implement solutions which can dynamically transform company service delivery methods while improving stakeholder and end-user experience?

If you're our next Data Analyst, you would look forward to engaging in activities such as:
Utilizing business systems and tools such as BOE or BI to mine and analyze data across multiple data sources, generating business insights and identifying opportunities for improvement
Leverage quantitative skills to gather necessary data sets, formulate and conduct analyses with that data to provide teams with key insights on business analytics and business operations support
Creating analytics and KPI's to help stakeholders track their progress toward individual and group goals as they monitor their impact
Crafting robust numerical reports and visual dashboards that enhance decision making processes and create actionable outcomes
Working with data scientists to help enhance the efficacy of our analytic models
Working with a data engineer to prioritize data sets for ingestion into the data lake and partner with the Data Scientists to commercialize/operationalize AI/ML solutions
If you're our next Data Analyst, your journey up to this point will likely have included:
Advanced modeling in Excel, dashboard development and data visualization via PowerBI, and SQL ELT
Creating service analytics that enable others to identify optimization and financial improvements opportunities in key business areas
Communicating data results to others, with an emphasis on answering business questions and developing clear visual analytics that tell a compelling and insightful story, not just reading a report
Solid technical understanding of machine learning principles, big data/advanced analytics concepts and algorithms (e.g. text mining, recommender systems, predictive modeling, etc.)
Supporting customer experience teams through analytics by providing key data insights and strategic approaches to improve processes and drive business improvements
Using relevant data from industry, competitors, and customer behavior trends to effectively inform best practices that enable enterprises to make smart, data driven decisions
Proficient understanding of the development, testing, maintenance, and application of artificial intelligence (AI), machine learning (ML) and visual analytics
Here is a little bit more about us:

Voice Systems Engineering, Inc. (VSE) pioneers technologies and builds brands that foster beneficial impact through direct personal connections. Our lines of business provide people with expert advice and care at the right time to help optimize positive emotional and psychological experiences.

There are some serious perks to work with us. We are headquartered in Feasterville-Trevose, Philadelphia although we are fully enabled for remote work. Our management process is built for high collaboration and innovation, we have an unlimited vacation policy, flexible work hours, an on-site gym, dog friendly, yoga and fitness classes, and a ton of social opportunities. Want to join forces?

We offer a comprehensive benefits plan including:
Medical/Prescription/Vision
Dental/Orthodontia
Company paid group life and disability insurance
Retirement Savings Plan 401(k) with company match
Tuition reimbursement
Health & Wellness reimbursement
VSE is an Equal Opportunity Employer, apply to learn more!","VSE, Inc.
4.1","Feasterville Trevose, PA","Cable, Internet & Telephone Providers",Telecommunications
Data Engineer,"The Philadelphia District Attorneys Office (DAO), led by District Attorney Larry Krasner, is committed to the mission of providing fair and just prosecution to all Philadelphians. DA Krasner believes that justice is best achieved through policies grounded in research, data, and science. Holding true to these commitments, the DAO has improved its capabilities to process data, craft policy, and conduct research. As we continue to modernize a progressive and fast-paced office, we aim to be responsive, forward thinking, and collaborative.

The Data Engineer will join an innovative team of researchers, lawyers, analysts, and software engineers in the development and deployment of applications to support prosecution, analytics, data-driven policy, and public transparency. They will support DA Krasners targeted areas for informed reform, including charging, diversion, sentencing, focusing on the most serious crimes, preventing violence, enhancing harm reduction, and ameliorating disparities in the criminal justice process. The Data Engineer will work with both the development and research and analytics teams to create tools to help transform and structure our data to help developers and analysts to access our data quickly, accurately, and efficiently. The Data Engineer will be expected to:
Build and maintain the DAO data warehouse to house both internally created data, administrative data, and other data from external partners about the criminal justice system and the welfare of individuals associated with the criminal justice system.
Create and build tools and libraries, to help our developers and analysts query the data warehouse expertly
Maintain a cloud-based development environment for a team of analysts to work in
Evangelize and educate teams across the DAO on standard methodologies around data services development, data privacy and security, as well as improving efficiency
Help the DAO improve our data operations by automating manual processes, optimizing data storage and delivery, re-designing infrastructure for scalability
Work with our DATA Lab to enable and optimize their data and data services usage
Qualifications

A Bachelors or Masters degree in Computer Science, Software Engineering, Mathematics or related technical discipline is preferred, but not required. Additional years of experience exceeding the minimum requirement as well as a proven track record of work may stand in for a degree. The preferred candidate will also have or demonstrate:
Ability to professionally deal with changing environments, be self-directed; and given broad direction, be able to prioritize work and allocate time and resources effectively;
Experience with or knowledge of: web application security concerns and solutions to mitigate those concerns;
Familiarity with Bitbucket, Git, or similar version control systems;
Experience with developing and maintaining custom and non-proprietary software based data platform infrastructure services
Experience with a systems language such as C, C++, C#, Go, Java or Scala
Experience with a scripting language such as Python, PHP, or Ruby
Experience developing data solutions using storage platforms like S3, Cassandra, Hbase, and using data warehouse systems like Snowflake, Redshift, Cosmos DB, or BigQuery
Experience developing applications and solutions using data ecosystem components such as Spark, Flink, Solr, Redis, InfluxDB, Elasticsearch
Experience working with cloud services such as AWS, Google Cloud, Azure
Experience with building and integrating logging, alerting, and monitoring as an integral part of data platform services
Enthusiasm to collaborate, innovate, and solve problems;
A proven ability to prioritize work in a team and independently, and handle multiple complex tasks simultaneously;
Experience working in the legal field/with attorneys and a knowledge of the criminal justice system are both a plus.","Philadelphia District Attorney's Office
3.6","Philadelphia, PA",Municipal Governments,Government
Machine Learning Engineer,"OverviewPenn Interactive Ventures (PI) is a real-money interactive gaming company headquartered in Philadelphia. As the digital arm to Penn National Gaming (NASDAQ: PENN), the largest regional casino operator in the U.S., we are poised for fast-paced growth in the sports betting and online casino space and are looking for a Machine Learning Engineer to join our expanding Sportsbook team!The machine learning engineer will design and develop tools and processes to collect, clean, analyze and monitor player and market data in an effort to provide actionable customer insights. You will work with data scientists to fuel quality decision making across all teams at the company. This role will focus on the aspects of machine learning model creation having to do with producing well-crafted, production-grade software: RESTful API creation, error collection, monitoring, process automation, CI/CD.Your daily responsibilities include* Work closely with our Product Managers to understand features/game performance* Work closely with data scientists to tune models and bring them to production* Automate and productize reporting to increase analytical efficiency* Automate machine learning model creation and hypothesis testing* Improve experiment design and analysis to test user behavior hypotheses* Perform exploratory analyses to better understand our users* Build predictive models to predict migrations in player lifecycle* Produce actionable insights from quantitative and qualitative dataTo be successful in this position it will require the following skill set* BS/MS degree in a quantitative discipline required (math, statistics, engineering, economics, physics and computer science, etc.)* 2 - 5 years of relevant analytics/data science experience or equivalent combination of education and experience.* An understanding of free-to-play game systems, economies, currencies & balance a big plus* An ability to embrace an environment that moves quickly, iterates rapidly and celebrates failure as much as success* Strong python skills a must.* Strong SQL knowledge and experience* Proficiency in R is a plus.* Foundational understanding of statistics and machine learningBONUS* Bayesian statistical inference, deep learning esp. sequence-to-sequence modeling, time series forecasting, natural language processing.Something to leave you withPenn Interactive is committed to helping our team members live their best, healthy life. We offer unique and competitive benefits that help our employees, through a private exchange which allows our team members the ability to choose from several coverage levels and insurance carriers (both local and national carriers). Along with medical, prescription, dental, and vision coverage, there are also voluntary plans available to employees. PI also offers our employees office perks such as free catered lunches, snacks, and beverages in the office.","Penn National Gaming
3.1","Philadelphia, PA",Gambling,"Arts, Entertainment & Recreation"
Data Engineer,"Data Engineer Location Philadelphia, PA 19139 Duration 6+ Months Initial 3 months remote, then 3 months onsite in Philadelphia, PA. Duties We are looking for a motivated Data Engineer who would help build data pipelines to ingest and transform the data into our Data platform (on-premcloud). Candidate should be passionate about Python coding. Job Responsibilities 1. Develop and enhance data pipelines, mostly batch (if necessary ""streaming"" processes) 2. Apply best approaches for large scale data movement, capture data changes and apply incremental data load strategies. 3. Build automated test pipelines to ensure data integrity and completion. 4. Identify and improve current data pipelines through automation and optimization. Skills Understand and comply with all enterprise and IS departmental information security policies, procedures and standards. Support the integration of information security in the development, design, and implementation of Hospital Technology Resources that process, transmit, or store CHOP information. Support all compliance activities related to state, federal regulatory requirements, healthcare accreditation standards, and all other applicable regulations that govern the use and disclosure of patient, financial, or other confidential information.","Digital Intelligence Systems, LLC
3.4","Philadelphia, PA",IT Services,Information Technology
Data Analyst,"Job Description
Job description
Interpret data, analyze results using statistical techniques and provide ongoing reports
Develop and implement databases, data collection systems, data analytics and other strategies that optimize statistical efficiency and quality
Acquire data from primary or secondary data sources and maintain databases/data systems
Identify, analyze, and interpret trends or patterns in complex data sets
Filter and “clean” data by reviewing computer reports, printouts, and performance indicators to locate and correct code problems
Work with management to prioritize business and information needs
Locate and define new process improvement opportunities
Requirements
Proven work experience as a data analyst or business data analyst
Technical expertise regarding data models, database design development, data mining and segmentation techniques
Strong knowledge of and experience with reporting packages (Business Objects etc), databases (SQL etc), programming (XML, Javascript, or ETL frameworks)
Knowledge of statistics and experience using statistical packages for analyzing datasets (Excel, SPSS, SAS etc)
Strong analytical skills with the ability to collect, organize, analyze, and disseminate significant amounts of information with attention to detail and accuracy
Adept at queries, report writing and presenting findings
Master's in Computer Science or Engineering Management or Project Management or Information Systems/Technology (Preferred)
Powered by JazzHR

9vIqzKWc9m","Staffigo Technical Services, LLC
5.0","Philadelphia, PA",IT Services,Information Technology
Data Analyst,"To continue our growth path, we need a Data Analyst who thrives working with large data sets to create & analyze reports & prove out multiple scenarios that support business decisions across all areas of the business. This is a highly impactful role as you’ll work across every step of the analytics process from problem identification, data gathering, and data cleansing, to developing thoughtful analysis and making presentation of findings.
The Turn5 business is built on using data – not opinions – to guide the path forward. Turn5 boasts industry leading business strategies. Those strategies come from smart people armed with the right data and analysts to challenge their thinking, provide insights & pounce on opportunities.
You will be challenged to work collaboratively across all departments to spread the use of data and knowledge to make better decisions throughout the company. One minute you might be using custom SQL code to build reports that help analyze a new data set, the next minute collaborating with our department leads to analyze KPI reports, and the next minute partnering with your peers to gather, cleanse and move data to maintain integrity. Regardless of the task, it’s critical you have strong situational awareness and EQ as you’ll work with diverse stakeholders across the organization.
If your passionate about data & analysis and want to work with people who believe in the power of analysis, join us!

Responsibilities
Year 1 is going to be about:
Discovering opportunities for improvement and provide recommendations for improvement within Turn5's strategy to drive incremental operational success
Working with team of Data Engineers to ensure performance reliability of dashboards and visualizations available via Tableau Server
Using custom SQL to improve data structure, optimize/automate data flow, and build custom reports
Collaborating with representatives from across Turn5's departments to contribute to analytics and data integration projects
Performing ad-hoc reporting analysis for all Turn5 business functions
Performing ad-hoc analysis to help predict performance or to assist future decisions
Managing our analytics project and ticketing system, ensuring the highest impact projects are prioritized and ensuring quality scoping of projects
Being presented with business problems and doing any required aspects (data identification, data cleansing, data movement, analysis, etc.) to figure out the cause and how to improve performance

Qualifications
We can’t skip over some of the specific skills and experience we know are a “must” to be successful. So, we need you to have:
BA/BS in IT, marketing, e-commerce, economics, mathematics, or other related degrees & at minimum 1-2 years of experience working in a similar capacity
BA/BS degree requirement can be substituted for 3+ years of related work experience
Excellent analytical skills: including being able to quality-assure, clean, and analyze large data sets to draw conclusions and propose recommendations
6 months - 2 years of experience with MS SQL Server 2012+
Comfortable with implementing basic statements for DDL (SELECT, INSERT, DELETE & MERGE).
6 months - 2 years of experience working in/moving data from Tableau, Google Analytics, or any other analytics platforms
Data centric experience working with various applications (OMS, WMS, etc.) implemented within an eCommerce setting would be a plus
Proficiency in Excel","ORS Partners
4.0","Paoli, PA",Staffing & Outsourcing,Business Services
Data Engineer,"Data Engineer in Philadelphia, PA 19103

Interview Logistics:

WebEx Interview

Required Skills Set:

Years of Experience:4+

Education Required:Bachelors Degree
BS/MS degree in Computer Science, Mathematics, or other relevant science and engineering discipline.
4+ years working as a software engineer.
2+ years working within an enterprise data lake/warehouse environment or big data architecture.
Excellent programming skills with experience in at least one of Python, Scala, Java, Node.js.
Great communication skills.
Proficiency in testing frameworks and writing unit/integration tests
Proficiency in Unix-based operating systems and bash scripts.
Additional Preferred Skills:
Experience with working in Spark
Experience with AWS
Experience with monitoring and visualization tools such as Grafana, Prometheus, Data Dog, and Cloudwatch.
Experience with NoSQL databases, such as DynamoDB, MongoDB, Redis,Cassandra, or HBase
Project Description:

Join a multi-disciplinary team of devops engineers, software engineers, data analysts, and data scientists working together to improve the user experience.

Do you likebigchallenges and working within ahighly motivatedteam environment?As a data software engineer on the Data Science and Engineering team within the organization, you will be part of a team that thrives onbigchallenges, results, quality, and agility. You will work closely with business stakeholders, data analysts, and data scientists within the organization developing software solutions helping to deliver insights into customer and network behavior that drive business decisions shaping the future of the company.

Who does the Data Engineer work with?

You will collaborate with a diverse set of professionals ranging from software engineers whose software integrates with analytics services, network architects and engineers who are tasked with evolving the network, service delivery engineers who provide support for our products, data analysts and data scientists distilling key insights from massive amounts of raw data, operational stakeholders with all manner of information needs,and executives who rely ondatafor fact-based decision making.

What are some interesting problems you'll be working on?

Develop large scale, cloud based data pipelines for the collection and processingof device telemetry and network events, providing both a real time and historical view into the operation of our products and services.Work on high performance, real time data stores and a massive historical data sets usingbest-of-breed and industry leading technology. Expose services over REST APIs. Work closely with various engineering teams to solve key optimization, insight and access network data challenges.

Where can you make an impact?

The Data Science and Engineering teamis acquiring, studying, simulating, and modeling to enable data as a key driver and core functional component toward better understanding, predicting, and dynamically optimizing the access network to improve overall user experience. Success in this role is best enabled by a broad mix of skills and interests ranging from traditional distributed systems software engineering prowess to the multidisciplinary field of data science.

Responsibilities:
Developing large scale data pipelines exposing data sources within the company to our team of data analysts and data scientists.
Developing REST APIs utilizing AWS lambda and API Gateway.
Developing Spark streaming and batch jobs to clean and transform data.
Writing build automation to deploy and manage cloud resources.
Writing unit and integration tests.
Some of the specific technologies we use:
Programming Languages (Python, Scala, Golang, Node.js)
Build Environment: GitHub Enterprise, Concourse CI, Jira, Serverless, SAM
Cloud Computing (AWS Lambda, EC2, ECS)
Spark(AWS EMR, Databricks)
Stream Data Platforms: Kinesis, Kafka
Databases: S3, MySQL, Oracle,MongoDB, DynamoDB
Caching Frameworks (ElasticCache/Redis)
Physical Environment and Working Conditions:

Must be able to work on site in Philadelphia after coronavirus restrictions are lifted.","Turnberry Solutions
4.6","Philadelphia, PA",IT Services,Information Technology
Data Analyst,"Direct HireData Analyst

The Data Analyst will be working with high volumes of data to support project needs. Your success is dependent on building a strategic partnership and becoming aligned with the operations and technology teams. We require a candidate with the motivation to succeed and a passion to excel. The candidate must be capable of rising to the challenge of working for a preeminent organization that serves national clients. As an industry leader, we expect our team to be willing to learn to accomplish their work with the highest operational excellence. You will work internally across departments and externally with clients and vendors, so it is imperative to always demonstrate the highest level of professionalism.

Responsibilities of the Data Analyst include:

Manipulate large amounts of data (mass insert, update, upsert, delete) either directly, using SQL statements or Excel, or through dedicated data management software Review project requirements and provide expert advice regarding the structure of databases and forms
Utilize data analysis and SQL skills to design and develop database queries, extract participant-level data from databases and analyze the data using a variety of analytical techniques
Generate and analyze data reports from internal and external sources
Research and data-mine as directed to retrieve data/status and develop/provide metrics as required
Collaborate in all aspects of the collection, verification and entry of data Perform data transfer functions by importing and exporting data to and from the SQL Server, or other sources Conduct quality control and auditing of databases in a client/server environment to ensure the accurate and appropriate use of data
Design workflows to control access to data and optimize the flow of information
Provide all activities related to the administration of databases
Provide data and analytical support for cases
Document guidelines for appropriate database usage, data maintenance, and key report processing
Monitor data management repositories and communicate documentation to team Support with organization, tracking, maintenance and validation of spreadsheets Develop a process and associated plan for the maintenance of existing reports, trackers, and documents for the creation, incorporation and maintenance of new reports Design, implement, and maintain complex databases with respect to access methods, access time, device allocation, validation checks, organization, protection and security, documentation, and statistical methods
Fully document all work and comply with development best practices
Participate in and conduct code reviews of both team and vendor-supplied code and determine quality, identify bugs and evaluate risks
Ensure architecture is consistent with organizational development standards and align with industry guidelines and best practices
Continually work towards strengthening industry knowledge and all relevant applications
Communicate regularly and effectively with all colleagues
Exhibit a very organized approached and superior attention to details
Meet regularly with managers to provide feedback and facilitate communication
Adhere to all business processes while performing tasks
Able to take on new tasks and responsibilities as needed
Perform other work-related duties as assigned by management

Requirements of the Data Analyst:

Bachelors(TM) degree in computer science, business or other related field or discipline
Database system(s) experience required
Complex data analytics experience required
LAW PreDiscovery "" LexisNexis experience preferred
SQL, advanced Excel (including VBA), data mining; prior coding experience constitutes an advantage
System implementation and system integration experience
Skilled in business analysis, process improvement, and project management
Minimum of 3-5 years of experience and a demonstrated track record of accomplishments
Aggressive problem diagnosis and creative problem-solving skills
Demonstrate a high degree of productivity while handling multiple tasks simultaneously
Ability to perform comfortably in a fast-paced, deadline-oriented work environment
Excellent written, verbal, communication, and research skills a must
Ability to be flexible to adapt and act quickly when urgent matters require it
Able to work effectively with diversified individuals of various ethnic backgrounds and professional
competencies
Project a positive, professional image toward clients, vendors, and staff in all interactions and situations
Maintain the highest level of confidentiality
Problem analysis and resolution skills at both a strategic and functional level
Excellent computer skills including all MS Office applications. (Word, Excel, Outlook, PowerPoint) required
Must be presently authorized to work in the U.S. without a requirement for work authorization
sponsorship by our company for this position now or in the future

#LI-DR1","Contemporary Staffing Solutions
4.4","Philadelphia, PA",Staffing & Outsourcing,Business Services
Data Analyst,"A leading Third Party Claims Administrator, located in Pittsburgh, PA, is seeking (2) Data Analysts for a 9+ month contract role. Summary The Senior Data Analyst position is responsible for MySQL data monitoring, enhancements and improvements deemed warranted by the compliance team and product manager. This role will serve as gatekeeper of the MySQL data and include automating of data conversions and procurement, interpretation and conversion of Medical Bill Review data as required by the needs of the data team. Responsibilities Applicationdata monitoring and improvements to enhance efficiency and productivity. Automation of data conversions. Work with the database assigned product manager and database infrastructure lead to implement changes aimed at efficiency and scalability. Procurement, interpretation and documentation of all data applicable to Medical Bill Review. (CMS Pricer, CMS APC, Physician Fee Schedules, Usual and Customary, Pharmaceutical, CPT, ICD9, etc?) Knowledge of state, federal and industry standard fee schedules, reimbursement methodologies and regulations, including but not limited to DRG, ASC, APR-DRG, OPPS and RBRVS Populating andor manipulating data in development, test and production environments. Work with software developers to implement changes defined by the State and Federal laws. Internal support and assistance to other members of the data team. Qualifications Knowledge of SQL and related database tools. Knowledge of Microsoft Access. Ability to work with the software development community. ExperienceEducation Six (6) years of related experience or equivalent combination of education and experience required. Experience in multi-line claims management processes and system requirements strongly preferred. Experience working in a relational database environment MySQL experience preferred Experience in the medical field necessary Detail oriented person desired","Login Consulting Services, Inc
3.8","Allegheny West, PA",Consulting,Business Services
Data Engineer,"Site Name: USA - Pennsylvania - King of Prussia
Posted Date: Jun 5 2020

As a Data Scientist, you will support process and product understanding & monitoring through the utilization of relevant data and quantitative methods; develop and implement solutions delivering insight to multiple stakeholders by application of Data Engineering and Data Science; and support standardization and alignment of data informatics related to process and analytical control strategies across GSK network.

This role will provide YOU the opportunity to lead key activities to progress YOUR career. These responsibilities include some of the following:
Position will support CPV (Continuous Process Verification) program for Biologics manufacturing process.
Position will support projects using analysis methods including classical and multivariate statistics and machine learning.
Performs routine administration and maintenance of Process Informatics computer systems and applications
Configures and maintains manual data entry forms and associated workflows for reviews/approvals/edits
Performs configuration updates and maintenance to analysis configurations & report configurations to support ongoing trending & monitoring
Executes testing to support validation for changes to GMP configurations/interfaces
Supports break/fix root cause analysis of issues identified with Process Informatics computer systems
Provide support to site stakeholders for development and deployment of reports and visuals with MS Power BI
Work in a way that models respect for safety and EHS, quality compliance, data integrity, and engineering standards.
Why you?
Basic Qualifications:


We are looking for professionals with these required skills to achieve our goals:
Bachelors in Data Science, Computer Science, Applied Statistics or equivalent technical discipline
3 years of relevant technical experience
Preferred Qualifications:


If you have the following characteristics, it would be a plus:
Experience in GMP environment
Experience with HTML
Experience with STATISTICA (or similar experience using SAS, JMP, Minitab, Discoverant, and/or SIMCA)
Experience with Aspen Manufacturing Suite software
General quantitative training and experience through an engineering curriculum or similar in college or self-study
Ability to automate data aggregation from multiple information systems
Ability to create Control Charts and determine process capability for process data
Ability to program using VBA
Experience creating visualizations using MS Power BI
Execute projects in change management environment
Experience with SQL and programmable SQL
Experience with design and implementation of databases objects: Database design and stored procedures
Why GSK?


Our values and expectationsare at the heart of everything we do and form an important part of our culture.

These include Patient focus, Transparency, Respect, Integrity along with Courage, Accountability, Development, and Teamwork. As GSK focuses on our values and expectations and a culture of innovation, performance, and trust, the successful candidate will demonstrate the following capabilities:
Operating at pace and agile decision-making using evidence and applying judgement to balance pace, rigour and risk.
Committed to delivering high quality results, overcoming challenges, focusing on what matters, execution.
Continuously looking for opportunities to learn, build skills and share learning.
Sustaining energy and well-being
Building strong relationships and collaboration, honest and open conversations.
Budgeting and cost-consciousness
If you require an accommodation or other assistance to apply for a job at GSK, please contact the GSK Service Centre at 1-877-694-7547 (US Toll Free) or +1 801 567 5155 (outside US).

GSK is an Equal Opportunity Employer and, in the US, we adhere to Affirmative Action principles. This ensures that all qualified applicants will receive equal consideration for employment without regard to race, color, national origin, religion, sex, pregnancy, marital status, sexual orientation, gender identity/expression, age, disability, genetic information, military service, covered/protected veteran status or any other federal, state or local protected class.

Important notice to Employment businesses/ Agencies

GSK does not accept referrals from employment businesses and/or employment agencies in respect of the vacancies posted on this site. All employment businesses/agencies are required to contact GSK's commercial and general procurement/human resources department to obtain prior written authorization before referring any candidates to GSK. The obtaining of prior written authorization is a condition precedent to any agreement (verbal or written) between the employment business/ agency and GSK. In the absence of such written authorization being obtained any actions undertaken by the employment business/agency shall be deemed to have been performed without the consent or contractual agreement of GSK. GSK shall therefore not be liable for any fees arising from such actions or any fees arising from any referrals by employment businesses/agencies in respect of the vacancies posted on this site.

Please note that if you are a US Licensed Healthcare Professional or Healthcare Professional as defined by the laws of the state issuing your license, GSK may be required to capture and report expenses GSK incurs, on your behalf, in the event you are afforded an interview for employment. This capture of applicable transfers of value is necessary to ensure GSKs compliance to all federal and state US Transparency requirements. For more information, please visit GSKs Transparency Reporting For the Record site.","GSK
3.9","King of Prussia, PA",Biotech & Pharmaceuticals,Biotech & Pharmaceuticals
Data Engineer,"Join a team of financial software specialists responsible for the acquisition and management of financial market and related data required for research implementation of systematic trading strategies.

Primary Responsibilities:
Implement robust solutions for adoption, storage and management of large volumes of data
Develop quality assurance systems in support of high integrity data sets
Assist quantitative analysts in crafting custom, bespoke data sets
Support timely and fault tolerant data systems in support of production trading algorithms
Meet tight deadlines in an efficient manner


Requirements of the Candidate include:
Bachelor’s degree in Computer Science or applicable degree and very strong exposure to programming and computer systems
Experience with Python and C++
Experience with data storage and manipulation using approaches such as HDF5, Pandas, and RDBMS/SQL
2+ years professional experience in data management role
The desire to work in a fast-paced, hardworking and committed environment with a talented team
Strong problem solving skills, critical thinking and clear written and verbal communications
Financial industry, market data and cloud data environment experience are beneficial","STEVENS CAPITAL MANAGEMENT LP
4.6","Radnor, PA",Financial Analytics & Research,Finance
Data Analyst,"Data Analyst Horsham, PA 19044

My client, a loan origination company in Horsham, PA is in need of a Data Analyst for a 9 month + contract to potential hire opportunity to help build out a new Data Warehouse.

Responsibilities include:

· Writing source to target mapping documentations

· Performing SQL queries

Qualifications include:

· 5 + years of data analytics experience

· Extensive SQL querying experience

· Expert level Microsoft Excel experience

· Understanding of Data Warehouse concepts
Dimensions
Fact Tables
Star Schema
· Strong analytical mind within data

· Detail oriented (this is vital work for the Data Engineering team)

· Strong communications skills in order partner with the business side

· Be able to pick apart the current Data Warehouse

Compensation Expectations:

· $50 - $60/Hour W2

· Full Benefits: Healthcare, Dental, Vision","Piper Companies
4.5","Horsham, PA",Staffing & Outsourcing,Business Services
Data Engineer,"Nearly half of U.S. households struggle to handle an unexpected expense of $400 or more. When it comes to managing household expenses, things like a broken appliance or a growing family can be financially burdensome. Ranked 5th on Inc. Magazine's annual list of fastest-growing private companies in the United States, our team is on a mission to make life's purchases more accessible and affordable.Located in the heart of vibrant Philadelphia, we're building a FinTech-enabled e-commerce marketplace that combines quality brands with sensible financing to improve the lives of our neighbors and communities.Position OverviewWe are searching for a Data Engineer who is a quantitative, critical thinker with a passion for data and the capacity to work in a fast-paced, entrepreneurial environment. We are looking for an individual who desires experience in serving data-driven solutions at scale, crossing multiple functional areas and driving organizational efficiency. Applicants should be highly motivated and comfortable with taking on and adapting to a diverse array of subject matter. This opportunity is both unique and pivotal, as it provides the chance to contribute greatly to a rapidly-growing team.Initial Responsibilities* Analyze and resolve complex challenges around data and tools. Optimize analytical workflows by identifying opportunities and automating them* Implement solutions to bring together application data generated by distributed systems, third-party data, and real-time user data needed to make key business decisions* Work within the Data Science team to serve machine learning solutions at scale* Work on projects of growing responsibility, both individually and as part of a team, to build experience and skills at a pace matched to your shown ability* Learn more about the industry and Perpay, establishing a solid foundation to be better positioned for long-term career successBasic Qualifications* Bachelor's degree or higher in a quantitative/technical field (Computer Science, Statistics, Engineering)* Minimum two years work experience in related field required* Working knowledge of data design, architecture and warehousing* Understanding of data management fundamentals and data storage principles* Knowledge of distributed systems as it pertains to data storage and cloud computing* Understanding and administration of AWS, Docker and Linux-based systems* Experience in custom ETL design, implementation and maintenance* Experience in large scale data processing using traditional and distributed systems like Hadoop, Spark, Dataflow, and Airflow.* Strong working knowledge of SQL/NoSQL, relational databases and Python is required (2+ years experience)Preferred Qualifications* Knowledge and practical experience in machine learning and AI fundamentals* Experience implementing machine learning solutions at scale* Experience working with both Batch and Real Time data processing systems* Ability to work and communicate effectively with stakeholders.* Effective project management, problem solving, analytical and troubleshooting skills.Benefits* Opportunity to work with one of the fastest growing financial startups* Competitive salary + equity* Health/dental/vision insurance + 401K* Gym + public transportation subsidy* Relocation assistance* Centrally located in downtown PhiladelphiaWe are an equal opportunity employer and value diversity at our company. We do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status.We don't work with external recruiting agencies, please contact us or apply directly!",Perpay,"Philadelphia, PA",-1,-1
Data Engineer,"Job Responsibilites Develop and enhance data pipelines, mostly batch (if necessary ""streaming"" processes) Apply best approaches for large scale data movement, capture data changes and apply incremental data load strategies. Build automated test pipelines to ensure data integrity and completion. Identify and improve current data pipelines through automation and optimization. Skills Understand and comply with all enterprise and IS departmental information security policies, procedures and standards.2. Support the integration of information security in the development, design, and implementation of Hospital Technology Resources that process, transmit, or store client information.3. Support all compliance activities related to state, federal regulatory requirements, healthcare accreditation standards, and all other applicable regulations that govern the use and disclosure of patient, financial, or other confidential information. General Basic knowledge on structured operational processes, conformance with SLAs, and metrics based reporting.2. Foundational knowledge in Change Control Mgt. processes3. Experience with process documentation and communication tools including MS Word, Project, Excel, Visio and PowerPoint. Basic experience and proven use of one or more of the subject areas listed below SQL and Database Knowledge ndash Understanding SQL, Relational and Multidemensional Databases and Designs1. Knowledge of relational database structures (tables, data types, data model schemas), SQL Syntax SQL Functions, develop Views and SQL Optimization Moderate experience and proven use of one or more of the subject areas listed below Tableau, Qliksense, Power PI, or any other data visualization application. Data Warehouse Support and Design1. CreatingMaintaining Tables, views, indexes bull Proficiency in appropriate Business IntelligenceData Warehousing technology or subject domain. Soft Skills Comfortable working in a collaborative environment. Ability to self-organize one's priorities and schedule. Have mindset to perform necessary documentation. Should be a self-starter to work independently or in a team. Keywords Education bull Bachelor's degree in computer related field required.bull 2-4 years of Business IntelligenceData Warehousing experience, preferably in an academic research (Administration) environment. Preferred experience 5+ years of experience with Python 3+ years of experience working with BigData platform, large and complex 3+ file types such as XML, JSON, AVRO, PARQUET, ORC etc., Should be comfortable using SQL, Git, JIRA, Docker, CICD for testingdeployment. Skills and Experience Required Skills PYTHON","RennerBrown
3.0","Philadelphia, PA",IT Services,Information Technology
Data Engineer,"IntePros is looking to hire a Sr. Data Engineer for a premier client in Philadelphia, PA
suggest, prototype and deploy machine learning solutions.
expose your models as service interfaces for the application integration.
build data pipelines for sourcing data from disparate sources which later can be analyzed, cleaned and transformed for building intelligent systems.
Primary Requirements:
• Strong and proven software development skills
• Proficient in Python programming language
• Should be able to build interfaces for collecting data, data extraction, transformations through Python
• Should be able to work with data through SQL - Preparing data, cleanup, Aggregating, Slicing/Dicing Data
• Should have worked in Python Stats, Machine learning packages - Pandas, Data frames, Scipy, NumPy, StatsModel, Scikit packages. Familiarity with frameworks such as MLlib, H2O, TensorFlow or similar.
• Should have experience in working with Kafka using Python or Java API
• Should have worked with a NoSQL database. Should be able to build interfaces for serving data-in/data-out of the database through API.
• Preferred Telecom and Billing
• Experience working in an Agile organization and understanding of Agile fundamentals, JIRA with CI/CD
• Excellence at formulating, understanding, and solving complex, non-routine problems
• Exposure in working with Big Data; experience with Hadoop, Kafka, and Spark preferred
• Familiarity with managed cloud-based options for building machine learning models","IntePros
4.2","Philadelphia, PA",Consulting,Business Services
Data Engineer,"Location Philadelphia, PA Description Our client is currently seeking a Data Engineer for our client in Philadelphia! This job will have the following responsibilities Work closely with stakeholders, analysts, and data scientists within the organization developing software solutions helping to deliver insights into customer and network behavior that drive business decisions. Develop large scale, cloud based data pipelines for the collection and processing of device telemetry and network events, providing both a real time and historical view into the operation of our products and services. Expose services over REST APIs and work closely with various engineering teams to solve key optimization, insight and access network data challenges. Develop large scale data pipelines exposing data sources Develop REST APIs utilizing AWS lambda and API Gateway. Develop Spark streaming and batch jobs to clean and transform data. Write build automation to deploy and manage cloud resources and unit and integration tests. Qualifications Requirements Strong python development experience required Experiences with Oracle database, especially in AWS RDS, Cloud Computing (AWS Lambda, EC2, ECS), and Spark (AWS EMR, Databricks). BSMS degree in Computer Science, Mathematics, or other relevant science and engineering discipline. 4+ years working as a software engineer and 2+ years working within an enterprise data lakewarehouse environment or big data architecture. Proficiency in testing frameworks and writing unitintegration tests and in Unix-based operating systems and bash scripts. Preferred Additional Skills Experience with working in Spark Experience with AWS Experience with monitoring and visualization tools such as Grafana, Prometheus, Data Dog, and Cloudwatch. Experience with NoSQL databases, such as DynamoDB, MongoDB, Redis, Cassandra, or HBase If interested, please email LEltringhamjudge.com with an updated resume! Thanks! Contact leltringhamjudge.com mailtoleltringhamjudge.com?subjectData20Engineer This job and many more are available through The Judge Group. Find us on the web at www.judge.com httpwww.judge.com","The Judge Group, Inc.
3.5","Philadelphia, PA",Staffing & Outsourcing,Business Services
Data Analyst,"Data AnalystKey responsibilities for the Data Analyst include:
• Writing complex SQL queries that analyze source data to understand relationships within the data
• Write SQL queries to perform data profiling to better understand the data contained within the systems
• Create source-to-target mappings that capture business logic, data standardization rules, and data integration logic that can be used by the ETL team.
• Identifying and interpreting patterns within data
• Work closely with business partners to resolve data discrepancies, explain data findings, and garner final approval of the source-to-target mappings
• Work closely with the data modelers, data engineers, and QA team to ensure that the data is properly loaded into the data warehouse
About You
Ideal characteristics in a candidate include:
• Exceptional analytical skills
• Strong oral and written communications skills,
• Meticulous and detail-oriented
• Must be a problem solver, critical thinker, self-motivated and possess integrity and a strong work ethic
• Ability to work independently on concurrent tasks and adhere to deadlines
• Ability to easily adapt to changing priorities
• Ability to meet high expectations for precision and accuracy
• High degree of initiative and intellectual curiosity

Required qualifications from an ideal candidate are:
• 3+ years' experience performing data analysis in a data warehouse, data mart, or business intelligence environment
• Deep knowledge of database structures, normalization, de-normalization and entity relationships
• Deep knowledge of data warehouse concepts
• Strong data manipulation and data analysis skills
• Advanced Excel skills are preferred to ensure repetitive tasks can be completed in an efficient manner
• Ability to work both independently as well as a team
• Ability to communicate highly technical concepts in business terms
• Experience working in an Agile environment
• Experience in a financial services industry preferred

For more information please contact Brian Otten at 203-433-7817 or botten@itechsolutions.com

Since 1995, iTech Solutions Inc., has been providing IT Consulting and Direct Hire Services to the Insurance, Financial, Communications, Manufacturing and Government sectors with local offices in Connecticut, Minnesota, Colorado, Massachusetts, Tennessee, North Carolina, and New Jersey / Pennsylvania area.

Our recruiting strategy is simple, if you want to find qualified IT professionals then use IT professionals to find them. So at iTech Solutions, our personnel are all career IT professionals with a wide range of IT experience. We can honestly say our staff understands the technologies, the complexities of finding and selecting the appropriate personnel and the pressures of running successful IT projects.

Employer will not sponsor applicants for any employment visas, at hiring or in the future, including but not limited to H-1B visas. Corp-to-Corp or subcontract personnel will not be considered for this position.

Job Requirements:","iTech Solutions, Inc
3.8","Conshohocken, PA",Staffing & Outsourcing,Business Services
Data Engineer,"Overview

goPuff is seeking a Data Engineer which will be responsible for supporting the data ingest and integration needs at goPuff. The data engineer must provide technical expertise and leadership on architecture, design, and integration of multiple datasets into goPuff’sever evolving, large scale data environment. Emphasis of this position will be in developing and deploying a robust data processing pipeline and streams.

Responsibilities
Responsible for designing, deploying, and maintaining analytics about goPuff’s environment that process data at scale
Contributes design, configuration, deployment, and documentation for components that manage data ingestion, real time streaming, batch processing, data extraction, transformation, enrichment, and loading of data into a variety of cloud data platforms, including AWS and Microsoft Azure
Identifies gaps and improves the existing platform to improve quality, robustness, maintainability, and speed
Evaluates new and upcoming big data solutions and makes recommendations for adoption to extend our platform to meet advanced analytics use cases, such as predictive modeling and recommendation engines
Performs development, QA, and dev-ops roles as needed to ensure total end to end responsibility of solutions
Qualifications
4-6 years of experience in a Data Engineering role
Experience building, maintaining, and improving Data Processing Pipeline / Data routing in large scale environments
Fluency in common query languages, API development, data transformation, and integration of data streams
Strong experience with large dataset platforms such as (e.g. Amazon EMR, Amazon Redshift, Elasticsearch, Amazon Athena, Azure SQL Database, Azure Database for PostgreSQL, Azure Cosmos DB)
Experience in producing and consuming topics to/from Apache Kafka, AWS Kinesis, or Azure Event Hubs
Experience with data flow monitoring, batching, and streaming
Experience working with variety of databases and expert using SQL
Experience data storage performance analysis and enhancements such as data replication, distribution, and compression
Experience with acquiring data from varied sources such as: API, data queues, flat-file, remote databases
Creativity to go beyond current tools to deliver the best solution to the problem
Data QA experience is a plus
Experience with event-based and transaction-based system is a plus
About Us

The only predictable thing about life is that it’s wildly unpredictable. That’s where we come in.

When life does what it does best, customers turn to goPuff to deliver their everyday essentials, and to get through their day & night, work day and weekend.

We’re assembling a team of thinkers, dreamers & risk-takers...the kind of people who know the value of peace of mind in an unpredictable world. (And people who love snacks.)

Like what you’re hearing? Welcome to goPuff.

The goPuff Fam is committed to an inclusive workplace where we do not discriminate on the basis of race, sex, gender, national origin, religion, sexual orientation, gender identity, marital or familial status, age, ancestry, disability, genetic information, or any other characteristic protected by applicable laws. We believe in diversity and encourage any qualified individual to apply. We are an equal employment opportunity employer.","Gopuff
3.4","Philadelphia, PA",Express Delivery Services,Transportation & Logistics
Data Engineer,"Job Description US Tech Solutions is seeking a ldquoData Engineerrdquo for a 06+ Months Contract with a client in Philadelphia, PA Job Poster Akhil Kumar Description We are looking for a motivated Data Engineer who would help build data pipelines to ingest and transform the data into our Data platform (on-premcloud). Candidate are to be passionate about Python coding. Job Responsibilities Develop and enhance data pipelines, mostly batch (if necessary ""streaming"" processes) Apply best approaches for large scale data movement, capture data changes and apply incremental data load strategies. Build automated test pipelines to ensure data integrity and completion. Identify and improve current data pipelines through automation and optimization. Skills Understand and comply with all enterprise and IS departmental information security policies, procedures and standards. Support the integration of information security in the development, design, and implementation of Hospital Technology Resources that process, transmit, or store client information. Support all compliance activities related to state, federal regulatory requirements, healthcare accreditation standards, and all other applicable regulations that govern the use and disclosure of patient, financial, or other confidential information. General Basic knowledge on structured operational processes, conformance with SLAs, and metrics based reporting. Foundational knowledge in Change Control Mgt. processes Experience with process documentation and communication tools including MS Word, Project, Excel, Visio and PowerPoint. Basic experience and proven use of one or more of the subject areas listed below SQL and Database Knowledge ndash Understanding SQL, Relational and Multidimensional Databases and Designs Knowledge of relational database structures (tables, data types, data model schemas), SQL Syntax SQL Functions, develop Views and SQL Optimization Moderate experience and proven use of one or more of the subject areas listed below Tableau, Qliksense, Power PI, or any other data visualization application. Data Warehouse Support and Design CreatingMaintaining Tables, views, indexes Proficiency in appropriate Business IntelligenceData Warehousing technology or subject domain. Education Bachelorrsquos degree in computer related field required. 2-4 years of Business IntelligenceData Warehousing experience, preferably in an academic research (Administration) environment. Preferred experience 5+ years of experience with Python 3+ years of experience working with BigData platform, large and complex file types such as XML, JSON, AVRO, PARQUET, ORC etc., Should be comfortable using SQL, Git, JIRA, Docker, CICD for testingdeployment. About US Tech Solutions Your talent, our opportunities - This is the premise behind US Tech Solutions. You have the skill we have the opportunity. As a team, we work passionately for you to get the right career opportunity across industry verticals and functions. For past sixteen years, leading Global Companies and Fortune 500 come to us to get the right talent. Whether you want to work as full-time, contractor or part-time, technical or non-technical our talent consultants will connect with the right career opportunity globally. Connect with our talent team today. USTECH was founded in 2000 by Manoj Agarwal. Today, we are a global firm offering talent solutions to 150 customers including 20 of Fortune 500 across Financial Services, Healthcare, Life Sciences, Aerospace, Energy, Retail, Telecom, Technology, Manufacturing, and Engineering. We are headquartered in New Jersey with 40 global locations across the USA, Canada, Europe, and India. Deloitte has recognized USTECH as one of the fastest growing private businesses for the past five consecutive years and INC 500 for the past three. We have also been rated ldquoThe Top Business in the US"" by Diversity Business since 2011. To learn more about how US Tech Solutions visit our website www.ustechsolutions.com. ldquoUS Tech is an Equal Opportunity Employer"" and ldquos all other parties authorized to work in the US are encouraged to apply."" Apply Interested candidates are requested to send their resume to Akhil at AkhilKustechsolutionsinc.com","US Tech Solutions Inc.
3.8","Philadelphia, PA",Staffing & Outsourcing,Business Services
Data Engineer,"Data EngineerLocation: Philadelphia, PA Full-time/Permanent position Summary: You will support the engineering team’s data endeavors, diving in to fix issues, optimize processes, and automate what you do more than once. You’ll use the best tools for the job, whether modern and revolutionary or time tested and proven, to deliver elegant, scalable solutions that meet business and technical needs. What you will do -Work with internal stakeholders to load data into a data warehouse -Troubleshoot and resolve issues relating to data integrity -Help establish procedures and best practices for transforming and storing data -Lead requirements gathering around data pipeline automation improvements -Work with some of the most exciting open-source tools like Spark, Hadoop, Docker, Airflow, Zeppelin -Leverage distributed computing and serverless architecture such as AWS EMR & AWS Lambda, to develop pipelines for transforming data -Enjoy the peace that comes with working in a mature software development environment -Marvel at the speed with which your creation makes it into production -Research and implement new technologies with a team of developers to execute strategies and implement solutions -Produce peer reviewed quality software -Solve complex problems related to the real-time discovery of large data About you You are... -Experienced in writing scalable applications on distributed architectures -Data driven, testing and measuring as much as you can -Eager to both review peer code and have your code reviewed -Comfortable on the command line and consider it an essential tool -Confident in SQL, you know it, write smart queries, it’s no big deal Required skills and experience -5+ years of work experience -3+ years of experience with Python -3+ years of experience with PySpark and Spark-SQL (writing, testing, debugging spark routines) -1+ years of experience with AWS EMR, AWS S3 service. Comfortable using AWS CLI and boto3 -Comfortable working in remote environments -Comfortable using *nix command line (shell scripting, AWK, SED) -Experience with MySQL and Postgres Desired experience -Experience with Apache Airflow -Experience with Apache Zeppelin -Experience with healthcare data",DL Staffing Solutions,"Philadelphia, PA",-1,-1
Software Engineer,"Job Description
About us:
Oncora is an oncology software and data company dedicated to helping physicians and scientists collect and use real-world data to improve outcomes for cancer patients. Our machine learning algorithms, which are deployed in active clinical environments, accurately predict oncology outcomes such as unplanned hospitalization, survival, and recurrence. Our software products include: a data capture system for radiation oncology clinical care, a data warehouse that leverages connections other healthcare software systems such as EMRs, PACS, to amass real-world, regulatory-grade oncology data, a machine learning platform to train and validate predictive models of key oncology events, a publicly machine learning API to power external software tools, and a virtual clinical trial platform that allows pharma and device companies to leverage automated medical image analysis to advance new technologies in the fight to cure cancer. We work with world-leading cancer centers such as MD Anderson and Northwell Health, global device companies such as Varian Medical Systems, and innovative biopharma companies. Our team is mission-driven to its core.

About the role:
We are looking for an experienced engineer to join our mission driven team to help develop our data platform that integrates and transforms multiple imperfect and messy healthcare data sources into clean, usable data so that we can learn from every cancer patient.

We are a small team trying to tackle a large problem, so we need teammates that are ultimately accountable to themselves and continuously push the product and the organization forward. You will need to play a vital role in developing and operating our core data platform and help to scale it to serve additional hospitals.

Responsibilities:
Designing and implementing improvements to our data extraction and transformation processes to increase performance and stability
Overseeing and monitoring our existing data platforms for stability, performance and accuracy
Incrementally evolving our platform architecture without disrupting operations
Working with Product and Engineering to define, document, and build transformations to extract intelligence from multiple incomplete and siloed data sources
Building pipelines to de-identify and consolidate cross-institutional data to fuel predictive analytics, research, and clinical trials
Building visibility into all aspects of our data platform (workflow status, system health, data lineage, etc.)
Qualifications:
Demonstrated experience independently leading complex software projects
Experience designing and building data pipelines (real-time or batch)
Deep understanding of data persistence technologies, relational, document, key/value, columnar, etc (we use MongoDB, Postgres, Redis, and ElasticSearch)
Experience building asynchronous and distributed systems (we use RabbitMQ)
Fluency with a functional or imperative language (we use Python & JS)
A focus on writing understandable, testable, and maintainable code
Familiarity with modern containerized environments (we use Docker & Kubernetes)
Experience with healthcare data standards and integrations (HL7, FHIR, DICOM, etc.)
Compensation, Benefits, and Perks:
Salary: $100k-130k
401k, health and dental insurance, flexible vacation, paid parental leave
eBooks, online courses, home office budget
Work with smart, passionate people on a product that will have a direct impact on the lives of cancer patients

Oncora is an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to race, color, age, sex, religious creed, disability, ancestry, national origin, sexual orientation, gender identity, or gender expression.",Oncora Medical,"Philadelphia, PA",Health Care Services & Hospitals,Health Care
Data Analyst,"Job Description
Opportunity

Angeion Group is looking to welcome a Data Analyst to its rapidly growing team. This is a full time, onsite role, and you will be working at our headquarters in Center City, Philadelphia.

About the Company

Angeion Group is a leading provider of comprehensive settlement management services for class actions, mass tort, and bankruptcy administration. Leveraging world-class technology, proven best practices, and expert consulting, Angeion delivers the services and capabilities that drive greater efficiency in settlement administration. Formed by a proven and experienced executive leadership team, Angeion is bringing novel ideas and fresh approaches to notice and claims administration. For more information, please visit our website, http://www.angeiongroup.com.

About the position

The Data Analyst will be working with high volumes of data to support project needs. Your success is dependent on building a strategic partnership and becoming aligned with the operations and technology teams. We require a candidate with the motivation to succeed and a passion to excel. The candidate must be capable of rising to the challenge of working for a preeminent organization that serves national clients. As an industry leader, we expect our team to be willing to learn to accomplish their work with the highest operational excellence. You will work internally across departments and externally with clients and vendors, so it is imperative to always demonstrate the highest level of professionalism.

Duties and Responsibilities
Manipulate large amounts of data (mass insert, update, upsert, delete) either directly, using SQL statements or Excel, or through dedicated data management software
Review project requirements and provide expert advice regarding the structure of databases and forms
Utilize data analysis and SQL skills to design and develop database queries, extract participant-level data from databases and analyze the data using a variety of analytical techniques
Generate and analyze data reports from internal and external sources
Research and data mine as directed to retrieve data/status and develop/provide metrics as required
Collaborate in all aspects of the collection, verification and entry of data
Perform data transfer functions by importing and exporting data to and from the SQL Server, or other sources
Conduct quality control and auditing of databases in a client/server environment to ensure accurate and appropriate use of data
Design workflows to control access to data and optimize the flow of information
Provide all activities related to the administration of databases
Provide data and analytical support for cases
Document guidelines for appropriate database usage, data maintenance and key report processing
Monitor data management repositories and communicate documentation to team
Support with organization, tracking, maintenance and validation of spreadsheets
Develop a process and associated plan for the maintenance of existing reports, trackers, and documents for the creation, incorporation and maintenance of new reports
Design, implement, and maintain complex databases with respect to access methods, access time, device allocation, validation checks, organization, protection and security, documentation, and statistical methods
Fully document all work and comply with development best practices
Participate in and conduct code reviews of both team and vendor-supplied code and determine quality, identify bugs and evaluate risks
Ensure architecture is consistent with organizational development standards and align with industry guidelines and best practices
Continually work towards strengthening industry knowledge and all relevant applications
Communicate regularly and effectively with all colleagues
Exhibit a very organized approached and superior attention to details
Meet regularly with managers to provide feedback and facilitate communication
Adhere to all business processes while performing tasks
Able to take on new tasks and responsibilities as needed
Perform other work-related duties as assigned by management
Qualifications
Bachelors’ degree in computer science, business or other related field or discipline
Database system(s) experience required
Complex data analytics experience required
LAW PreDiscovery – LexisNexis experience preferred
SQL, advanced Excel (including VBA), data mining; prior coding experience constitutes an advantage
System implementation and system integration experience
Skilled in business analysis, process improvement, and project management
Minimum of 3-5 years of experience and a demonstrated track record of accomplishments
Aggressive problem diagnosis and creative problem-solving skills
Demonstrate a high degree of productivity while handling multiple tasks simultaneously
Ability to perform comfortably in a fast-paced, deadline-oriented work environment
Excellent written, verbal, communication, and research skills a must
Ability to be flexible to adapt and act quickly when urgent matters require it
Able to work effectively with diversified individuals of various ethnic backgrounds and professional competencies
Project a positive, professional image toward clients, vendors and staff in all interactions and situations
Maintain the highest level of confidentiality
Problem analysis and resolution skills at both a strategic and functional level
Excellent computer skills including all MS Office applications. (Word, Excel, Outlook, PowerPoint) required
Must be presently authorized to work in the U.S. without a requirement for work authorization sponsorship by our company for this position now or in the future","Angeion Group
3.2","Chester Township, PA",Consulting,Business Services
Data Analyst,"Data Analyst - Horsham, PA 19044 My client, a loan origination company in Horsham, PA is in need of a Data Analyst for a 9 month + contract to potential hire opportunity to help build out a new Data Warehouse. Responsibilities include bull Writing source to target mapping documentations bull Performing SQL queries Qualifications include bull 5 + years of data analytics experience bull Extensive SQL querying experience bull Expert level Microsoft Excel experience bull Understanding of Data Warehouse concepts Dimensions Fact Tables Star Schema bull Strong analytical mind within data bull Detail oriented (this is vital work for the Data Engineering team) bull Strong communications skills in order partner with the business side bull Be able to pick apart the current Data Warehouse Compensation Expectations bull 50 - 60Hour W2 bull Full Benefits Healthcare, Dental, Vision","Zachary Piper Solutions, LLC
3.9","Horsham, PA",Enterprise Software & Network Solutions,Information Technology
Data Analyst,"Job Description
Job Summary: The Data Analyst will initiate, support and maintain processes of automated data into the data warehouse at AccessLex. Conduct full data lifecycle analysis; engaging the business in requirements gathering, complete analysis of project data, drafting and developing solution design, of reporting\data resolution. Continuous monitoring of performance and quality control programs to identify improvements.

Responsibilities and Duties:

· Collaborate with business and development community to understand data requirements.

· Work with various customer groups to develop the business data access layer across various business intelligence products.

· Develop and implement technical designs of data reports and models in support of business requirements.

· Develop and implement technical designs of data integration processes and models in support of business requirements.

· Assist in gathering and defining business and technical metadata in support of projects.

· Collect and document business requirements in support of all Business Intelligence (BI) initiatives.

· Develop and deliver training materials in support of delivered BI applications.

· Educate business owners of available data as well as any limitations.

· Continuous review, update and adherence to data governance policies.

· Other duties as assigned.

Candidate Requirements:

Knowledge, Skills and Abilities (KSAs) – Things a candidate should know and/or a skill or ability he or she should possess to be successful in the role.

o Required
Excellent interpersonal and communications skills. Job requires the ability to work hand in hand with customers, facilitating meetings, preparing written documents and communication, and the ability to develop detailed requirements for reporting and analysis applications.
Proven analytical skills with the ability to collect, organize, analyze and disseminate significant amounts of information with attention to detail and accuracy.
Strong attention to data validation and data quality requirements.
2+ years’ experience writing TSQL, views, and stored procedures, with the ability to learn other analytic tools.
Adept at report writing and presenting findings.
Strong knowledge of database design and data models.
Familiarity with cloud-based data platforms and tools.
o Preferred
Experience with Microsoft Business Intelligence suite of products, including Integration Services, Reporting Services and Analysis Services.
Experience with dashboarding software such as Power BI or QLIK
Knowledge of creating APIs.
o BACKGROUND Experiences.The following are required unless otherwise noted:
BS/BA in Business Administration, Computer Science,or similar related field.
Minimum 2 years of related experience in a similar role.
Thorough knowledge of a broad range of business and technology issues.
Equal Employment Opportunity Statement: AccessLex Institute provides equal employment opportunity to all individuals regardless of their race, color, creed, religion, gender, age, sexual orientation, national origin, disability, veteran status, or any other characteristic protected by state, federal, or local law.
Company Description
AccessLex Institute is a nonprofit organization committed to helping talented, purpose-driven students find their path from aspiring lawyer to fulfilled professional. In partnership with its nearly 200 Member law schools, improving access and positively influencing legal education have been at the heart of the Company's mission since 1983. AccessLex Institute has offices in West Chester, PA, and Washington, D.C., with a team of accredited financial education counselors based throughout the United States. Learn more at AccessLex.org.","AccessLex Institute
2.6","West Chester, PA",Colleges & Universities,Education
Data Engineer,"SUMMARYData Analytics team is looking for a smart, data-savvy data engineer to help us re-invent our data and analytics platforms. You should have a deep passion for understanding and solving data issues and bring logic, enthusiasm and an analytical approach to work issues.

RESPONSIBILITIES

Drive engineering efforts to design, develop, and test data-driven solutions
Drive the optimization, testing and tooling that will improve data quality
Improve performance, availability and scalability of our backend systems
Partner with engineering, product and operations teams to design tech solutions
Utilize CI/CD throughout the development, automation and testing lifecycle
Deliver updates in different backend components and
Contribute strategy and tactics to the long-term roadmap for enterprise data strategy

REQUIREMENTS

3+ years(TM) experience building large scale big data applications in a business setting
Excellent SQL and database knowledge
Ability to pull data from disparate sources, (RDBMS, Excel), and deliver to Cloud data lake
Hands-on experience with Python, Ruby, Scala, and/or Java.
Knowledge/experience using AWS, Snowflake or other Cloud technology
Proficient with Linux commands and environments
Demonstrated ability to learn new languages.
Bachelor(TM)s degree in an analytic or technical field, (Math, Stat, Computer Science, etc.)

PREFERENCES

Hands-on experiences with data processing, reporting or analysis tools
Experiences with Hadoop/Spark/Kafka/Presto/etc.","Numeric, LLC
3.2","King of Prussia, PA",Staffing & Outsourcing,Business Services
Data Engineer,"Data EngineerData Engineer

You will support the engineering team's data endeavors, diving in to fix issues, optimize processes, and automate what you do more than once. You'll use the best tools for the job, whether modern and revolutionary or time tested and proven, to deliver elegant, scalable solutions that meet business and technical needs.

• Work with internal stakeholders to load data into the data warehouse
• Troubleshoot and resolve issues relating to data integrity
• Help establish procedures and best practices for transforming and storing data
• Lead requirements gathering around data pipeline automation improvements
• Work with some of the most exciting open-source tools like Spark, Hadoop, Docker, Airflow, Zeppelin
• Leverage distributed computing and serverless architecture such as AWS EMR & AWS Lambda, to develop pipelines for transforming data
• Enjoy the peace that comes with working in a mature software development environment
• Marvel at the speed with which your creation makes it into production
• Research and implement new technologies with a team of developers to execute strategies and implement solutions
• Produce peer reviewed quality software
• Solve complex problems related to the real-time discovery of large data

• Experienced in writing scalable applications on distributed architectures
• Data driven, testing and measuring as much as you can
• Eager to both review peer code and have your code reviewed
• Comfortable on the command line and consider it an essential tool
• Confident in SQL, you know it, write smart queries

Required skills and experience

• 5+ years of work experience
• 3+ years of experience with Python
• 3+ years of experience with PySpark and Spark-SQL (writing, testing, debugging spark routines)
• 1+ years of experience with AWS EMR, AWS S3 service. Comfortable using AWS CLI and boto3
• Comfortable working in remote environments
• Comfortable using *nix command line (shell scripting, AWK, SED)
• Experience with MySQL and Postgres
Desired experience

• Experience with Apache Airflow
• Experience with Apache Zeppelin
• Experience with healthcare data

Interested candidates please send resume in Word format Please reference job code 528434 when responding to this ad.

Job Requirements:","Ettain Group
3.0","Philadelphia, PA",Staffing & Outsourcing,Business Services
Data Engineer,"Job Description
Hands on experience in developing big data pipelines end to end

· 5-8 years of Java and Python experience

· Experience in software development of largescale distributed systems including proven track record of delivering backend systems that participate in a complex ecosystem

· Experience working with imperfect data sets that, at times, will require improvements to process, definition and collection

· Experience with real-time data pipelines and components including Kafka, Spark Streaming

· Proficient in Unix/Linux environments

· AWS experience developing data streaming pipelines

· Deep Spark understanding

· Must Have Skills : Spark, SQL,Kinesis/Kafka, python for scripting on AWS and Java for APIs","Globex Digital Solutions
3.4","Philadelphia, PA",-1,-1
Data Engineer,"Job Description
How you will help
You will support the engineering team’s data endeavors, diving in to fix issues, optimize processes, and automate what you do more than once. You’ll use the best tools for the job, whether modern and revolutionary or time tested and proven, to deliver elegant, scalable solutions that meet business and technical needs.

What you will do
Work with internal stakeholders to load data into HealthVerity's data warehouse
Troubleshoot and resolve issues relating to data integrity
Help establish procedures and best practices for transforming and storing data
Lead requirements gathering around data pipeline automation improvements
Work with some of the most exciting open-source tools like Spark, Hadoop, Docker, Airflow, Zeppelin
Leverage distributed computing and serverless architecture such as AWS EMR & AWS Lambda, to develop pipelines for transforming data
Enjoy the peace that comes with working in a mature software development environment
Marvel at the speed with which your creation makes it into production
Research and implement new technologies with a team of developers to execute strategies and implement solutions
Produce peer reviewed quality software
Solve complex problems related to the real-time discovery of large data
About you
You are...
Experienced in writing scalable applications on distributed architectures
Data driven, testing and measuring as much as you can
Eager to both review peer code and have your code reviewed
Comfortable on the command line and consider it an essential tool
Confident in SQL, you know it, write smart queries, it’s no big deal

Required skills and experience
5+ years of work experience
3+ years of experience with Python
3+ years of experience with PySpark and Spark-SQL (writing, testing, debugging spark routines)
1+ years of experience with AWS EMR, AWS S3 service. Comfortable using AWS CLI and boto3
Comfortable working in remote environments
Comfortable using *nix command line (shell scripting, AWK, SED)
Experience with MySQL and Postgres
Desired experience
Experience with Apache Airflow
Experience with Apache Zeppelin
Experience with healthcare data
HealthVerity, based in Center City Philadelphia, is a venture-backed technology company that is transforming the way data-led organizations make critical decisions. Our technology platform serves as the foundation for the rapid creation, exchange and management of healthcare and consumer data in a fully-interoperable, privacy-protecting manner. Advantaged by highly sophisticated identity resolution and matching capabilities, HealthVerity is on a mission to increase transparency, forge interoperability and activate deeper insights.

Our company challenges
Empowering clients with highly rewarding data discovery and licensing tools
Ingesting and managing billions of healthcare records from a wide variety of partners
Standardizing on common data models across data types
Orchestrating an industry-leading HIPAA privacy layer
Innovating our proprietary de-identification and data science algorithms
Building a culture that supports rapid iteration and new possibilities
The infrastructure and culture we are building will provide an environment that cultivates innovation. We want to move fast knowing we can fix anything we break along the way. If a new need arises, we want to turn around a solution quickly. We want to solve our challenges in ways that create even more possibilities. We’re creating a platform that lets us discover what else we might do.

We have big plans
We are building a platform that will scale to support an ever-growing array of data providers and innovative products. You must be able to think big while still delivering on near-term requirements.

HealthVerity is an equal opportunity employer.","HealthVerity
5.0","Philadelphia, PA",Enterprise Software & Network Solutions,Information Technology
Data Engineer,"JOB DESCRIPTION Role Java Analytics Analyst Work Location Philadelphia, PA Type Long Term Contract Salary 50hr C2C Openings 2 Responsibilities Development and maintenance of ETL applications written using Java, SQL and Python. Performance tuning and management of SQL based Databases like MySQL, Redshift etc. BackupRestoreArchiving of Database Exploring new data store technologies for various business scenarios like DashboardsReportingVisualization, Business Intelligence software, Data Warehousing, Real time stream analytics etc. Required Skills Java experience is a must. Hands on ETL and SQL experience with relational DB like Teradata, Redshift, Snowflake etc. Hands on experience in either one of the leading BI tools like Tableau, Looker etc or VisualizationFront EndWeb Development experience. Experience with Open stack andor AWS Cloud services Experience with Linux (Ubuntu preferred) system","K-Tek Resourcing LLC
3.9","Philadelphia, PA",IT Services,Information Technology
Software Engineer,"Software Engineer

Why YOU want this position

Enverus delivers business-critical insights to the global energy industry through a state-of-the-art SaaS platform built on industry-leading data and energy analytics. Our solutions deliver value across the entire energy value chain, empowering customers to be more agile, efficient and competitive. The range of energy industry participants we serve includes exploration and production (E&P) companies and related businesses such as oilfield services, midstream, capital markets, power generators and utilities, energy traders, and downstream commercial & industrial energy consumers.

Enverus Software Engineering culture emphasizes team building, mentorship, and accountability that fits well with individuals who are self-starters, team players, and have a strong desire for continuous learning and growth. We offer a competitive compensation package along with industry leading perks that include:
Casual dress code
Annual technical training budget
A well-stocked kitchen with snacks and beverages
We are currently seeking a highly driven Software Engineer to join our Data Science team in Conshohocken, PA, Denver, CO, or Calgary, AB. This role offers the opportunity to join a rapidly growing company delivering industry-leading solutions to customers in the worlds most dynamic and fastest growing sector. Enverus is the right company at the right time.

Performance Objectives
Collaborate with Data Scientists to productize machine learning models
Design, develop, test, and maintain production ready code
Support and maintain current production platform
Evaluate different tools and algorithms for reliable functionality and scalability
Participate in performance and stress testing with the development team
Participate in scrum planning and daily team standup
Competitive Candidate Profile
5+ years Python experience
Solid understanding of algorithms and data structures
Solid Linux and git expertise
Preferred Qualifications
Pandas, NumPy, scikit-learn, TensorFlow, multiprocessing
Docker, Airflow, Kubernetes, Spark, Jenkins
SQL Server
GoLang
Azure cloud computing","Enverus
3.6","Conshohocken, PA",Energy,"Oil, Gas, Energy & Utilities"
Data Engineer,"Aetea has been asked by their valued client, to assist with their need for a Data Engineer. The client and the team yoursquoll be working in are great and offer positive challenges in a dynamic environment. Specific Responsibilities Design and develop Extraction, Transformation and Loading (ETL) processes using standard ETL tools to streamline and automate the collection of data from source systems using SQL, Snowflake and AWS technologies Assemble large, complex data sets that meet functional non-functional business requirements Identify, design, and implement internal process improvements automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc. Work with stakeholders including the Marketing, CRM, Finance, Operations, Product, and Development teams to assist with data-related technical issues and support their data infrastructure needs. Create data tools for analytics and data scientist team members that assist them in building and optimizing our product into an innovative industry leader. Develop repeatable and scalable data quality audits Requirements Design and develop Extraction, Transformation and Loading (ETL) processes using standard ETL tools to streamline and automate the collection of data from source systems using SQL, Snowflake and AWS technologies Assemble large, complex data sets that meet functional non-functional business requirements Identify, design, and implement internal process improvements automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc. Work with stakeholders including the Marketing, CRM, Finance, Operations, Product, and Development teams to assist with data-related technical issues and support their data infrastructure needs. Create data tools for analytics and data scientist team members that assist them in building and optimizing our product into an innovative industry leader. Develop repeatable and scalable data quality audits Requirements Bachelorrsquos Degree in Computer Science, MIS or related field 5+ years Advanced SQL knowledge and experience working with relational databases, query authoring (T-SQL) as well as working familiarity with a variety of databases. Able to write advanced SQL queries with multi-table joins, group functions, subqueries, set operations, functions, Stored Procedures and basic Java Scripting. 2+ years of Experience with Snowflake Cloud Datawarehouse Platform 2+ Years Experience with object-orientedobject function in one of scripting languages (Python, PySpark) Experience with AWS DatabasesTools a plus (S3, Glue, Lambda) Experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement. Strong understanding of data modeling and data warehousing principles Excellent documentation and general organization of ongoing tasks, including the ability to evaluate and question business rules. Ability to solve problems and work directly with business SMErsquos Financial Experience is a plus JavaScripting is a plus This is a great opportunity to get in with a stable and growing organization that values technology and the people that drive it. There is a lot more we can share with you about the role, so please contact me (or apply) at gkumaraetea.com mailtogkumaraetea.com or through the ldquoapplyrdquo function listed. This is an urgent opportunity and the client committed to moving quick when they identify the right person. For more than 30 years, Aetea Information Technology has been the go-to partner for both premier clients and IT professionals alike. As a full spectrum IT Human Capital organization, we have experience in all industries, supporting clients ranging from emerging start-ups to Fortune 50. Our consultants value Aetea for their benefits, length of assignments, sequential employment opportunities, and compensation models not to mention the attentiveness and world-class support you will receive from the internal Aetea team.","AETEA Information Technology Inc
3.9","Wilmington, DE",IT Services,Information Technology
Statistician,"A new start-up in its series C funding stage is looking to add a new member to its rapidly growing team based here in Philadelphia. For years, our team have been working to solve one of the most impending and global issues, energy consumption and optimization. They are looking for someone with a background in the energy industry who has experience building out advanced Statistical models using either Python or R, as well as experience building out data pipelines to deploy data to their cloud platform(AWS). Experience with a machine learning tools and computer vision is greatly preferred.Required Skills & Experience* Experience with cloud platforms AWS* Experience building advanced statistical models* Background building out Data PipelinesWhat You Will Be DoingTech Breakdown* 60% Building models/creating algorithm* 40% Deploying data to AWSDaily Responsibilities* 50% Hands On* 20% Research* 30% Team CollaborationThe Offer* Competitive Pay: Up to $70/hour, DOE* Contract Duration: 9 MonthsYou will receive the following benefits:* Medical & Dental Insurance* Health Savings Account (HSA)* 401(k)* Paid Sick Time Leave* Pre-tax Commuter Benefit* Commuter pass* On-site gym* Remote FlexibilityApplicants must be currently authorized to work in the United States on a full-time basis now and in the future.Workbridge Associates, part of the Motion Recruitment network, provides IT Staffing Solutions (Contract, Contract-to-Hire, and Direct Hire) in major North American markets. Our unique expertise in today's highest demand tech skill sets, paired with our deep networks and knowledge of our local technology markets, results in an exemplary track record with candidates and clients.","Management Decisions, Inc.
1.6","Philadelphia, PA",Advertising & Marketing,Business Services
Data Engineer,"Title: SSIS ConsultantLocation : Minneapolis MN Duration : 3 month contract (strong possibility to extend) Top 3 Skills: 1) SQL ETL, SSIS, SSIS catalogue to deploy package - how they are moving data from point a to point b - bringing it into Azure ++ SQL based ERP system 2) Analysis Services - to use Tabular cubes - supplement invoicing data with delivery information 3) experience with Data viz - QLIK Description: Looking for a strong MS ETL developer to assist with migrating data from an old ERP/DW system into the central source. The bulk of the work will be ancillary data onboarding and some data cleansing, so if you've connected to a data system in the past, it should be relatively straight forward work. Project Background: ASC acquired a company that uses ERP called Falcon - they created a looping script, so that when there is a new acquisition, if they are connecting to a known system, they could onboard data in a day. Title: SSIS Consultant Location : Minneapolis MN Duration : 3 month contract (strong possibility to extend) Top 3 Skills: 1) SQL ETL, SSIS, SSIS catalogue to deploy package - how they are moving data from point a to point b - bringing it into Azure ++ SQL based ERP system 2) Analysis Services - to use Tabular cubes - supplement invoicing data with delivery information 3) experience with Data viz - QLIK Description: Looking for a strong MS ETL developer to assist with migrating data from an old ERP/DW system into the central source. The bulk of the work will be ancillary data onboarding and some data cleansing, so if you've connected to a data system in the past, it should be relatively straight forward work. Project Background: ASC acquired a company that uses ERP called Falcon - they created a looping script, so that when there is a new acquisition, if they are connecting to a known system, they could onboard data in a day.","System Soft Technologies
4.8","Cherry Hill, NJ",IT Services,Information Technology
Data Scientist,"Master's / bachelor's degree in computer science, Applied Mathematics, Quantitative Economics, Statistics, or related field.* 5-8 years of experience in predictive modeling, large data analysis and computer science* Experience in modeling, machine learning, and other advanced mathematical techniques (e.g., neural nets, simulation, graph analysis)* Experience using statistical computer languages (SAS, Python, R, PL SQL) to manipulate data and draw insights from large data sets.* Expertise in experimental design, advanced statistical analysis, and modeling to discover key relationships in data and applying that information to predict likely future outcomes; fluent in regression, classification, tree-based models, clustering methods, text mining, and neural networks.* Excellent written and verbal communication skills for coordinating across teams","Tata Consultancy Services
3.8","San Antonio, TX",Computer Hardware & Software,Information Technology
Data Scientist,"Ability to develop analytics for multiple cyber weapon systems with many different infrastructure and end-point devices. Ability to incorporate predictive, descriptive, and presumptive modeling; machine learning; artificial intelligence into analytics. Must be able to code proficiently in one or more of the following languages: Python, R, Scala, Spark, and Maven. Develop algorithms in one or more of the following Machine Learning areas: anomaly detection, one/few-shot learning, deep learning, unsupervised feature learning, ensemble methods, probabilistic graphical models, reinforcement learning. Ability to develop analytics based upon the Mitre ATT&CK Matrix or other applicable CS&D framework to discover, identify, characterize, and/or create signatures for cyberspace threat activity. Ability to assist in the development and implementation of a data analytics program. Develop robust documentation and comprehensive user manuals for all developed projects

Original Hire Document for data scientist below:

Job Responsibilities:

· Perform big data analysis on information technology infrastructure and end-point devices

· Customer outreach and engagement

· Problem solving

· Time management

· Collaborate with others

· Mission focused

· Deliver findings

· Accept and assess customer data, dashboard, requirements

· Identify new ways to visualize and analyze data

· Develop analytics to identify anomalous activity based on customer requirements

· Perform hunt operations identifying anomalous activity

· Produce reports based on misconfigurations and/or anomalous activity discovered through analysis

Knowledge/Skills Ability:

Required:

· Ability to analyze and assess software development or data acquisition requirements and determine optimum, cost-effective solutions.

· Proficiency in one or more big data programming languages, such as R, Python, Scala, or Spark and Maven.

· Experience working with a hybrid team of analysts, visualization experts, engineers, and developers to conduct research, and build and deploy complex, but easy-to-use analytical platforms.

· Previous experience performing research in Data Analytics or big data.

· Be Director of Central Intelligence Directives 6/4 eligible (Top Secret) with a current Single Scope Background Investigation (SSBI)

Minimum Experience/Education:

· At least one (1) of the following:

· One (1) year experience in cyberspace operations

· IAT Level 1 per DoD 8140 (Net+, Sec+, etc.)

· Experience on National/Service cyber weapon system/platform within last five years

Highly Desired:

· Education/ Certifications:

· 4+ years of experience in data analytics or quantitative intelligence analysis

· Four (4) years of experience in an intelligence field at a tactical or operational level

· DoD 8570 IAT related BA/BS degree

*BEAT LLC IS AN EQUAL OPPORTUNITY EMPLOYER - DISABILITY AND VETERANS*","B.E.A.T.
4.5","San Antonio, TX",Enterprise Software & Network Solutions,Information Technology
Data Scientist,"Knowesis is seeking an experienced data scientist to support the Hearing Center of Excellence (HCE) and HCE stakeholders. This person will help execute the DHA/HCE Data Vision of providing seamless data services and decision support for clinicians, patients, beneficiaries, analysts, researchers, and DoD leadership. This individual's primary responsibility will be to provide advanced analytics to support HCEs understanding of the issues on military service IAW SEC. 721 of the NDAA for FY 2009. The Data scientist will perform, collect, analyze, and report data to support a variety of hearing-related initiatives.

Responsibilities Include:
Provide a variety of business intelligence and advanced analytics services, including descriptive, predictive, and prescriptive analytics
Perform advanced exploratory and predictive analytics using machine learning techniques to gain insights on outcomes of interest to help improve patient care through clinical communities
Support DoD/VA internal and external research partnerships in the hearing health community as well as general analyses required within the HCE
Work with both structured and unstructured data employing unsupervised learning models including isolation forest, k-means clustering, anomaly detection, and principal component analysis
Handle Big Data problems utilizing unique technologies that store, manipulate, extract, and create features for processing and modeling
Implement machine learning algorithms with multidimensional data for classification and clustering problems and graphical networks
Provide overall data management and analytic solutions, ensuring adherence to all applicable privacy, data security, and HIPAA regulations and guidelines for Human and Non-Human Subject Researches
Serve as a Subject Matter Expert of MHS/VHA data and make recommendations on improving data collection methodologies related to any hearing requirements. Extract data from multiple data warehousing sources to generate and design standard and ad-hoc reports.
Required Experience:
Minimum of 5 years of demonstrated experience in statistics and statistical software (R, SAS, Python, SQL)
Exposure and understanding of Data Science/Machine Learning Techniques (isolation forest, k-means clustering, anomaly detection, and principal component analysis, Baysian, etc.)
1-2 years of experience with data visualization software (Tableau, Qlik, PowerBI)
Expert knowledge in Microsoft Office products and Sharepoint
Demonstrated experience in preparing and editing technical documentation
Experience and Skills

Qualifications:
Experience working with Military Health Systems (MHS) and/or Veteran Health Administration (VHA) and Veteran Benefits Administration (VBA) data systems, such as Management Analysis and Reporting Tool (M2), MHS Data Repository (MDR) and Defense Manpower Data Center (DMDC)/Defense Eligibility and Enrollment Systems (DEERS), VA CDW and DSS.
Proficient in Python, R, SAS, Tableau, Shiny, SQL, and Hadoop ecosystem
Exposure to distributed files frameworks including Hive and Spark
Experience in leveraging machine learning algorithms to perform predictive modeling and forecasting.
Experience of performing statistical modeling with multiple regression techniques, variable selection methods, time series analyses, and neural networks in Python, R, and/or SAS
Experience of utilizing Python or R in data analytics to collect, understand, transform, cleanse, store, and share data in a privacy-preserving way
Proficient in data visualization tools to design report and graphs to identify autonomous patterns and behaviors
Experience with text analytics including Natural Language Processing
Strong background in mathematics, statistics, and probability preferred
Applicants must possess, at a minimum, a favorably adjudicated National Agency Check with Inquiries (NACI) or an equivalent or higher investigation
Education:

Master's degree in Data Science, Statistics, Computer Science, or an associated technical discipline with three (3) years minimum experience in data analytics, including providing analytical management by planning, coordinating and directing programs, conducting surveys and studies, and special projects OR

Bachelor's degree in one of the above disciplines with eight (8) years minimum experience in data analytics, including providing analytical management by planning, coordinating and directing programs, conducting surveys and studies, and special projects.","Knowesis Inc.
4.4","San Antonio, TX",Consulting,Business Services
Data Scientist,"Job Description
Required Skills:
Python/Machine Language/SAS /Python - Data Science","Sysmind LLC
4.1","San Antonio, TX",Enterprise Software & Network Solutions,Information Technology
Data Scientist,"Data Scientist 6 years of exp Hands on Exp with the following Python, R studios, sas statistical modeling mehnaz At sierrasoln DOT com 5202888121","Sierra Business Solution LLC
4.1","San Antonio, TX",-1,-1
Data Scientist,"Ke`aki Technologies, LLC is looking for a qualified Data Scientist to support our contract with OMNIBUS.Description of Responsibilities:* Provide analytical tools and resources to assess the health of the Military Health System (MHS) beneficiary population.* Provide technical expertise in the areas of prevention, managed care, medical readiness issues, health promotion, clinical safety and quality, and other health Service-related issues in order to support the DHA.* Perform clinical and business analytical studies using accepted data science techniques to provide insight into areas of trending/improvement for prevention, managed care, medical readiness issues, health promotion, clinical safety and quality, and other health Service-related issues.* Aggregate and analyze population health data to respond to questions from the various Congressional inquiries, DoD senior leaders, DHA, Services' Surgeon General, Service-specific Headquarters agencies, and the MTFs.* Access, validate and analyze information about the MHS population by developing, validating and linking various medical, safety, environmental, occupational and personnel databases.* Identify and troubleshoot data import, analysis, and display errors from multiple data sources.* Provide data analysis and decision support using research expertise as well as literature review/evidence-base to develop clinical and business measures and prototypes of health information technology (IT) tools, programs, procedures, services or databases to support DHA's goal of building a managed healthcare system that considers and optimizes safety, quality, cost and access.* Research, identify and apply, when available, national/standardized benchmarks and thresholds to DHA/MHS metrics as appropriate or the contractor shall identify reasons established benchmarks/thresholds/methods are not appropriate/relevant.* Provide technical knowledge to customers, internal and external to DHA, regarding study design and methodologies. Provide program management to refine the business and clinical measures and prototypes for optimal implementation by DHA and other agencies/MHS as appropriate.REQUIRED SKILLS AND EXPERIENCE:* Must have experience with Data Modeling and the application of Predictive Analytics.* Mush have expert level skills in one or more of the following: Python, R, SQL, SAS, Tableau/Tableau Creator and Application/Dashboard Development.* Must have a three year experience data mining and analysis of MHS health data.* Able to read, write, speak and understand English.* Proven ability to synthesize disparate facts from multiple sources and coalesce into an accurate and useful analytic product, incorporating Service and MHS strategic goals for use by leadership in both tactical and strategic decision making.* Demonstrated ability to provide accurate and timely analytical products containing well-reasoned and cogent discussion points providing leadership with substantiated options or courses of action.* Demonstrated ability to organize/participate/lead working groups to develop analytic products and byproducts or to develop/understand processes leading to effective optimization of analytic efforts.* Demonstrated ability to effectively and clearly communicate analytical discoveries and appropriate recommendations/mitigation strategies to all levels of customers including Senior DHA leadership.* Demonstrated advanced proficiency in Microsoft Office products PLUS additional software/hardware skills and capabilities.* Ability to critically examine and evaluate, problem-solve.* Demonstrated ability to undertake and complete multiple tasks with multiple deadlines simultaneously.* Ability to deliver products on time, on schedule, within budget.* Flexibility and ability to adapt to rapidly changing and often time-constrained environment.* Ability to acquire skills/capabilities necessary to meet growing needs/demands of systems/software/hardware.DEGREE/EDUCATION/CERTIFICATION REQUIREMENT:* Master's degree in Public Health, Health Services Research, Epidemiology, Mathematics, Biostatistics, Statistics, Informatics or related areas, or previous participation in advanced training/program with one of those related areas, and identified as a Fellow in their area of expertise is required.* Other significant related clinical/medical/health data experience such as previous participation in an analytics/quantitative field fellowship/training may be considered as an appropriate substitute for education, but minimum of Bachelor's degree in above areas required unless otherwise specified and with few exceptions.CITIZENSHIP/SECURITY CLEARANCE REQUIREMENTS:Must be able to pass a NACI background checkKe`aki Technologies LLC is a fast-growing government service provider. Employees enjoy competitive salaries; a 401K plan with company match; medical, dental, disability, and life insurance coverage; tuition reimbursement; paid vacation and sick time; and 10 paid holidays. Ke`aki Technologies is proud to be an equal opportunity employer.We are an Equal Opportunity/Affirmative Action Employer of individuals with disabilities and veterans. We are proud to state that we do not discriminate in employment decisions on the basis of race, color, religion, sex, pregnancy, sexual orientation, gender identity, national origin, age, protected veteran status, or disability status. If you are a person with a disability and you need an accommodation during the application process, please click here to request accommodation. We E-Verify all employees.The Alaka`ina Foundation Family of Companies (FOCs) is comprised of industry-recognized government service firms designated as Native Hawaiian Organization (NHO)-owned and 8(a) certified businesses. The Family of Companies (FOCs) includes Ke`aki Technologies, Laulima Government Solutions, Kupono Government Services, and Kapili Services, Po`okela Solutions, Kikaha Solutions, LLC, and Pololei Solutions, LLC. Alaka`ina Foundation activities under the 501(c)3 principally benefit the youth of Hawaii through charitable efforts which includes providing innovative educational programs that combine leadership, science & technology, and environmental stewardship.For additional information, please visit www.alakainafoundation.com.#Monster",Alakaina Family of Companies,"San Antonio, TX",-1,-1
Data Scientist,"*Current employees and contingent workers click** **here** at https://wd5.myworkday.com/iheartmedia/d/task/3005$4482.htmld **to apply and search by the Job Posting Title.**
iHeartMedia
*Job Summary:**
iHeartMedia is the number one audio company in the United States, reaching nine out of 10 Americans every month - and with its quarter of a billion monthly listeners, has a greater reach than any other media company in the U.S. The company's leadership position in audio extends across multiple platforms including 850 live broadcast stations; streaming music, radio and on demand via its iHeartRadio digital service available across more than 250 platforms and 2,000 devices including smart speakers, digital auto dashes, tablets, wearables, smartphones, virtual assistants, TVs and gaming consoles; through its influencers; social; branded iconic live music events; and podcasts as the #1 commercial podcast publisher globally. iHeartMedia also leads the audio industry in analytics and attribution technology for its marketing partners, using data from its massive consumer base.

The Data Scientist will provide research, modeling, analysis, and guidance using Advanced Analytics and Data Science techniques to develop and support data and model-driven decision making through leading-edge business solutions. The Data Scientist will engage directly with business and technology partners to research, identify, and seek out information, facts, and data, and will conduct and promote scientific, inquisitive, and innovative approaches to business decision problems and technical solutions.

Responsibilities:

+ Demonstrate passion about using data assets and mathematical modeling to optimize systems, processes, and products across iHeartMedia

+ Use emerging tools and technology to develop advanced analytics models and automation in content programming, ad sales and operations, consumer insights, music research, audience attribution, demand and revenue forecasting, and other areas of the company

+ Assist or lead the formulation, calibration, validation, and implementation of predictive analytics, statistical, and machine learning models

+ Employ a pragmatic approach to evaluate new algorithms and technologies for positive impact within iHeartMedia

+ Communicate complex solutions and ideas to a variety of stakeholders (other team members, IT leadership, and business leaders) in easily understandable language

+ Work on a number of projects as a member of the project team and/or as an individual contributor

+ Write code that meets standards and delivers desired functionality using agreed upon technology

+ Participate in system and user acceptance testing

+ Participate in project planning sessions to gather user requirements

+ Assist in the preparation of time estimates for project schedules

+ Troubleshoot production problems within area of expertise

+ Utilize and stay current in programming languages and software technology

Qualifications:

+ Master's Degree in Statistics, Applied Mathematics, Operations Research or a related analytical field - Ph.D. desired

+ 2+ years of commercial experience in a data science, machine learning, or predictive analytics role, formulating and implementing predictive analytics models

+ A demonstrable scientific foundation and understanding of concepts of predictive analytics and data science such as theoretical statistics, estimation theory, simulation, consumer choice modeling, machine learning, etc.

+ Solid programming skills in a general-purpose language and expertise in Python or R

+ Exceptional analytical, decision-making, and problem-solving skills as well as solid communication and presentation skills with technical and non-technical audiences

+ Experience and understanding of software development practice concepts and technology obtained through formal training and/or work experience
*Location**
San Antonio, TX: 20880 Stone Oak Parkway, 78258

Position Type

Regular

The Company is an equal opportunity employer and will not tolerate discrimination in employment on the basis of race, color, age, sex, sexual orientation, gender identity or expression, religion, disability, ethnicity, national origin, marital status, protected veteran status, genetic information, or any other legally protected classification or status.

Our organization participates in E-Verify. Click here at http://iheartmediacareers.com/Pages/EEO.aspx to learn about E-Verify.

Current employees and contingent workers click here at https://wd5.myworkday.com/iheartmedia/d/task/3005$1999.htmld to apply and search by the Job Posting Title.

iHeartMedia is the number one audio company in the United States, reaching nine out of 10 Americans every month - we specialize in radio, digital, social, podcasts, influencers, data, and events across the nation and provide premier opportunities for advertisers.

Visit iHeartMedia.com at https://iheartmedia.com/ to learn more about us.","iHeartMedia
3.2","San Antonio, TX",Radio,Media
Data Scientist,"Job Description

• Master's / bachelor’s degree in computer science, Applied Mathematics, Quantitative Economics, Statistics, or related field.

• 5-8 years of experience in predictive modeling, large data analysis and computer science

• Experience in modeling, machine learning, and other advanced mathematical techniques (e.g., neural nets, simulation, graph analysis)

• Experience using statistical computer languages (SAS, Python, R, PL SQL) to manipulate data and draw insights from large data sets.

• Expertise in experimental design, advanced statistical analysis, and modeling to discover key relationships in data and applying that information to predict likely future outcomes; fluent in regression, classification, tree-based models, clustering methods, text mining, and neural networks.

• Excellent written and verbal communication skills for coordinating across teams

Job Function

FINANCE

Role

Scientist

Job Id

158701

Desired Skills

Data scientist

Desired Candidate Profile

Qualifications :
BACHELOR OF COMPUTER SCIENCE","Tata Consultancy Services (North America)
3.7","San Antonio, TX",IT Services,Information Technology
Data Scientist,"Ke`aki Technologies, LLC is looking for a qualified Data Scientist t o support our contract with OMNIBUS.

Description of Responsibilities:

Provide analytical tools and resources to assess the health of the Military Health System (MHS) beneficiary population.
Provide technical expertise in the areas of prevention, managed care, medical readiness issues, health promotion, clinical safety and quality, and other health Service-related issues in order to support the DHA.
Perform clinical and business analytical studies using accepted data science techniques to provide insight into areas of trending/improvement for prevention, managed care, medical readiness issues, health promotion, clinical safety and quality, and other health Service-related issues.
Aggregate and analyze population health data to respond to questions from the various Congressional inquiries, DoD senior leaders, DHA, Services Surgeon General, Service-specific Headquarters agencies, and the MTFs.
Access, validate and analyze information about the MHS population by developing, validating and linking various medical, safety, environmental, occupational and personnel databases.
Identify and troubleshoot data import, analysis, and display errors from multiple data sources.
Provide data analysis and decision support using research expertise as well as literature review/evidence-base to develop clinical and business measures and prototypes of health information technology (IT) tools, programs, procedures, services or databases to support DHAs goal of building a managed healthcare system that considers and optimizes safety, quality, cost and access.
Research, identify and apply, when available, national/standardized benchmarks and thresholds to DHA/MHS metrics as appropriate or the contractor shall identify reasons established benchmarks/thresholds/methods are not appropriate/relevant.
Provide technical knowledge to customers, internal and external to DHA, regarding study design and methodologies. Provide program management to refine the business and clinical measures and prototypes for optimal implementation by DHA and other agencies/MHS as appropriate.

REQUIRED SKILLS AND EXPERIENCE:

Must have experience with Data Modeling and the application of Predictive Analytics.
Mush have expert level skills in one or more of the following: Python, R, SQL, SAS, Tableau/Tableau Creator and Application/Dashboard Development.
Must have a three year experience data mining and analysis of MHS health data.
Able to read, write, speak and understand English.
Proven ability to synthesize disparate facts from multiple sources and coalesce into an accurate and useful analytic product, incorporating Service and MHS strategic goals for use by leadership in both tactical and strategic decision making.
Demonstrated ability to provide accurate and timely analytical products containing wellreasoned and cogent discussion points providing leadership with substantiated options or courses of action.
Demonstrated ability to organize/participate/lead working groups to develop analytic products and byproducts or to develop/understand processes leading to effective optimization of analytic efforts.
Demonstrated ability to effectively and clearly communicate analytical discoveries and appropriate recommendations/mitigation strategies to all levels of customers including Senior DHA leadership.
Demonstrated advanced proficiency in Microsoft Office products PLUS additional software/hardware skills and capabilities.
Ability to critically examine and evaluate, problem-solve.
Demonstrated ability to undertake and complete multiple tasks with multiple deadlines simultaneously.
Ability to deliver products on time, on schedule, within budget.
Flexibility and ability to adapt to rapidly changing and often time-constrained environment.
Ability to acquire skills/capabilities necessary to meet growing needs/demands of systems/software/hardware.

DEGREE/EDUCATION/CERTIFICATION REQUIREMENT:

Masters degree in Public Health, Health Services Research, Epidemiology, Mathematics, Biostatistics, Statistics, Informatics or related areas, or previous participation in advanced training/program with one of those related areas, and identified as a Fellow in their area of expertise is required.
Other significant related clinical/medical/health data experience such as previous participation in an analytics/quantitative field fellowship/training may be considered as an appropriate substitute for education, but minimum of Bachelors degree in above areas required unless otherwise specified and with few exceptions.

CITIZENSHIP/SECURITY CLEARANCE REQUIREMENTS:

Must be able to pass a NACI background check

Ke`aki Technologies LLC is a fast-growing government service provider. Employees enjoy competitive salaries; a 401K plan with company match; medical, dental, disability, and life insurance coverage; tuition reimbursement; paid vacation and sick time; and 10 paid holidays. Ke`aki Technologies is proud to be an equal opportunity employer.

We are an Equal Opportunity/Affirmative Action Employer of individuals with disabilities and veterans. We are proud to state that we do not discriminate in employment decisions on the basis of race, color, religion, sex, pregnancy, sexual orientation, gender identity, national origin, age, protected veteran status, or disability status. If you are a person with a disability and you need an accommodation during the application process, please click here to request accommodation. We E-Verify all employees.

The Alaka`ina Foundation Family of Companies (FOCs) is comprised of industry-recognized government service firms designated as Native Hawaiian Organization (NHO)-owned and 8(a) certified businesses. The Family of Companies (FOCs) includes Ke`aki Technologies, Laulima Government Solutions, Kūpono Government Services, and Kapili Services, Po`okela Solutions, Kīkaha Solutions, LLC, and Pololei Solutions, LLC. Alaka`ina Foundation activities under the 501(c)3 principally benefit the youth of Hawaii through charitable efforts which includes providing innovative educational programs that combine leadership, science & technology, and environmental stewardship.

For additional information, please visit www.alakainafoundation.com.

#Monster","Alaka`ina Foundation Family of Companies
3.6","San Antonio, TX",-1,-1
Data Scientist,"Ability to develop analytics for multiple cyber weapon systems with many different infrastructure and end-point devices. Ability to incorporate predictive, descriptive, and presumptive modeling; machine learning; artificial intelligence into analytics. Must be able to code proficiently in one or more of the following languages: Python, R, Scala, Spark, and Maven. Develop algorithms in one or more of the following Machine Learning areas: anomaly detection, one/few-shot learning, deep learning, unsupervised feature learning, ensemble methods, probabilistic graphical models, reinforcement learning. Ability to develop analytics based upon the Mitre ATT&CK Matrix or other applicable CS&D framework to discover, identify, characterize, and/or create signatures for cyberspace threat activity. Ability to assist in the development and implementation of a data analytics program. Develop robust documentation and comprehensive user manuals for all developed projects

Original Hire Document for data scientist below:

Job Responsibilities:

· Perform big data analysis on information technology infrastructure and end-point devices

· Customer outreach and engagement

· Problem solving

· Time management

· Collaborate with others

· Mission focused

· Deliver findings

· Accept and assess customer data, dashboard, requirements

· Identify new ways to visualize and analyze data

· Develop analytics to identify anomalous activity based on customer requirements

· Perform hunt operations identifying anomalous activity

· Produce reports based on misconfigurations and/or anomalous activity discovered through analysis

Knowledge/Skills Ability:

Required:

· Ability to analyze and assess software development or data acquisition requirements and determine optimum, cost-effective solutions.

· Proficiency in one or more big data programming languages, such as R, Python, Scala, or Spark and Maven.

· Experience working with a hybrid team of analysts, visualization experts, engineers, and developers to conduct research, and build and deploy complex, but easy-to-use analytical platforms.

· Previous experience performing research in Data Analytics or big data.

· Be Director of Central Intelligence Directives 6/4 eligible (Top Secret) with a current Single Scope Background Investigation (SSBI)

Minimum Experience/Education:

· At least one (1) of the following:

· One (1) year experience in cyberspace operations

· IAT Level 1 per DoD 8140 (Net+, Sec+, etc.)

· Experience on National/Service cyber weapon system/platform within last five years

Highly Desired:

· Education/ Certifications:

· 4+ years of experience in data analytics or quantitative intelligence analysis

· Four (4) years of experience in an intelligence field at a tactical or operational level

· DoD 8570 IAT related BA/BS degree

*BEAT LLC IS AN EQUAL OPPORTUNITY EMPLOYER - DISABILITY AND VETERANS*","B E A T LLC
4.9","San Antonio, TX",Telecommunications Services,Telecommunications
Data Scientist,"Job Title: Data Scientist
Location: San Antonio, TX
Duration: Full Time

Required Skills:
Python/Machine Language/SAS /Python - Data Science
Job Type: Full-time","Horizon Corp
3.5","San Antonio, TX",Investment Banking & Asset Management,Finance
Data Scientist,"Data Scientist
Location


TX - San Antonio

Job Code

6688

# of openings

1

Apply Now

Ke`aki Technologies, LLC is looking for a qualified Data Scientist to support our contract with OMNIBUS.

Description of Responsibilities:
Provide analytical tools and resources to assess the health of the Military Health System (MHS) beneficiary population.
Provide technical expertise in the areas of prevention, managed care, medical readiness issues, health promotion, clinical safety and quality, and other health Service-related issues in order to support the DHA.
Perform clinical and business analytical studies using accepted data science techniques to provide insight into areas of trending/improvement for prevention, managed care, medical readiness issues, health promotion, clinical safety and quality, and other health Service-related issues.
Aggregate and analyze population health data to respond to questions from the various Congressional inquiries, DoD senior leaders, DHA, Services’ Surgeon General, Service-specific Headquarters agencies, and the MTFs.
Access, validate and analyze information about the MHS population by developing, validating and linking various medical, safety, environmental, occupational and personnel databases.
Identify and troubleshoot data import, analysis, and display errors from multiple data sources.
Provide data analysis and decision support using research expertise as well as literature review/evidence-base to develop clinical and business measures and prototypes of health information technology (IT) tools, programs, procedures, services or databases to support DHA’s goal of building a managed healthcare system that considers and optimizes safety, quality, cost and access.
Research, identify and apply, when available, national/standardized benchmarks and thresholds to DHA/MHS metrics as appropriate or the contractor shall identify reasons established benchmarks/thresholds/methods are not appropriate/relevant.
Provide technical knowledge to customers, internal and external to DHA, regarding study design and methodologies. Provide program management to refine the business and clinical measures and prototypes for optimal implementation by DHA and other agencies/MHS as appropriate.
REQUIRED SKILLS AND EXPERIENCE:
Must have experience with Data Modeling and the application of Predictive Analytics.
Mush have expert level skills in one or more of the following: Python, R, SQL, SAS, Tableau/Tableau Creator and Application/Dashboard Development.
Must have a three year experience data mining and analysis of MHS health data.
Able to read, write, speak and understand English.
Proven ability to synthesize disparate facts from multiple sources and coalesce into an accurate and useful analytic product, incorporating Service and MHS strategic goals for use by leadership in both tactical and strategic decision making.
Demonstrated ability to provide accurate and timely analytical products containing well‐reasoned and cogent discussion points providing leadership with substantiated options or courses of action.
Demonstrated ability to organize/participate/lead working groups to develop analytic products and byproducts or to develop/understand processes leading to effective optimization of analytic efforts.
Demonstrated ability to effectively and clearly communicate analytical discoveries and appropriate recommendations/mitigation strategies to all levels of customers including Senior DHA leadership.
Demonstrated advanced proficiency in Microsoft Office products PLUS additional software/hardware skills and capabilities.
Ability to critically examine and evaluate, problem-solve.
Demonstrated ability to undertake and complete multiple tasks with multiple deadlines simultaneously.
Ability to deliver products on time, on schedule, within budget.
Flexibility and ability to adapt to rapidly changing and often time-constrained environment.
Ability to acquire skills/capabilities necessary to meet growing needs/demands of systems/software/hardware.
DEGREE/EDUCATION/CERTIFICATION REQUIREMENT:
Master’s degree in Public Health, Health Services Research, Epidemiology, Mathematics, Biostatistics, Statistics, Informatics or related areas, or previous participation in advanced training/program with one of those related areas, and identified as a Fellow in their area of expertise is required.
Other significant related clinical/medical/health data experience such as previous participation in an analytics/quantitative field fellowship/training may be considered as an appropriate substitute for education, but minimum of Bachelor’s degree in above areas required unless otherwise specified and with few exceptions.
CITIZENSHIP/SECURITY CLEARANCE REQUIREMENTS:

Must be able to pass a NACI background check

Ke`aki Technologies LLC is a fast-growing government service provider. Employees enjoy competitive salaries; a 401K plan with company match; medical, dental, disability, and life insurance coverage; tuition reimbursement; paid vacation and sick time; and 10 paid holidays. Ke`aki Technologies is proud to be an equal opportunity employer.

We are an Equal Opportunity/Affirmative Action Employer of individuals with disabilities and veterans. We are proud to state that we do not discriminate in employment decisions on the basis of race, color, religion, sex, pregnancy, sexual orientation, gender identity, national origin, age, protected veteran status, or disability status. If you are a person with a disability and you need an accommodation during the application process, please click here to request accommodation. We E-Verify all employees.

The Alaka`ina Foundation Family of Companies (FOCs) is comprised of industry-recognized government service firms designated as Native Hawaiian Organization (NHO)-owned and 8(a) certified businesses. The Family of Companies (FOCs) includes Ke`aki Technologies, Laulima Government Solutions, Kūpono Government Services, and Kapili Services, Po`okela Solutions, Kīkaha Solutions, LLC, and Pololei Solutions, LLC. Alaka`ina Foundation activities under the 501(c)3 principally benefit the youth of Hawaii through charitable efforts which includes providing innovative educational programs that combine leadership, science & technology, and environmental stewardship.

For additional information, please visit www.alakainafoundation.com.

#Monster","Ke`aki Technologies, LLC
3.4","San Antonio, TX",Computer Hardware & Software,Information Technology
Data Scientist,"Provide Research Project Development and Support
Maintains a basic knowledge of human physiology, medical burn/trauma/critical care, combat casualty care concept, medical informatics and DoD clinical information systems (e.g. Electronic Medical Record.)
Conducts literature reviews in medical and information technology fields related to our Task Area goals and key research areas of interest.
Advances the science of information technology research, Advanced Technology Development by writing and submitting intramural and extramural grant proposals
Assists in the writing Cooperative Research and Development Agreements, Memorandums of Understanding and any other document required to collaborate with internal and external partners.
Independently conceptualizes, writes, develops and conducts laboratory, animal, non-human & human subject research protocols for execution consistent with the goals of the Task Area.
Works with the sponsors, collaborators, Principal/Associate investigators, Institutional Review Board and Institutional Animal Care and Use Committee, and client research support departments to coordinate activities for protocol approval and implementation and to assure that appropriate regulatory documentation is completed.
Assists in the internal and external assessment of adherence to protocols, ethical requirements, as well as relevant DoD and Institute regulations and guidance
Develops and maintains records of research activities, maintains research study regulatory readiness and assists in regulatory audits/inspections.
Manages research activities within a defined budget
Leads a team of software developers, clinicians and researchers; provides scientific research leadership and mentoring to junior researchers and fellows on team.
Participates in investigator/study and Task Area team meetings.
Data Collection and Analysis
Serves as a Primary or Associate Investigator on research protocols that involve multiple Task Areas and projects (collaborative efforts).
Collects data, documents experimental findings, summarizes data, prepares figures through use of available computer resources, and conducts preliminary analysis.
Develop schema templates and relational database repositories and utilize statistical processes and applications including JMP, SAS, Prism, and R-Studio for data input formats.
Writes code in Python, Java, SQL, Oracle Database, Java, R-language programming languages to support further development on artificial intelligence and clinical decision support tools
Possesses skills and familiarity utilizing computer dataset tools: Python, SQL, Oracle Database, Java, R-language
Performs appropriate statistical computations on raw data to determine significance, summarize results and draws appropriate conclusions.
Data Dissemination
Participates in the interpretation of results and prepares reports, abstracts, presentations and manuscripts for publication.
Prepares figures, tables, methodological text, photography, graphics, and image production, for study presentations and publications.
Participates in lectures, seminars, and conferences.
Presents research findings at military and scientific conferences.
Facilitates the gathering and sharing of relevant intellectual knowledge, expertise and data with clinical and research groups within the federal government, private sector and research facilities.
Prepares periodic and status reports, as required by investigators, administrators, funding agencies, and/or regulatory bodies.
Assists in the preparation for patent applications, intellectual property protections, invention disclosures, technology transfer etc…
Assists in the transition of TA developed technologies toward Advanced Development.
Required Experience:
A qualified data scientist will have hands-on experience - JMP, SAS, Prism, and R-Studio
Experience writing code in Python, Java, SQL, Oracle Database, Java, R-language programming languages
Experience with some number of the following statistical and predictive modeling approaches: Gaussian Process; Markov Models; Hierarchical Clustering; K-Means; Linear Regression; Logistic Regression; Monte Carlo Simulation; Neural Networks
5+ years of experience with the following:
Strong analytical skills (use of Microsoft Excel, Macros and/or Access to analyze data)
Strong presentation development and writing skills (e.g., proficient in Microsoft PowerPoint and Word)
Ability to facilitate client meetings and sessions to define client processes and needs
Ability to lead small teams to complete a project
Strong written and oral skills required
Experience in one of the following areas: Statistical Analysis, Strategic Management, or Data Analysis/Reporting
Minimum Bachelor's Degree in Business, Economics, Mathematics, Statistics, Data Science or Hard Sciences with a focus on research and analysis, Master’s Degree is preferred.

Additional Qualifications: Applicant selected must be a US citizen

Location: This work will be performed at the client site in San Antonio, TX.

Core hours of work are between the hours of 0800 to 1500 daily. Employees is expected to be available during core hours.

CICONIX, LLC is an Equal Opportunity Employer
Competitive market-based salary, commensurate with experience and education
Comprehensive benefits package available (Medical, Dental, PTO, 401k etc).","CICONIX, LLC
4.0","San Antonio, TX",Federal Agencies,Government
Data Scientist,"Tuknik Government Services (TGS) is looking for an experienced individual to perform the duties of a Data Scientist to support our government client in San Antonio, TX.

We offer competitive compensation and an extraordinary benefits package including health, dental and vision insurance, 401K with company matching, flexible spending accounts, paid holidays, three weeks paid time off, and more.

Essential Functions, Responsibilities & Duties may include, but are not limited to:
Apply statistics, machine learning and analytic approaches to answer key intelligence questions, producing results and re-usable products that provide real value to Intelligence Analysts
Apply machine learning techniques to identify and transform data features, find hidden patterns and trends, build and optimize classifiers, create automated anomaly detection systems, and automate steps of the intelligence process
Evaluate statistical models to determine the validity of analyses, implement evaluated models into production by collaborating with software developers, periodically re-evaluate and refine machine learning models being used in production
Develop and refine date sets to achieve stakeholder goals and objectives as requested
Work with analysts to interpret analytic results and refine analysis as needed
Coordinate with Data Analysts to refine and implement models and monitor outcomes
Develop processes and tools to monitor and analyze model performance and data accuracy
Communicate results and ideas to key decision makers, analysts and other stakeholders
Advise on the interpretation and use of data intelligence products, quality assessments and applications
Collaborate with Intelligence Analysts to understand needs and devise possible solutions
Assess training requirements based on current system and functional baseline
Develop training artifacts in support of operations including Standard Operating Procedures (SOPs), and Tactics, Techniques and Procedures (TTPs)
Required Qualifications:
Top Secret clearance with SCI eligibility
MS in Data Science, Statistics, Applied Math, or related field
Two years of experience leading data science projects is desired
Five years of intelligence analysis experience is desired
Demonstrated proficiency with R or Python, and SQL to manipulate data and draw insights from large and small data sets
Demonstrated proficiency in a variety of supervised and unsupervised machine learning techniques (clustering, decision tree learning, artificial neural networks, etc.) and their real-world advantages/drawbacks
Demonstrated proficiency in advanced statistical techniques and concepts (regression, properties of distributions, statistical tests and proper usage, etc.) and experience with applications
Demonstrated proficiency with common data science libraries
Demonstrated proficiency visualizing/presenting data for stakeholders
Demonstrated proficiency with MS Office tools including Excel, PowerPoint, and Word
Demonstrated proficiency with AWS, in particular products related to analytics, compute, database, developer tools, and machine learning
Experience with database solutions including SQL, NoSQL (e.g. MongoDB) and graph (e.g. Neo4j)
Experience with data visualization tools, such as D3.js, ggplot, Bokeh, etc.
Capability to recognize when Data Science can add value to an intelligence problem, and when it cannot
Ability to translate an intelligence problem into a Data Science problem, and to work with the Intelligence Analysts and ACE Chief to refine the understanding of the problem
Comfortable working in a dynamic environment with several ongoing concurrent projects; able to multitask, prioritize, and manage time effectively
Interpersonal skills and communication with all levels of leadership
A drive to learn and master new technologies and techniques; desire to maintain currency on latest industry trends including completing additional training; able to articulate trends and potential clearly and confidently
Creative problem solver who thrives when presented with a challenge; able to analyze problems and strategize for better solutions; strong problem-solving skills with an emphasis on production for re-use
Goal-oriented, encouraging to team and staff; comfortable as a team-player, leader and mentor
Working Environment & Conditions

This position is primarily indoors, consistent with a standard office position and has a noise level of mostly low to moderate. The incumbent is required to stand; walk; sit; use hands to finger, handle, or feel objects, tools, or controls; reach with hands and arms; talk and hear. The work load may require the incumbent to sit for extended periods of time. The incumbent must be able to read, do simple math calculations and withstand moderate amounts of stress. The incumbent must occasionally lift and/or move up to 25 lbs. Specific vision abilities required by the job include close vision, distance vision, color vision, depth perception, and the ability to adjust focus.

Our Equal Employment Opportunity Policy

The company is an equal opportunity employer. The company shall not discriminate against any employee or applicant because of race, color, religion, creed, sex, sexual orientation, gender or gender identity (except where gender is a bona fide occupational qualification), national origin, age, disability, military/veteran status, marital status, genetic information or any other factor protected by law. We are committed to equal employment opportunity in all decisions related to employment, promotion, wages, benefits and all other privileges, terms and conditions of employment.

The company is dedicated to seeking all qualified applicants. If you require an accommodation to navigate or to apply to a position on our website, please contact Heaven Wood via e-mail at accommodations@koniag.com or by calling 703-488-9377 to request accommodations. This contact information is used for accommodation requests only and cannot be used to inquire on a status of your application.","Koniag, Inc.
3.4","San Antonio, TX",Consulting,Business Services
Data Engineer,"Group O is seeking a strong candidate with advanced analytics experience to fill an exciting Data Engineer role for an AI partner to Fortune 500 companies. In this role, you will be a valuable in managing large amounts of data and implement loading disparate data sets while managing the technical communication between the team and client.

Implementation including loading from disparate data sets, preprocessing using Hive and Pig.
Manage the technical communication between the team and client
Work with big data team to deliver cutting edge solutions

2-5 years of demonstrable experience designing technological solutions to complex data problems, developing & testing modular, reusable, efficient and scalable code to implement those solutions.
Ideally, this would include work on the following technologies:
Proficiency in at least one of the following: R, C++ or Python (preferred). Scala knowledge a strong advantage.
Strong understanding and experience in distributed computing frameworks, particularly Apache Hadoop 2.0 (YARN; MR & HDFS) and associated technologies -- one or more of Hive, Sqoop, Avro, Flume, Oozie, Zookeeper, etc..
Hands-on experience with Apache Spark and its components (Streaming, SQL, MLLib) is a strong advantage.
Operating knowledge of cloud computing platforms (AWS, especially EMR, EC2, S3, SWF services and the AWS CLI)
Experience working within a Linux computing environment, and use of command line tools including knowledge of shell/Python scripting for automating common tasks
In addition, the ideal candidate would have great problem-solving skills, and the ability & confidence to hack their way out of tight corners.
Education:
Bachelor's degree in Computer Science or related technical degree","Group O
3.1","San Antonio, TX",Staffing & Outsourcing,Business Services
Statistician,"The U.S. Department of the Treasury has a distinguished history dating back to the founding of our nation. As the steward of U.S. economic and financial systems, Treasury is a major and influential leader in today's global economy. We have over 100,000 employees across the country and around the world. Come Join the Department of the Treasury and Invest in Tomorrow.
See Other Information for Locations
Positions are to be filled in the Large Business & International (LB&I), Data Solutions division.
Eight (8) positions are to be filled in any of the following locations:
Birmingham, AL
Fayetteville, AR
Little Rock, AR
Phoenix, AZ
El Monte, CA
Glendale, CA
Laguna Niguel, CA
Los Angeles, CA
Long Beach, CA
Oakland, CA
Sacramento, CA
San Diego, CA
San Francisco, CA
San Jose, CA
Santa Ana, CA
Lakewood, CO
Hartford, CT
New Haven, CT
Norwalk, CT
Washington, DC
Newark, DE
Miami, FL
Ft. Myers, FL
Jacksonville, FL
Maitland, FL
Plantation, FL
Tampa, FL
West Palm Beach, FL
Atlanta, GA
Honolulu, HI
Des Moines, IA
Chicago, IL
Downers Grove, IL
Schiller Park, IL
Springfield, IL
Indianapolis, IN
Wichita, KS
Louisville, KY
New Orleans, LA
Boston, MA
Brockton, MA
Stoneham, MA
Southborough, MA
Baltimore, MD
Lanham-Seabrook, MD
Rockville, MD
Ann Arbor, MI
Clinton Township, MI
Detroit, MI
Farmington Hills, MI
Flint, MI
Grand Rapids, MI
Pontiac, MI
Bloomington, MN
Chesterfield, MO
Lee's Summit, MO
Charlotte, NC
Greensboro, NC
Raleigh, NC
Omaha, NE
Edison, NJ
Iselin, NJ
Mountainside, NJ
Paterson, NJ
Las Vegas, NV
Albany, NY
Bethpage, NY
Buffalo, NY
New York, NY
Rochester, NY
Cincinnati, OH
Columbus, OH
Independence, OH
Oklahoma City, OK
Tulsa, OK
Portland, OR
Philadelphia, PA
Pittsburgh, PA
King Of Prussia, PA
Guaynabo, PR
Warwick, RI
Franklin, TN
Memphis, TN
Nashville, TN
Austin, TX
Farmers Branch, TX
Fort Worth, TX
Houston, TX
San Antonio, TX
Ogden, UT
Salt Lake City, UT
Norfolk, VA
Richmond, VA
Vienna, VA
Seattle, WA
Milwaukee, WI
Waukesha, WI
Kearneysville, WV
Martinsburg, WV
WHAT DOES A DATA SCIENTIST DO? The Data Scientist utilizes advanced analytical, statistical, and computer programming skills to develop data- driven solutions to difficult business challenges. As a data scientist, you are responsible for conducting data-centric projects to provide insight and informed decisions for mission- oriented programs of the Internal Revenue Service (IRS), which may impact multiple program segments, divisions, the Service, or segments of the taxpayer population. This is accomplished by utilizing a wide range of technical competencies such as statistics and machine learning, coding languages, data wrangling, and reporting and visualization techniques. The Data Scientist may lead team or cross functional projects, and will apply critical thinking, problem solving and ability to communicate complex analysis to advance the use of data-driven decision making in IRS operations.

WHAT IS THE LARGE BUSINESS AND INTERNATIONAL (LB&I) DIVISION OF THE INTERNAL REVENUE SERVICE? The Large Business and International (LB&I) business unit provides service and enforcement activities to support tax compliance of businesses and related entities with assets of $10 million or more, as well as small U.S. businesses engaged in international, U.S. citizens abroad, and foreign persons and businesses with a U.S. tax requirement.
As a Data Scientist, you will:
Serve as a technical expert with responsibility for the initiation, planning, implementation, controlling, modifying and executing of all or part of an entire project, including such tasks as formulation of workload estimates for program segments, specification of the methodology to be used, preparation of appropriate specifications and procedures, and review of computer systems specifications and materials and instructions needed for assuring the adequacy of the project’s design and objectives.
Explore novel methods of retrieving data and develop innovative recommendations to management and senior leadership as a means for making data driven decisions such as modification of processes and policies. Review, evaluate, validate, and document the results of the findings.
Assist the supervisor in determining the scope, goals and schedules for future programs in the Office. Collaborate with business or technology partners to understand business needs, identify opportunities, and develop and implement analytical solutions.
Identify and assess relevant data sources’ validity and reliability to meet project needs. Collate, clean, transform, analyze, and integrate structured and unstructured data from various sources in preparation for analysis.
Apply statistical methods and concepts including data mining, statistical theory and research procedures to test hypotheses using structured and unstructured data. Develop data product solutions to improve customer experiences, anomaly detection, and business outcomes. Develop proofs of concept or demonstrations to evaluate feasibility of project solutions and recommend visualization strategies.
Document project work and review deliverables for validity, reliability and timeliness. Communicate analytic solutions to technical and non-technical stakeholders, including during executive- level and/or cross-agency meetings, in a clear and effective manner using oral and written communications.
Maintain knowledge of state-of-the-art innovations in data science from both academic and industry sources and identify opportunities for implementation. Engage in general professional development to improve knowledge of IRS processes/programs.
Apply computer based mathematical/statistical techniques using software. Lead or participate in statistical projects or studies in survey sampling (design and estimation), modeling, or statistical research. Apply knowledge of programming/coding language (i.e., SQL, SAS, SPSS, RStudio) to develop scripts or applications.
Act as a troubleshooter in resolving bottlenecks at any step in a project by identifying and proposing solutions; this may include coordination with other project team members or stakeholders to mitigate issues.

WHERE CAN I FIND OUT MORE ABOUT OTHER IRS CAREERS? If you want to find out more about IRS careers, visit us on the web at www.jobs.irs.gov
#LI-POST
You must meet the following requirements by the closing date of this announcement
BASIC QUALIFICATION REQUIREMENTS:

GS-1530 Statistician All Grades:
You must have a Bachelor's degree that included 15 semester hours in statistics (or in mathematics and statistics, provided at least 6 semester hours were in statistics), and 9 additional semester hours in one or more of the following: physical or biological sciences, medicine, education, or engineering; or in the social sciences including demography, history, economics, social welfare, geography, international relations, social or cultural anthropology, health sociology, political science, public administration, psychology, etc. Credit toward meeting statistical course requirements should be given for courses in which 50 percent of the course content appears to be statistical methods, e.g., courses that included studies in research methods in psychology or economics such as tests and measurements or business cycles, or courses in methods of processing mass statistical data such as tabulating methods or electronic data processing. OR
Combination of education and experience -- courses as shown above, plus appropriate experience or additional education. The experience should have included a full range of professional statistical work such as (a) sampling, (b) collecting, computing, and analyzing statistical data, and (c) applying statistical techniques such as measurement of central tendency, dispersion, skewness, sampling error, simple and multiple correlation, analysis of variance, and tests of significance.
GS-13 LEVEL: You must have one year of specialized experience at a level of difficulty and responsibility equivalent to the GS-12 grade level in the Federal service. Specialized experience for this position includes all of the following:
Experience applying project management principles on a data science project
Experience planning and executing a variety of data science and/or analytics projects.
Experience using data mining process models (such as CRISP-DM, SEMMA, etc.,) to design and execute data science project.
Experience preparing and analyzing structured and unstructured datasets to explorations and evaluating data science centric models.
Experience working with multiple data types and formats as a part of a data science project.
Experience applying a range of analytic approaches, including (but not limited to) machine learning, text analytics, and natural language processing; graph theory, link analysis and optimization models; complex adaptive systems; and/or deep learning neural networks that are part of the exploration.
Experience coding in various programming languages (such as R, Python, SQL, or JAVA) to conduct various phases of data science projects.
Experience creating and querying different datastores and architectures (such as Sybase, Oracle, and open-source databases) to work with various types of data as part of the data science project.
Experience using tools for data visualization (graphs, tables, charts, etc.,) and end-user business intelligence.
-The experience may have been gained in the public sector, private sector or Volunteer Service. One year of experience refers to full-time work; part-time work is considered on a prorated basis.
-To ensure full credit for your work experience, please indicate dates of employment by month/year, and indicate number of hours worked per week, on your resume.","Internal Revenue Service
3.5","San Antonio, TX",Federal Agencies,Government
Data Analyst,"Job Description
Job description
Interpret data, analyze results using statistical techniques and provide ongoing reports
Develop and implement databases, data collection systems, data analytics and other strategies that optimize statistical efficiency and quality
Acquire data from primary or secondary data sources and maintain databases/data systems
Identify, analyze, and interpret trends or patterns in complex data sets
Filter and “clean” data by reviewing computer reports, printouts, and performance indicators to locate and correct code problems
Work with management to prioritize business and information needs
Locate and define new process improvement opportunities
Requirements
Proven work experience as a data analyst or business data analyst
Technical expertise regarding data models, database design development, data mining and segmentation techniques
Strong knowledge of and experience with reporting packages (Business Objects etc), databases (SQL etc), programming (XML, Javascript, or ETL frameworks)
Knowledge of statistics and experience using statistical packages for analyzing datasets (Excel, SPSS, SAS etc)
Strong analytical skills with the ability to collect, organize, analyze, and disseminate significant amounts of information with attention to detail and accuracy
Adept at queries, report writing and presenting findings
Master's in Computer Science or Engineering Management or Project Management or Information Systems/Technology (Preferred)
Powered by JazzHR

tgfzjKcdkk","Staffigo Technical Services, LLC
5.0","San Antonio, TX",IT Services,Information Technology
Data Analyst,"The Information Security team is sourcing for an additional analyst to support the increasing demand for data analytics and the publication of routine metrics and reporting. Key Responsibilities Support the Metrics and Reporting team via the delivery of adhoc and routine reporting needs. Support the maturity of this new team as it develops an operational model in a tracking system to manage and measure workloads within the team Use knowledge of data structures and sources to extract data and develop intuitive reporting to Information Security management and stakeholders Deliver adhoc reporting on a flexible schedule Facilitate requirements for new reporting needs and changes to existing report Skills Data structures, SQL, MS Access, scripting and querying languages, data mining and analytics Qualifications 3+ years experience in similar role Problem solving and investigating Articulate in English written and spoken","Ionidea
3.6","San Antonio, TX",IT Services,Information Technology
Data Analyst,"Job Description
JOB TITLE: Data Analyst

SALARY: $18.27+

Data Analyst

Under close supervision, this position is responsible for ongoing analysis of data and information, obtained from a variety of sources to ensure management and staff has actionable information to ensure quality data entry and integrity and contribute to meeting contracted performance measures.

OVERVIEW:

SUMMARY OF ESSENTIAL DUTIES AND RESPONSIBILITIES:

· Oversees, collects, compiles, analyzes, and interprets workforce data and information data for the workforce system, management and staff.

· Uses all reports generating methods and information technologies to extract, compile and analyze data; uses TWIST & WIT Web, ad-hoc and related methods to develop reports, review the information and provide meaningful feedback to management and staff.

· Provides detailed analysis of the data in support of the workforce system goals and provides staff with the tools to monitor and achieve performance targets.

· Participates in strategy development to meet/exceed performance measures.

· Provides quality analysis & workforce planning.

· Prepares and provide presentations for staff to individual or in a group setting.

· Provides technical assistance to staff regarding workforce programs, performance measures, and/or related policies and procedures.

· Runs ad hoc reports to meet requests and needs and utilizes external software to collect and analyze data.

· Apply proven principles of theory and design to build and manage a database.

· Implement best practices in information technology management.

· Determine significant features, advantages and disadvantages of various database systems.

· Provides monthly scorecards to gauge career center and staff performance.

· Monitors center staff caseloads and shares information with management.

· Reviews and processes data integrity (DINT) requests.

· Reviews and processes deletion requests.

· Reviews and processes merge of customer records requests and change of customer social security number requests.

· Performs other related duties as required.

Skills/Qualifications:

· Bachelor degree from an accredited university or college in a relevant field of study and 2 years of experience working in the public or private sector, preferably in a field of workforce development, or

· Associate Degree from accredited college with 4 years of experience working in the public or private sector, preferably in a field of workforce development, or

· High School Diploma or equivalent from an accredited educational institution with 6 years of experience working in the public or private sector, preferably in a field of workforce development.

· Prefer knowledge of workforce development programs, economic development, business intelligence, business trends and project management experience.

· Prefer work experience in a performance based environment, public or private, the ability to analyze and interpret information and data and provide relevant feedback for action.

· Strong leadership skills, ability to motivate and provide guidance to staff and management.

· Strong interpersonal skills; ability to communicate effectively and interact with all stakeholders; ability to develop solutions.

· Strong knowledge of effective management techniques and practices, including planning, developing and implementing strategies and assessing results.

· Analytical and problem solving skills.

· Must have a working knowledge of, and be familiar with Windows operating systems and client/server hosted and on-premise applications.

· Scripting languages (VBScript, JavaScript, etc.)

· Microsoft SQL database querying, scripting, and administration.

· Time management skills to stay on target with goals.

· Detail orientated and strong organizational skills.

· Excellent computer software skills for database and spreadsheet; advanced skills in Microsoft office suite, including Excel.

· Strong documentation skills.

· Extensive knowledge of workforce information systems, TWIST, WIT, and other relevant management information systems.

· The position is in the Workforce Solutions service delivery area. A Data Analyst must be able to relocate anywhere in the service delivery area.

· Ability to develop and maintain professional working relationships with management, coworkers, workers from other programs as well as the public.

· Bilingual English and Spanish preferred.

EEO/AA

C2 Global Professional Services, LLC reaffirms its commitment to the principles of equal opportunity and diversity. Our policy prohibits employment decisions based on race, color, religion, sex, gender, gender identity, sexual orientation, ancestry, pregnancy, medical condition, age, marital status, national origin, citizenship status, disability, genetic information, veteran status, or any other protected status in accordance with the requirements of all federal, state, and local laws. Further, the company takes affirmative action to ensure that applicants are employed, and employees are treated during employment without regard to any of these characteristics. Employment decisions can include hiring, firing, compensation, benefits, promotion, training selection, or other statuses or conditions of employment. All employment decisions will be made on the basis of individual skills, knowledge, abilities, job performance, and other appropriate qualifications.

Pre-employment Drug Testing/Background Check Required. C2 Global Professional Services, LLC is an equal opportunity employer/program. Auxiliary aids and services are available upon request to individuals with disabilities. Relay Texas: 800.735.2989 (TDD) and 800.735.2988 (Voice) or 711

Overview:

Under general supervision, this position is responsible for ongoing analysis of data and information, obtained from a variety of sources to ensure management and staff has actionable information to ensure quality data entry and integrity and contribute to meeting contracted performance measures.

Essential Duties and Responsibilities

· Oversees, collects, compiles, analyzes, and interprets workforce data and information data for the workforce system, management and staff.

· Uses all reports generating methods and information technologies to extract, compile and analyze data; uses TWIST & WIT Web, ad-hoc and related methods to develop reports, review the information and provide meaningful feedback to management and staff.

· Provides detailed analysis of the data in support of the workforce system goals and provides staff with the tools to monitor and achieve performance targets.

· Participates in strategy development to meet/exceed performance measures.

· Provides quality analysis & workforce planning.

· Prepares and provide presentations for staff to individual or in a group setting.

· Provides technical assistance to staff regarding workforce programs, performance measures, and/or related policies and procedures.

· Runs ad hoc reports to meet requests and needs and utilizes external software to collect and analyze data.

· Apply proven principles of theory and design to build and manage a database.

· Implement best practices in information technology management.

· Determine significant features, advantages and disadvantages of various database systems.

· Provides monthly scorecards to gauge career center and staff performance.

· Monitors center staff caseloads and shares information with management.

· Reviews and processes data integrity (DINT) requests.

· Reviews and processes deletion requests.

· Reviews and processes merge of customer records requests and change of customer social security number requests.

· Performs other related duties as required.

Skills/Qualifications:

· Bachelor degree from an accredited university or college in a relevant field of study and 2 years of experience working in the public or private sector, preferably in a field of workforce development, or

· Associate Degree from accredited college with 4 years of experience working in the public or private sector, preferably in a field of workforce development, or

· High School Diploma or equivalent from an accredited educational institution with 6 years of experience working in the public or private sector, preferably in a field of workforce development.

· Prefer knowledge of workforce development programs, economic development, business intelligence, business trends and project management experience.

· Prefer work experience in a performance based environment, public or private, the ability to analyze and interpret information and data and provide relevant feedback for action.

· Strong leadership skills, ability to motivate and provide guidance to staff and management.

· Strong interpersonal skills; ability to communicate effectively and interact with all stakeholders; ability to develop solutions.

· Strong knowledge of effective management techniques and practices, including planning, developing and implementing strategies and assessing results.

· Analytical and problem solving skills.

· Must have a working knowledge of, and be familiar with Windows operating systems and client/server hosted and on-premise applications.

· Scripting languages (VBScript, JavaScript, etc.)

· Microsoft SQL database querying, scripting, and administration.

· Time management skills to stay on target with goals.

· Detail orientated and strong organizational skills.

· Excellent computer software skills for database and spreadsheet; advanced skills in Microsoft office suite, including Excel.

· Strong documentation skills.

· Extensive knowledge of workforce information systems, TWIST, WIT, and other relevant management information systems.

· The position is in the Workforce Solutions service delivery area. A Data Analyst must be able to relocate anywhere in the service delivery area.

· Ability to develop and maintain professional working relationships with management, coworkers, workers from other programs as well as the public.

· Bilingual English and Spanish preferred.

Physical Demands:

The physical demands described here are representative of those that must be met by an employee to successfully perform the essential functions of this job. Reasonable accommodations may be made to enable individuals with disabilities to perform the essential functions. While performing the duties of this job, the employee is regularly required to stand, walk, sit, use hands for finger coordination, reach with arms and hands, pulling standard file cabinet and vertical file drawers, lift/carry 10 pounds of paper, drive a vehicle, stoop, kneel, talk and hear. Occasional travel required.

COMPANY OVERVIEW:

C2 Global Professional Services is an award-winning employment and training organization, that prepares and places people into productive jobs. We’re located in five regions in Texas and one in Florida. We strive to fulfill our mission by following our Core Values of “Respect, Communication, Customer Engagement and Ingenuity.”

Come and surround yourself with talented and professional individuals who have also taken the next step of making a difference in someone’s life. You would not only have a great and dedicated team to work with, but you would also be eligible to take advantage of a competitive benefits plan which includes:
Health Insurance (with no cost options for employee only plans)
Wellness Reimbursement
Generous Paid Time Off
Paid Parental Leave
401(K) with 6% Employer Match
Dental
Vision
Life Insurance
Short and Long Term Disability
Pet Insurance
Equal Opportunity Employer: minority/female/disability/veteran","C2 GPS- Alamo Workforce
3.4","San Antonio, TX",Consulting,Business Services
Data Engineer,"Data Engineer
Chargify | San Antonio, TX, USA

Chargify, a Scaleworks portfolio business is seeking an individual that is driven, intensely curious, and smart to join our team of developers, engineers, and data scientists. One day you might work with our front-end development team strategizing how to coordinate APIs and workflows to serve up historical data to customers. The next day you might assist our Operations team in getting our Data Scientists the data they need to compare the effectiveness of pricing strategies. The ideal candidate has a strong software engineering background, but gravitates towards building scalable data products.

Role Responsibilities
Ensure the reliability, efficiency, and scalability of the ETL system
Work closely with the development and data science teams to redesign data warehouse schemas
Perform and automate data preparation for internal consumption upon request
You’ll have opportunities to work on high impact projects that improve data availability/quality and provide reliable access to data for the analytics team and the rest of the business

Requirements
Experience with solution building and architecting with AWS
Expertise in data pipeline tools such as Airflow or Luigi
Expertise in SQL, SQL Tuning, schema design
Expertise in Ruby and Python, particularly with ensuring data quality across multiple datasets used for analytic purposes
Experience with database systems including MySQL, Elasticsearch, Postgres, Redshift, etc.
Great communication skills
Working knowledge of Jupyter
Bonus points for:
Bachelor’s degree in Computer Science, Computer Engineering, or equivalent field
Elasticsearch expertise
Worked with data infrastructure in a SaaS product
Knowledge of statistical sciences
Have worked with marketing organizations or advertising technologies
Have worked with Data Scientists

*No visa sponsorship is available for this position*

We are an equal opportunity employer and do not discriminate against protected characteristics. We guarantee that all candidates will be given the same consideration.","Scaleworks
4.5","San Antonio, TX",Computer Hardware & Software,Information Technology
Data Engineer,"Our direct end client in San Antonio, Texas is looking for 2 Data engineers for contract position. The candidate should be a data engineer who has build pipelines to ingest data into data lakes, understandanalyze data, script (SQL, UNIX), understand business process. A coder vs user of traditional ETL tools like Informatica. Soft skills are critical with this role - the manager is looking for a resource who is a problem solver, not just take direction. They need someone who can work independently, focus on the learning the data to relate it to the requirements. Key technical skills Big Data tools experience with SparkHiveImpala Datawarehouse experience with TeradatanetezzaGreenplum MPP Databases OR Hadoop Data Lake Experience Cloud Experience - AWS, Azure, or Google is a nice-to-have, but not required Build Data PipeLineELTETL using JAVA or Python or Linux scripting Advanced SQL development Experience The resource should be willing to relocate to San Antonio Job Summary Data Engineer. Responsible for developing and implementing data models for multiple business processes on client s data warehouse and big data analytics infrastructure within the Medical Solutions Division. This particular role will focus on developing datamarts and datasets in conjunction with analysts and data scientists. Principle Responsibilities (essential job duties and responsibilities) Design and implement data models, datamarts, and datasets on a modern data warehouse and data hub Interface directly with business and systems subject matter experts to understand analytic needs and determine logical data model requirements Develop and implement ETL processes across Hadoop, BI systems, and databases Work closely with data architects to identify common data requirements and develop shared solutions Develop close collaboration with senior analysts and data owners across multiple business domains Maintain data modeling standards and ETL best practices Support data model and ETL solutions in production Skills and Experiences Strong data warehouse and ETL background Advanced SQL programming capabilities. HiveImpala or Snowflake preferred Strong background in preparing data for analysis and reporting creating analytical datasets and working with others to define simple to use data models (i.e. star schema) Experience with analytical tools for data discovery modeling, visualization, and analysis Success in a highly dynamic technology demand driven environment with ability to shift priorities with agility Ability to go from whiteboard discussion to code Willingness to explore and implement new ideas and technologies Ability to effectively communicate with technical and non-technical audiences Ability to work independently with minimal supervision Minimum Qualifications 8+ years experience with SQL 6+ years experience with data modeling design and implementation 4+ years experience working directly with subject matter experts in both business and technology domains 4+ years experience with BI and analytic tools such as Tableau, Datameer, R, or similar Nice-to-have Hands-on experience with Cloudera or Snowflake Familiarity with Agile methodologies Education Bachelor s in Computer Science, Information Systems, Engineering, science discipline, or similar","York Solutions, LLC
3.5","San Antonio, TX",Staffing & Outsourcing,Business Services
Data Analyst,"Under the direction of the Data Analyst, the Quality Specialist II, will support activities and procedures associated with complaint data reporting and usage. The Complaints Analyst II will be responsible for pulling, interpreting, and generating metrics and reports for product complaint data from various sources for the local North America Regional Complaint Center as well as for the broader North America Region. Most reports are already established and require a high level of attention to detail in order to provide consistent and accurate information each time they are generated. Ad hoc reports are also required, and the associate will need strong critical-thinking and problem-solving skills in order to translate the requirements into usable and valuable deliverables. Must be highly skilled in verbal and written communication. Strong administrative and organizational skills; ability to work independently and with team. Other responsibilities may be delegated by the Data Coordinator as needed.

Duties:
Generate established reports and metrics in a timely manner. These range from daily, weekly, monthly, and yearly.
Generate ad hoc reports and metrics in a timely manner by transforming new and potentially complex requirements into actionable deliverables.
Monitor process performance to proactively assure complaint center metrics are met based on internal and external customer needs.
Engage with internal analysts throughout the world for data requests, verification, and alignment.
Present data and metrics to teams, leadership, and other stakeholders.
Understand the complaint handling process in order to generate meaningful reports and metrics.
Support data requests for site audits, CAPA investigations, and continuous improvement activities to support the Quality Management System.
Maintains annually competencies through training and documentation of training.
Understand the importance of request in order to properly triage to ensure that higher priority requests are processed first.
Provide feedback to management for compliant process improvement opportunities identified through data analysis.
Raise any escalated customer concerns to the next level of management.
May perform other duties as required.

Knowledge:
High level of problem identification, analysis, and formulation of conceptual/technical and business solutions.
Data extraction experience from a multitude of systems.
Provide support to customer facing teams.
Must be motivated, self-directed, and able to work with minimal supervision.
Ability to assess priorities.
Ability to take ownership, think independently and perform task with minimal supervision.
Teamwork and collaboration.
Bachelor's degree minimum, preferably in Life or Computer/Data Sciences, or in lieu of degree, education and 2+ years of relevant data analysis experience combination.
Stronger candidates will have knowledge of Quality System standards and regulations including 21 CFR 803 & 820, ISO 13485, and Canadian Regulations.

Skills:
Proficiency in data analysis tools and software, including Microsoft Excel at minimum.
Meticulous attention to detail
Strong time management skills
Effective communication
Excellent documentation skills
Ability and desire to learn quickly
Objectivity
Assertiveness
Thoroughness","Integrated Resources
3.1","San Antonio, TX",Staffing & Outsourcing,Business Services
Data Engineer,"Job Title Data Engineer Location San Antonio, TX(Remote till Covid-19) Duration Long term Contract Job Description Requirements ndash MUST HAVE all of the bullets below 5+ years Data Engineering experience Big Data tools experience with SparkHiveImpala Must Have Data Warehouse builds with TeradataNetezzaGreenplum OR lsquoHadoop Data Lakersquo experience Building Data PipelinesELTETL using Java or Python or Linux scripting Cloud experience AWS or Azure OR GCP Advanced SQL development Preferred ndash The strongest candidates will have Experience with 1 or more Talend, Ab Initio, Datastage, Informatica Oracle EBS Agile methodology environments BI and Analytics tools Tableau, Datameer, R, or similar Education Qualification Bachelor's Degree in Computer Science, Information Technology (IT), or closely related field. Master s in Computer Science or related degree Preferred. Contact Details Pawan Ph 312-967-6667 Email Pawan.drsrit.com Reliable Software is an Equal Opportunity Employer. Reliable Software does not discriminate on the basis of race, religion, color, sex, gender identity, sexual orientation, age, non-disqualifying physical or mental disability, national origin, veteran status or any other basis covered by appropriate law. All employment is decided on the basis of qualifications, merit, and business need.","Reliable Software Resources
4.0","San Antonio, TX",IT Services,Information Technology
Data Engineer,"Job Summary As part of Damanrsquos Data Engineering team, you will be architecting and delivering highly scalable, high performance data integration and transformation platforms. The solutions you will work on will include cloud, hybrid and legacy environments that will require a broad and deep stack of data engineering skills. You will be using core cloud data warehouse tools, hadoop, spark, events streaming platforms and other data management related technologies. You will also engage in requirements and solution concept development, requiring strong analytic and communication skills. Responsibilities Function as the solution lead for building the data pipelines to support the development enablement of Information Supply Chains within our client organizations ndash this could include building (1) data provisioning frameworks, (2) data integration into data warehouse, data marts and other analytical repositories (3) integration of analytical results into operational systems, (4) development of data lakes and other data archival stores. Optimally leverage the data integration tool components for developing efficient solutions for data management, data wrangling, data packaging and integration. Develop overall design and determine division of labor across various architectural components Deploy and customize Daman Standard Architecture components Mentor client personnel. Train clients on the Daman Integration Methodology and related supplemental solutions Provide feedback and enhance Daman intellectual property related to data management technology deployments Assist in development of task plans including schedule and effort estimation Skills and Qualifications Bachelorrsquos Degree or foreign equivalent in Computer Science, Electrical Engineering, Mathematics, Computer Applications, Information Systems or Engineering is required Experience building high-performance, and scalable distributed systems Good experience in migration from Netezza DB2 to Snowflake AWS cloud experience (EC2, S3, Lambda, EMR, RDS, Redshift) Experience in ETL and ELT workflow management Familiarity with AWS Data and Analytics technologies such as Glue, Athena, Spectrum, Data Pipeline Experience building internal cloud to cloud integrations is ideal Experience with streaming related technologies ex Spark streaming or other message brokers like Kafka is a plus 3+ years of Data Management Experience 3+ years of batch ETL tool experience (DataStage Informatica Talend) 3+ yearsrsquo experience developing, deploying and supporting scalable and high-performance data pipelines (leveraging distributed, data movement technologies and approaches, including but not limited to ETL and streaming ingestion and processing) 2+ yearsrsquo experience with Hadoop Ecosystem (HDFSS3, Hive, Spark) 2+ yearsrsquo experience in a software engineering, leveraging Java, Python, Scala, etc. 2+ yearsrsquo advanced distributed schema and SQL development skills including partitioning for performance of ingestion and consumption patterns 2+ yearsrsquo experience with distributed NoSQL databases (Apache Cassandra, Graph databases, Document Store databases) Experience in the financial services, banking and or Insurance industries is a nice to have Daman Is an Equal Opportunity Employer and All Qualified Applicants Will Receive Consideration for Employment Without Regard to Race, Color, Religion, Sex, National Origin, Disability Status, Protected Veteran Status, Or Any Other Characteristic Protected by Law.","Daman, Inc.
3.9","San Antonio, TX",-1,-1
Data Analyst,"Job Description:
Identify and implement process improvements Lead discussions with cross-functional teams on complex problems Oversee alignment of best practices and tools based on business needs.
Metadata and Data Quality Support.
metadata repository maintenance, access requests, and proper metadata association Review validate and record metadata and data quality information.
Development of definitions, data quality rules, thresholds, and standard metrics of quality for data elements that support critical business processes.
Development of controls to mitigate data quality risks including data quality plan development, monitoring data quality results, reports, and dashboards for high-risk issues.
Define and oversee high-risk data quality corrective action plans.
Oversee the data quality compliance assessment process.
Information Lifecycle Management.
Oversee archiving and purging activities of data.
Develop archiving and purging strategies and processes.
Oversee the ILM compliance assessment process identifying items that may be a risk to the corporation.
Data Security and Privacy.
Manage Data Access security as needed.
Support Privacy initiatives through analysis of sensitive data.
Ensure sensitive data is accessed and shared in accordance with policies and processes.
Master and Reference Data.
Develop Master and Reference Data processes and procedures to align with Enterprise Policies and Standards.
Create and maintain reference data in accordance with processes and procedures.
Ensure the quality and maintenance of master data.","CYNET SYSTEMS
4.0","San Antonio, TX",IT Services,Information Technology
Data Engineer,"Ability to coordinate with people of many different types of skillsets including systems engineers, network defenders, network engineers, data scientists and analytics developers. Must be able to identify, analyze, normalize, ingest, and parse structured and unstructured cybersecurity and intelligence data from a wide variety of sources, to include large datasets (over 1TB). Data types include, but are not limited to, network appliance event logs, system logs, domain logs, firewall logs, Zeek logs, audit logs, vulnerability scans, packet capture, STIX formatted messages, PDF/text files, .csv files.

Statement of Work for Data Engineer

Job Responsibilities:

· Utilize various Big Data Platform technologies, to include but not limited to, Elastic/Lucene databasing, Hadoop Distributed File System (HDFS), Kafka, and Gem to prepare various datasets for use in data analytics.

· Work with 35 IS and external support engineers to develop, adapt, modify, and implement data parsers for analytic use in the Big Data Platform and other Air Force CS&D weapon systems.

· Utilize one or more of several coding languages to include Java, Python, and Scala.

· Develop documentation and comprehensive user manuals for all developed projects, to be understandable by the average analyst familiar with BDP.

· Assist in the development and implementation of a data analytics program within the 35 IS.

· Provide support to training development and instruction focusing on CS&D data analytics development.

Knowledge/Skills Ability:

Required: · Be Director of Central Intelligence Directives 6/4 eligible (Top Secret) with a current Single Scope Background Investigation (SSBI)

· Proficiency in one or more big data programming languages, such as R, Python, Scala, or Java.

· Experience working with a hybrid team of analyst, engineers, and developers to conduct research, and build and deploy complex, but easy-to-use analytical platforms.

· Previous experience performing research in Data Analytics or big data.

Minimum Experience/Education:

· Minimum 2 years of recent experience in data engineering

· Programming experience, ideally in Python, Spark, Kafka, or Java

· Experience in data cleaning, wrangling, visualization and reporting

· Experience processing large amounts of structured and unstructured data, including integrating data from multiple sources

· Knowledge of data mining, machine learning, natural language processing, or information retrieval

Highly Desired:

· Education/ Certifications:

· Bachelors Degree or more in Computer Science or related field

· DoD 8570 Sec+

· 4+ years of experience in data analytics or quantitative intelligence analysis

· Four (4) years of experience in an intelligence field at a tactical or operational level

· Experience with a DoD Big Data platform is a plus

*BEAT LLC IS AN EQUAL OPPORTUNITY EMPLOYER - DISABILITY AND VETERANS*","B E A T LLC
4.9","San Antonio, TX",Telecommunications Services,Telecommunications
Machine Learning Engineer,"Job Title: Machine Learning Engineer
Location: San Antonio, TX
Duration: Full Time

Required Skills:
Python/Machine Language/SAS /Python - Data Science
Job Type: Full-time","Horizon Corp
3.5","San Antonio, TX",Investment Banking & Asset Management,Finance
Data Analyst,"Job Description


Job #: 1067859

We're looking for a Data Analyst in the San Antonio area that would start off working fully remotely! If interested please reply to the posting listed!

Top three skills required:
Data Profiling and analysis
Business Requirement Development
Testing
Top technology tools:
Excel/Access, Business Objects, Salesforce
What are the responsibilities that this resource will have on a day-to-day basis?
Data process flow analysis
Data Mapping
Business Requirements
Testing/Validation
Issue and Risk identification and remediation
Additional Details:
Partners with key stakeholders in the business to identify, assess, aggregate and document risks and controls, including risks associated with new or modified products, services, distribution channels, regulations and third party operations.
May present findings to various levels of leadership.
Communicates results of risk assessments to governance committees, business process owners and various levels of leadership.
Contributes to the implementation of new risk policies, practices, appetites and solutions to ensure holistic understanding and management of risks according to industry best practice.
Enhances strategies, tools, and methodologies to measure, monitor, and report risks.
EEO Employer

Apex Systems is an equal opportunity employer. We do not discriminate or allow discrimination on the basis of race, color, religion, creed, sex (including pregnancy, childbirth, breastfeeding, or related medical conditions), age, sexual orientation, gender identity, national origin, ancestry, citizenship, genetic information, registered domestic partner status, marital status, disability, status as a crime victim, protected veteran status, political affiliation, union membership, or any other characteristic protected by law. Apex will consider qualified applicants with criminal histories in a manner consistent with the requirements of applicable law. If you have visited our website in search of information on employment opportunities or to apply for a position, and you require an accommodation in using our website for a search or application, please contact our Employee Services Department at employeeservices@apexsystemsinc.com or 844-463-6178.","Apex Systems
3.8","San Antonio, TX",Staffing & Outsourcing,Business Services
Data Engineer,"Ability to coordinate with people of many different types of skillsets including systems engineers, network defenders, network engineers, data scientists and analytics developers. Must be able to identify, analyze, normalize, ingest, and parse structured and unstructured cybersecurity and intelligence data from a wide variety of sources, to include large datasets (over 1TB). Data types include, but are not limited to, network appliance event logs, system logs, domain logs, firewall logs, Zeek logs, audit logs, vulnerability scans, packet capture, STIX formatted messages, PDF/text files, .csv files.

Statement of Work for Data Engineer

Job Responsibilities:

· Utilize various Big Data Platform technologies, to include but not limited to, Elastic/Lucene databasing, Hadoop Distributed File System (HDFS), Kafka, and Gem to prepare various datasets for use in data analytics.

· Work with 35 IS and external support engineers to develop, adapt, modify, and implement data parsers for analytic use in the Big Data Platform and other Air Force CS&D weapon systems.

· Utilize one or more of several coding languages to include Java, Python, and Scala.

· Develop documentation and comprehensive user manuals for all developed projects, to be understandable by the average analyst familiar with BDP.

· Assist in the development and implementation of a data analytics program within the 35 IS.

· Provide support to training development and instruction focusing on CS&D data analytics development.

Knowledge/Skills Ability:

Required: · Be Director of Central Intelligence Directives 6/4 eligible (Top Secret) with a current Single Scope Background Investigation (SSBI)

· Proficiency in one or more big data programming languages, such as R, Python, Scala, or Java.

· Experience working with a hybrid team of analyst, engineers, and developers to conduct research, and build and deploy complex, but easy-to-use analytical platforms.

· Previous experience performing research in Data Analytics or big data.

Minimum Experience/Education:

· Minimum 2 years of recent experience in data engineering

· Programming experience, ideally in Python, Spark, Kafka, or Java

· Experience in data cleaning, wrangling, visualization and reporting

· Experience processing large amounts of structured and unstructured data, including integrating data from multiple sources

· Knowledge of data mining, machine learning, natural language processing, or information retrieval

Highly Desired:

· Education/ Certifications:

·Bachelor’s Degree or more in Computer Science or related field

·DoD 8570 Sec+

· 4+ years of experience in data analytics or quantitative intelligence analysis

· Four (4) years of experience in an intelligence field at a tactical or operational level

· Experience with a DoD Big Data platform is a plus

*BEAT LLC IS AN EQUAL OPPORTUNITY EMPLOYER - DISABILITY AND VETERANS*","B.E.A.T.
4.5","San Antonio, TX",Enterprise Software & Network Solutions,Information Technology
Data Engineer,"Data Engineer (AWS, Snowflake, Batch ETL tool) 12+ Months Phoenix, AZ San Antonio, TX Skills and Qualifications Data Engineer with Bachelorrsquos Degree or foreign equivalent in Computer Science, Electrical Engineering, Mathematics, Computer Applications, Information Systems or Engineering is required 1+ year experience with Snowflake database AWS cloud experience (EC2, S3, Lambda, EMR, RDS, Redshift) Experience in ETL and ELT workflow management Familiarity with AWS Data and Analytics technologies such as Glue, Athena, Spectrum, Data Pipeline Experience building internal cloud to cloud integrations is ideal Experience with streaming related technologies ex Spark streaming or other message brokers like Kafka is a plus 3+ years of Data Management Experience 3+ years of batch ETL tool experience (DataStage Informatica Talend) 3+ yearsrsquo experience developing, deploying and supporting scalable and high-performance data pipelines (leveraging distributed, data movement technologies and approaches, including but not limited to ETL and streaming ingestion and processing) 2+ yearsrsquo experience with Hadoop Ecosystem (HDFSS3, Hive, Spark) 2+ yearsrsquo experience in a software engineering, leveraging Java, Python, Scala, etc. 2+ yearsrsquo advanced distributed schema and SQL development skills including partitioning for performance of ingestion and consumption patterns 2+ yearsrsquo experience with distributed NoSQL databases (Apache Cassandra, Graph databases, Document Store databases) Experience in the financial services, banking and or Insurance industries is a nice to have","Speridian Technologies LLC
3.8","San Antonio, TX",IT Services,Information Technology
Data Engineer,"Job Description
Data Engineer

Location: San Antonio, TX

THIS COMPANY OFFERS…
Fast-pace, ground floor opportunity to make a true impact on the bottom line through Data
Upward mobility, career path that will allow this person to develop as a professional
Robust Bonus Opportunity – high performance equals reward
Stock Options
Remote work opportunity!
YOUR TYPICAL DAY…
Collaborate with business and IT to build a roadmap to extract, transform and load data from various sources
Build data models that will fuel business intelligence to increase data access
Champion opportunities to automate processes for great scalability
Foster a culture of utilizing data to influence decisions across the organization
YOU HAVE…
Demonstrated experience in building a data warehouse from scratch in a cloud environment
Ability to connect with the business and guide the internal customer to the solution they seek
Experience in executing ETL solutions, comfortable and thrives in an environment that requires heads down coding
Schema design and data modeling
Bachelor’ s Degree in Computer Engineering, Mathematics, or related field required
EXTRA CREDIT…
Financial Services experience highly preferred
For a Confidential Conversation and/or Personal Meeting regarding this outstanding career opportunity please contact:

Holly Esquivel, CPC | 210.807-5602 | hesquivel@deaconrecruiting.com","Deacon Recruiting
3.0","San Antonio, TX",Staffing & Outsourcing,Business Services
Data Analyst,"Must be on Our W2

Â

Job Title: Data Analyst â Mid/Senior Level

Location: San Antonio

Job Overview: The resource will be a part of PNC Business Data Analytics team, Must have strong SQL knowledge to contribute in Research, Validation, Development, Quality and reports activities assigned to the team.

Responsibilities and Duties:

Â

Partner with data analyst, Business and product owners, to better understand requirements, solution designs, finding bottlenecks, resolutions, etc.

Â

Understand clients business data environment.

Â

Research, Validate the Incoming tables and find any discrepancies in the data and giving the report to the business about the findings.

Â

Propose solutions to critical data issues through specific inquiries and consultation.

Â

Server Monitoring - Should be able to Analyze, Debug and Troubleshoot Server issues

Â

User Access Management â He should be familiar with access management tools and how to enable/disable user accesses considering all the compliance policies and rules in the Org.

Â

Update and maintain project artifacts and documents. Assist in developing knowledge assets such as methodologies, templates, etc.

Â

Should be having good knowledge of Agile and Scrum

Â

Qualifications

Â

6+ years Exp--Excellent Domain knowledge of maintaining data and validation

Â

6+ Years Exp--Must have strong SQL knowledge, understanding of Databases like SQL Server, Oracle, Netezza

Â

3+ Years --SAS Enterprise Guide 8.1

Â

2+ Years --Aginity (Workbench for Hadoop)

Â

2+ Years--Domain Knowledge of Business side.

Â

Not mandatory but good to have:

Â

Linux

Â

Putty

Â

Python

Â

Agile and SCRUM

Â

Reporting Tools like BO\Tableau","Vinsari
2.5","San Antonio, TX",-1,-1
Data Engineer,"The Business

GradTests.com is a leading provider of practice psychometric tests to graduates, students and young professionals.

The Role

The core purpose of the role is to make high quality, high availability, accurate data available for our data analysts and data scientists to do their analysis, derive their insights and build their models. You are the Scotty Pippin to the Michael Jordans. You are the Xavi to the Messis.

You'll do things like:
Ensure our data warehouse is well structured, running smoothly and efficiently for all business intelligence
Set up and maintain various data pipelines used for customer analytics, marketing analytics and product analytics
Skills and experience

Non negotiables:
SQL
Python
Strong knowledge of traditional relational databases - we don't mind which
Some experience with cloud technologies - again we don't mind if it's AWS, GCP or Azure
Experience in any streaming technology
Great experience in using third party APIs at scale
Some web scraping experience
An obsession with data quality
Strong communication skills
Nice to haves:
Experience in working with analysts
Any basic knowledge of advanced analytics techniques
Experience in a visualisation tool like Tableau
Job Types: Full-time, Contract

Salary: $100,000.00 /year

Work Remotely:
Yes",GradTests (gradtests.com.au),"San Antonio, TX",-1,-1
Data Analyst,"Data Anayst
San Antonio, TX
Contract position

Job Description:
Must have expertise in Tableau reportingHave idea on data visualization including different types of charts,graphs.Have idea on BI architecture","Diverse Lynx
3.9","San Antonio, TX",IT Services,Information Technology
Data Engineer,"Hi, Data Engineer Work location would be San Antonio once the Covid restrictions are lifted. Long Term Need candidates who are strong in ETL, Python Spark Scala is mandatory. Snowflake not mandatory for this role, good to have. Sincerely, HR Manager nFolks Data Solutions LLC Phone 425-999-4933 email arun(AT)nfolksdata.com","nfolks
2.5","San Antonio, TX",Advertising & Marketing,Business Services
Data Engineer,"Data Engineer

Skills and Qualifications:
Data Engineer with Bachelor's Degree or foreign equivalent in Computer Science, Electrical Engineering, Mathematics, Computer Applications, Information Systems or Engineering is required
1+ year experience with Snowflake database
AWS cloud experience (EC2, S3, Lambda, EMR, RDS, Redshift)
Experience in ETL and ELT workflow management
Familiarity with AWS Data and Analytics technologies such as Glue, Athena, Spectrum, Data Pipeline
Experience building internal cloud to cloud integrations is ideal
Experience with streaming related technologies ex Spark streaming or other message brokers like Kafka is a plus
3+ years of Data Management Experience
3+ years of batch ETL tool experience (DataStage / Informatica / Talend)
3+ years' experience developing, deploying and supporting scalable and high-performance data pipelines (leveraging distributed, data movement technologies and approaches, including but not limited to ETL and streaming ingestion and processing)
2+ years' experience with Hadoop Ecosystem (HDFS/S3, Hive, Spark)
2+ years' experience in a software engineering, leveraging Java, Python, Scala, etc.
2+ years' advanced distributed schema and SQL development skills including partitioning for performance of ingestion and consumption patterns
2+ years' experience with distributed NoSQL databases (Apache Cassandra, Graph databases, Document Store databases)
Experience in the financial services, banking and/ or Insurance industries is a nice to have
The Company is an equal opportunity employer and makes employment decisions on the basis of merit and business needs. The Company will consider all qualified applicants for employment without regard to race, color, religious creed, citizenship, national origin, ancestry, age, sex, sexual orientation, genetic information, physical or mental disability, veteran or marital status, or any other class protected by law. To comply with applicable laws ensuring equal employment opportunities to qualified individuals with a disability, the Company will make reasonable accommodations for the known physical or mental limitations of an otherwise qualified individual with a disability who is an applicant or an employee unless undue hardship to the Company would result.","NTT DATA, Inc.
2.9","San Antonio, TX",Accounting,Accounting & Legal
Data Engineer,"Overview Guidehouse is a leading management consulting firm serving the public and commercial markets. We guide our clients forward towards new futures that build trust in society and your professional skills along the journey. Join us at Guidehouse. Responsibilities The Data Engineer will need to demonstrate experience and knowledge of Activity Management, Requirement Identification, and Project Programming Programs or cross-Directorate programs which are still under development and need support to meet the end-state. Develop life-cycle sustainment and risk mitigation strategy recommendations for two FYDP's for each portfolio. Analyze built infrastructure data, aggregate requirements, assesses asset performance predictions from SMS, analyze statistics and trend across portfolios, validate data, perform data management, compile other summarizing reports for each AMP portfolio, and recommend enhancements to processes. Support AMP Enterprise Managers with the development of portfolio-specific SEED's to support Installation Development Plans (IDPs) and the Enterprise Planning Process. Maturation of Requirement Identification by analyzing built infrastructure data, aggregating requirements, assessing asset performance predictions from SMS, analyzing statistics and trends across portfolios, validating data, performing data management, compiling other summarizing reports for each AMP portfolio, and recommending enhancements to process. Assisting in the AFCAMP process, establishment of document templates/tools, logistic support, training, and process refinement recommendations associated with the maturation of the AFCAMP process. Qualifications + BA/BS or MA/MS degree in the field(s) of Data Engineering and Information Technology + 3 to 10 years of related experience in Web Based Application Design, Data Management, Document Management/Repository + Active Public Trust clearance Qualifications - Desired + Air Force Activity Management Experience Additional Requirements The successful candidate must not be subject to employment restrictions from a former employer (such as a non-compete) that would prevent the candidate from performing the job responsibilities as described. Disclaimer Guidehouse is an Equal Employment Opportunity / Affirmative Action employer. All qualified applicants will receive consideration for employment without regard to race, color, national origin, ancestry, citizenship status, military status, protected veteran status, religion, creed, physical or mental disability, medical condition, marital status, sex, sexual orientation, gender, gender identity or expression, age, genetic information, or any other basis protected by law, ordinance, or regulation. Guidehouse will consider for employment qualified applicants with criminal histories in a manner consistent with the requirements of applicable law or ordinance including the Fair Chance Ordinance of Los Angeles and San Francisco. If you have visited our website for information about employment opportunities, or to apply for a position, and you require an accommodation, please contact Guidehouse Recruiting at 1-571-633-1711 or via email at RecruitingAccommodation@guidehouse.com. All information you provide will be kept confidential and will be used only to the extent required to provide needed reasonable accommodation. Guidehouse does not accept unsolicited resumes through or from search firms or staffing agencies. All unsolicited resumes will be considered the property of Guidehouse and Guidehouse will not be obligated to pay a placement fee. Rewards and Benefits Guidehouse offers a comprehensive, total rewards package that includes competitive compensation and a flexible benefits package that reflects our commitment to creating a diverse and supportive workplace. Benefits include: Medical, Rx, Dental & Vision Insurance Personal and Family Sick Time & Company Paid Holidays Parental Leave and Adoption Assistance 401(k) Retirement Plan Basic Life & Supplemental Life Health Savings Account, Dental/Vision & Dependent Care Flexible Spending Accounts Short-Term & Long-Term Disability Tuition Reimbursement, Personal Development & Learning Opportunities Skills Development & Certifications Employee Referral Program Corporate Sponsored Events & Community Outreach Emergency Back-Up Childcare Program","Guidehouse
3.4","San Antonio, TX",Consulting,Business Services
Data Engineer,"Great sales are the result of strong purpose, conviction and pride - pride in your ability and your product. UnitedHealth Group offers a portfolio of products that are greatly improving the life of others. Bring along your passion and do your life's best work.(sm)

Primary Responsibilities:
Excellent analytical and problem solving capabilities with special attention to accuracy and detail
Self-starter with a proven ability to take ownership of job responsibilities and ensure successful completion of all projects and requests
Designs, develops, tests, documents and maintains database queries and reports related to-but not limited to - clinical systems data
Works with customers to define and document additional requirements to enrich reporting capabilities
Develops systematic reporting processes and procedures to ensure timely delivery of daily, weekly, monthly, annual and ad hoc reporting to management
Troubleshoots data integrity issues, analyzes data for completeness to meet business needs, and proposes documented solution recommendations
Transfers data into meaningful, professional and easy to understand formats for various audiences
Combines various data sources into a comprehensive understanding of customer behaviors and feedback for service improvement opportunities
Manages reporting and analysis elements on all business initiative projects
Recommends and implements new or modified reporting methods and procedures to improve report content and completeness of information
Troubleshoots and coordinates resolutions to all system issues affecting clinical applications
Creates on-line tools to improve efficiency and effectiveness of staff in their role of servicing our customer
Youll be rewarded and recognized for your performance in an environment that will challenge you and give you clear direction on what it takes to succeed in your role as well as provide development for other roles you may be interested in.

Required Qualifications:
Bachelor's degree in Business, Healthcare Administration, Information Technology or related field required. (4 additional years of comparable work experience beyond the required years of experience may be substituted in lieu of a bachelor?s degree)
Four or more years related experience in a reporting and analytic role
Two or more years of experience in Healthcare or Clinical environment
Proficient in SQL, SQL Reporting Services, , MS Access, and MS Excel
Preferred Qualifications:
MS Visual Studio
SSIS
Ability to effectively prioritize and multi-task in high volume workload situations.

Careers with WellMed. Our focus is simple. We're innovators in preventative health care, striving to change the face of health care for seniors. We're impacting 380,000+ lives, primarily Medicare eligible seniors in Texas and Florida, through primary and multi-specialty clinics, and contracted medical management services. We've joined Optum, part of the UnitedHealth Group family of companies, and our mission is to help the sick become well and to help patients understand and control their health in a lifelong effort at wellness. Our providers and staff are selected for their dedication and focus on preventative, proactive care. For you, that means one incredible team and a singular opportunity to do your life's best work.(sm)

WellMed was founded in 1990 with a vision of being a physician-led company that could change the face of healthcare delivery for seniors. Through the WellMed Care Model, we specialize in helping our patients stay healthy by providing the care they need from doctors who care about them. We partner with multiple Medicare Advantage health plans in Texas and Florida and look forward to continuing growth.

OptumCare is committed to creating an environment where physicians focus on what they do best: care for their patients. To do so, OptumCare provides administrative and business support services to both owned and affiliated medical practices which are part of OptumCare. Each medical practice part and their physician employees have complete authority with regards to all medical decision-making and patient care. OptumCares support services do not interfere with or control the practice of medicine by the medical practices or any of their physicians.

Diversity creates a healthier atmosphere: OptumCare is an Equal Employment Opportunity/Affirmative Action employers and all qualified applicants will receive consideration for employment without regard to race, color, religion, sex, age, national origin, protected veteran status, disability status, sexual orientation, gender identity or expression, marital status, genetic information, or any other characteristic protected by law.

OptumCare is a drug-free workplace. Candidates are required to pass a drug test before beginning employment","OptumCare
3.4","San Antonio, TX",Health Care Services & Hospitals,Health Care
Data Analyst,"Huntington Ingalls Industries is America's largest military shipbuilding company and a provider of professional services to partners in government and industry. For more than a century, HII's Newport News and Ingalls shipbuilding divisions in Virginia and Mississippi have built more ships in more ship classes than any other U.S. naval shipbuilder. HII's Technical Solutions division provides a wide range of professional services through its Fleet Support, Mission Driven Innovative Solutions, Nuclear & Environmental, and Oil & Gas groups. Headquartered in Newport News, Virginia, HII employs more than 42,000 people operating both domestically and internationally. Job Description HII - Technical Solutions Division (HII-TSD) is seeking a Data Analyst for the US Courts in San Antonio, TX. The CIS team is engaged in continual improvement activities tied to services provided by, and systems monitored by, the Enterprise Operations Center (EOC). Our objective is to drive continual service and process improvements through data analysis and organizational alignment. This position will use best practices in data gathering, modeling, visualization, analysis, and reporting around Key Performance Indicators to make improvement recommendations for the federal judiciary. This position will identify and help implement tools that will make EOC processes more efficient, including but not limited to, Artificial Intelligence and Robotics. Essential Job Responsibilities + Develops, inspects, mines, transforms, and models data to raise productivity, improve decision making, and gain competitive advantage. + Conducts quantitative and qualitative analysis on data and information to ensure correct predictive forecasting or classification. + Manages all aspects of end-to-end data processing utilizing customized report building functions of systems. + Maintains analytical systems, verifies the accuracy of the data, and acts as liaison with business. Minimum Qualifications + 6-9 Years with Bachelors or 4-7 Years with Masters or HS diploma + 10-13 years of relevant experience. + Competency in the use of data analysis tools and practices required + High level of literacy in both relational and non-relational database concepts and structures + Proficient with data query languages and reporting packages (for example, SQL, Power Query, JavaScript, R) + Knowledge of game theory, Machine Learning algorithms, and other statistical methods + High level of literacy in Business Intelligence concepts, tools, and frameworks + Knowledge of data governance structures and purpose + Use resources effectively and efficiently; can orchestrate multiple activities at once to accomplish goals + Fast learner when facing new problems and situations + Keen listening, written, and verbal skills + Ability to work independently, as well as effectively within a team + Negotiate skillfully in tough situations with internal and external groups + Effective problem-solving ability and strong analytical skills + Ability to analyze and interpret complex patterns in complex data sets + Demonstrate flexibility, reliability, and dependability Preferred Requirements + Tableau experience is preferred Huntington Ingalls Industries is an Equal Opportunity/Vets and Disabled Employer. U.S. Citizenship may be required for certain positions.","Huntington Ingalls Industries
3.7","San Antonio, TX",Aerospace & Defense,Aerospace & Defense
Data Analyst,"Requirements
Adept at using Access, Excel, Power Point and Word.
General Data Warehouse / Business Intelligence knowledge including data modeling and Key Performance Indicators (PKIs) preferably in the SAP Business Objects environment.
Develop, implement, and maintain leading-edge analytic systems, taking complicated problems and building simple frameworks
Identify trends and opportunities for growth through analysis of complex data sets
Evaluate organizational methods and provide source-to-target mappings and information-model specification documents for data sets
Create best-practice reports based on data mining, analysis, and visualization
Evaluate internal systems for efficiency, problems, and inaccuracies, developing and maintaining protocols for handling, processing, and cleaning data
Work directly with management and users to gather requirements, provide status updates, and build relationships
Work closely with project managers to understand and maintain focus on their analytical needs, including identifying critical metrics and KPIs, and deliver actionable insights to relevant decision-makers
Proactively analyze data to answer key questions from stakeholders or out of self-initiated curiosity with an eye for what drives business performance, investigating and communicating areas for improvement in efficiency and productivity
Create and maintain rich interactive visualizations through data interpretation and analysis integrating various reporting components from multiple data sources
Define and implement data and integration logic, selecting appropriate combination of methods and tools within defined technology stack to ensure optimal scalability and performance of the solution
Develop and maintain databases by acquiring data from primary and secondary sources, and build scripts that will make our data evaluation process more flexible or scalable across data sets (1.) Suggest design solutions (2.) To participate and facilitate the walkthrough to brief the Functional Specification mapping to Business Requirements. (3.) To prepare the functional specification document and ensure for completeness and storage. (4.) To prepare and / or aid the preparation of test cases in line with functional requirements (5.) To understand the business requirements and map it to functional specifications.
AWS experience highly desired
Requirements
Bachelor's degree in a related field and 2 years experience in Business Intelligence (BI) or Data Warehouses and 2 years experience working with SQL and Access. Four additional years of related experience will be considered in lieu of a Bachelor's degree.
5 years experience in quantitative analysis and statistical modeling (regression, correlation, clustering, etc.).
4 year of experience consulting or experience in a similar field requiring client collaboration, presentation, and delivery.
3 years experience using analytics tools and languages R, Python, SAS, Oracle and SQL etc.
3 years experience combining data sets, extracting key variables, and creating new variables to enhance modeling.
3 years experience performing basic ETL functions and understanding of data quality steps/measures.
US Citizen; no dual citizenship.
Minimum of a Secret Interim clearance to start (Day 1 requirement).
CompTIA Security+ certification required to start (Day 1 requirement).
CDO is an Equal Opportunity Employer","CDO Technologies Inc
3.3","San Antonio, TX",Computer Hardware & Software,Information Technology
Data Engineer,"Current employees and contingent workers click here to apply and search by the Job Posting Title.
iHeartMedia

Job Summary:

iHeartMedia is the number one audio company in the United States, reaching nine out of 10 Americans every month – and with its quarter of a billion monthly listeners, has a greater reach than any other media company in the U.S. The company’s leadership position in audio extends across multiple platforms including 850 live broadcast stations; streaming music, radio and on demand via its iHeartRadio digital service available across more than 250 platforms and 2,000 devices including smart speakers, digital auto dashes, tablets, wearables, smartphones, virtual assistants, TVs and gaming consoles; through its influencers; social; branded iconic live music events; and podcasts as the #1 commercial podcast publisher globally. iHeartMedia also leads the audio industry in analytics and attribution technology for its marketing partners, using data from its massive consumer base.

The Data Engineer will be responsible for developing expanding, testing and/or optimizing the infrastructure and architecture of existing and future data pipelines, as well as optimizing data collection, flow, and delivery for cross-functional teams including software engineers, data scientists, and business partners. The ideal candidate is an experienced data pipeline builder and data wrangler who enjoys optimizing data systems and building them from the ground up. They must be self-directed and comfortable supporting the data needs of multiple teams, systems, and products

Responsibilities:
Assemble large, complex data sets that meet functional and non-functional business requirements
Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources
Develop and maintain standards for administration and operation including the scheduling, running, monitoring, logging, error management, failure recovery, and output validation
Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc.
Work with cross functional teams to strive for greater functionality in our data systems, and recommend and implement ways to improve data reliability, efficiency, and quality
Collaborate with data scientists to build data products that ingest data from a variety of data sources, process it with sophisticated data science techniques, and produces results that are consumed by business partners for analysis or action
Contribute to the project planning process by estimating tasks and deliverables
Communicate complex solutions and ideas to a variety of stakeholders (other team members, IT leadership, and business leaders) in easily understandable language
Utilize and stay current in programming languages and software technology
Qualifications:
Bachelor’s Degree in Computer Science, Information Technology, Informatics, or Applied Math – Graduate degree desired
5+ years of commercial experience in a data engineer role with a proven record of manipulating, processing and extracting value from large disconnected datasets.
Strong understanding of ETL processes
Expert-level knowledge of SQL and experience with NoSQL databases
Strong analytic skills related to working with unstructured datasets
Solid programming skills and expertise in Python
Experience working with REST and SOAP APIs
Strong project management, organizational, communication, and presentation skills
Experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement
Experience supporting and working with cross-functional teams in a dynamic environment
Location

San Antonio, TX: 20880 Stone Oak Parkway, 78258

Position Type

Regular

The Company is an equal opportunity employer and will not tolerate discrimination in employment on the basis of race, color, age, sex, sexual orientation, gender identity or expression, religion, disability, ethnicity, national origin, marital status, protected veteran status, genetic information, or any other legally protected classification or status.

Our organization participates in E-Verify. Click here to learn about E-Verify.

Current employees and contingent workers click here to apply and search by the Job Posting Title.","iHeartMedia
3.2","San Antonio, TX",Radio,Media
Data Engineer,"OverviewInterested in working with talented people to help develop innovative solutions to some of society's most complex and challenging problems? We are Guidehouse, a leading consulting firm serving the public sector and commercial clients with specialized capabilities in strategy, technology, and risk management. You may not yet know our name, but we have a rich history. Guidehouse is a combination of PwC's former public sector practice and Navigant's deep expertise in energy, financial services and healthcare.We offer an exciting, fast-paced environment that fosters intellectual growth and rewards individuals based on impact, not tenure. Our firm is at the forefront of an emerging model solving complex problems that stretch across government and private companies, affording our people the opportunity to be on the cutting edge of the consulting profession. By focusing on markets facing transformational change, technology-driven innovation, and significant regulatory pressure, our employees also develop and deploy world class knowledge and problem solving that leads to breakthrough solutions.ResponsibilitiesThe Data Engineer will need to demonstrate experience and knowledge of Activity Management, Requirement Identification, and Project Programming Programs or cross-Directorate programs which are still under development and need support to meet the end-state.Develop life-cycle sustainment and risk mitigation strategy recommendations for two FYDP's for each portfolio.Analyze built infrastructure data, aggregate requirements, assesses asset performance predictions from SMS, analyze statistics and trend across portfolios, validate data, perform data management, compile other summarizing reports for each AMP portfolio, and recommend enhancements to processes.Support AMP Enterprise Managers with the development of portfolio-specific SEED's to support Installation Development Plans (IDPs) and the Enterprise Planning Process. Maturation of Requirement Identification by analyzing built infrastructure data, aggregating requirements, assessing asset performance predictions from SMS, analyzing statistics and trends across portfolios, validating data, performing data management, compiling other summarizing reports for each AMP portfolio, and recommending enhancements to process.Assisting in the AFCAMP process, establishment of document templates/tools, logistic support, training, and process refinement recommendations associated with the maturation of the AFCAMP process.Qualifications* BA/BS or MA/MS degree in the field(s) of Data Engineering and Information Technology* 3 to 10 years of related experience in Web Based Application Design, Data Management, Document Management/Repository* Active Public Trust clearanceQualifications - Desired* Air Force Activity Management ExperienceAdditional RequirementsThe successful candidate must not be subject to employment restrictions from a former employer (such as a non-compete) that would prevent the candidate from performing the job responsibilities as described.DisclaimerGuidehouse is an Equal Employment Opportunity / Affirmative Action employer. All qualified applicants will receive consideration for employment without regard to race, color, national origin, ancestry, citizenship status, military status, protected veteran status, religion, creed, physical or mental disability, medical condition, marital status, sex, sexual orientation, gender, gender identity or expression, age, genetic information, or any other basis protected by law, ordinance, or regulation.Guidehouse will consider for employment qualified applicants with criminal histories in a manner consistent with the requirements of applicable law or ordinance including the Fair Chance Ordinance of Los Angeles and San Francisco.If you have visited our website for information about employment opportunities, or to apply for a position, and you require an accommodation, please contact Guidehouse Recruiting at 1-571-633-1711 or via email at RecruitingAccommodation@guidehouse.com. All information you provide will be kept confidential and will be used only to the extent required to provide needed reasonable accommodation.Guidehouse does not accept unsolicited resumes through or from search firms or staffing agencies. All unsolicited resumes will be considered the property of Guidehouse and Guidehouse will not be obligated to pay a placement fee.Rewards and BenefitsGuidehouse offers a comprehensive, total rewards package that includes competitive compensation and a flexible benefits package that reflects our commitment to creating a diverse and supportive workplace.Benefits include:* Medical, Rx, Dental & Vision Insurance* Personal and Family Sick Time & Company Paid Holidays* Parental Leave and Adoption Assistance* 401(k) Retirement Plan* Basic Life & Supplemental Life* Health Savings Account, Dental/Vision & Dependent Care Flexible Spending Accounts* Short-Term & Long-Term Disability* Tuition Reimbursement, Personal Development & Learning Opportunities* Skills Development & Certifications* Employee Referral Program* Corporate Sponsored Events & Community Outreach* Emergency Back-Up Childcare Program","Navigant Consulting
3.2","San Antonio, TX",Consulting,Business Services
Data Engineer,"H-E-B Digital is seeking new team members (Partners)! Since our inception, we’ve been investing heavily in our customers’ digital experience, reinventing how they find inspiration from food, how they make food decisions, and how they ultimately get food into their homes. This is an exciting time to join H-E-B Digital, and we’re hiring across the stack: front-end web and mobile, full-stack, and backend engineering. We’re using the best available technologies to deliver modern, engaging, reliable, and scalable experiences to meet the needs of our growing audience. Our digital solutions are growing in popularity and adoption—like Curbside and Home Delivery—so you’ll get the opportunity to define the user experience for millions of customers and hundreds of thousands of Partners. If you’re someone who enjoys taking on new challenges, working in a rapidly changing environment, learning new skills, and applying it all to solve large and impactful business problems, we want you as part of our team.

Our Partners thrive The H-E-B Way. In the Data Engineer position, that means you have a…

HEART FOR PEOPLE… you’re willing to communicate with and learn from your manager and your team

HEAD FOR BUSINESS… you can follow technical guidance and understand why it’s important

PASSION FOR RESULTS… you’ll take the initiative to get familiar with technology / the software development process
What you’ll do
Work with HEB Digital teams to provide data solutions for e-commerce, supply chain, store operations, finance, and marketing reporting and analytics platforms
Contribute to existing data platforms and implement new technologies
Develop a deep understanding of HEB’s data and become a domain expert
Ensure data is distributed in a timely and accurate manner
Make data discoverable and accessible to business users

Who You Are
2 years of data engineering experience
Proficient with data technologies (e.g. Spark, Kinesis, Kafka, Airflow, Oracle, PostgreSQL, Redshift, Presto, etc.)
Experienced with designing and developing ETL data pipelines using tools such as Airflow, Nifi, or Kafka.
Strong understanding of SQL and data modeling
Understanding of Linux, Amazon Web Services (or other cloud platforms), Python, Docker, and Kubernetes
Experienced with common software engineering tools (e.g., Git, JIRA, Confluence, or similar)
Bachelor's degree in computer science or comparable field or equivalent experience
A proven understanding and application of computer science fundamentals: data structures, algorithms, design patterns, and data modeling

What are the Perks?
A robust Benefits plan with coverage starting Day One
Dental, vision, life, and other insurance plans; flexible spending accounts; short term / long term disability coverage
Partner Care Team, for any time you have healthcare or coverage questions
Telehealth offers 24/7 access to board-certified doctors by phone
Partner Guidance allows free counselor visits
Funeral leave, jury duty, and military pay (subject to applicable law)
Maternal / paternal leave for new parents, including adoptions
10"" off H-E-B brand products in-store and online
Eligibility to participate in 401(k)
Opportunity to become a “Partner-Owner” after 12 months
Who We Are
H-E-B is one of the largest, independently owned food retailers in the nation, operating over 400 stores throughout Texas and Mexico, with annual sales generating over $25 billion
We hire talented people (109,000 Partners), and give them autonomy to be creative in how they impact the business
We’re a Partner-driven company with a Bold Promise – Because People Matter
We embrace Diversity and Inclusion as core values, and support them with thriving company-wide programs
We’re a truly original Texas-based company that created the Spirit of Giving to help Texas communities every day
Once eligible, our Partners become Owners in the company. “Partner-owned” means our most important resources—People—drive the innovation, growth, and success that make H-E-B The Greatest Retailing Company
04-2019

DASO3232","H E B
4.3","San Antonio, TX",Grocery Stores & Supermarkets,Retail
Data Analyst,"As we navigate through these unprecedented times, MCMs focus continues to be our commitment to our Consumers and Employees. Over the past couple of weeks our teams have worked diligently to ensure wherever possible our employees were able to move to 100% remote work and our Consumers were still supported.

MCM continues to hire in areas which aid in the support of our Consumers and Employees. We have also leveraged our digital capabilities to continue to provide a great recruiting experience. As an applicant, you may be asked to complete a phone screen, or a virtual interview and our Recruiting Team is committed to supporting any questions you may have throughout the Interview process.

Now more than ever, we have a high demand for goal-driven, motivated individuals to join our team.

The Data Analyst is primarily responsible for using data extraction tools, largely Excel, SQL, and Python to perform in-depth analysis of programs and opportunities in the business. The Data Analyst will make recommendations to improve the operational processes based on their analysis and may design strategies to implement those recommendations. The analyst will then coordinate with other stakeholders to ensure the implementations meet the needs of the business. The primary area of focus for the data analyst is working with data related to Encore Advantages customers and tailoring strategies to best serve them.

The position is also responsible for creating and monitoring reports to identify trends, issues and opportunities.

Responsibilities:
Create and monitor reports to identify issues, trends, and opportunities.
Extract and analyze data to support business initiatives (e.g. profitability, performance and variance analysis).
Recommend improvements related to business profitability or processes.
Collaborate with relevant stakeholders to design and execute new strategies
Qualifications:

Required: Bachelor; Quantitative field","Midland Credit Management
3.4","San Diego, CA",Banks & Credit Unions,Finance
Data Scientist,"At CliniComp, Intl. we create cool products, in a pleasant place with people we like. We design, develop, and implement software and hardware solutions for Healthcare IT. Our state-of-the-art technology has contributed to fundamental advancements in computer science. We are proud of our artificial intelligence initiatives that are adding significant depth to products that will further improve healthcare outcomes for patients. The foundation of all we do is to create things that really matter.

Position Summary

The Data Scientist will actively research and implement approaches to model complex physiological, tabular, and/or imaging data and discover insights using statistical, algorithmic, mining, and visualization techniques. You will collaborate with other Data Scientists, Analysts and Engineers to improve existing models, workflows, and databases using quantitative methods.

Responsibilities
Select, design, develop and apply machine learning algorithms in a tested and reproducible manner.
Clearly communicate the design and operation of implemented algorithms (short reports, diagrams).
Work expertly with intermediate data structures (e.g., SQL databases, flat files).
Use relevant packages (e.g., PyTorch, TensorFlow, Theano, Lasagne) for running neural networks
Rapid prototyping of code in Python and/or R (numpy, pandas, matplotlib, wfdb / glmnet, data. table, ggplot2, survival, etc).
Maintain breadth of knowledge in latest developments in AI/machine learning and industry best practices.
Optimize algorithm parameters, and work with data engineers to ensure the usage of high-quality data and correct application of statistical methods and assumptions.
Use internal ticketing system tools (Softzilla and Service Direct) to report and document work according to CCI standards and protocols.
Perform, visualize, and validate statistical analyses.
Requirements

Required
Bachelor’s degree in Computer Science, Data Science, Statistics, Applied Mathematics, or related technical field.
At least 1+ years database experience with solid understanding of SQL query development (in MySQL, SQLite, and/or Postgres).
At least 1+ years Python experience
Possesses a strong quantitative approach to analyzing data and fundamental knowledge in statistics and statistical software with large datasets.
Preferred
Master’s Degree in Computer Science, Data Science, Statistics, Applied Mathematics, or related technical field.
2-5 years of relevant quantitative and qualitative research and analytics experience.
Deep understanding of statistical and predictive/dynamical modeling concepts, machine-learning approaches, and clustering and classification techniques.
Proficiency with large datasets.
Comfortable installing and configuring software, as well as conducting analysis in Unix/Linux environments (RHEL7).
Working knowledge of high performance distributed computing or code-optimization through parallelization (GPU, clusters); git, or other method of version control
Security Clearance: The start of the security clearance process is up to the discretion of the company and may begin no later than the successful completion of the first 90 days of employment, and commensurate with job requirements and the needs of the business. Successful completion of the security clearance process may not be required for every position but all candidates must be willing to submit to the process if requested by their manager according to the requirements of the position and business needs.

Benefits
100% covered Medical and Dental coverage for you & your family
Generous 401(k) plan and contribution
Events and weekly lunches
Engaging wellness activities
Corporate Social Responsibility Program
So many more to list…
CCI complies with the Americans with Disabilities Act and considers reasonable accommodation measures that may be necessary for eligible applicants/employees to perform primary responsibilities. EEO/AA/M/F/Veteran/Disabled","CliniComp, Intl.
3.8","San Diego, CA",Computer Hardware & Software,Information Technology
Data Scientist,"Our vision at Petco
is Healthier Pets. Happier People. Better World. We’re making things
better for pets, people and the planet through our Think Adoption First
philosophy, the Petco Foundation and other important initiatives that focus on
putting animals first, educating pet parents and reducing our carbon footprint.
The journey starts with knowledgeable, passionately engaged associates who are
proud to recommend Petco as a place to work, who believe in our Vision and who
are committed to delivering a superior customer experience.

From our retail stores
and our network of Distribution Centers to our Corporate offices, you'll work
with others who share your values and commitment. We seek individuals who are
passionate about animal welfare, have great people skills and are driven to
grow and advance in their careers with us. Our ongoing growth is creating
exceptional opportunities for professional development and personal enrichment
throughout our organization.

Position Purpose

This Data Scientist position
is responsible for leveraging strategic insights, advanced analytics, data
science, and market research to understand customer behavior trends, product
relationships, competitive price position, and marketing opportunities in order
to maximize financial performance and deliver an exceptional customer
experience.

Within
the team, you combine advanced analytical skills and big data techniques with
strong business acumen to build predictive models aimed at providing actionable
solutions to some of the most pressing and high-value business problems we
face. You will actively engage and influence the business with your models and
algorithms as well as consult on implementation of new strategies.

Essential
Job Functions The incumbent must be able
to perform all of the following duties and responsibilities with or without a reasonable accommodation.
Develop and implement behavioral
and predictive models that drive customer value and achieve strategic
business objectives (machine learning, linear & logistic regression,
clustering, statistical sampling, A/B testing, and text mining/sentiment
analysis).
Go beyond delivering insights and
instead translate business questions into concrete solutions that can be
effectively executed and operationalized to improve value.
Utilize deep experience
manipulating large volumes of information from a variety of disparate
sources into clean data sets; proficient use of SQL/Hive and other data
mining tools is required.
Partner with the IT team to stay
current on the latest trends in big data technologies. Contribute to new
data tools and system integrations, and lead projects to continuously
improve data quality, computing power, and query optimization.
Create compelling data
visualizations and develop new performance metrics to quantify the value
of corporate initiatives and highlight trends in consumer behavior.
Present findings to executive
leadership by effectively translating complex data and methodologies into
clear insights, opportunities, and tangible business actions.
Display deep intellectual
curiosity, creativity, and commitment to learning in order to solve
critical business problems and push the boundary of our capabilities.
Supervisory Responsibility: No direct reports.
Incumbent will collaborate and lead cross-functional business projects.

Work Environment: The majority of job duties are conducted while
seated indoors at a computer terminal with little or no exposure to
hazards. Occasional travel may be required for presentations, training,
and convention.

Education/Experience:

M.S. in Computer Science, Math, Statistics preferred with 3 years experience applying data mining techniques to real business problems
Expertise in one or more of R, Python, SAS; deep understanding of Machine Learning and Data Mining techniques.
Experience building large data sets across disparate sources (SQL, Hive, Pig).
Familiarity with basic principles of distributed computing/databases (Hadoop, NoSQL).
Experience with retail industry, customer-level demographic and transactional data a must.
Experience with web API’s, clickstream and mobile app engagement/telemetry data a plus.
Proven ability to deploy new analytic and data manipulation techniques.
Ability to think conceptually and creatively about problems and solutions.
Strong interpersonal communication, verbal and written, due to the nature and level of interaction with senior management.
Demonstrated ability to prioritize workload and ability to manage multiple projects while meeting deadlines.



#LI-DNI

Petco Animal Supplies, Inc. is an Equal Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability, age, protected veteran status, or any other protected classification.","PETCO
2.9","San Diego, CA",Pet & Pet Supplies Stores,Retail
Data Scientist,"Realty Income, The Monthly Dividend Company®, one of four San Diego based S&P 500 companies dedicated to providing shareholders with dependable monthly income. Our company is structured as a REIT, and its monthly dividends are
supported by the cash flow, over 6,000 real estate properties owned under long-term lease agreements with regional and national commercial tenants. To date, our company has declared over 600 consecutive common stock monthly dividends throughout its 50-year
operating history and has continually increased the dividend since Realty Income's public listing in 1994 (NYSE: O). Our company attracts individuals who value integrity, perseverance, and teamwork. If you appreciate working on a truly collaborative team in
a professional environment in a company that encourages a work-life balance, make sure to apply today!

As Realty Income’s Data Scientist, you will be a ground-breaking leader who works as part of a team that builds and owns analytics-based assets, bringing the value of real estate predictive analytics to our business
leaders. You will shape the future of a data-savvy organization, in part by driving processes for data extraction and analysis, and by creating new lines of thinking within our core real estate and investing business. In this role, you will design, develop
and execute predictive analytics work streams that serve as the catalyst to increase ROI for the business.

Your Contribution to the Team Includes:

Predictive Analytics
Build predictive analytics for use cases such as: Portfolio Management; Development; Acquisitions
Work with business teams to identify, develop and deliver new use cases over time
Prioritize predictive analytics initiatives based on multiple factors, e.g., ROI/productivity, business continuity, ease of delivery
Deliver insights with user friendly end-products such as web-based tools, reports (e.g., Power BI) or visualizations that are accessible and understandable for business users
Ensure we remain state of the art by keeping up on the latest technologies and approaches, attending conferences or other events as needed
Infrastructure for Predictive Analytics
Create the vision for static and dynamic data architecture for predictive analytics encompassing internal data in our ERP system or other data sources as well as externally sourced data (e.g., census information news feeds)
Oversee the process for data management leveraging IT and business teams using clearly articulated responsibility matrices and timelines, including meeting internal audit requirements for data/process integrity
Coordinate with the IT team to buy or license required tools, data and feeds
Work with the IT team as they set up the necessary infrastructure and processes to support predictive analytics, e.g., ETL from the ERP system to data warehouse/lake
Determine how and when to take and store “snapshots” of data so that we can go back in time to test new models and approaches
Organizational Relationships
Work closely with business teams, IT, internal audit and enterprise risk to define end products and processes
Create cross-functional working groups or teams as needed to initiate, approve or complete work
Update the Investment Committee monthly or quarterly on key matters such as portfolio risk
Support business teams in the achievement of their objectives using predictive analytics tools

Requirements

What You’ll Need to be Successful
PHD Preferred in a relevant discipline, e.g., machine learning, statistics, applied mathematics, econometrics, or operations research
3-5+ years of experience providing advanced analytics within a business setting
Prior work experience within real estate or financial services is preferred, but not required
Programming experience in Python, Spark and SQL. Java/Scala is a plus
Experience with RDBMS systems like PostgreSQL and NoSQL systems like MongoDB
Hands-on experience in Microsoft Azure and Amazon EC2 cloud platform
Demonstrated ability to design and implement ETL workflows across both Windows and Linux environments
Ability to clearly communicate ideas, orally or via written communications
Must be authorized to work for any employer in the US without restriction
In response to COVID-19, Realty Income has maintained our business operations and have open opportunities, yet made necessary adjustments to our hiring process. We are conducting all steps of the interview process
in a virtual capacity. In response to California’s Stay at Home order and other states with similar provisions, our employees will continue to work remotely until these restrictions have been lifted and it is safe to work in an office again. Realty Income
has endeavored to be adaptable and strategic in our capacity to maneuver in an unfamiliar situation, and we pride ourselves on our resilience. We immensely appreciate both your flexibility and consideration of Realty Income for employment.

To all recruitment agencies: Realty Income does not accept unsolicited agency resumes. Please do not forward resumes to our job’s alias, Realty Income employees, or any company location. Realty Income is not
responsible for any fees related to unsolicited resumes.","Realty Income
4.6","San Diego, CA",Real Estate,Real Estate
Statistician,"The U.S. Department of the Treasury has a distinguished history dating back to the founding of our nation. As the steward of U.S. economic and financial systems, Treasury is a major and influential leader in today's global economy. We have over 100,000 employees across the country and around the world. Come Join the Department of the Treasury and Invest in Tomorrow.
See Other Information for Locations
Positions are to be filled in the Large Business & International (LB&I), Data Solutions division.
Eight (8) positions are to be filled in any of the following locations:
Birmingham, AL
Fayetteville, AR
Little Rock, AR
Phoenix, AZ
El Monte, CA
Glendale, CA
Laguna Niguel, CA
Los Angeles, CA
Long Beach, CA
Oakland, CA
Sacramento, CA
San Diego, CA
San Francisco, CA
San Jose, CA
Santa Ana, CA
Lakewood, CO
Hartford, CT
New Haven, CT
Norwalk, CT
Washington, DC
Newark, DE
Miami, FL
Ft. Myers, FL
Jacksonville, FL
Maitland, FL
Plantation, FL
Tampa, FL
West Palm Beach, FL
Atlanta, GA
Honolulu, HI
Des Moines, IA
Chicago, IL
Downers Grove, IL
Schiller Park, IL
Springfield, IL
Indianapolis, IN
Wichita, KS
Louisville, KY
New Orleans, LA
Boston, MA
Brockton, MA
Stoneham, MA
Southborough, MA
Baltimore, MD
Lanham-Seabrook, MD
Rockville, MD
Ann Arbor, MI
Clinton Township, MI
Detroit, MI
Farmington Hills, MI
Flint, MI
Grand Rapids, MI
Pontiac, MI
Bloomington, MN
Chesterfield, MO
Lee's Summit, MO
Charlotte, NC
Greensboro, NC
Raleigh, NC
Omaha, NE
Edison, NJ
Iselin, NJ
Mountainside, NJ
Paterson, NJ
Las Vegas, NV
Albany, NY
Bethpage, NY
Buffalo, NY
New York, NY
Rochester, NY
Cincinnati, OH
Columbus, OH
Independence, OH
Oklahoma City, OK
Tulsa, OK
Portland, OR
Philadelphia, PA
Pittsburgh, PA
King Of Prussia, PA
Guaynabo, PR
Warwick, RI
Franklin, TN
Memphis, TN
Nashville, TN
Austin, TX
Farmers Branch, TX
Fort Worth, TX
Houston, TX
San Antonio, TX
Ogden, UT
Salt Lake City, UT
Norfolk, VA
Richmond, VA
Vienna, VA
Seattle, WA
Milwaukee, WI
Waukesha, WI
Kearneysville, WV
Martinsburg, WV
WHAT DOES A DATA SCIENTIST DO? The Data Scientist utilizes advanced analytical, statistical, and computer programming skills to develop data- driven solutions to difficult business challenges. As a data scientist, you are responsible for conducting data-centric projects to provide insight and informed decisions for mission- oriented programs of the Internal Revenue Service (IRS), which may impact multiple program segments, divisions, the Service, or segments of the taxpayer population. This is accomplished by utilizing a wide range of technical competencies such as statistics and machine learning, coding languages, data wrangling, and reporting and visualization techniques. The Data Scientist may lead team or cross functional projects, and will apply critical thinking, problem solving and ability to communicate complex analysis to advance the use of data-driven decision making in IRS operations.

WHAT IS THE LARGE BUSINESS AND INTERNATIONAL (LB&I) DIVISION OF THE INTERNAL REVENUE SERVICE? The Large Business and International (LB&I) business unit provides service and enforcement activities to support tax compliance of businesses and related entities with assets of $10 million or more, as well as small U.S. businesses engaged in international, U.S. citizens abroad, and foreign persons and businesses with a U.S. tax requirement.
As a Data Scientist, you will:
Serve as a technical expert with responsibility for the initiation, planning, implementation, controlling, modifying and executing of all or part of an entire project, including such tasks as formulation of workload estimates for program segments, specification of the methodology to be used, preparation of appropriate specifications and procedures, and review of computer systems specifications and materials and instructions needed for assuring the adequacy of the project’s design and objectives.
Explore novel methods of retrieving data and develop innovative recommendations to management and senior leadership as a means for making data driven decisions such as modification of processes and policies. Review, evaluate, validate, and document the results of the findings.
Assist the supervisor in determining the scope, goals and schedules for future programs in the Office. Collaborate with business or technology partners to understand business needs, identify opportunities, and develop and implement analytical solutions.
Identify and assess relevant data sources’ validity and reliability to meet project needs. Collate, clean, transform, analyze, and integrate structured and unstructured data from various sources in preparation for analysis.
Apply statistical methods and concepts including data mining, statistical theory and research procedures to test hypotheses using structured and unstructured data. Develop data product solutions to improve customer experiences, anomaly detection, and business outcomes. Develop proofs of concept or demonstrations to evaluate feasibility of project solutions and recommend visualization strategies.
Document project work and review deliverables for validity, reliability and timeliness. Communicate analytic solutions to technical and non-technical stakeholders, including during executive- level and/or cross-agency meetings, in a clear and effective manner using oral and written communications.
Maintain knowledge of state-of-the-art innovations in data science from both academic and industry sources and identify opportunities for implementation. Engage in general professional development to improve knowledge of IRS processes/programs.
Apply computer based mathematical/statistical techniques using software. Lead or participate in statistical projects or studies in survey sampling (design and estimation), modeling, or statistical research. Apply knowledge of programming/coding language (i.e., SQL, SAS, SPSS, RStudio) to develop scripts or applications.
Act as a troubleshooter in resolving bottlenecks at any step in a project by identifying and proposing solutions; this may include coordination with other project team members or stakeholders to mitigate issues.

WHERE CAN I FIND OUT MORE ABOUT OTHER IRS CAREERS? If you want to find out more about IRS careers, visit us on the web at www.jobs.irs.gov
#LI-POST
You must meet the following requirements by the closing date of this announcement
BASIC QUALIFICATION REQUIREMENTS:

GS-1530 Statistician All Grades:
You must have a Bachelor's degree that included 15 semester hours in statistics (or in mathematics and statistics, provided at least 6 semester hours were in statistics), and 9 additional semester hours in one or more of the following: physical or biological sciences, medicine, education, or engineering; or in the social sciences including demography, history, economics, social welfare, geography, international relations, social or cultural anthropology, health sociology, political science, public administration, psychology, etc. Credit toward meeting statistical course requirements should be given for courses in which 50 percent of the course content appears to be statistical methods, e.g., courses that included studies in research methods in psychology or economics such as tests and measurements or business cycles, or courses in methods of processing mass statistical data such as tabulating methods or electronic data processing. OR
Combination of education and experience -- courses as shown above, plus appropriate experience or additional education. The experience should have included a full range of professional statistical work such as (a) sampling, (b) collecting, computing, and analyzing statistical data, and (c) applying statistical techniques such as measurement of central tendency, dispersion, skewness, sampling error, simple and multiple correlation, analysis of variance, and tests of significance.
GS-13 LEVEL: You must have one year of specialized experience at a level of difficulty and responsibility equivalent to the GS-12 grade level in the Federal service. Specialized experience for this position includes all of the following:
Experience applying project management principles on a data science project
Experience planning and executing a variety of data science and/or analytics projects.
Experience using data mining process models (such as CRISP-DM, SEMMA, etc.,) to design and execute data science project.
Experience preparing and analyzing structured and unstructured datasets to explorations and evaluating data science centric models.
Experience working with multiple data types and formats as a part of a data science project.
Experience applying a range of analytic approaches, including (but not limited to) machine learning, text analytics, and natural language processing; graph theory, link analysis and optimization models; complex adaptive systems; and/or deep learning neural networks that are part of the exploration.
Experience coding in various programming languages (such as R, Python, SQL, or JAVA) to conduct various phases of data science projects.
Experience creating and querying different datastores and architectures (such as Sybase, Oracle, and open-source databases) to work with various types of data as part of the data science project.
Experience using tools for data visualization (graphs, tables, charts, etc.,) and end-user business intelligence.
-The experience may have been gained in the public sector, private sector or Volunteer Service. One year of experience refers to full-time work; part-time work is considered on a prorated basis.
-To ensure full credit for your work experience, please indicate dates of employment by month/year, and indicate number of hours worked per week, on your resume.","Internal Revenue Service
3.5","San Diego, CA",Federal Agencies,Government
Data Scientist,"Seismic is on the lookout for experienced, creative, and dynamic Data Science talent to join and make a massive impact on our product and operations. In this role, you will collaborate with your team and Executive Engineering/Data leadership to sleuth through our proprietary data to help our teams and customers make better decisions. Make a Seismic-Shift and join our team!
Who You Are:
An experienced Data Scientist with a passion for digging deep and finding trends that others may miss
You can release high-quality, production-ready products. This requires rapid iterations, robust debate, and technical skills. The better you are at writing code, the more efficiently we can release a product that's used daily to make critical decisions.
Seen as an active contributor in the team problem-solving-process – you aren’t afraid to share your opinions in a low-ego manner
You enjoy solving challenging problems, all while having a blast with equally passionate and talented team members
You are comfortable and enjoy working with data. This requires a high level of mathematical and statistical literacy and an intense interest in applying quantitative analysis to real-world problems
You can extract meaning from data. Our product lives and dies based on the accuracy of our data-driven advice
You are intellectually honest, not fooled by randomness, and obsessive about details
You are well versed in techniques such as statistical analysis, exploratory analysis, and predictive analysis
What you will be doing:
Rapidly design and implement machine learning and data products that our enterprise customers and internal teams will use to make informed data-backed decisions
Design and implement the data and analytics products that are leveraged by our enterprise customers
Provide data insights back to the organization in an accessible and end-user friendly manner
Collaborate with software engineers, data engineers, and fellow scientists to create the best solutions for our customers internally and externally
Work closely with stakeholders and contribute your suggestions to build optimal solutions
Implement algorithms with modern software development and delivery techniques
Remain up-to-date with the latest trends in data science and bring that knowledge to life in our products and analysis
Be flexible to handle other duties as assigned
What you bring to the team:
Bachelor's degree in Computer or Data Science, Applied Mathematics, similar technical field of study, or equivalent practical experience
Minimum of 5 years of experience as a Data Scientist, Data Engineer, or Machine Learning Engineer
3-5 years of experience with Python and SQL as it pertains to Data Analytics / Data Mining
Deep familiarity with BI/Data tools such as Tableau, Spark, Snowflake, etc.
Familiarity with Kubernetes, C#, Docker, Apache Kafka a plus!
Strong background in Machine Learning a must. Focus on recommendation systems, natural language processing (NLP), Bayesian estimation, or reinforcement learning would be nice.
What we have for you:
Generous PTO, paid holidays, and paid sick leave
Competitive Medical, Dental and Vision Plans
Robust 401(k) fund options with company matching
Catered meals, healthy snacks and coffee bars
Seismic Cares volunteer program
#OneSeismic culture that celebrates wins, encourages autonomy, ownership, and transparency
About Seismic:

Seismic, ranked as one of the best places to work by Inc. Magazine, is a rapidly growing Forbes Cloud 100 company and is emerging as the recognized category leader in sales enablement. Seismic unites marketing and sales teams in delivering the most compelling stories throughout a buyers’ journey. More than 600 customers rely on the world’s most powerful storytelling platform to connect the right buyer, with the right content, at the right time, every time. Seismic customers such as T. Rowe Price, IBM, American Express, PayPal, Rockwell Automation, and Quest Diagnostics are achieving higher win rates, larger deal sizes, and improved customer retention rates with our solution. Seismic recently achieved a billion-dollar valuation and was named to the 2019 Forbes Cloud 100.

Headquartered in San Diego and with more than 800 employees across the globe, Seismic is privately held and backed by investment firms General Atlantic, JMI Equity, Jackson Square Ventures, Lightspeed Venture Partners, and T. Rowe Price. Seismic also recently expanded its team and product portfolio with the acquisition of Percolate. Our board of directors is composed of several industry luminaries, including John Thompson, chairman of the board of directors for Microsoft.

Please note this job description is not designed to cover or contain a comprehensive listing of activities, duties, or responsibilities that are required of the employee for this job. Duties, responsibilities and activities may change at any time with or without notice.","Seismic
4.5","San Diego, CA",Enterprise Software & Network Solutions,Information Technology
Data Engineer,"Do you believe that people with compassion will support one another to create a better world? Well, we do! GoFundMe is the largest social fundraising community in the world and is just getting started. With over $9 billion raised from more than 120 million donations, GoFundMe is the largest social fundraising community in the world and is just getting started.Data is at the center of all decisions and strategy at GoFundMe. The Data Engineer will be a key part of our growing platform engineering team to help build scalable data platforms that enable business analytics, data science and data products, resulting in driving business growth toward a global culture of peer-to-peer giving. This role requires technical expertise in a wide variety of technologies to develop and own our enterprise data warehouse, sourcing data from various databases/web APIs and integrate data with external systems. If you are interested in working in a fast paced environment and like being challenged with fun data problems to solve, come join us in our Los Angeles or San Diego offices.What you'll be doing day to day...* Develop and maintain enterprise data warehouse (in Amazon Redshift)* Create and manage ETL data pipelines (sourcing data from databases, streaming data, various web APIs, etc.)* Integrate data from data warehouse into 3rd party tools to make data actionable* Develop and maintain REST API endpoints for data science products* Provide ongoing maintenance and enhancements to existing data warehouse solutions* Ensure data quality through automated testing* Collaborate with analysts, engineers and business users to design solutions* Research innovative technologies and make continuous improvementsWhat you bring to the role...* 3+ years as a data engineer designing, developing and maintaining enterprise data warehouse solutions consisting of structured and unstructured data* Proficiency with building data pipelines using ETL/data preparation tools* Experience with web APIs and data integrations across internal and external systems* Expertise in writing and optimizing SQL queries* Knowledge of Python, Java, C++ or other scripting languages* Experience with Spark and Scala* Good understanding of database architecture and best practices* Understanding of data science and machine learning technologies a plus* Experience with event tracking is a plus* Bachelor's degree in Engineering* Ping pong skills, a love for boba tea, and a sense of humorWhy you'll love it here...* Your work has real purpose and will be helping to change lives at a global scale.* Our people consistently vote GoFundMe a Great Place to Work®.* You can nominate your favorite GoFundMes to receive a donation from the company.* Great perks like lunch, snacks, wellness, company/team activities, and full benefits.* The company is strong and growing with incredible opportunities ahead.* We're a fun, close team of people who care about their work and impact.More about GoFundMe...https://www.gofundme.com/2019https://www.gofundme.com/c/heroeshttps://medium.com/gofundme-storieshttps://www.gofundme.com/why-gofundmeGoFundMe is changing the way the world gives. Every day friends, family, and members of the community come together to support one another and the causes they care about most. Our campaigners have raised over $9 billion for medical expenses, education, community projects, sports, emergencies, pets and other personal causes and life events--making us the world's largest crowdfunding platform.GoFundMe has assembled one of the best teams to go build the next leading consumer Internet company - including leaders from LinkedIn, Intuit, Groupon, YouTube, Facebook, Twitter, GoPro, Uber and several others. We are also funded by some of Silicon Valley's best venture capital firms, including Accel, Greylock, TCV, and others.GoFundMe is proud to be an equal opportunity employer that actively pursues candidates of diverse backgrounds and experiences. We are committed to providing diversity, equity, and inclusion training to all employees, and we do not discriminate on the basis of race, color, religion, ethnicity, nationality or national origin, sex, sexual orientation, gender, gender identity or expression, pregnancy status, marital status, age, medical condition, mental or physical disability, or military or veteran status.","CrowdRise
4.5","San Diego, CA",Internet,Information Technology
Data Scientist,"Job Number: R0085562

Data Scientist, Mid

The Challenge:

Are you excited at the prospect of unlocking the secrets held by a data set? Are you fascinated by the possibilities presented by machine learning, artificial intelligence advances, and IoT? In an increasingly connected world, massive amounts of structured and unstructured data open up new opportunities. As a data scientist, you can turn these complex data sets into useful information to solve global challenges. Across private and public sectors-from fraud detection, to cancer research, to national intelligence-you know the answers are in the data.

We have an opportunity for you to use your analytical skills to improve the DoD and federal agencies. You’ll work closely with your customer to understand their questions and needs, then dig into their data-rich environment to find the pieces of their information puzzle. You’ll develop algorithms, write scripts, build predictive analytics, use automation, and apply machine learning to turn disparate data points into objective answers to help our nation’s services and leaders make data-driven decisions. You’ll provide your customer with a deep understanding of their data, what it all means, and how they can use it. Join us as we use data science for good in the DoD and federal agencies.

Empower change with us.

You Have:

-3+ years of experience in data science and analytics

-Experience with extract, transform, load (ETL) operations, including on-premises or cloud infrastructure

-Experience with source control and collaboration software, including Git and Atlassian tools

-Knowledge of machine learning approaches, techniques, and their advantages and disadvantages

-Knowledge of cloud infrastructure as a service (IaaS) offerings, including AWS EC2, RDS, ECS, and Lambda or Azure VM, SQL Database, Container Instances, and Functions

-Knowledge of relational and non-relational database technologies, including SQL or GraphQL

-Ability to automate or script tasks on Linux or Windows operating systems, including Bash or PowerShell

-Ability to obtain a security clearance

-BA or BS degree

Nice If You Have:

-Experience with deploying analytics workloads on platform as a service (PaaS) and software as a service (SaaS), including AWS EMR, Redshift, and SageMaker or Azure Databricks, SQL Data Warehouse, and Machine Learning Service

-Experience with distributed or parallel programming frameworks, including Apache Spark or NVIDIA CUDA

-Experience with infrastructure as code (IaC) frameworks and services, including Terraform or CloudFormation

-Experience with developing and presenting complex technical information for both technical and non-technical audiences and senior leaders

-Experience with developing and deploying large-scale batch and stream analytics pipelines

-Experience with integrated groups comprised of product managers, infrastructure engineers, data scientists, and software engineers

-Experience with DoD information systems

-Knowledge of cloud technology and its advantages and disadvantages in secure environments

-Knowledge of secure information systems architecture design and implementation principles

-Knowledge of DevOps principles and tools, including continuous integration and continuous deployment (CI/CD) with Jenkins or AWS CodeDeploy

-Cloud development certification, including AWS Solutions Architect or Azure

-Information Security certification, including Security+ or CISSP Certification

-MA degree in Mathematics, CS, or a related quantitative field

Clearance:

Applicants selected will be subject to a security investigation and may need to meet eligibility requirements for access to classified information.

We’re an EOE that empowers our people—no matter their race, color, religion, sex, gender identity, sexual orientation, national origin, disability, veteran status, or other protected characteristic—to fearlessly drive change.","Booz Allen Hamilton Inc.
3.8","San Diego, CA",Consulting,Business Services
Data Analyst,"At Seer, we pride ourselves on innovation; standing out among the rest and enabling our clients to do the same. We're a Digital Marketing Agency powered by Big Data to drive integrated, holistic strategy for our clients. We get excited at the thought of bringing together millions of data points from disparate data sets (including qualitative!) to drive empathy-fueled opportunities and insights at scale. Big Data, automation, and problem solving at scale: it's what's for breakfast. Could this be love? Maybe.

What about you? You’re a data-obsessed problem-solver. You pay attention to the details without losing sight of the big picture. You know how to think critically and turn business problems into data problems. You’re quick to pick up patterns and patient enough to identify long-term trends. You're detail-oriented, logical, and endlessly curious about how big data is used to inform digital marketing.
Here are some highlights of what you'll be doing...
You’ll be entrenched in the data; working across divisions to turn business problems into data problems through critical thinking and consulting skills
You’ll help manage Seer’s data warehouse leveraging BigQuery and SQL expertise to optimize queries and drive other cost-saving opportunities
You’ll work within our data warehouse, using BigQuery and pulling business insights out of data
You’ll create dashboards in Data Studio & Power BI to display data for greater cross-divisional analysis and crafting strategy
You’ll complete cross-divisional training, gaining a strong foundation of PPC, SEO, Analytics, and how they all work together
You'll contribute to the Seer blog, industry forums, and grow your thought leadership skills from the ground up
The skills you'll bring to the table...
You're an innovator. You're excited to work with Big Data and use your experience in SQL to problem solve and answer business questions
You've worked with data visualization tools, specifically Power BI and/or Data Studio
You have relevant internship experience or hands-on project experience working with data
You take initiative and can self-direct in the absence of detailed guidelines
You’re comfortable managing deadlines for multiple deliverables and thrive in a fast-paced, open environment
You have a strong sense of self, which means you’re able to say no, deliver feedback, have the confidence to provide input, etc.
Bonus Points...
You have experience leveraging Python and APIs to access new data sources not available in the data warehouse
You can interpret API instructions and build MVPs to transfer data from an API into a database or flat file.
You have an understanding of digital marketing data, specifically SEO and PPC. Perhaps you’ve even worked in a marketing agency!? We should definitely chat!!


Sometimes the best opportunities are hidden by self-doubt. We disqualify ourselves before we have the opportunity to be considered. Regardless of where you came from, how you identify, or the path that led you here-- you are welcome. If you read this job description with a belly full of excitement, we’re just as excited about you. You’ve gotta apply though :)","Seer Interactive
3.9","San Diego, CA",Internet,Information Technology
Data Scientist,"Position Role/Tile: Data Scientist
Location: San Diego, CA .

Job Description:
Have strong scientific coding aptitude efficient code that is numerically stable and of production quality.
Are strong analytical thinkers, including reasoning through probabilities and statistics, as well as delving into detailed deterministic thinking and using individual examples
Can learn new business domains, understanding the context for the data science
Can learn and apply machine learning and AI techniques to new domains, with a focus on client needs
Have interest in working from start to finish: gather data, clean and prepare, model, code, package, guide into production, and help clients use the results.
Enjoy working with data.
Can communicate complex and sophisticated ideas to people without scientific backgrounds
Enjoy working in a team environment
You will be responsible for:
Working on problems in the fintech area, including online payments, banking, and other areas
Working on a team under the leadership of other Data Scientists
Communicating with clients, internal and external, to understand the business problems that we can solve using machine learning and AI
Analyzing and understanding data from different domains, including data cleansing and detailed analysis of relationships between fields
Developing supervised, unsupervised, and reinforcement models in the laboratory
Coding models for production, with particular attention to efficient use of computational resources and robustness of the code
Working with Software Engineers and SaaS Operations to package and deploy the models
Monitoring the models to ensure that they are working properly, and generalizing to new data
Working with clients to ensure that they are using the results of the models effectively.
Skills needed include: excellent written and verbal communications, and presentation skills.
Languages needed include a subset of: Python, C++, Unix scripting, SAS, PySpark, Scala, Perl, C
Strong command of Unix is preferred.
Experience: PhD plus 3 years of industry experience in a relevant area, including taking machine learning into a production environment. Alternatively, Master's degree plus 6 years of industry experience in a relevant area, including taking machine learning into a production environment.

Central Business Solutions, Inc,
37600 Central Ct.
Suite #214
Newark, CA 94560","Central Business Solutions, Inc
3.0","San Diego, CA",Consulting,Business Services
Data Analyst,"Department
Bioengineering
Location
San Diego, CA
Job Type
Full Time
ID #
1234624
Cue Health Inc. is seeking to hire a full-time Data Analyst with expertise in data management and analysis.
Responsibilities:
Compile data in designated format
Analyze data and generate summary reports
Exercise considerable judgment and take initiative required to resolve problems and make recommendations
Document experimental data, present data, conclusions, and interpretations
Requirements:
BS degree in Biology, Molecular Biology, Biochemistry, or related field - Great opportunity for a recent graduate (preferred)
2+ years of relative work in bio-production and analytical biochemistry
Knowledge of GMP and GDP lab practices
Proficient in analytical and critical thinking
Proficient in Microsoft and Google applications
Candidate will adhere to established protocols and good laboratory practices while meeting expected daily and weekly deliverables
Excellent written and verbal communication skills
Self-motivated to lead projects while working effectively in a team
Recommended but not Required:
Experience with JMP
Experience in mammalian and bacterial cell culture and transfection
Track record with antibody expression and protein engineering
IVD experience is a plus
Analytical biochemistry for QA/QC of proteins
Physical Requirements:
Remaining in a stationary position, often standing or sitting for prolonged period of time
Adjusting, moving or lifting objects up to 25 pounds
Repeating motions that may include the wrists, hands
and/or fingers
Operating machinery and/or power tools
As part of Cue, you will:
Benefit the organization through use of your expertise in data management and analysis
Where you’ll work
You will work in a modern open office located in Sorrento Valley in San Diego, CA, with a lot of natural light. As an early employee your contribution will set the pace and have an impact in Cue’s future. Your work and ideas will be valued and respected, and we hope you will find enjoyment working with a great team on such an innovative device.
Perks within Cue culture
Unlimited snacks
Competitive salary
Stock options
Robust Health/Dental/Vision benefits, including optional HSA","Cue
4.2","San Diego, CA",Biotech & Pharmaceuticals,Biotech & Pharmaceuticals
Data Scientist,"PURPOSE OF THE JOB

The purpose of this job is to provide analyses of internal and external data sources in support of key business functions. The Data Scientist performs data analysis to support portfolio management and operations goals.

ESSENTIAL DUTIES AND RESPONSIBILITIES

Provides quantitative analysis for portfolio management decisions.
Uses advanced data mining techniques to discover patterns, insights, and trends in ICW data.
Collaborates with other scientists and ICW groups to ensure effective execution of data-drive initiatives.
Collects, aggregates, and analyzes data from multiple internal and external sources for use in advanced analytics.
Writes and maintains code to build and maintain data pipelines for production models.
Develops high quality, replicable predictive and descriptive analytics for business use.
Analyzes, refines, and documents functional requirements for modeling projects.
Drives insights into business performance optimization.
Evaluates complex business and system requirements to create detailed business user requirements, system documentation, workflow procedures, and data modeling.
Develops an understands the business issues and data challenges of the organization in order to provide meaningful insights.
Communicates findings and insight to stakeholders and provide business strategy recommendations for optimizing business performance.
Evaluates the business and end user data requirements and develops analytical and reporting solutions to address those needs.
Understands and translates business requirements into functional requirements.
Improves workflows and business processes in assigned business units.
Aids in the analysis of current business processes; makes recommendations to management for new, more efficient, workflows, and processes.
Develops or assists with developing functional specifications and system design specifications for assigned projects.
Uses analytics and metrics to improve processes and provide data-driven forecasts of potential costs, risks, and profits of new business initiatives.
Provides reporting solutions and responds to ad-hoc report requests across multiple business areas.
SUPERVISORY RESPONSIBILITIES

This role does not have supervisory responsibilities.

EDUCATION AND EXPERIENCE

Bachelor's degree from four-year college or university preferred with a major or emphasis in Mathematics, Data, Computer Science or related field. Minimum 3 years of related technical experience and/or training required or equivalent combination of education and experience. Or Master’s degree plus one-year experience in related discipline. Insurance industry experience preferred.

CERTIFICATES, LICENSES, REGISTRATIONS

None required.

KNOWLEDGE AND SKILLS

Demonstrated experience with statistical modeling techniques, especially generalized linear models, cluster analysis, latent class analysis, and factor analysis. Demonstrated experience and knowledge of machine learning techniques, including random forests, gradient boosted machines, extreme gradient boosting, and support vector machines.

Knowledge of and experience with contemporary model validation methods, including cross validation and nested cross validation. Knowledge of databases and database methodology; experience with SQL Server is a plus. NoSQL database experience is beneficial. Knowledge of data warehouse principles, data modeling, and other business intelligence architecture methods is desirable. Experience with contemporary reporting tools is desired.

Demonstrated knowledge and experience with open source analytics platforms, such as Python and/or R. Working knowledge in analytic platforms such as Sagemaker, TensofFlow and Keras a plus. Process and model documentation using Markdown or other electronic means and experience using Git and GitLab are desired.

PHYSICAL REQUIREMENTS

Office environment– no specific or unusual physical or environmental demands and employees are regularly required to sit, walk, stand, talk, and hear.

COMPETENCIES

This position maps to the Individual Contributor level. Additional competencies required: None.

WORK ENVIRONMENT

This position operates in an office environment and requires the frequent use of a computer, telephone, copier, and other standard office equipment.","ICW Group
3.3","San Diego, CA",Insurance Carriers,Insurance
Data Engineer,"Mercato connects independent food retailers with consumers and suppliers to streamline their business, increase sales, and lower operating costs.

Reporting to the VP of Engineering, the Data Engineer will own Mercato’s data warehouse, its design. The Data Engineer will implement and maintain custom ETLs.

You will be the first Data Engineer at Mercato and have opportunities to contribute to a variety of projects and technologies including analytics, ML modeling, tooling, services, and more.

You are focused on results, a self-starter, and have demonstrated success in developing and maintaining data infrastructure to ensure your colleagues are empowered with reliable access to data.

Responsibilities
Collaborate with Product Management and Engineering to understand data needs, solve problems, and identify trends and opportunities.
Design, build and launch new data extraction, transformation, and loading processes in production.
Manage data warehouse plans for a group of products.
Work with data infrastructure to triage infrastructure issues and drive to resolution.
Build data expertise and own data quality for allocated areas of ownership.
Support existing processes running in production.
Requirements
Experience with custom ETL design, implementation and maintenance, including schema design and dimensional data modeling.
Significant experience with workflow management engines (i.e. Airflow, AWS Step Functions, etc).
Expert proficiency in any scripting language (Python, Node.js, R, etc.) and SQL.
Experience working with cloud or on-prem Big Data/MPP analytics platform (i.e., AWS Redshift or similar).
Ability to analyze data to identify deliverables, gaps, and inconsistencies.
Communication skills. A strong ability to identify and communicate data-driven insights.
Managing and communicating data warehouse plans to internal clients.
4+ years experience working with either a Map Reduce or an MPP system.
Ability to thrive in an unstructured environment, working autonomously to find opportunities to deliver business impact.
Success Drivers And Competencies
Must be able to convey information in a clear, focused, and concise manner.
Experience in planning, coordinating, and executing multiple projects simultaneously.
Ability to think creatively and work in a team environment.
Must work well in a dynamic environment and be able to recommend and implement process improvements, work independently, and handle multiple tasks simultaneously.
Passion for helping others.
Benefits

Mercato is an equal opportunity employer. We believe passionately that employing a diverse workforce is central to our success. We make recruiting decisions based on your experience and skills. We value your passion to discover, invent, simplify, and build.

By submitting your resume and application information, you authorize Mercato to transmit and store your information in the Mercato group companies' nationwide recruitment database.

Compensation Commensurate With Experience.

Upbeat work environment at a company with a huge vision.","Mercato
3.9","San Diego, CA",-1,-1
Data Analyst,"Job Description
Job Title: Data Analyst
Location: San Diego, CA
Longterm Contract (W2)
Salary: DOE

Job Description:
Identifies, locates and extracts data from a variety of sources for use in reporting, analysis, and statistical modeling
Responsible for providing reporting, ad-hoc data and analytical support across operational areas of the business through a translation of complex analytics into concise and consumable reports
Tests, analyzes and problem solves data issues to ensure data integrity and provide technical support for end-users self-service BI tool.
Participates in analytical investigations aimed at answering specific business problems using data with an emphasis on recommending actionable solutions based on insights
Builds strong relationships with business partners and leaders to provide thought partnership on metrics and visualizations
Collaborates and provides support to multiple departments to ensure the business intelligence, analytics, and reporting needs are met with technology, architecture, processes, and tools
Develops and maintains automated reports for daily consumption using specific formatting and presentation guidelines
Documents data definition and report sources and for all reports
REQUIREMENTS:
0 to 2 years of experience in database marketing analysis including analytics, response analysis, ROI analysis, customer profiling or equivalent
SAP BI or equivalent BI tool expertise required
Experience with visualization tools such as Tableau preferred
Experience with database querying tools, languages and analytical platforms supporting database marketing, including SQL, required
Big data experience preferred","Conflux Systems Inc.
4.5","San Diego, CA",Accounting,Accounting & Legal
Data Scientist,"Job Description
Job Title: Data Scientist
Location: San Diego, CA
FULLTIME ROLE

Overview:
We are looking for a hands-on research scientist with a good track record of experience in
applying machine learning methods towards solving real-world problems through
(Un)supervised Learning, Operations Research and Optimization Problems to name a few. You
will be joining an excellent, multidisciplinary team and will be participating in cutting-edge
work in data science. You will be providing quality answers to large-scale problems with broad
impact.

Responsibilities:
1. Conceptualize, design and develop prototypes which demonstrate the required
functionality rapidly
2. Understand the latest industrial and academic developments in AI/ML, and apply it to
create prototypes for demonstration.
3. Work with development teams to mature these algorithms into production quality
programs
4. Do applied research on a wide array of Operations research and machine learning
projects.

Desired candidate profile:
1. Degree in relevant field or considerable hands-on experience in data science algorithms
2. Basic understanding of Supervised learning, Unsupervised learning. Graph theory
knowledge is a plus
3. Basic knowledge in working with Deep Learning libraries such as Tensorflow or Pytorch
or Keras or Theano is a plus.

Basic Qualifications:
1. A good foundation in AI Methodologies like ML and Deep Learning. NLP, Computer
vision is a plus.
2. Very good python programming skills. Java programming skills a bonus
3. Detailed oriented and penchant for data quality control
4. Ability to Dig deeper into data, understand characteristics of data, evaluate alternate
models and validate hypothesis through theoretical and empirical approaches
5. Is a Self-Driven individual contributor who prefers working in an agile manner.
6. Ability to work independently and have ownership mentality
7. Innovation minded, highly capable to think systematically, capable of redefining the
solutions to overcome the competitors and solving problems.
8. Curious and willing to challenge existing solutions with innovative technology concepts.
Thanks,
Amit Sehdev
APN Software Services Inc.
Direct: 510-402-1061 | Fax: 510-623-5055 | Amit@apninc.com
“Ranked Top Work Places 2016”
“Certified Small and Minority Business”
“Ranked Top 50 Organizations for Diversity”
“Ranked Top Diversity Business”","APN Software Services Inc.
4.1","San Diego, CA",Computer Hardware & Software,Information Technology
Data Analyst,"As we navigate through these unprecedented times, MCM’s focus continues to be our commitment to our Consumers and Employees. Over the past couple of weeks our teams have worked diligently to ensure wherever possible our employees were able to move to 100% remote work and our Consumers were still supported.

MCM continues to hire in areas which aid in the support of our Consumers and Employees. We have also leveraged our digital capabilities to continue to provide a great recruiting experience. As an applicant, you may be asked to complete a phone screen, or a virtual interview and our Recruiting Team is committed to supporting any questions you may have throughout the Interview process.

Now more than ever, we have a high demand for goal-driven, motivated individuals to join our team.

The Data Analyst is primarily responsible for using data extraction tools, largely Excel, SQL, and Python to perform in-depth analysis of programs and opportunities in the business. The Data Analyst will make recommendations to improve the operational processes based on their analysis and may design strategies to implement those recommendations. The analyst will then coordinate with other stakeholders to ensure the implementations meet the needs of the business. The primary area of focus for the data analyst is working with data related to Encore Advantage’s customers and tailoring strategies to best serve them.

The position is also responsible for creating and monitoring reports to identify trends, issues and opportunities.

Responsibilities:
Create and monitor reports to identify issues, trends, and opportunities.
Extract and analyze data to support business initiatives (e.g. profitability, performance and variance analysis).
Recommend improvements related to business profitability or processes.
Collaborate with relevant stakeholders to design and execute new strategies
Qualifications:

Required: Bachelor; Quantitative field","Encore Capital Group
3.2","San Diego, CA",Financial Analytics & Research,Finance
Data Analyst,"Client Solution Architects

CSA is a Federal Contractor and an Equal Opportunity/Affirmative Action Employer of Females/Minorities/Veterans/Individuals with Disabilities. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity or national origin.

remote Mid Atlantic - Program Management Contingent

CSA is seeking a Data Analyst to join our team. This position is contingent upon award.

Duties and responsibilites are but not limited to the following:

Assesses complex data systems and programs in support of ad-hoc and standing management or customer requests.

Creates programs, methodologies, and files for analyzing and presenting data.

Examines data quality, applications, and functions.

Produces output and sustains operation.

Researches new data sources and analytical tools.

Contributes to new product development and improvement in product delivery and presentation.

Develops awareness of and familiarity with issues and events affecting organization, department, and/or customer.

Uses and supports database applications and analytical tools.

Uses timely and appropriate participation of users/customers in data collection and query systems.

Provides accurate and appropriate interpretation of data, applying knowledge to evaluation, analysis, and interpretation of data.

Develops appropriate methodologies for collecting, analyzing, and presenting data products.

Develops useful and insightful information from a variety of data sources.

Works with management and/or customers to develop and understand product specifications.

Communicates regularly and effectively with team members and management, and communicates results effectively to management and/or customers.

Delivers data products in report/presentation format, or verbally, to management and/or customer specifications and timelines.

Points out system or process problems when noticed and engages the team in problem solving.

Facilitates satisfactory communication and resolution of problems.

Required Qualifications
5 years of relevant experience; DoD preferred
B.S., Computer Science or related field; can be substituted with 4 years relevant experience
Ability to obtain a DoD Secret clearance
Applicants may need to meet eligibility requirements for access to classified information; an active United States Department of Defense security clearance or the ability to obtain one may be required for this role.

CSA Rocks! We are a rapidly growing consulting firm recognized for being one of America's Fastest Growing Companies on the Inc. 5000 list for a record 7 years in a row, averaging an 81% increase in revenues for each of the past three years. So how do we do it? It's no secret, we owe the past 15 years of our success to our outstanding and ambitious team members. To support our hard working team, we offer an environment focused on learning and growth, an awesome benefits package, and opportunities to build a long and successful career.

We are constantly on the hunt for talented, forward-thinking problem solvers with an energetic attitude and a strong work ethic to join our elite team of CSAers.

Be a part of CSA... do great things!PI121230637","Client Solution Architects
3.4","San Diego, CA",Aerospace & Defense,Aerospace & Defense
Data Engineer,"Primary Skills 4+ years working experience in data integration and pipeline development. BS degree in CS, CE or EE. 2+ years of Experience with AWS Cloud on data integration with Apache Spark, EMR, Glue, Kafka, Kinesis, and Lambda in S3, Redshift, RDS, MongoDBDynamoDB ecosystems Strong real-life experience in python development especially in pySpark in AWS Cloud environment. Design, develop test, deploy, maintain and improve data integration pipeline. Experience in Python and common python libraries. Strong analytical experience with database in writing complex queries, query optimization, debugging, user defined functions, views, indexes etc. Strong experience with source control systems such as Git, Bitbucket, and Jenkins build and continuous integration tools. Databricks or Apache Spark Experience is a plus.","Kaygen Inc
3.9","San Diego, CA",Consulting,Business Services
Data Analyst,"Job Title: Data Analyst
Location: San Diego, CA
Duration: 6 Months
Job Description:
The Data Analyst will design and perform data testing and validation functions and contribute to the enhancement of policies, processes, and documentation for various types of data acquired or produced by the agency's modeling, forecasting, analysis, and mapping efforts.
The Data Analyst ensures the integrity, validity, and credibility of data flowing into and out of various spatial and non-spatial databases.
Roles & Responsibilities:
This position is best suited for a data quality assurance/quality control professional with experience in data analytics and complex query development. We anticipate career development will occur while working on the types of duties and responsibilities described below and through mentoring and close collaboration with agency executives. Examples of primary responsibilities include:
Analyze and validate regional economic, demographic, land use, and transportation data for use in operational, procedural, and policy decision-making activities; interpret multi-disciplinary data demonstrating a thorough understanding of issues that could affect the validity and reliability of information.
Design, develop, and perform robust quality assurance testing and analysis of regional data; apply analytical and problem-solving skills to identify and report data anomalies, identify root cause patterns, and facilitate resolutions to issues.
Develop complex queries to examine existing or prospective datasets; develop and implement test approaches, automated tests, test environment requirements, and data strategies; identify risks and problem areas and recommend standards, policies, and procedures to correct deficiencies.
Create and maintain documentation related to data compliance, business rules, data flows, process flows, and reporting.
Coordinate the preparation of metrics and statistical reports, perform audits, and complete special studies; prepare spreadsheets, charts, and graphs to support information sharing.
Participate in the maintenance and documentation of comprehensive computerized databases in SQL Server, Excel, and Access formats.
Participate on inter-departmental and interagency teams assembled for various agency projects.
Prepare and present written, oral, and visual reports and recommendations to various teams and upper management.
Required Qualification:
The minimum education, training, and experience qualifications include a bachelor's degree with major course work in computer science, management information systems, regional planning, geography, demography, economics, statistics, mathematics or a related field, and one to four years of professional quality assurance, data analysis, database, and programming experience.
Knowledge of quality assurance and quality control practices used for validating data and ensuring data integrity, including statistical analysis and sampling techniques, preferably for demographic and economic data.
Experience with data analysis and research methodologies; knowledge of data acquisition and quality control methods used for gathering and compiling various types of information; knowledge of factors that contribute to the reliability and integrity of collected data.
Ability to understand, simplify, statistically analyze, and effectively interpret data and report problems through written and/or graphical formats in a highly complex and data-centric environment.
Experience analyzing, organizing, interpreting, and exploring data with the ability to Client patterns, meaningful relationships, anomalies, and trends.
Experience performing complex dataset queries, to include developing and maintaining various tests and data strategies for risk identification and highest quality data standards assurance.
Demonstrated computer software proficiency using the Microsoft Office Suite especially Excel and Access, SharePoint or other collaboration portal systems, SQL Server or other relational database management system; knowledge of database construction, management, and retrieval methods.
Programming experience in SQL, R, Python, Java, or other language.
Experience using Business Intelligence/Information Sharing software (Power BI, Tableau, etc.) to create reports and dashboards.
Experience participating in multi-disciplinary project teams and providing expertise regarding quality assurance and quality control practices.
Familiarity with formalized data governance processes and procedures.
Experience communicating highly technical information effectively, both orally and in writing; to a broad range of audiences; ability to prepare and deliver findings, presentations and recommendations regarding various analytical efforts to management, partner teams, and other audiences.
Excellent organizational skills and the ability to manage several concurrent projects at various stages of completion; ability to establish and maintain priorities and work independently.
Required Experience:
Experience analyzing, organizing, interpreting, and exploring data with the ability to Client patterns, meaningful relationships, anomalies, and trends.
Experience performing complex dataset queries, to include developing and maintaining various tests and data strategies for risk identification and highest quality data standards assurance.
Demonstrated computer software proficiency using the Microsoft Office Suite especially Excel and Access, SharePoint or other collaboration portal systems, SQL Server or other relational database management system; knowledge of database construction, management, and retrieval methods.
Programming experience in SQL, R, Python, Java, or other language.
Experience using Business Intelligence/Information Sharing software (Power BI, Tableau, etc.) to create reports and dashboards.
4-5 years of experience
About our Company:
22nd Century Technologies is a business enterprise that supports demanding staffing programs for Corporations and State and Local Government Agencies. Its journey began in 1997 by supporting large Federal contracts which nudged us in the direction of creating large candidate pools across the country. Over the last 20 years, we have built a strong business model that is carefully constructed to deliver on multiple facets. We have proven past performance of providing services that exceed our clients' expectations. Today 22nd Century technologies supports clients in all 50 states and has grown to be a company that is trusted and sought for providing a complex mix of workforce solutions. With a firm grip on the entire spectrum of staffing solutions, we have placed more than 500,000 skilled resources and delivered 15 million+ man-hours.
“22nd Century Technologies is an Equal Opportunity Employer"" and “US Citizens & all other parties authorized to work in the US are encouraged to apply.""","22nd Century Technologies
3.7","San Diego, CA",IT Services,Information Technology
Data Analyst,"Job Description
The Customer Engineering Operations team in San Diego is devoted to the support of our internal Engineering personnel as well as our External Customers. This position will be based in San Diego and working in the Customer Engineering Operations team supporting all data analysis activities. Candidate will be responsible for working with a number of different systems to track, report, data mine, and ascertain critical business trends and perform necessary analysis as needed for NRE and non-NRE headcount, budget, third party and IoT business activities. This individual will work via email and telephone with the Ops teams across several countries and must have good writing and verbal skills. Use of multiple business intelligence tools to track and assemble reports for end users. Creation and development of Reports/Dashboards and carrying out statistical analysis and trend analysis of data. Creation of annual billing reports per agreements as needed. Close partnership with the San Diego Ops team for the creation of Salesforce Projects as needed and to capture customer support efforts. Working with IT to troubleshoot day to day end user issues with reporting tools (Salesforce/Qlikview). Candidate will use Excel and Powerpoint skills and should be highly detail oriented.

Minimum Qualifications:
Bachelor's in Electrical Engineering or Computer Science Knowledge of ThoughtSpot and Qlikview tools Expert level knowledge in MS Office, including mastry in Excel (current versions) and MS Powerpoint Proven experience working with Big Data and able to provide customized BI solutions Experience working with data analysis, including driving needs gathering, documentation creation and reporting Salesforce Dashboards and Reporting expertise Salesforce Dashboards and Reporting expertiseSalesforce Dashboards and Reporting expertise

Preferred Qualifications:
MBA with Engineering or Computer Science Degree (MSEE, MSCS, BSEE) -Experience in creating Statement of Work for Engineering Projects -Knowledge of Salesforce
Education:
Strongly preferred: Bachelor's, Computer Science and/or Electrical Engineering
Preferred: Master's, Business Administration and/or Computer Science and/or Electrical Engineering

Duration: 12 months+","ProMedia
4.4","San Diego, CA",Advertising & Marketing,Business Services
Data Engineer,"Job Description
Context

Working in teams (consisting of Hadoop data engineers, Hadoop data warehouse engineers, and platform engineers) that are building and managing Hadoop stacks. The teams install, configure and manage Hadoop ecosystem components.

As Hadoop data engineer, you are responsible for the functional part of provisioning data – e.g. building data ingestion pipelines and data connectors. You work closely with the data scientists and business intelligence engineers who are using this data to create analytical models.

Competence

You are well acquainted with the complete Hadoop stack. In addition, you have practical experience of being part of a DevOps team. Further requirements:
Bachelor of Science / Master’s degree in Computer Science, System Administration, or any other IT infrastructure or software related study with a passion for the automation side of IT infrastructure
Minimum 2-3 years of relevant work experience
Capable of building/operating highly available, distributed systems of data extraction, ingestion, and processing of large data sets of structured, semi-structured and unstructured data
Experience in building data products incrementally and integrating and managing data sets from multiple sources
Data quality oriented
Familiar with data architecture including data ingestion pipeline design, Hadoop information architecture
Hortonworks Certified Hadoop Developer and/or Cloudera Certified Hadoop Developer and/or Certified Hadoop Administrator
Knowledge of continuous integration & delivery tooling: e.g. Jira, Git, Jenkins, Bamboo
Coding proficiency in at least one modern programming language (Python, Ruby, Java)
Strong verbal and written communication skills
Good documenting capabilities
You have a hands-on mindset, a strong customer focus, a problem-solving orientation and can show fast results
You have a clear focus on results and quality.
Willingness to travel to the Netherlands if required for training or project work
Activities
Build efficient and highly reliable data ingestion pipelines for the Hadoop stack
Own data quality and data knowledge around all data that you touch
Work side-by-side with software engineers and data scientists in designing modeled data sets to be used in many different applications, from proof-of-concept to production
Understand the entire life cycle of data that flows through any systems for which you are responsible
Pay constant attention and effort to the reliability of your pipelines
Contact

Reports to the Itility project manager, working in close harmony with team members and interfacing with the standing IT organization.
Company Description
In large organizations, project managers, architects, and business analysts often operate autonomously. Not at Itility. Here these competencies are combined into customer-targeted teams, enabling the rapid delivery of results (within weeks). This rigorous approach is an essential feature of the Itility high-end consultancy formula.

At Itility, you can advance your career as an IT professional; working on projects, Smart Factories, Smart Run, and consulting assignments onsite. An Itility team always comprises multiple competencies; ranging from project manager and scrum master to stack engineer, DevOps engineer and architect.

Our teams direct project implementation. We begin by using our own IT assessment methodology to analyze customer problems, then define the best solutions, while determining required actions.

This knowledge-intensive approach has a proven direct and positive impact on career development. With Itility, you’ll obtain a broad view of the IT profession; working with one customer in the implementation phase and another in the preparatory phase.

To support your development, we provide resources in the form of training, and our Itility toolkits (Ikits); including the Project Management Ikit, the Scrum Ikit, and the Smart Factory Ikit.","Itility
4.0","San Diego, CA",IT Services,Information Technology
Statistician,"PSI Pax, Inc. has an exciting opportunity for a Data Scientist 2 (Tableau - Statistics (IT Portfolio), Predictive Analysis & Visualization) to support our government customer in San Diego, CA.

Position is contingent upon contract award.

Essential Job Functions & Responsibilities:

Tableau - Statistics (IT Portfolio), Predictive Analysis & Visualization.

Conduct planning, analysis, integration, extraction, migration, and reporting of data in Navy Enterprise Resource Planning (N-ERP) and its associated software products. Create, maintain, and manage the tables, cubes, extracts, and reports used to provide the required information. Sustain the data structures, processes, principles, business rules, and operational practices of N-ERP in the current operating environment.

Utilize Government provided software environments, applications, and tools to support N-ERP, data analytics, and other IT operations. Configuration files, source code, scripts, reports, visualizations, analytics, and algorithms shall be developed and retained in tools within the Government provided environment.

Required Qualifications:
One (1) year of experience translating business requirements into reporting designs, predictive and statistical analysis, data cleansing, and visualizing business data.
One (1) year of experience using analytics environments necessary for specific job duties (Tableau, R, Python, etc.)
Eligible to obtain a SECRET level security clearance (final SECRET clearance required if tasking includes access to classified systems).
Education Requirements:

Bachelor's degree from an accredited college or university in one of the following fields: Computer Science, Engineering, Mathematics, Statistics, Operations Research. An additional 4 years of relevant specialized experience may be substituted for a Bachelor's degree.

In addition, U.S Citizenship is required. Applicants selected will be subject to a government security investigation and must meet eligibility requirements for access to classified information and be able to obtain a DoD government-granted security clearance. Individuals may also be subject to a background investigation to include but not limited to criminal history, employment and education verification, drug testing, and creditworthiness.

PSI Pax is an Equal Opportunity/Affirmative Action Employer. Qualified applicants will receive consideration for employment without regard to race, color, religion, sex, age, national origin, marital status, disability, protected veteran status, sexual orientation, or genetic information.

PSI Pax is an E-Verify Participant","PSI Pax
4.1","San Diego, CA",IT Services,Information Technology
Data Analyst,"Job Description
Job description

• Interpret data, analyze results using statistical techniques and provide ongoing reports

• Develop and implement databases, data collection systems, data analytics and other strategies that optimize statistical efficiency and quality

• Acquire data from primary or secondary data sources and maintain databases/data systems

• Identify, analyze, and interpret trends or patterns in complex data sets

• Filter and “clean” data by reviewing computer reports, printouts, and performance indicators to locate and correct code problems

• Work with management to prioritize business and information needs

• Locate and define new process improvement opportunities

Requirements

• Proven work experience as a data analyst or business data analyst

• Technical expertise regarding data models, database design development, data mining and segmentation techniques

• Strong knowledge of and experience with reporting packages (Business Objects etc), databases (SQL etc), programming (XML, Javascript, or ETL frameworks)

• Knowledge of statistics and experience using statistical packages for analyzing datasets (Excel, SPSS, SAS etc)

• Strong analytical skills with the ability to collect, organize, analyze, and disseminate significant amounts of information with attention to detail and accuracy

• Adept at queries, report writing and presenting findings

• Master's in Computer Science or Engineering Management or Project Management or Information Systems/Technology (Preferred)

Powered by JazzHR

XeoT3TSJ4T","Staffigo Technical Services, LLC
5.0","San Diego, CA",IT Services,Information Technology
Data Analyst,"What you'll be doing:The Data Analyst uses advanced data analysis expertise to guide the Behavioral Sciences team across a wide range of data and reporting projects such as customer experience, retention and post-market surveillance studies. The person in this role will co-design processes and structures to enhance data flow between back end systems in collaboration with the Business Intelligence team. The Data Analyst handles quantitative and qualitative datasets for analyses and synthesis. The person in this role needs experience a) writing efficient SQL queries b) using Qualtrics software, and c) designing statistical analyses plans for the generation of behavioral insights.Who we are:Here at Tandem, Diabetes is all we do and we are dedicated to making the lives of people with diabetes better and better, through relentless innovation. ""In Tandem"" means together, and we strive to embody that in every aspect of our business. We believe that working in tandem, not in isolation, is the best way to continually exceed expectations.We've have been named one of the fastest growing insulin pump companies in the U.S! Why? Designed, assembled and supported from our San Diego, CA headquarters, Tandem has created the simple-to-use t:slim X2 Insulin Pump, which is the smallest pump available, the only color touch-screen insulin pump capable of remote feature updates, and the first CGM-enabled pump approved to let users make treatment decisions without pricking their finger.Read more about our company & culture here: https://www.tandemdiabetes.com/careers/life-at-tandem and see what our customers are saying here: #tsliminthewildWhat you need for this position:PRIMARY DUTIES & RESPONSIBILITIES:* Writes SQL queries to extract data for publications and research projects.* Creates dashboards and reports using software such as Power B.I. and Qualtrics that require use of Tandem's Enterprise Data Warehouse.* Sets up Qualtrics surveys so that data can be automatically consumed in the Enterprise Data Warehouse with no manual post-processing.* Serves as the primary liaison between Behavioral Sciences and Business Intelligence team.* Teaches other members of the team and other Behavioral Sciences stakeholders technical skills for use of various software tools.* Performs data and statistical analyses for publications and research projects.* Assists in the writing of original research for peer reviewed publications (e.g. research journals and conference posters) as needed.* Takes a supporting role in establishing the strategic direction of Tandem product offerings within diabetes and in pipeline therapeutic areas.* Supports and/or initiates innovative use of data to support senior management and Tandem initiatives.* Initiates research in measuring the effectiveness of behavioral sciences projects.* Provides extra support as needed to the organization on all end to end research projects.* Attends industry business, clinical and technical conferences.* Ensures compliance with company policies, including Privacy/HIPAA, and other legal and regulatory requirements.* Other responsibilities as assigned.Knowledge, skills & abilities:* Advanced SQL knowledge.* Experience cleaning and analyzing real-world data.* Advanced statistical analysis skills (both qualitative and quantitative) required.* Experience using social statistics (i.e. ANOVA, MANOVA, Repeated Measures, Multiple Regression).* Experience using data analysis software such as R, Python, SPSS, SAS, or another statistical software highly preferred.* Strong T-SQL skills including proven ability to read, write and debug complex SQL queries.* Experience with Microsoft Power BI preferred.* Experience with OLTP data sources (MS Dynamics AX & CRM preferred).* Ability to explain numeric data in a clear, concise, written and verbal format.* Advanced technical skills in utilizing, integrating, analyzing large databases that originate from multiple database sources.* Ability to work in a ""high growth"" environment.* Able to assert own ideas and persuade others through effectively consolidating, evaluating, and presenting relevant information.* Able to exhibit Tandem required values and behaviors to serve as an effective team member.* Able to use RACI matrix and other role clarity tools as needed across projects.* Adept at seeing change as an opportunity to improve business performance and campaigning for it when necessary.* Strong written presentation skills.* Highly organized, process-oriented, and thorough.* Ability to effectively and efficiently manage/assist multiple projects and tasks and be flexible when presented with unexpected change.* Knowledge and implementation of ethical behavior when handling, managing, and using statistical methods to analyze data.* Ability to produce novel and innovative research ideas that can be used to help guide internal company decisions and/or be published to highlight benefit of Tandem customer experience.Minimum certifications/educational level:* Master's degree in a data analytics field, experimental psychology, or a related field or equivalent combination of education and applicable job experience.Minimum experience:* Experience using Qualtrics, SQL, Power BI, and Microsoft Office Suite is required.* Experience working within medical device, medical diagnostics, biotechnology, or pharmaceuticals industry is preferred.* Experience in healthcare is a strong plus.JOB SCOPE:* Understands professional concepts of area of specialization and uses them to creatively resolve issues.* Works on problems of varied scope where analysis of situations or data requires a review of a variety of factors.* Normally receives general instructions on routine work, requires instructions only on new projects or assignments.* Customarily and regularly exercises discretion and independent judgment.What's in it for you?We've got you covered. We offer a robust benefits package to support your health and your family. From medical, dental, and vision, to flexible spending accounts for both health and dependent care - Tandem's got you covered!Stay well with us. Enjoy the outdoors during your workday by biking, running, or walking on one of our nearby trails. Or check out our offsite gym, which boasts luxurious amenities including specialty fitness classes and state-of-the-art equipment.Invest in your career. Tandem offers all employees access to training and development programs and courses to help keep your career and skillset updated, not outdated.Live your life. Relax with 20 days of paid time off and celebrate 10 paid holidays in your first year. Save for your future with a company-provided 401(k) plan. Look forward to saving money on tickets to the San Diego Zoo, movies, restaurants, and so much more with our exclusive employee discount program.Celebrate in Tandem. Join in monthly employee get-togethers, tacos for Cinco de Mayo, corned beef for St. Patrick's Day, costume-contest for Halloween, and the annual JDRF walk.","Tandem Diabetes Care
3.6","San Diego, CA",Health Care Products Manufacturing,Manufacturing
Data Engineer,"Position OverviewStepStone Portfolio Analytics and Reporting (""SPAR"") is looking for a Data Engineer to join the Analytics team. The team applies its comprehensive knowledge of private markets to deliver customized performance reports and monitoring services to meet the needs of various types of investors. The Data Engineer will ensure necessary data is being recorded, validate and maintain a large data pipeline, mine large quantities of data, and build new data infrastructures as needed.We are looking for candidates who are interested in building the team's capabilities around the extract, transform, and load processes of analytic projects. The ideal candidates will be passionate about creating better standardized processes so that the broader team is able to focus more on the analysis portion of the pipeline. Minimizing the team's efforts around ETL is the number one priority. This will be a fast-paced and dynamic environment that is ideal for those who want to continuously tackle challenging problems and learn new things.Essential Job Functions:* Develop highly efficient systems to retrieve, maintain and analyze discrete financial data* Perform data normalization and management ensuring data security and efficiency* Perform ETL tasks and maintenance* Maintain and test data integrity to ensure accuracy and timeliness* Peer review SQL queries for errors and optimization* Define and iterate on development of analytics infrastructure for interactive dashboardsQualifications:* 2+ years' experience programming large complex data sets* Experience revising and optimizing complex queries with SQL* Solid grasp of Python programming* Database management experience is a plus* Good understanding of data modeling and relational databases* Experience working in collaborative environments* Inquisitive and intellectually curious: able to independently learn new technologies, skills, and industry standards* Bachelor's degree from an accredited institution","StepStone
3.8","La Jolla, CA",Membership Organizations,Business Services
Data Analyst,"Job Description
Job title Data Analyst
Reports to Grants Director
Department: Administration
Status: Full-time Exempt

SHC Health Center Mission
Building Healthier and Happier Communities Together

SHC Health Center (SHC) is a federally qualified community health center that emerged over forty years ago. The agency serves low-income families and individuals in the County of San Diego in strategic areas with a high density population of Filipinos/Asian and other low-income, uninsured individuals

JOB PURPOSE

The Health Care Data Analyst role will be responsible for helping develop SHCs reporting application and capabilities including the build out of robust dashboards that monitor clinical quality, medical cost, key trends, program tracking, and operational performance. The job entails the acquisition, management, manipulation, and analysis of data specifically related to the healthcare industry. This role will work with data from a variety of disparate sources including claims, patient records, hospital systems, laboratory results, pharmacy data, and other relevant areas. The Analyst must identify trends and patterns in healthcare cost and quality performance as well as operational reports for the management of the overall health and wellness of the patients supported by SHC. Developing focus areas for medical cost and quality action plans is also a critical function. The role will actively partner with SHCs technology, program management, business operations, executive leadership, and client operations to deliver insights and tools to support a market leading analytics and reporting infrastructure.
ESSENTIAL DUTIES AND RESPONSBILITIES

Development and maintenance of a full suite of reporting capabilities that help manage, track, and control the overall medical cost and clinical quality of a given population set
In collaboration with others, interpret data and develop recommendations and trainings based on findings
Articulation of complex data through the development of graphs, reports, and presentations
Develop value realization plans to monitor the effectiveness of implemented programs and trainings
Identify, analyze, and interpret trends or patterns in complex data sets
Create and present quality and medical cost dashboards internally to senior management and mid managers.
Analyze and problem solve issues with current and planned systems as they relate to the integration and
management of patient data.
Ad hoc report development and analysis as necessary.
Other duties as assigned.

QUALIFICATIONS
1+ years of experience working with healthcare data
Bachelor's degree in Information Management, Healthcare.
Information, Computer Science, Mathematics, Statistics, Economics, or related fields.
eClinicalWorks Experience preferred.
Exceptionally strong analytic abilities, with a proven track record of driving insightful findings from quantitative and qualitative data.
Ability to develop contextually rich and visually compelling presentations to communicate complex concepts.
Extensive experience in the following environments: SQL, Access, Excel, and or other statistical packages.

PHYSICAL DEMANDS

Move throughout the clinic and community.
Repetitive hand movement use and view PC. Use fax, telephone, and copier.
Sits or stand for long period of time, reach, bend, climb, stoop, and lift up to 25lb.

WORKING RELATIONSHIPS

Reports to: Grants Director
FLSA Status: Full Time/Exempt",Operation Samahan Health Clinic,"National City, CA",-1,-1
Data Engineer,"SmartDrive Systems gives fleets and drivers unprecedented driving performance insight and analysis, helping save fuel, expenses and lives. Its video analysis, predictive analytics and personalized performance program help fleets improve driving skills, lower operating costs, and deliver significant ROI. With an easy-to-use managed service, fleets and drivers can access and self-manage driving performance anytime, anywhere. The Company has compiled the world's largest storehouse of nearly 200 million analyzed risky-driving events, including video and comprehensive sensor data. SmartDrive Systems is based in San Diego, CA, Shenzhen, China, and Hyderabad, India, and employs over 600 people worldwide.

We are looking for an experienced data-focused engineers to join our team, leading the design, development, and delivery of our high-performance analytics engines for solving computer vision, machine learning, sensor fusion problems running in vehicle and in the cloud at high throughput and high accuracy vehicle event analysis engines (in vehicle and in the cloud), and robust and flexible coaching workflow, reporting, and alert management engines.

Our business is nearly doubling every year, and our people and our platforms are the foundation and enabler of that growth. We are significantly expanding our team, and are looking for technologists with a passion for high performance software development, and a drive to deliver software products that make a meaningful difference in the lives of others.

Responsibilities:
Data Engineering to the core - analysis, modelling, transformation and visualization of datasets for online products and backend data platform.
Implement data engineering codebase using server-side languages Java/Scala or scripting using Python and Javascript
Design and develop apis for data pipelining frameworks on data collection, processing and storage across data stores.
Understand noSQL and stream programming apis for building data pipelines and micro-service based architecture across products
Design and development of data solutions for fast datastores, large scale data warehousing, machine learning and computer vision analytics.
Minimum Qualifications:
Bachelor's Degree in Computer Science or related discipline
5+ years of software development experience
2+ years of experience as a Data Engineer
Preferred Qualifications
Extensive knowledge of RDBMS (Microsoft SQL Server, Mysql, Postgres or similar)
Proven experience with NoSQL stores (one or more of Cassandra, MongoDB, InfluxDB, HBase/HDFS, ElasticSearch)
Experience in a distributed microservices and/or serverless (Lambda) cloud software architecture
In-Depth knowledge of ETL commercial software products (any of Informatica, Talend, Nifi or SSIS) with hands-on experience designing, implementing, and delivering solutions
Expertise with integration of complex and large data from multiple data sources, data and sensor fusion, and migration to newer methodologies
Prior experience as part of a large group working on massive data engineering pipelines and analytics for machine learning, computer vision
An aggressive problem solver who can provide creative solutions to complex situations and obtain buy-in from those affected
An independent worker who can take the initiative to define and prioritize specific goals and objectives, and to do the same for others
Strong people skills - able to communicate with colleagues while building credibility and rapport, modifying behavioral style to respond to the needs of others while maintaining objectives
An organized individual who is very detail oriented and can document and develop plans necessary for deliverables towards specific product or platform goals.
A team player that works hard, admits his/her strengths and weaknesses, and has the flexibility to improve by learning new things","SmartDrive Systems
3.3","San Diego, CA",Computer Hardware & Software,Information Technology
Statistician,"PSI Pax, Inc. has an exciting opportunity for a Data Scientist 2 (Tableau – Statistics (IT Portfolio), Predictive Analysis & Visualization) to support our government customer in San Diego, CA.

Position is contingent upon contract award.

Essential Job Functions & Responsibilities:

Tableau – Statistics (IT Portfolio), Predictive Analysis & Visualization.

Conduct planning, analysis, integration, extraction, migration, and reporting of data in Navy Enterprise Resource Planning (N-ERP) and its associated software products. Create, maintain, and manage the tables, cubes, extracts, and reports used to provide the required information. Sustain the data structures, processes, principles, business rules, and operational practices of N-ERP in the current operating environment.

Utilize Government provided software environments, applications, and tools to support N-ERP, data analytics, and other IT operations. Configuration files, source code, scripts, reports, visualizations, analytics, and algorithms shall be developed and retained in tools within the Government provided environment.

Required Qualifications:

• One (1) year of experience translating business requirements into reporting designs, predictive and statistical analysis, data cleansing, and visualizing business data.

• One (1) year of experience using analytics environments necessary for specific job duties (Tableau, R, Python, etc.)

• Eligible to obtain a SECRET level security clearance (final SECRET clearance required if tasking includes access to classified systems).

Education Requirements:

Bachelor’s degree from an accredited college or university in one of the following fields: Computer Science, Engineering, Mathematics, Statistics, Operations Research. An additional 4 years of relevant specialized experience may be substituted for a Bachelor’s degree.

In addition, U.S Citizenship is required. Applicants selected will be subject to a government security investigation and must meet eligibility requirements for access to classified information and be able to obtain a DoD government-granted security clearance. Individuals may also be subject to a background investigation to include but not limited to criminal history, employment and education verification, drug testing, and creditworthiness.

PSI Pax is an Equal Opportunity/Affirmative Action Employer. Qualified applicants will receive consideration for employment without regard to race, color, religion, sex, age, national origin, marital status, disability, protected veteran status, sexual orientation, or genetic information.

PSI Pax is an E-Verify Participant","PSI Pax
4.1","San Diego, CA",IT Services,Information Technology
Machine Learning Engineer,"Job Role: Machine Learning EngineerWork Location: San Diego, CA
Duration: 12+ Months

Primary Skill Set:
Knowledge of validated approaches for scale-ability, productionalizing AI/ML models and implementing machine learning applied to expansive and diverse datasets (storage GPUs/TPUs, techniques for deep learning at scale)
Deployment of Machine Learning and Deep Learning algorithms on cloud based services (AWS Sage maker, GCP MLE, Digital Ocean, etc.)
Expertise in configuration management systems CI/CD (Docker, Kubernetes, etc.)
Programming experience with Python (and ML packages) and either Javascript, C/C++ or related
Version control (Git, Jenkins), Unix Shell scripting
Experience or familiar with serverless architecture/ paradigm in cloud stack

Preferred Skill Set:
Experience with Image Analysis/Computer Vision is a plus
Experience with Swift, Objective-C, Cocoa, Cocoa Touch, and/or CoreML
Networking concepts and protocols, e.g.: TCP/IP, HTTP, etc.
Knowledge or familiarity of ML algorithms (deep learning, classification, TensorFlow etc.)
Preferred knowledge of Python libraries such as Scikit-learn, SciPy, Spacy, and NLTK

Roles and Responsibilities:
Deploy scalable Machine Learning and CNN based Computer Vision algorithms on local and multi cloud-based inferencing platforms.
Designing and deploying models at scale using automated pipelines.
Convert Python based ML scripts to production quality level applications.
Test applications for stability, resilience, HA and scale them to serve thousands of inferences on a daily basis.
Work closely with data Engineers, developers and Machine Learning engineering peers to integrate ML/AI models and applications with existing suite of APD smart products.
Be approachable, a team player and ready to assist SRE & DevOps to build pipelines that need minimal operational maintenance.
If needed, be ready to independently learn new technologies.
Be able to prioritize tasks and take ownership.
Ability to communicate and meaningfully present results of analyses in a clear and impactful manner.","SVK Technology Solutions Inc
5.0","San Diego, CA",-1,-1
Data Engineer,"????????????????????????Hi Folks ,

Greetings from Logic Planet,

We are pleased t introduce you Logic Planet as a leading recruitment and staffing company,

Regarding I have an exciting new opportunity???s that I wanted to share with you and your network. Our top client, located San Diego, CA is currently seekingData Engineer. Joins their organization. I have included a complete job description below in case you or someone you know might be interested in learning more

Job Title: Data Engineer
Location: San Diego, CA
Work Authorizations: Authorized to Work
Position Type: Contract
No: of Positions: 1
Position Start Date:
Duration: 6+ Months
Primary Skills: ETL, Date warehousing, SQL
Secondary Skills:
Description:

Roles and Responsibility:-

??? Interfacing with business customers, gathering requirements and developing new datasets in data platform

??? Building and migrating the complex ETL pipelines from on premise system to cloud

??? Identifying the data quality issues to address them immediately to provide great user experience

??? Extracting and combining data from various heterogeneous data sources

??? Designing, implementing and supporting a platform that can provide ad-hoc access to large datasets

Basic Qualifications:

??? Bachelors or Masters in Computer Science, Engineering, Mathematics, Statistics, or related field

3+ years relevant experience in data engineering.

??? Demonstrated ability in data modeling, ETL development, and data warehousing.

Advanced SQL experience is a must

??? Data Warehousing Experience with SQL Server.

??? Experience with Big Data Technologies (NoSQL databases, Hadoop, Hive, Hbase, Pig, Spark, Elastic Search etc.)

??? Experience in using .Net , C# and/or other data engineering languages

??? Knowledge and experience of SQL Sever and SSIS.

Preferred Qualifications:

??? Industry experience as a Data Engineer or related specialty (e.g., Software Engineer, Business Intelligence Engineer, Data Scientist) with a track record of manipulating, processing, and extracting value from large datasets.

??? Experience building/operating highly available, distributed systems of data extraction, ingestion, and processing of large data sets

??? Experience building data products incrementally and integrating and managing datasets from multiple focus.

Regards,

Vinay

Logic Planet Inc
4525 Route 27,Princeton, NJ 08540

Ph: 732 512 0009 Ext: 134 Direct : 609 256 4342
Email: vinay@logicplanet.com | www.logicplanet.com

Certified Minority Women Based Enterprise

18 years in IT. 300 employees. $30M in revenues","Logic Planet
3.1","San Diego, CA",IT Services,Information Technology
Data Engineer,"Data Engineer

Prescient Holdings Group, LLC is looking for extraordinary people to join our team!

Prescient Holdings Group (PHG) is a healthcare company providing pharmaceutical management solutions to payers, patients, and providers. We are focused on developing the most effective strategies for optimizing drug access and spend through our suite of formulary and rebate services. PHG is currently searching for a dynamic addition to its team. If you’re interested in a career within a customer-focused, team-oriented environment that rewards innovation, quality, integrity and collaboration, we welcome your application.

Why join Prescient? Because our success is dependent on you; innovative professionals with top notch skills who thrive on opportunity, high performance, and teamwork. We look for individuals who want to work on a team that cares about making a difference in the value of healthcare.

The Scoop:

Using industry best practices for data architecture and management, the Data Engineer plans, designs, and optimizes custom application databases. Such activities involve understanding of the business processes the application data supports, interacting with development teams and end-users to determine application data access requirements, transaction rates, volume analysis, data modification/transformation needs, and other pertinent data required to maintain integrated databases and support business processes. Designs data access methodologies for optimal use of the data environments. Makes recommendations on and implements data-driven tuning exercises.

What You Get To Do:
Analyzes, designs and develops enterprise data and information architecture
Creates conceptual, logical, and physical data models
Develops ETL processes to automate data ingestion and processing
Serves as database subject matter expert (SME); assists developers and analytics staff with SQL Queries as well as stored procedures
Organizes data and tune data environments for optimal performance while managing cloud compute and storage costs
Establishes data standards and ensure data quality
Supports data cataloging and data governance activities
Works within Azure Cloud environment
Mentors software engineers on best practices related to data access and management
What You Need:

Education and/or Experience
For consideration, candidates will need a Bachelor's degree (or equivalent combination of education and experience) along with at least eight (8) plus years’ related experience
Prior experience in PBM, pharmaceutical or managed health care industry preferred
Computer Skills

To perform this job successfully, an individual must have:
Hands on experience developing complex SQL queries and stored procedures (T-SQL)
Experience developing data ingestion and processing solutions (ETL using SSIS)
Experience creating conceptual, logical, and physical data models
Knowledge of Microsoft SQL Server best practices
Familiarity with Microsoft Azure services (Azure SQL, Data Factory, Data Lake Store, Power BI)
Certificates, Licenses, Registrations
None required
Azure Data Engineer Associate certification is highly desired
Other Skills and Abilities
Experience with healthcare data (drug information, formulary, etc.)
Knowledge of HIPAA standards
Working knowledge of database and data-access concepts
Proficiency in identifying data patterns, trends and anomalies
Understanding of web applications and/or other distributed application architectures
Knowledge of SQL Server performance tuning, key configuration parameters, and version features
Analytical and problem-solving skills
Ability to work in a fast-paced and dynamic environment
Requirements gathering and analysis
Proven experience promoting process improvement
Familiarity with software development fundamentals
Good verbal/writing communication as well as interpersonal skills
Travel - This position may require occasional domestic travel and attendance maybe required at various local conferences and meetings.

The Perks:

Medical / Dental / Vision / Wellness Programs

Paid Time Off / Company Paid Holidays

401K with Company match

Life and Disability Insurance

Tuition Reimbursement

Employee Referral Bonus

This position is eligible for Employee Referral Bonus at Level II

EOE, M/F/D/V

OSHA/ADA:

To perform this job successfully, the successful candidate must be able to perform each essential duty satisfactorily. The requirements listed are representative of the knowledge, skill, and/or ability required. Reasonable accommodations may be made to enable individuals with disabilities to perform the essential functions.

Disclaimer:

The above statements are intended to describe the general nature and level of work being performed by people assigned to this classification. They are not intended to be construed as an exhaustive list of all responsibilities, duties, and skills required of personnel so classified.

Job Type: Full-time

Work Remotely:
Temporarily due to COVID-19","HFE, Inc
5.0","San Diego, CA",-1,-1
Data Engineer,"Job Description:
Bachelors or Masters in Computer Science, Engineering, Mathematics, Statistics, or related field.
3+ years of relevant experience in data engineering.
Demonstrated ability in data modeling, ETL development, and data warehousing.
Advanced SQL experience is a must.
Data Warehousing.
Experience with SQL Server.
Experience with Big Data Technologies (NoSQL databases, Hadoop, Hive, Hbase, Pig, Spark, Elasticsearch, etc.).
Experience in using DotNet, C#, and/or other data engineering languages.
Knowledge and experience of SQL Server and SSIS.
Preferred Qualifications:
Industry experience as a Data Engineer or related specialty (e.g., Software Engineer, Business Intelligence Engineer, Data Scientist) with a track record of manipulating, processing, and extracting value from large datasets.
Experience building/operating highly available, distributed systems of data extraction, ingestion, and processing of large data sets.
Experience building data products integrating and managing datasets from multiple focus.","CYNET SYSTEMS
4.0","San Diego, CA",IT Services,Information Technology
Data Engineer,"ABOUT CUREMETRIX

Delivering CAD that Works, CureMetrix is committed to the advancement of technology that improves cancer survival rates worldwide. With research that leverages artificial intelligence (AI) and deep learning to develop the next generation of medical image analysis, CureMetrix delivers technology that radiologists, healthcare systems, and patients can confidently rely on. For more information visitwww.curemetrix.com

ROLE OVERVIEW

CureMetrix is looking for a talented, multi-disciplinary, individual to own our data ingestion, curation, and access management, as well as develop processes and tools to help derive more value and utility from the data.. At CureMetrix, curated radiology data is our lifeblood. The Data Engineer position will work with our Research and our Development teams to acquire, build, and maintain our database of clinical data and radiology images. The Data Engineer will also help build and maintain tools to assist our Research group with their Machine Learning pipeline.

Local (San Diego) candidates only, please.

ROLE SPECIFICS

Data Management
Working with a variety of public and private health institutions around the world to gather images and clinical mammography data.
Developing data validation specifications and data management plans
Cleaning and validating incoming data
Normalizing and standardizing data according to set standards
Verifying the integrity of the data
Anonymize data according to set standards
Ensuring the HIPAA compliance of the data at rest and in transit
Working to establish and maintain the security of the data
Curating the data as needed
Designing queries to extract study data as needed for both internal uses and for publications.
Working with internal and external teams to design and execute clinical studies utilizing data
Working with CTO to build dashboards providing company insight into our dataset
Ensure data adheres to company HIPAA and cybersecurity compliance policies
Performing analysis and reporting to help ensure ongoing data integrity
Performing analysis and reporting to support customer audits and consulting engagements
Python Toolset
Minimum of 4 years of Python experience working with development and research teams to build specifications, implement, and maintain data extraction and mining tools.
Cloud Storage
Minimum of 4 years of experience working in the cloud. Familiarity with AWS S3 storage in a HIPAA compliant environment. Requires knowledge of boto3 and AWS CLI tools.
Machine Learning Pipeline
Own internal medical image ground truth pipeline from ingestion to training.
Work with radiologists to determine medical image ground truth
Help manage medical image annotation vendors including quality management
Work with Development and Research teams to build specifications, implement, and maintain our internal Machine Learning training pipeline.
Assist the Research team in building datasets for Machine Learning training.
Development
Working with CTO to develop custom tools and applications for data access and management
Supporting bi-directional integrations with 3rd-parties
As needed supporting the entire team with development expertise on specific projects.


QUALIFICATIONS
Bachelor's degree in science, IT, or business-related field and/or equivalent work experience.
Ability to build and maintain a growing study database along with strong SQL skills
Strong experience using python scripting in a technical environment
A Minimum of 5 years of working with large and complex datasets, preferably in a regulated device/diagnostic, laboratory, or CRO setting.
Strong project management skills
Ability to prioritize activities and meet regular deadlines according to reasonable levels of quality.
Ability to work independently.
Have strong writing, verbal communication skills, good organizational, interpersonal and team skills
Used to working in an Agile environment
POSITION TYPE AND HOURS OF WORKFull-time position. General Hours of work are Monday through Friday, from 8:30 a.m. to 5:30 p.m. Occasional early, late or weekend work required.

POSITION COLLABORATES WITH AND IS SUPPORTED BY
Research
Software Development
Operations and IT
Business Development
Key Executives
WORK ENVIRONMENTThis job operates in a professional office environment. This role routinely uses standard office equipment such as computers, phones, photocopiers, filing cabinets, and fax machines. However, at this time all work is remote in your home office until further notice. As such candidates must be comfortable with remote work and prepared to contribute full engagement in such an environment.

PHYSICAL DEMANDS:This position requires the ability to navigate throughout a large office, 3-story complex. This is primarily a sedentary role; however, some walking, standing, bending, lifting up to 20 lbs., and hand/eye coordination for keyboard data entry and viewing data on a computer monitor may be required. Specific vision abilities required by this job include close vision, distance vision, color vision, peripheral vision, depth perception, and ability to adjust focus. The physical demands described above must be met by an employee to successfully perform the essential functions of this job.","Curemetrix
4.0","San Diego, CA",-1,-1
Statistician,"PSI Pax, Inc. has an exciting opportunity for a Data Scientist 3 (Tableau - Statistics (Fleet Readiness), Tableau - Statistics (IT Portfolio), Predictive Analysis & Visualization) to support our government customer in San Diego, CA.

Position is contingent upon contract award.

Essential Job Functions & Responsibilities:

Tableau - Statistics (Fleet Readiness), Tableau - Statistics (IT Portfolio), Predictive Analysis & Visualization.

Conduct planning, analysis, integration, extraction, migration, and reporting of data in Navy Enterprise Resource Planning (N-ERP) and its associated software products. Create, maintain, and manage the tables, cubes, extracts, and reports used to provide the required information. Sustain the data structures, processes, principles, business rules, and operational practices of N-ERP in the current operating environment.

Utilize Government provided software environments, applications, and tools to support N-ERP, data analytics, and other IT operations. Configuration files, source code, scripts, reports, visualizations, analytics, and algorithms shall be developed and retained in tools within the Government provided environment.

In support of data analytics, work with other functional SME to produce and improve relevant analytics and reports in areas such as financial management, accounting, cost analysis, material management, human resources (workforce), total force management (manpower), logistics, Fleet readiness, installations, facilities, program management, IT management, cybersecurity, and other areas within the customer's mission. Support business process engineering to align data analytics requirements to the customer's business processes. Interact with SME to develop understanding of data sets, analytics requirements, business problems, leadership objectives, external stakeholder objectives, and metrics and produce requirements specifications. Digitize processes and implement tools integrated with data sources. Provide data integration to enable the discovery and monitoring of correlations among disparate data sources and metrics, as well as the identification of causal factors associated with anomalous data observations. Develop and implement predictive algorithms to identify leading indicators. Implement artificial intelligence driven knowledge bases. Provide user training on analytics and reporting.

Required Qualifications:
Three (3) years of experience translating business requirements into reporting designs, predictive and statistical analysis, data cleansing, and visualizing business data.
Two (2) years of experience using analytics environments necessary for specific job duties (Tableau, R, Python, etc.)
Development of Systems Specification, Systems Analysis, Systems Architecture, Systems/Equipment Integration, Test & Evaluation Criteria for business systems.
Eligible to obtain a SECRET level security clearance (final SECRET clearance required if tasking includes access to classified systems).
Education Requirements:

Bachelor's degree from an accredited college or university in one of the following fields: Computer Science, Engineering, Mathematics, Statistics, Operations Research. An additional 4 years of relevant specialized experience may be substituted for a Bachelor's degree. Master's degree preferred.

In addition, U.S Citizenship is required. Applicants selected will be subject to a government security investigation and must meet eligibility requirements for access to classified information and be able to obtain a DoD government-granted security clearance. Individuals may also be subject to a background investigation to include but not limited to criminal history, employment and education verification, drug testing, and creditworthiness.

PSI Pax is an Equal Opportunity/Affirmative Action Employer. Qualified applicants will receive consideration for employment without regard to race, color, religion, sex, age, national origin, marital status, disability, protected veteran status, sexual orientation, or genetic information.

PSI Pax is an E-Verify Participant.","PSI Pax
4.1","San Diego, CA",IT Services,Information Technology
Data Engineer,"Description:Born digital, Axos Bank has reinvented the banking model and grown to over $12 billion in assets since our founding in 2000. With a broad and ever-growing range of financial products, Axos Bank is rated among the top 5 digital banks in the country! Axos Financial is our holding company and publicly traded on the New York Stock Exchange under the symbol ""AX (NYSE: AX).We bring together human insight and digital expertise to anticipate the needs of our customers. Our team members are innovative, technologically sophisticated, and motivated to achieve.Learn more about working here!Responsibilities include:* Work with technical and business team to understand the business requirements, functional and technical specifications* Design, code and maintain new and existing complex SQL stored procedures and functions* Performance tune existing stored procedures, tables and indexes* Work with other engineers to troubleshoot, repair and performance tune databases* Review SQL code written by other developers to ensure compliance to coding standards and best practices as well as maximum performance* Create SSIS packages for data transformation, cleansing, caching, aggregation, staging, and transfer* Troubleshoot problems that may come up with database environments: performance issues; replication issues; or operational issues* Perform data analysis and data profiling tasks to provide support and recommendations for development and design decisions* Analyze and define data flow requirements and prepare applicable system documentation and operation manuals as needed* Support production data loads and ongoing refreshes of the database systems* Define, prepare, execute and implement data validation and unit testing methods to ensure data quality* Maintain re-usable development standards that help implement each solution and/or enhancements to existing systems to meet current and future needs* Perform enhancements and bug fixes as required* Perform any additional duties as assignedKey Skill Sets or Knowledge Requirements:* Expertise in SQL server design and development* Excellent verbal and written communication skills, including ability to simplify complex concepts for technical and non-technical audience* Superior problem-solving skills, self-motivation, and the capacity to work under pressure and tight deadlines* Demonstrated ability to learn, acquire and utilize new technologies, disciplines and frameworks as needed* Technical expertise in the areas of data profiling, data mining and data analytics* Technical expertise in building reliable data ETL/ELT processes, query optimization and dynamic SQL* Strong customer focus, excellent problem solving and analytical skills* Ability to work independently under minimal supervision and strong track record of setting and meeting delivery commitmentsDesired Career Experience & Education Requirements:* 3+ years' working with relational DBs in a production environment* 3+ years' experience with Microsoft SQL Server* 2+ years' experience in SSIS packages* 2+ years' experience working in an Agile/SCRUM environment* Experience delivering high quality, high traffic, scalable database objects* Bachelor's Degree in Computer Science, Information Systems, Computer Engineering or related fieldPreferred:* Experience in BigData* Banking industry experienceApply directly for consideration as we are not using any outside agencies for any of our openingsPre-Employment Drug Test:All offers are contingent upon the candidate successfully passing a credit check, criminal background check, and pre-employment drug screening, which includes screening for marijuana. Axos Bank is a federally regulated banking institution. At the federal level, marijuana is an illegal schedule 1 drug; therefore, we will not employ any person who tests positive for marijuana, regardless of state legalization.Equal Employment Opportunity:Axos Bank is an Equal Opportunity employer. We are committed to providing equal employment opportunities to all employees and applicants without regard to race, religious creed, color, sex (including pregnancy, breast feeding and related medical conditions), gender, gender identity, gender expression, sexual orientation, national origin, ancestry, citizenship status, military and veteran status, marital status, age, protected medical condition, genetic information, physical disability, mental disability, or any other protected status in accordance with all applicable federal, state and local laws.Job Functions and Work Environment:While performing the duties of this position, the employee is required to sit for extended periods of time. Manual dexterity and coordination are required while operating standard office equipment such as computer keyboard and mouse, calculator, telephone, copiers, etc.The work environment characteristics described here are representative of those an employee may encounter while performing the essential functions of this position. Reasonable accommodations may be made to enable individuals with disabilities to perform the essential functions of this position.Options","Axos Bank
3.4","San Diego, CA",Banks & Credit Unions,Finance
Statistician,"PSI Pax, Inc. has an exciting opportunity for a Data Scientist 3 (Tableau – Statistics (Fleet Readiness), Tableau – Statistics (IT Portfolio), Predictive Analysis & Visualization) to support our government customer in San Diego, CA.

Position is contingent upon contract award.

Essential Job Functions & Responsibilities:

Tableau – Statistics (Fleet Readiness), Tableau – Statistics (IT Portfolio), Predictive Analysis & Visualization.

Conduct planning, analysis, integration, extraction, migration, and reporting of data in Navy Enterprise Resource Planning (N-ERP) and its associated software products. Create, maintain, and manage the tables, cubes, extracts, and reports used to provide the required information. Sustain the data structures, processes, principles, business rules, and operational practices of N-ERP in the current operating environment.

Utilize Government provided software environments, applications, and tools to support N-ERP, data analytics, and other IT operations. Configuration files, source code, scripts, reports, visualizations, analytics, and algorithms shall be developed and retained in tools within the Government provided environment.

In support of data analytics, work with other functional SME to produce and improve relevant analytics and reports in areas such as financial management, accounting, cost analysis, material management, human resources (workforce), total force management (manpower), logistics, Fleet readiness, installations, facilities, program management, IT management, cybersecurity, and other areas within the customer’s mission. Support business process engineering to align data analytics requirements to the customer’s business processes. Interact with SME to develop understanding of data sets, analytics requirements, business problems, leadership objectives, external stakeholder objectives, and metrics and produce requirements specifications. Digitize processes and implement tools integrated with data sources. Provide data integration to enable the discovery and monitoring of correlations among disparate data sources and metrics, as well as the identification of causal factors associated with anomalous data observations. Develop and implement predictive algorithms to identify leading indicators. Implement artificial intelligence driven knowledge bases. Provide user training on analytics and reporting.

Required Qualifications:

• Three (3) years of experience translating business requirements into reporting designs, predictive and statistical analysis, data cleansing, and visualizing business data.

• Two (2) years of experience using analytics environments necessary for specific job duties (Tableau, R, Python, etc.)

• Development of Systems Specification, Systems Analysis, Systems Architecture, Systems/Equipment Integration, Test & Evaluation Criteria for business systems.

• Eligible to obtain a SECRET level security clearance (final SECRET clearance required if tasking includes access to classified systems).

Education Requirements:

Bachelor’s degree from an accredited college or university in one of the following fields: Computer Science, Engineering, Mathematics, Statistics, Operations Research. An additional 4 years of relevant specialized experience may be substituted for a Bachelor’s degree. Master’s degree preferred.

In addition, U.S Citizenship is required. Applicants selected will be subject to a government security investigation and must meet eligibility requirements for access to classified information and be able to obtain a DoD government-granted security clearance. Individuals may also be subject to a background investigation to include but not limited to criminal history, employment and education verification, drug testing, and creditworthiness.

PSI Pax is an Equal Opportunity/Affirmative Action Employer. Qualified applicants will receive consideration for employment without regard to race, color, religion, sex, age, national origin, marital status, disability, protected veteran status, sexual orientation, or genetic information.

PSI Pax is an E-Verify Participant.","PSI Pax
4.1","San Diego, CA",IT Services,Information Technology
Statistician,"Principal Research Scientist/ Statistician, Real World Evidence (RWE)/ Late Phase

Job Purpose / Summary:
Responsible for planning, implementing and reporting RWE or health economics and outcomes research projects within CTI. This includes working closely with pharmaceutical, medical device, and diagnostics clients, among others, in partnership with CTI business development personnel in the development of project-specific methods and project deliverables. The person in this role may conduct face-to-face client meetings, teleconference calls, and publication strategies autonomously and may serve as mentor for other Research Scientists.

What You'll Do
Provide leadership or management for Real-World Evidence (RWE) programs with responsibilities to include: business development, client interactions, developing research objectives and statistical methodology for clients, participating in and overseeing projects
Consult and design of RWE study protocols, to include retrospective studies (EMR, chart reviews, cohort) and cross-sectional and prospective observational studies
Apply knowledge of statistical theory, techniques and methods encompassing such areas as sampling, ratios and proportions, measures of dispersion and central tendency, reliability, validity, correlations, survival, trends, index numbers, forecasting, categorical data analysis, non-parametric methods
Design and conduct analyses of large- and small-scale healthcare databases, registries, and non-regulatory clinical study data including EMR, EPIC, marketscan or other large scale databases
Write statistical analysis plans for studies and work with programmers and analysts to create the necessary analyzable datasets
Effectively communicate with clients to develop and report RWE solutions during the course of business development or within the context of a project
Required Education/Experience
Bachelors in biostatistics, health services research, pharmacy, nursing, natural science, epidemiology, biostatistics, or closely related discipline
10 years experience in working in outcomes research design, epidemiology, or biostatistics
Master of Public Health (MPH), or PhD (or DrPH, ScD/PharmD/MD) level scientist in health services research, pharmacy, nursing, natural science, epidemiology, biostatistics, or closely related discipline preferred
Pharmaceutical / biotech and/or contract research organization (CRO) experience preferred
Knowledge of statistical software packages including SAS preferred
Data visualization software (e.g. Tableau) and other advanced data presentation methodology preferred
Economic modeling building experience preferred
Significant demonstrated experience with developing peer-reviewed publications in relevant medical/pharmacy journals
Why CTI?
We support career progression 25% of our global staff is promoted annually and we have a structured mentoring program to provide the support you need to move forward
We value education and training We provide tuition reimbursement, partner with universities and colleges to create programs in our field, and have a dedicated training department
We value our people - We have never had a layoff in our 20-year history, support a work-life balance with flexible schedules, and have provided cash bonuses every year for the past decade
Our culture is unparalleled Click here to learn more about The CTI Way
We think globally and act locally We have a global philanthropic program supporting our teams efforts to improve their local communities (Click here to learn more about our CTI Cares program)
We are looking toward the future We have had a consistent 15% growth rate over the last decade, invest in cutting-edge technology, and pride ourselves on our average 95% annual retention rate
Our work makes a difference We focus our work on treatments for chronically and critically-ill patients, who are depending on us to bring these life-changing therapies to market","CTI Clinical Trial Services, Inc
4.0","San Diego, CA",Health Care Services & Hospitals,Health Care
Data Scientist,"About Us:

Located in Allen, TX Cytracom is the leading SaaS provider of business voice services delivered through the IT channel and our mission is to make business communications simple!

As for the culture, we love going to work and think you should too! The team holds our company culture near and dear as it represents an intermix between passion for leadership and passion for an active, healthy life centered around family and friends. Cytracom represents community, collaboration, camaraderie and we are DOUBLING in size this year! It's a very exciting time here at Cytracom and we are focused on finding the best talent as we continue to grow!

Our Benefits:

• Medical, dental, and vision insurance is available
• 401K
• Disability insurance
• Paid vacations and holidays
• Flexible PTO policy
• Casual, laid-back work environment
• Free snacks

Here's a closer look at this key role:

The Data Scientist will use data-based insights to conceptualize, plan, and develop solutions to solve complex problems. In this role, you will be responsible for discovering information and identifying patterns within vast amounts of data and using that data to help our teams make smarter decisions. Your primary focus will be in applying data mining techniques, data visualization, doing statistical analysis, and building high-quality prediction systems.

Requirements:
2+ years of recent experience working as a data scientist.
Expertise in SQL (including but not limited to transforming data) and proficiency in another data programming language (Python, R, etc.)
Experience in creating experiments and analyzing results that drive key decisions
Proficiency in one or more analytics & visualization tools (e.g., Looker, Tableau, etc.)
Strong interpersonal skills and the ability to tailor communication such as analyses and interpretations to match the audience
We prefer someone who currently lives in the DFW metroplex
Responsibilities:
Maintain solid working relationships with all stakeholders, primarily the Executive Team.
Work with business experts to better understand goals and identify alternative approaches to extract insights from data.
Drive adoption of BI platform across organization
Present ideas/analyses/interpretations in a clear, concise manner tailored to audience
Maintain integrity, organization and consistency of data by coordinating with system administration to ensure accurate data input or collection and by managing ETL processes","Cytracom
5.0","Allen, TX",Enterprise Software & Network Solutions,Information Technology
Data Scientist,"We have a long term contract position with our client, to work onsite (remote during Covid). Please review below job description and send us Resume, Work Authorization, Current Location and Availability, if interested to sam at 40kinc dot com Our client in Dallas TX is looking to hire a Data Scientist for long term project to work onsite. A data scientistforecaster with experience in multi variate forecasting for demand and supply type of problem with an ability to do production deployment Domain Integrated Business Planning, Consensus Based Forecasting, Supply Chain Management Tools HiveImpala, Spark, Python - STATSMODELS, SKLEARN, TENSORFLOW, KERAS, PROPHET, Implementation from Research Paper Forecasting Methods Univariate and Multi-variate time series like ARIMA, LSTM, Bagging, Boosting, Mathematical Programming (LP, MIP), etc.","40K INC
4.0","Dallas, TX",-1,-1
Statistician,"Description:

Founded in 2014, Vinli is an automotive technology company based in the heart of Downtown Dallas. In just six years, our team has built the most advanced vehicle data computing platform, grown into the largest connected car app ecosystem, and secured global partnerships with significant players in the telecom, automotive, and asset management industries. Vinli’s fully customizable platform has enabled sophisticated brands to easily engineer connected car services, allowing them to capitalize on both their vehicle data and other related data sources.

At Vinli, our passion is building products that unlock the true value of connected cars by showing drivers, passengers and organizations the potential hidden within their vehicles' data. This includes staying on the cutting edge by investing in technologies like machine learning & AI. We are looking for a well-rounded individual with interest and experience in the engineering, mathematical and scientific sides of developing a machine learning product. This role also has the opportunity to develop into a team leadership position.

The ideal candidate is located in Dallas, TX, but telecommuting is an option for exceptional candidates with proven remote experience.

ABOUT THE ROLE
Vinli is looking for an exceptional talent to add to an already amazing team. You’ll have the chance to work with the latest technologies - GoLang based microservices in a true, cloud-based, big-data application environment. You’ll work in partnership with a group of amazing engineers with expertise in designing and building beautiful customer experiences and structuring the data to support them. There will be many opportunities to forge your own path and demonstrate individual excellence, all while pulling together with a team who is ready to support you and eager for your help. We practice Agile development in the true sense - adhering to the principles of Agile, not adhering to a specific methodology. And, we have a lot of fun. Join us in creating the future of mobility.

Responsibilities
Develop and execute on testing and evaluation methodologies to optimize product prices
Perform market research and develop automated methods to keep research up to date
Behavioral Segmentation
Build production-grade segmentation models using customer behavior data
Develop and execute on experimental methodology to focus our digital marketing and maximize the return on ad spend
Predictive Model Building & Analysis
Build and maintain production-grade clustering, classification, and predictive models
Develop algorithms to provide a deeper understanding of our data
Contribute to our data models and derive insights from a variety of data sources

Experience
Master’s degree in statistics, mathematics or related analytical discipline preferred (PhD a plus)
Proficiency in statistical models and thinking (probability, regression, segmentation)
Proficiency in Python, Spark and SQL
2+ years experience in a fast-paced startup environment a plus
Prior experience in price optimization and consumer segmentation is a huge plus!
Experience writing production-grade code and running predictive models in production
Embrace commitment and support a ‘team-first’ mentality
Proven success leveraging data to empower sound decision making
Ability to get stuff done, delivering high-quality work on time
Desire to solve big problems, embracing challenges with excitement
Strong belief in transparency and capable of raising issues or concerns early and often
Comfortable with ambiguity, with a passion for collaboration to achieve objectives

ABOUT YOU
You thrive in challenging environments that require collaborative problem solving
You prefer to spend your time coding and collaborating, not in meetings
You take pride and responsibility seeing the product you worked on meet the real world for the first time
You are capable of independently prioritizing your duties and still work well with a team
You can both accept and provide thoughtful, respectful constructive criticism.

BENEFITS
Vinli offers competitive benefits including health care, PTO, drinks & snacks, and a cool office in walking distance to Deep Ellum, the Dallas Farmers Market, and the historic East Quarter.

We are an equal opportunity employer. We strictly prohibit unlawful discrimination or harassment of any kind, including discrimination or harassment on the basis of race, color, national origin, ancestry, religion, veteran status, age, pregnancy status, sex, gender identity or expression, sexual orientation, marital status, mental or physical disability, medical condition, or any other characteristics protected by law. We also make all reasonable accommodations to meet our obligations under laws protecting the rights of the disabled.

Vinli Core Values

Integrity. Doing what you say you will do at Vinli is our way of building trust among our team members, partners, investors and vendors. We believe that maintaining integrity requires an openness and empathy in sharing goals and challenges with others.
Drive to Innovate. People at Vinli don’t just love to learn, they feel compelled to use their knowledge to make our Company and the world a better place. We believe in learning from our mistakes and always challenging ourselves to innovate - from the biggest product decisions to the smallest processes.
Joyful Work Environment. Loving where you work isn’t about ping pong tables and free snacks. It’s the feeling that you wouldn’t want to be on a project with any other team. It’s the feeling that you can get creative energy just by showing up to work. It’s the feeling that your entire team respects your life away from the job and understands how work impacts it. At Vinli, we believe in building camaraderie and joy in our environment by supporting and encouraging each other every day.","Vinli
4.6","Dallas, TX",Computer Hardware & Software,Information Technology
Data Scientist,"MS or PhD in Computer Science, Electrical Engineering, Statistics, or equivalent fields. Applied Machine Learning experience (regression and classification, supervised, and unsupervised learning). Strong mathematical background (linear algebra, calculus, probability and statistics). Experience with scalable ML (MapReduce, streaming). Ability to drive a project and work both independently and in a team. Smart, motivated, can do attitude, and seeks to make a difference. Excellent verbal and written communication. Preferred Experience with JavaScript and prototyping languages such as Python and R. Experience with Java and Scala is a plus. Knowledge in electrical engineering and cyber-physical systems is a plus. A portfolio of projects (GitHub, papers, etc.) is a plus.","PriceSenz
5.0","Dallas, TX",-1,-1
Data Scientist,"Onica is an APN Premier Consulting Partner. As a full spectrum AWS integrator, we assist hundreds of companies to realize the value, efficiency, and productivity of the cloud. We take customers on their journey to enable, operate, and innovate using cloud technologies from migration strategy to operational excellence and immersive transformation.

If you like a challenge, you'll love it here, because we're solving complex business problems every day, building and promoting great technology solutions that impact our customers' success. The best part is, we're committed to you and your growth, both professionally and personally.

Overview

Our Data Scientists are experienced technologists with technical depth and breadth, along with strong interpersonal skills. In this role, you will work directly with customers and our team to help enable innovation through continuous, hands-on, deployment across technology stacks. You will work to build data science pipelines that include building models, A/B testing, natural language processing, computer vision and AR/VR visualizations.

What You'll Be Doing
Confidence with manipulating complex, large and dense datasets with big data tools; must be comfortable with SQL and large database systems
Ability to Build complex data transformation code
Build complex SQL queries using MongoDB, Oracle, SQL Server, MariaDB, MySQL
Excellent ability to work with structured and unstructured data sets
Deep experience with R or Python, SQL and running ETL jobs
Ability to apply supervised and unsupervised machine learning techniques
Strong understanding of continuous learning and model training
Knowledge of data labeling, categorization, and structuring techniques
Expert ability to break down and clearly define problems
Strong ability to communicate highly technical results to a diverse audience
Excellent analytical and problem-solving skills
Qualifications & Experience
3-5 years of hands-on experience in data mining and predictive analytics with statistical modeling techniques
3-5+ years of experience in networking, infrastructure, or database architectures
Experience working with data in the AWS ecosystem
Experience with advanced data science tools
Experience applying computational algorithms and statistical methods to structured and unstructured data
MS or PhD in Applied Mathematics, Physics, Computer Science, Statistics or related technical field
Experience in the cyber security domain
AWS certifications
SQL
Kubernetes is a plus
Artificial Intelligence
Predictive Analytics
Tableau or other visualization tools
Kafka / Confluent
CI / CD and Cloud Native Computing (Docker, Kubernetes, Consul, Vault)
If you get a thrill working with cutting-edge technology and love to help solve customers' problems, we'd love to hear from you. It's time to rethink the possible. Are you ready?","Onica, a Rackspace Company
4.3","Dallas, TX",IT Services,Information Technology
Data Scientist,"Job Description
Ateroz has teamed up with a growing global technology firm looking to bring on a Data Scientist to join their product management team. They are seeking data experts who are passionate about using leading edge technology to solve unique problems in the hospitality industry.

The ideal candidate is intellectually curious about how data can be used to tell a story and help drive profitable revenue enhancing decisions for the hospitality industry. In addition, candidate must have strong experience using a variety of data mining/data analysis methods, using a variety of data tools, building and implementing models, using/creating algorithms, creating/running simulations and must be comfortable working with a wide range of stakeholders and functional teams.

Ideal Candidate will have:
Master’s in Statistics, Mathematics, Computer Science or another quantitative field
3+ years of experience manipulating data sets and building statistical models in a professional environment
Deep knowledge of modern data warehouses, distributed data sets and analysis tools (SnowFlake, HDFS, S3, Tableau, DataRama, Jupyter Notebooks, etc)
Deep knowledge of numerical and statistical packages (Python, Pandas, Numby, Sklearn, R or related).
Knowledge of a variety of machine learning techniques (clustering, decision tree learning, artificial neural networks, etc.) and their real-world advantages/drawbacks
Knowledge of advanced statistical techniques and concepts (regression, properties of distributions, statistical tests and proper usage, etc.) and experience with applications
Strong problem-solving skills with an emphasis on developing new analytic products and services
Excellent written and verbal communication skills for coordinating across team
Apply now to join a growing global product team!!
Company Description
Helping Your Business Thrive With Human Capital Solutions

www.ateroz.com","Ateroz
5.0","Dallas, TX",Staffing & Outsourcing,Business Services
Data Scientist,"This position is responsible for business consulting activities for the Data Strategy and Analytics teams within our client organizations to monitor and assist in improving their analytics eco system. We need someone with a creative problem-solving skills to work on our clients business opportunities. Our Data Scientistwill work to understand high value opportunities and identify/build potential solutions, which often involve discovering new insights by transforming data into intuitive & interactive visualizations or applications

Responsibilities:

Serve as an expert in translating complex data into key strategy insights and valuable actions.

• Discover business narratives told by the data and present them to other scientists, business stakeholders, and managers at various levels.

• Develop and test heuristics.

• Create and run statistic/ML models.

• Perform data exploration and data mining.

• Create business intelligence, dashboards, visualizations, and/or other advanced analytics reports to adequately tell the business narrative and offer recommendations that are practiced, actionable, and have material impact, in addition to being well-supported by analytical models and data.

Skills:

Work experience in addition to degree: 3 - 5 years of data engineering/science related activities with overall 10+ years experience.

• Graduation from a four-year college or university with a degree in statistics, physics, mathematics, engineering, computer science, or management of information systems.

• Expert knowledge of SAS, Python Machine Learning or R

• Working knowledge of statistics, programming and predictive modeling.

• Working knowledge of code writing

• Big Data/Hadoop/NoSQL and experience with large datasets

Desired:

Doctorate in Computer science, Engineering, Physics or Statistics

Build your career with us.

It is an extraordinary time to be in business. As digital transformation continues to accelerate, CGI is at the center of this changesupporting our clients digital journeys and offering our professionals exciting career opportunities.

At CGI, our success comes from the talent and commitment of our professionals. As one team, we share the challenges and rewards that come from growing our company, which reinforces our culture of ownership. All of our professionals benefit from the value we collectively create.

Be part of building one of the largest independent technology and business services firms in the world.

Learn more about CGI at www.cgi.com.

No unsolicited agency referrals please.

CGI is an equal opportunity employer.

Qualified applicants will receive consideration for employment without regard to their race, ethnicity, ancestry, color, sex, religion, creed, age, national origin, citizenship status, disability, medical condition, military and veteran status, marital status, sexual orientation or perceived sexual orientation, gender, gender identity, and gender expression, familial status, political affiliation, genetic information, or any other legally protected status or characteristics.

CGI provides reasonable accommodations to qualified individuals with disabilities. If you need an accommodation to apply for a job in the U.S., please email the CGI U.S. Employment Compliance mailbox at US_Employment_Compliance@cgi.com. You will need to reference the requisition number of the position in which you are interested. Your message will be routed to the appropriate recruiter who will assist you. Please note, this email address is only to be used for those individuals who need an accommodation to apply for a job. Emails for any other reason or those that do not include a requisition number will not be returned.

We make it easy to translate military experience and skills! Click here to be directed to our site that is dedicated to veterans and transitioning service members.

All CGI offers of employment in the U.S. are contingent upon the ability to successfully complete a background investigation. Background investigation components can vary dependent upon specific assignment and/or level of US government security clearance held.

CGI will not discharge or in any other manner discriminate against employees or applicants because they have inquired about, discussed, or disclosed their own pay or the pay of another employee or applicant. However, employees who have access to the compensation information of other employees or applicants as a part of their essential job functions cannot disclose the pay of other employees or applicants to individuals who do not otherwise have access to compensation information, unless the disclosure is (a) in response to a formal complaint or charge, (b) in furtherance of an investigation, proceeding, hearing, or action, including an investigation conducted by the employer, or (c) consistent with CGIs legal duty to furnish information.

Your future duties and responsibilities

#LI-JS2

Required qualifications to be successful in this role","CGI
3.5","Dallas, TX",Consulting,Business Services
Data Scientist,"Job Description
We are looking for Data Scientist with Python, Tensorflow, SKLEARN, pandas,numpy skills. Experience 2-8 years.","Predictive Research Inc
3.9","Plano, TX",Consulting,Business Services
Data Scientist,"The Business

GradTests.com is a leading provider of practice psychometric tests to graduates, students and young professionals.

The Role

A data science all rounder role. The core purpose of the role is to build models to improve the product, the customer experience and ultimately the business. We're looking for someone with a nice blend of technical skills, and softer skills like business acumen, decision making and communication skills.

You'll do things like:
Conceive, devise, create, implement and fine tune data science models to solve a range of business problems, from customer churn through to
Set up, run and analyse A/B experiments for the website and email marketing campaigns
Help devise and layout a high quality infrastructure, upon which future data science can flourish
Help up skill other analytical team members into advanced data science techniques
Produce ad hoc analyses
And let's be honest, a whole load of data wrangling!
Skills and experience

Non negotiables:
SQL
Python or R
Data science models (K-means, random Forrest, neural nets etc.)
Strong foundational knowledge in stats and maths
Experience in actually productionising models and exposing to real customers
Business acumen
Strong communication skills, both written and verbal
Nice to haves:
Experience in working with developers, especially on experimentation
Some kind of cloud based experience (AWS preferred)
Some basic knowledge of source control with Git
Our application process consists of some online testing with Alooba, video call interview and then a case study. We expect the process to take about 10 business days end to end.

Job Types: Full-time, Contract

Salary: $120,000.00 /year

Experience:
Analytics: 1 year (Preferred)
Work Remotely:
Yes",GradTests (gradtests.com),"Dallas, TX",-1,-1
Data Scientist,"We are looking for an enthusiastic Data Scientist to add to Credera's Data & Analytics practice. Our ideal candidate is excited about being on project-based teams in a client facing role to analyze large data sets to derive insights through machine learning (ML) and artificial intelligence (AI) techniques. They have strong experience in data preparation and analysis using a variety of tools and programming techniques, building and implementing models, and creating and running simulations. The candidate has a track record of working with data engineers and data architects to implement models into production environments. The right candidate will have a passion for discovering solutions hidden in large data sets to improve business outcomes. They are passionate about problem solving with the use of data and feel comfortable applying their expertise across many use cases in various industries.

QUALIFICATIONS:
Candidate with 2+ years of hands-on statistical modeling and/or analytical experience
Master's degree in statistics, mathematics, computer science or related field (a PhD is preferred)
Experience with a variety of ML and AI techniques (e.g. multivariate/logistic regression models, cluster analysis, predictive modeling, neural networks, deep learning, pricing models, decision trees, ensemble methods, etc.)
Advanced skillset building models and performing analysis using scripting languages (Python, R, Scala, Octave)
Advanced knowledge of relational and non-relational databases (SQL, NoSQL)
Proficient in large-scale distributed systems (Hadoop, Spark, etc.)
Experience with designing and presenting compelling insights using visualization tools (RShiny, R, Python, Tableau, Power BI, D3.js, etc.)
Experience with wrangling, exploring, transforming, and analyzing datasets of varying size and complexity
Knowledgeable of tools and processes to monitor model performance and data quality, including model tuning experience
Comfortable presenting findings and recommendations to key client stakeholders
Experience with implementing machine learning models in production environments through one or more cloud platforms:
Google Cloud Platform
Azure cloud services
AWS cloud services
WHO WE ARE:
Credera is a full-service management consulting, user experience, and technology solutions firm, with clients ranging from Fortune 500 companies to emerging industry leaders.
Credera has received a number of national awards, including:
7-time awardee on Inc. Magazine's annual Inc. 5000 list
6-time winner of 100 Best Companies to Work for in Texas by Texas Monthly Magazine
Best Workplaces in Consulting & Professional Services by Great Place to Work and Fortune
Fortune100 Best Workplaces for Millennials
The Data & Analytics practice helps our clients gain competitive advantage by transforming raw data into insights that enable actionable decision making. Our business-driven approach to envisioning and implementing innovative solutions helps organizations tackle their market, increase customer engagement and grow revenue profitably via advanced technology. the Data & Analytics practice serves our clients across a broad spectrum of areas, specializing in Data Strategy, Modern Data Architecture, Data Visualization, Business Insights, Data Analytics and Artificial Intelligence.
HOW WE WORK:
Our foundational competitive advantage is simply doing what we say we will do with excellence. To deliver on that advantage, the Data & Analytics practice employs deep expertise in Organizational Data Strategy, Modern Data Architecture and Data Visualization, Advanced Analytics, Artificial Intelligence and Program Management to help our clients innovate, modernize and grow in their data-driven capabilities. Most teams are a mix of strategy, design and technology consultants working closely with clients to solve business critical challenges.
Check out Credera's Glassdoor reviewsto read what our employees have to say!
Travel: Up to 25%

LEARN MORE:

We do not currently commence ""sponsor"" immigration cases in order to employ candidates.

Credera is a management consulting, user experience, and technology solutions firm with offices in Dallas, Denver, Houston, Chicago, and New York. We work with clients ranging from Fortune 500 companies to emerging industry leaders, and provide expert, objective advice to help solve complex business and technology challenges. Our deep capabilities in strategy, organization, process, analytics, technology and user experience help our clients improve their performance. Clients depend on our ability to anticipate, recognize, and address their specific needs. Credera's consultants work with some of the world's best known brands in a variety of industries, including one of the top five fast food chains, leading energy organizations, retailers, airlines. More information is available at www.credera.com. We are part of the OPMG Group of Companies, a division of Omnicom Group Inc.

Along with a great company culture, Credera provides an outstanding compensation package including a competitive salary and a comprehensive benefit plan (e.g., medical, dental, disability, matching 401k, PTO, etc.). This position is an exempt position.

U.S. Equal Opportunity Employment Information (Completion is voluntary)

Individuals seeking employment at Credera are considered without regards to race, color, religion, national origin, age, sex, marital status, ancestry, physical or mental disability, veteran status, gender identity, or sexual orientation. Completion of the last four questions in our application is entirely voluntary. Whatever your decision, it will not be considered in the hiring process or thereafter. Any information that you do provide will be recorded and maintained in a confidential file.",Credera Experienced Hiring Job Board,"Dallas, TX",-1,-1
Data Scientist,"Reporting to our Director of Decision Science, the Data Scientist (a.k.a. Decision Science Analyst) positions charter is to increase the companys profits through data science, machine learning, and advanced statistical analytics techniques in the areas of payments, collections, operations, and companywide cross-functional projects. This individual will be a member of an exciting, fast-paced, and growing team making an immediate impact across the entire company. This is a great opportunity for a talented person to broaden his/her business skill set through exposure to a wide variety of business problems and challenge him/herself with projects that can span from tactical to strategic","Cottonwood Financial
2.5","Dallas, TX",Lending,Finance
Data Scientist,"HMS makes the healthcare system work better for everyone. We fight fraud, waste, and abuse so people have access to healthcare-now and in the future. Using innovative technology and powerful data analytics, we help government and commercial payers reduce costs, increase quality, and achieve regulatory compliance. We also help consumers take a more active role in their own health. Each year, we save our clients billions of dollars while helping people live healthier lives. At HMS, you will develop new skills and build your career in a dynamic industry while making a difference in the lives of others.

We are seeking a talented Data Scientist II to develop and execute data driven research supporting data science initiatives. This role is integral to development and creation of both ad hoc analytic projects and the long term development of machine learning models and system wide applications supporting both improved business and clinical outcomes. Candidates will be considered based on their ability to design modeling solutions that predict healthcare consumer behaviors and derive insights from big data. This role will support the design, testing, and implementation of customer segmentation, clinical propensity modeling and numerous other projects. Candidates must be able to clearly communicate the results to non-technical users and be detail-oriented. Candidates must poses strong understanding of data modeling (supervised and unsupervised), behavioral change theory, psychometrics, clinical/claims data analysis, actuarial, healthcare quality reporting and/or actuarial data analysis.

Essential Responsibilities:
Work with stakeholders to identify business requirements and the expected outcome
Collaborate with subject matter experts to select the relevant sources of information
Determine project plans, timelines, and/or technical objectives for statistical aspects of healthcare data analytic processes, applying valid statistical techniques and using information obtained from baselines or historical data to structure uncompromised and efficient analyses.
Become an expert in our health care datasets
Design experiments, test hypotheses, and build models
Develop analytic studies with an aim of delivering immediate and actionable insights to business users
Work in iterative processes and validates findings
Produce new and creative analytic solutions that will become part of our core deliverables
Non-Essential Responsibilities:
Performs other functions as assigned
Knowledge, Skills and Abilities:
Ability to translate business customer problems and questions into clear requirements for analysis
Ability to collaborate with others in diplomatic, tactful manner, while exercising sensitivity and discretion as needed
Strong understanding of statistics and probability
Ability to wrangle and analyze data using SAS, Python, R or other statistical packages
Strong understanding of data modeling (supervised and unsupervised), behavioral change theory, psychometrics, clinical/claims data analysis, healthcare quality reporting and/or actuarial data analysis.
Possess strong knowledge of and experience with analytical, quantitative, statistical, and/or consumer segmentation methodologies and theories (e.g. opportunity analyses, risk adjustment and predictive modeling, program evaluation studies, probability and inference, longitudinal analysis, mixed effect modeling, logistic regression analyses, and model building techniques)
Ability to work under pressure while managing competing demands and deadlines
Well organized with meticulous attention to detail
Strong sense of ownership, urgency, and drive
Mentor junior scientists
Work Conditions and Physical Demands:
Primarily sedentary work in a general office environment
Ability to communicate and exchange information
Ability to comprehend and interpret documents and data
Requires occasional standing, walking, lifting, and moving objects (up to 10 Ibs.)
Requires manual dexterity to use computer, telephone and peripherals
May be required to work extended hours for special business needs
May be required to travel at least 10% of time based on business needs
Minimum Education:
The knowledge typically acquired during the course of attaining a Master's Degree in Data Analytics, Data Science, Statistics, Applied Mathematics, Epidemiology or relevant major is required. A combination of education and experience may be used in lieu of a degree.
Minimum Related Work Experience:
5-10 years of work experience in a data science role required
Experience with SAS, SPSS, R or Python preferred
Experience in diverse statistical and data mining techniques with a mix of at least some of the following methods regression, random forest, clustering, consumer segmentation, social media analysis etc.
Experience working with healthcare data preferred (clinical, claims, eligibility, etc.)
Nothing in this job description restricts management's right to assign or reassign duties and responsibilities to this job at any time.

EOE including disability/veteran","HMS
3.5","Irving, TX",-1,-1
Data Scientist,"Data Scientist
If you are a Data Scientist with experience, please read on!

Located just north of the Dallas metropolitan area, we are a startup in MAJOR growth mode working within the augmented reality space and are looking to add a Data Scientist with experience to our growing team!
What You Will Be Doing
- Identify opportunities for leveraging company data to drive business solutions with company stakeholders
- Mine and analyze data from database to fuel optimization and improvement of product development, business strategies, and marketing techniques
- Develop custom data models and algorithms to apply to data sets
- Develop A/B testing framework and test model quality
- Analyze model performance and data accuracy by developing monitoring processes and tools
What You Need for this Position
Must have Majority of the following:

- R
- Python
- SQL
- Experience with clustering, Decision Tree Learning, GLM/Regression, Random Forest, social network analysis
- Artificial Neural Networks, Map/Reduce
- Hadoop, Spark, Gurobi, Hive
- MongoDB
- Masters of Science in related field


Nice to Have:

- Node.js (Very nice to have)
- PHD in Statistics, Mathematics, Computer Science
What's In It for You
We offer a comprehensive compensation package including but not limited to:

- Competitive Base Salary (DOE) + EQUITY!
- Full benefits (Medical, Dental, Vision)
- Performance based bonuses!
- Generous PTO/Sick time
- Collaborative/Friendly culture
So, if you are a Data Scientist with experience, please apply today or send your updated resume to bri.haggerty@cybercoders.com!
-
Applicants must be authorized to work in the U.S.


CyberCoders, Inc is proud to be an Equal Opportunity Employer

All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, disability, protected veteran status, or any other characteristic protected by law.

Your Right to Work In compliance with federal law, all persons hired will be required to verify identity and eligibility to work in the United States and to complete the required employment eligibility verification document form upon hire.","CyberCoders
4.2","Addison, TX",Staffing & Outsourcing,Business Services
Data Scientist,"Responsible for developing strategies for effective data analysis and reporting. Selects, configures, and implements analytical solutions. Develops and implements data analytics, data collection systems, and other strategies that optimize statistical efficiency and quality. Identifies, analyzes, and interprets trends or patterns in complex data sets. Manages computer systems in a business environment and responsible for resolving technical issues. Knowledgeable in programming, data structures, computer systems, and software engineering. Bachelor's or Master's degree in computer science, software engineering, or other related field. Ability to manage multiple assignments. Superior written and oral communication skills. 6-12+ years of experience.",Bits and Binaries Inc,"Irving, TX",-1,-1
Data Scientist,"HMS makes the healthcare system work better for everyone. We fight fraud, waste, and abuse so people have access to healthcare—now and in the future. Using innovative technology and powerful data analytics, we help government and commercial payers reduce costs, increase quality, and achieve regulatory compliance. We also help consumers take a more active role in their own health. Each year, we save our clients billions of dollars while helping people live healthier lives. At HMS, you will develop new skills and build your career in a dynamic industry while making a difference in the lives of others.

We are seeking a talented Data Scientist II to develop and execute data driven research supporting data science initiatives. This role is integral to development and creation of both ad hoc analytic projects and the long term development of machine learning models and system wide applications supporting both improved business and clinical outcomes. Candidates will be considered based on their ability to design modeling solutions that predict healthcare consumer behaviors and derive insights from big data. This role will support the design, testing, and implementation of customer segmentation, clinical propensity modeling and numerous other projects. Candidates must be able to clearly communicate the results to non-technical users and be detail-oriented. Candidates must poses strong understanding of data modeling (supervised and unsupervised), behavioral change theory, psychometrics, clinical/claims data analysis, actuarial, healthcare quality reporting and/or actuarial data analysis.

Essential Responsibilities:
Work with stakeholders to identify business requirements and the expected outcome
Collaborate with subject matter experts to select the relevant sources of information
Determine project plans, timelines, and/or technical objectives for statistical aspects of healthcare data analytic processes, applying valid statistical techniques and using information obtained from baselines or historical data to structure uncompromised and efficient analyses.
Become an expert in our health care datasets
Design experiments, test hypotheses, and build models
Develop analytic studies with an aim of delivering immediate and actionable insights to business users
Work in iterative processes and validates findings
Produce new and creative analytic solutions that will become part of our core deliverables
Non-Essential Responsibilities:
Performs other functions as assigned
Knowledge, Skills and Abilities:
Ability to translate business customer problems and questions into clear requirements for analysis
Ability to collaborate with others in diplomatic, tactful manner, while exercising sensitivity and discretion as needed
Strong understanding of statistics and probability
Ability to wrangle and analyze data using SAS, Python, R or other statistical packages
Strong understanding of data modeling (supervised and unsupervised), behavioral change theory, psychometrics, clinical/claims data analysis, healthcare quality reporting and/or actuarial data analysis.
Possess strong knowledge of and experience with analytical, quantitative, statistical, and/or consumer segmentation methodologies and theories (e.g. opportunity analyses, risk adjustment and predictive modeling, program evaluation studies, probability and inference, longitudinal analysis, mixed effect modeling, logistic regression analyses, and model building techniques)
Ability to work under pressure while managing competing demands and deadlines
Well organized with meticulous attention to detail
Strong sense of ownership, urgency, and drive
Mentor junior scientists
Work Conditions and Physical Demands:
Primarily sedentary work in a general office environment
Ability to communicate and exchange information
Ability to comprehend and interpret documents and data
Requires occasional standing, walking, lifting, and moving objects (up to 10 Ibs.)
Requires manual dexterity to use computer, telephone and peripherals
May be required to work extended hours for special business needs
May be required to travel at least 10> of time based on business needs
Minimum Education:
The knowledge typically acquired during the course of attaining a Master’s Degree in Data Analytics, Data Science, Statistics, Applied Mathematics, Epidemiology or relevant major is required. A combination of education and experience may be used in lieu of a degree.
Minimum Related Work Experience:
5-10 years of work experience in a data science role required
Experience with SAS, SPSS, R or Python preferred
Experience in diverse statistical and data mining techniques with a mix of at least some of the following methods regression, random forest, clustering, consumer segmentation, social media analysis etc.
Experience working with healthcare data preferred (clinical, claims, eligibility, etc.)
Nothing in this job description restricts management’s right to assign or reassign duties and responsibilities to this job at any time.

EOE including disability/veteran","HMS Holdings
3.8","Irving, TX",Health Care Services & Hospitals,Health Care
Data Scientist,"Job DescriptionReporting to our Director of Decision Science, the Data Scientist (a.k.a. Decision Science Analyst) position's charter is to increase the company's profits through data science, machine learning, and advanced statistical analytics techniques in the areas of payments, collections, operations, and companywide cross-functional projects. This individual will be a member of an exciting, fast-paced, and growing team making an immediate impact across the entire company. This is a great opportunity for a talented person to broaden his/her business skill set through exposure to a wide variety of business problems and challenge him/herself with projects that can span from tactical to strategic in nature. Data Scientists are based at our Corporate Office (HQ) in Irving (Las Colinas), Texas.KEY RESPONSIBILITIES* Provide data science solutions for the profitable management of key business areas of payments, collections, operations, and other companywide cross-functional projects by monitoring trends, identifying opportunities, developing and presenting recommendations, implementing the strategies, and measuring the impact* Work with the latest open source tools, libraries, platforms, and languages to build effective machine learning models to be used in non-credit decisioning throughout the firm* Proactively collaborate with Credit Risk Management, Marketing Analytics, Marketing, Data Management & Governance,* Application Development, Operations, Product Management, Compliance, and other internal groups to implement new business practices and decisioning strategies* Accountable for the successful management and completion of multiple concurrent projects that are on-time and with high quality* Provide timely and justified recommendations in response to ad hoc analysis requests by internal groups* Act as an internal resource for Python best practices* Develop actionable reports for use by the senior leadership teamREQUIREMENTS* BS in an analytical field such as Data Science, Machine Learning, Analytics, Statistics, Computer Science, or highly quantitative engineering (e.g. Chemical Engineering, Mechanical Engineering)* 2+ years of hands-on work experience developing data science solutions* 2+ years of coding experience in open source programming languages such as Python or R* Advanced user of database query languages such as SAS and SQL* Results-oriented self-starter who is confident in defending his/her critical thinking abilities* Proven track record of developing successful predictive analytics (i.e. statistical modeling)* Capitalistic mindset supported by a strong business acumen and work ethic* Demonstrated ability to communicate ideas and analysis results effectively both verbally and in writing to a non-technical audience* Local (Dallas/Fort Worth area) candidates only - no relocation* Must be currently authorized to work in the United States without sponsorship and not require sponsorship in the futurePREFERRED QUALIFICATIONS* Master's degree in a Quantitative field strongly preferred* 3+ years of hands-on work experience developing data science solutions leveraging data mining, machine learning, deep learning, operations research, or Bayesian methods* Work experience in consumer creditCOMPENSATION* Annual salary of $75,200BENEFITS* Medical, dental, and vision* Voluntary life/ AD&D* Short-term & long-term disability* 401K with company match* Paid vacation, holidays, and sick time* Paid maternity, paternity, extended medical leave, and jury duty* Corporate discount program on personal cell phone accounts with select providers* Business casual work environmentABOUT COTTONWOODFounded in 1996, Cottonwood Financial is one of the largest privately held retail consumer finance companies in the United States. We have zero debt, have been profitable every year since inception, and our growth is funded entirely through internally generated capital. Headquartered in Irving (Las Colinas), Texas, we have company-owned locations, under our Cash Store brand, across the country. Through this national brick-and-mortar footprint, we provide best-in-class customer service and offer an innovative mix of financial products and services to our customers.We have been named several times to the Inc. 5000 list of America's fastest-growing private companies, as well as to the Dallas 100 list of the fastest-growing private companies in North Texas.","Cash Store
2.2","Irving, TX",Lending,Finance
Data Scientist,"HMS makes the healthcare system work better for everyone. We fight fraud, waste, and abuse so people have access to healthcare-now and in the future. Using innovative technology and powerful data analytics, we help government and commercial payers reduce costs, increase quality, and achieve regulatory compliance. We also help consumers take a more active role in their own health. Each year, we save our clients billions of dollars while helping people live healthier lives. At HMS, you will develop new skills and build your career in a dynamic industry while making a difference in the lives of others.

We are seeking a talented **Data Scientist II** to develop and execute data driven research supporting data science initiatives. This role is integral to development and creation of both ad hoc analytic projects and the long term development of machine learning models and system wide applications supporting both improved business and clinical outcomes. Candidates will be considered based on their ability to design modeling solutions that predict healthcare consumer behaviors and derive insights from big data. This role will support the design, testing, and implementation of customer segmentation, clinical propensity modeling and numerous other projects. Candidates must be able to clearly communicate the results to non-technical users and be detail-oriented. Candidates must poses strong understanding of data modeling (supervised and unsupervised), behavioral change theory, psychometrics, clinical/claims data analysis, actuarial, healthcare quality reporting and/or actuarial data analysis.
*Essential Responsibilities:**
+ Work with stakeholders to identify business requirements and the expected outcome

+ Collaborate with subject matter experts to select the relevant sources of information

+ Determine project plans, timelines, and/or technical objectives for statistical aspects of healthcare data analytic processes, applying valid statistical techniques and using information obtained from baselines or historical data to structure uncompromised and efficient analyses.

+ Become an expert in our health care datasets

+ Design experiments, test hypotheses, and build models

+ Develop analytic studies with an aim of delivering immediate and actionable insights to business users

+ Work in iterative processes and validates findings

+ Produce new and creative analytic solutions that will become part of our core deliverables
*Non-Essential Responsibilities:**
+ Performs other functions as assigned
*Knowledge, Skills and Abilities:**
+ Ability to translate business customer problems and questions into clear requirements for analysis

+ Ability to collaborate with others in diplomatic, tactful manner, while exercising sensitivity and discretion as needed

+ Strong understanding of statistics and probability

+ Ability to wrangle and analyze data using SAS, Python, R or other statistical packages

+ Strong understanding of data modeling (supervised and unsupervised), behavioral change theory, psychometrics, clinical/claims data analysis, healthcare quality reporting and/or actuarial data analysis.

+ Possess strong knowledge of and experience with analytical, quantitative, statistical, and/or consumer segmentation methodologies and theories (e.g. opportunity analyses, risk adjustment and predictive modeling, program evaluation studies, probability and inference, longitudinal analysis, mixed effect modeling, logistic regression analyses, and model building techniques)

+ Ability to work under pressure while managing competing demands and deadlines

+ Well organized with meticulous attention to detail

+ Strong sense of ownership, urgency, and drive

+ Mentor junior scientists
*Work Conditions and Physical Demands:**
+ Primarily sedentary work in a general office environment

+ Ability to communicate and exchange information

+ Ability to comprehend and interpret documents and data

+ Requires occasional standing, walking, lifting, and moving objects (up to 10 Ibs.)

+ Requires manual dexterity to use computer, telephone and peripherals

+ May be required to work extended hours for special business needs

+ May be required to travel at least 10% of time based on business needs
*Minimum Education:**
+ The knowledge typically acquired during the course of attaining a Master's Degree in Data Analytics, Data Science, Statistics, Applied Mathematics, Epidemiology or relevant major is required. A combination of education and experience may be used in lieu of a degree.
*Minimum Related Work Experience:**
+ 5-10 years of work experience in a data science role required

+ Experience with SAS, SPSS, R or Python preferred

+ Experience in diverse statistical and data mining techniques with a mix of at least some of the following methods regression, random forest, clustering, consumer segmentation, social media analysis etc.

+ Experience working with healthcare data preferred (clinical, claims, eligibility, etc.)

_Nothing in this job description restricts management's right to assign or reassign duties and responsibilities to this job at any time._

_EOE including disability/veteran_
*Title:** _Data Scientist_
*Location:** _Texas-Irving_
*Requisition ID:** _200010ED_
EEO/Minorities/Females/Protected Veterans/Disabled.","Health Management Systems, Inc.
2.5","Irving, TX",Consulting,Business Services
Data Scientist,"Position Title Data Scientist Location Grapevine ,TX Position Type Full time SKILLS AND BACKGROUND 2 - 4 years of experience in Supply Chain or logistics data analytics Highly proficient in use of SAP and various supply Chain optimization tools Superior analytical and problem-solving skills, with an ability to deliver results in a highly dynamic and evolving environment Familiarity with demand planning and forecasting. Ability to Build models to visualize inventory scenarios and create what if simulations. Strong organizational and time management skills Excellent MS Office skills Advanced Microsoft Excel and PowerPoint skills. Interpersonal skills to work within a fast-paced team environment bull Strong communication skills, both verbal and written Ability to learn new skills and analytical tools quickly Experience working with multi-plant environment preferred Skilled data extract ability in various database platforms, such as MS ACCESS, MS SQL Experience with data visualization tools such as Tableau, MS Power BI, etc. is preferred General understanding of transportation, warehousing, and other supply chain concepts EDUCATION, CERTIFICATIONS, AND TRAINING Minimum Bachelorrsquos degree from accredited university in related discipline. Prefer Masterrsquos degree (MBA).","Prudent Technologies and Consulting
4.2","Grapevine, TX",IT Services,Information Technology
Data Scientist,"Job Description
Job Title: Data Scientist

Job Location: Irving, TX
Yrs of Exp: 6 to 9 Yrs

Description:
Responsible for developing strategies for effective data analysis and reporting.
Selects, configures, and implements analytical solutions.
Develops and implements data analytics, data collection systems, and other strategies that optimize statistical efficiency and quality.
Identifies, analyzes, and interprets trends or patterns in complex data sets.
Manages computer systems in a business environment and responsible for resolving technical issues.
Knowledgeable in programming, data structures, computer systems, and software engineering.
Bachelor's or Master's degree in computer science, software engineering, or other related field. Ability to manage multiple assignments.
Superior written and oral communication skills.
6-10+ years of experience.
Requirement:
Strong in Data Science and as a Data scientist experience with building statistical models and intelligence around it - AIML ·
Programming experience with at least 6 years of Oracle pl/sql, 3 years of Hadoop and 1 year of Java experience.
Proven understanding and related experience with Hadoop, HBase, Hive, Pig, Sqoop, Flume, Hbase, Map/Reduce, Apache Spark as well as Unix OS Core Java programming, Scala, shell scripting experience.
Hands on Experience in Oozie Job Scheduling, Zookeeper, Solr, ElasticSearch, Storm, LogStash or other similar technologies
Must have experience with MQ technologies (Kafka, RabbitMQ).
Solid experience in writing SQL, stored procedures, query performance tuning preferably on Oracle 12c.
Experience working with CI/CD and DevOps
Responsibilities:
Identify new opportunities, use cases and build data models in RA and Enforce . Train Data models to proactively identify revenue leakages and Fradulant behaviours Participate in Agile development on a large Hadoop-based data platform as a member of a distributed team .
Come out with different statistical models and build data insights on revenue leakages possiblities
Code programs to load data from diverse data sources into Hive structures using SQOOP and other tools.
Translate complex functional and technical requirements into detailed design.
Analyze vast data stores.
Code business logic using Scala on Apache Spark.
Create workflows using Oozie.
Code and test prototypes.
Code to existing frameworks where applicable
Education/Certifications: Bachelor's/Masters in Computer Engineering or Information Technology Hadoop and AIML Certification is added advantage","Radiant Digital
4.5","Irving, TX",-1,-1
Data Scientist,"Job Description
Data Scientist,

Coppell, TX

Phone + Skype

No H1B

6 Months Duration

JD:

Data Science projects: (ML Machine Learning)
Sales forecasting and revenue forecast using multiple regression
ML projects for Customer Success: Predict customer attrition; use several data points to predict attrition/ or will they renew
ML project for Cloud team : Anomaly detection- Some products hosted on BY private cloud; DS to find patterns in data to predict when an application could go down (ex: SF hosts products to us; they will want to know when it goes down to avoid cost) for predictive maintenance or anomaly detection
Models: *Working on LARGE DATA SETS
Classification, Regression models primarily
Key skills needed :
Data cleaning, Data wrangling, Data Visualization, Intellectual Curiosity, Business acumen, Communication Skills, Probability and Statistics, Machine Learning
Tools/Environment must haves:
Azure Databricks environment/environment experience, OR working on AWS Public Cloud environments
Python Programming skills 3 years (In-depth knowledge of Python, Pandas and its open-source ecosystem or similar)
SQL 2- 3 years
Spark ML domain knowledge
Visualization tools: Power BI or Tableau
Presenting to senior leadership, up to C-level execs, via PowerPoint presentations, etc.
FULL JOB DESCRIPTION:

Scope:
Data Scientist to help build classification, regression ML models for predictive analytics and anomaly detection
You will be responsible for transforming data and generating actionable insights into our customer behavior
Communicate key results with self-serve tools (dashboards, analytics tools) for the Customer Success team
Must have DS skills:
Data cleaning, Data wrangling, Data Visualization, Intellectual Curiosity, Business acumen, Communication Skills, Probability and Statistics, Machine Learning
Experience building (from scratch) Machine Learning (ML) models that can be put to production (with the support of data engineering and S.W engineering teams)
Professional experience building machine learning models (candidates will need to articulate detail project experience from research, model selection, action and results)
Statistics knowledge
Tools/Environment must haves:
Azure Databricks environment/environment experience,
Python Programming skills 3 years (In-depth knowledge of Python, Pandas and its open-source ecosystem or similar)
SQL 2- 3 years
Spark ML domain knowledge
Visualization tools: Power BI or similar
Responsibilities:
Build machine-learning models
Create regression, classification models; Work with engineering teams to deploy robust, highly available decisioning pipelines based on your models.
Analyze large amounts of information to discover trends and patterns
Combine models through ensemble modeling
Present information using data visualization techniques
Processing, cleansing, and verifying the integrity of data used for analysis. Undertake preprocessing of structured and unstructured data
Qualifications:
Business acumen and communication skills to gather the data requirement from the business
3+ years of related professional work experience
Theoretical and execution background of Data Science with specific focus on Machine Learning
Experience testing and validating models and assessing the trade-offs between different modeling techniques and specifications
Comfort manipulating and analyzing complex, high-volume, high-dimensionality data from varying sources
Strong analytics and problem-solving skills needed. Can take the data and come up with a solution specific to the use case
Experience in applying statistical learning methods to solve business problems
Experience working with complex and/or large data sets
Practical ability to visualize data, communicate the data, and utilize it effectively
Programming skills 2 years (In-depth knowledge of Python, Pandas and its open-source ecosystem or similar)
Proficiency in using query languages such as SQL, Hive, Pig, Sqoop.
Experience with NoSQL databases, such as MongoDB, Cassandra, Hbase and SQL databases and unstructured data stores
Excellent understanding of machine learning techniques and algorithms, such as k-NN, Na ve Bayes, SVM, Random Forests, etc.
NLP / NLU experience preferred.",Stellent IT LLC,"Coppell, TX",-1,-1
Data Scientist,"*Data Scientist** + Log in **Share this** Find similar career opportunities **Data Scientist** **Category:** Database Administration **City:** Dallas, Texas, United States **Position ID:** J0620-0337 **Employment Type:** Full Time **Position Description:** This position is responsible for business consulting activities for the Data Strategy and Analytics teams within our client organizations to monitor and assist in improving their analytics eco system. We need someone with a creative problem-solving skills to work on our client's business opportunities. Our Data Scientistwill work to understand high value opportunities and identify/build potential solutions, which often involve discovering new insights by transforming data into intuitive & interactive visualizations or applications Responsibilities: Serve as an expert in translating complex data into key strategy insights and valuable actions. • Discover business narratives told by the data and present them to other scientists, business stakeholders, and managers at various levels. • Develop and test heuristics. • Create and run statistic/ML models. • Perform data exploration and data mining. • Create business intelligence, dashboards, visualizations, and/or other advanced analytics reports to adequately tell the business narrative and offer recommendations that are practiced, actionable, and have material impact, in addition to being well-supported by analytical models and data. Skills: Work experience in addition to degree: 3 - 5 years of data engineering/science related activities with overall 10+ years' experience. • Graduation from a four-year college or university with a degree in statistics, physics, mathematics, engineering, computer science, or management of information systems. • Expert knowledge of SAS, Python Machine Learning or R • Working knowledge of statistics, programming and predictive modeling. • Working knowledge of code writing • Big Data/Hadoop/NoSQL and experience with large datasets Desired: Doctorate in Computer science, Engineering, Physics or Statistics **Your future duties and responsibilities:** \#LI-JS2 **Skills:** + Data Analysis + SQL + Python + QlikView + Data Architecture **What you can expect from us:** **Build your career with us.** It is an extraordinary time to be in business. As digital transformation continues to accelerate, CGI is at the center of this change-supporting our clients' digital journeys and offering our professionals exciting career opportunities. At CGI, our success comes from the talent and commitment of our professionals. As one team, we share the challenges and rewards that come from growing our company, which reinforces our culture of ownership. All of our professionals benefit from the value we collectively create. Be part of building one of the largest independent technology and business services firms in the world. Learn more about CGI at www.cgi.com . No unsolicited agency referrals please. CGI is an equal opportunity employer. Qualified applicants will receive consideration for employment without regard to their race, ethnicity, ancestry, color, sex, religion, creed, age, national origin, citizenship status, disability, medical condition, military and veteran status, marital status, sexual orientation or perceived sexual orientation, gender, gender identity, and gender expression, familial status, political affiliation, genetic information, or any other legally protected status or characteristics. CGI provides reasonable accommodations to qualified individuals with disabilities. If you need an accommodation to apply for a job in the U.S., please email the CGI U.S. Employment Compliance mailbox at US_Employment_Compliance@cgi.com . You will need to reference the requisition number of the position in which you are interested. Your message will be routed to the appropriate recruiter who will assist you. **Please note, this email address is only to be used for those individuals who need an accommodation to apply for a job. Emails for any other reason or those that do not include a requisition number will not be returned** . We make it easy to translate military experience and skills! Click here at https://cgi-veterans.jobs/ to be directed to our site that is dedicated to veterans and transitioning service members. All CGI offers of employment in the U.S. are contingent upon the ability to successfully complete a background investigation. Background investigation components can vary dependent upon specific assignment and/or level of US government security clearance held. CGI will not discharge or in any other manner discriminate against employees or applicants because they have inquired about, discussed, or disclosed their own pay or the pay of another employee or applicant. However, employees who have access to the compensation information of other employees or applicants as a part of their essential job functions cannot disclose the pay of other employees or applicants to individuals who do not otherwise have access to compensation information, unless the disclosure is (a) in response to a formal complaint or charge, (b) in furtherance of an investigation, proceeding, hearing, or action, including an investigation conducted by the employer, or (c) consistent with CGI's legal duty to furnish information.","CGI Technologies and Solutions, Inc.","Dallas, TX",-1,-1
Data Scientist,"The Data Scientist is an individual contributor that should be able to apply quantitative, data science and analytical skills to complex problems. He/or she should be able to work across teams to design, develop, and evaluate and execute against those data science and analytical solutions with a keen functional understanding of the business problem. He/she will be responsible for data wrangling, data analysis, modeling, including model selection and producing quick applicable modeling solutions.The position will serve as a thought leader including advising on optimal solutions and opining on challenger models. The role works on strategic, highly visible projects firm wide. It is an opportunity to have meaningful impact on a large scale at a leading financial services firm. The role will develop data-centric solutions that move the bottom line for the firm.In Corporate Technology Machine Learning at JPMorgan Chase, our role involves solving challenging business problems through data science and machine learning techniques across all the corporate functions, including Risk, Compliance, Finance, HR, Legal, and Audit.This role requires a wide variety of strengths and capabilities, including:* Advanced degree in analytical field (e.g., Data Science, Computer Science, Engineering, Applied Mathematics, Statistics, Data Analysis, Operations Research)* Extensive practical expertise and work experience with Machine Learning, both supervised and unsupervised. Deep Learning (neural network) experience is preferred.* Experience across broad range of modern analytic and data tools, particularly Python/Anaconda and/or R, XGBoost, Tensorflow and/or Keras, Spark, Hive, SQL.* Excellent problem solving, communications, and teamwork skills.* Financial service background preferred, but not required","JPMorgan Chase & Co.
3.9","Lewisville, TX",Investment Banking & Asset Management,Finance
Machine Learning Engineer,"Dialexa is expanding its Data Science practice and is looking for great talent to join us in building intelligent, next-generation platforms. Are you tired of just pushing out ones and zeros and you yearn to solve hard problems? Do you want to work on an awesome team of designers and developers in a full agile process? Do you want your creative technical ideas to be listened to, heard, and implemented? Do you want to create applications that people love?

We develop for a wide array of technology platforms and frameworks including mobile, web, Internet of Things (IoT), wearables, and embedded devices. We have an awesome culture that includes perks such as fun quarterly team outings, healthcare benefits, 401K, PTO, wellness programs, and much, much more. To learn more about Dialexa, please visit www.dialexa.com

Responsibilities
Mine and analyze data from large data sources
Develop machine learning models to automate business processes and decisions
Productionalize models into a variety of platform architectures
Coordinate with multiple internal and external functional teams to implement models and monitor outcomes
Assess the effectiveness and accuracy of new data sources and data gathering techniques
Help drive business results and participate in the account and department growth
Expectations (the more the better - we want great talent!)
Bachelor of Science in Computer Science, Statistics, or related major
5+ years in a client-facing role
Portfolio of applications or publications that demonstrate a deep knowledge of data science techniques
Knowledge of common data science languages (Python, R, Scala, Java, etc.)
Experience with...
Training machine learning models (Scikit-learn, Tensorflow, Keras, H2O.ai)
Cleaning, blending and visualizing data (Pandas, Spark, Matplotlib)
Cloud infrastructure and services (AWS, Azure, Google Cloud)
SQL and NoSQL databases (MySQL, PostgreSQL, Cassandra, MongoDB)
Searching and caching storage (Elasticsearch, Solr, Redis)","Dialexa
4.8","Dallas, TX",Computer Hardware & Software,Information Technology
Data Analyst,"Description –
6+ years of Data Analyst experience.
Good knowledge in Datastage, ETL, Data modelling & Reporting.
MUST have previous Wholesale Customer Data experience.
Strong in Tableau Development.
Experience creating visualizations and dashboards using Power BI, Tableau.
Experience in both UNIX/Linux and Windows environments.
Strong expertise with ETL, SQL, and Python, other like scripting/reporting tools.
Demonstrated ability to work cross-organizationally to gather business requirements, track and measure against goals, objectives or KPIs.
Demonstrated ability to interpret data to understand business impact and derive business insights.","Sphinix Solutions
1.0","Dallas, TX",IT Services,Information Technology
Data Analyst,"id Software has a great opportunity for you to partner with the existing team on Orion. Orion is technology that enhances the experience of a streamed game. Orion technology reduces latency and bandwidth while streaming a game, making streamed games accessible to more people, in more areas, at higher quality.
Our Data Analyst will be an integral part of the Orion team that not only helps the company take advantage of emerging trends but helps drive and define the trend. Our team is results driven and we are looking for people who want to actualize real world technologies that impact the industry in a profound way. Expect your abilities and scope of work to expand in a fast paced and highly innovative environment.

The Data Analyst must have knowledge and experience in data exploration and analysis to create standard and ad-hoc reports and dashboards, as well as being able to determine trends that result in actionable insights. With a deep understanding of advanced statistical methods, you want to be part of a new challenge.
Design, develop, and maintain reports, visualizations and dashboards of KPIs and metrics.
Analyze data to further understand, model, predict, segment, and monetize Bethesda’s players.
Create models to forecast key metrics.
Mine and explore multi-dimensional datasets.
Partner with stakeholders and development team to elicit and document reporting and analytics requirements that can help them.
Serve as a subject matter expert and resource for accessing and analyzing data.
Write complex set of SQL queries and Python scripts in order to extract and analyze big, multi-dimensional datasets with statistical modelling and visualization tools (Matplotlib, Seaborn, Tableau).

BS degree in Computer Science, Math, Statistics, Business Economics, Engineering, or BI with appropriate additional experience.
Minimum 2-4 years of experience on a similar role developing reports, visualizations, and dashboards using Tableau Desktop or similar.
Passion for video games.
Experience in performing quantitative analysis, statistical modelling and applied statistics, providing recommendations for stakeholders – ideally in the video game industry.
Experience with data extraction, manipulation, and wrangling.
Excellent SQL skills with the knowledge of statistical, aggregate, and windowing functions.
Strong knowledge of Excel and/or statistical packages.
Knowledge of Python or other programming languages.
Strong knowledge of logical database design, relational databases, and data warehouse principles.
Production of regular reports on key metrics.
Strong communication and teamwork skills.
Experience with monitoring, reporting, and logging tools at local and cloud scale.
Excellent verbal and written communication skills.
Excellent analytical and troubleshooting skills.
Prior experience in a fast-paced environment.

Experience in the video game industry would be a big plus.
Good understanding of free-to-play systems and economy-in-game.
General programming experience would be an asset.
Prior experience working in an AWS environment preferred.
Prior experience with predictive models / Machine learning.
Desire and vision to help shape a project from the ground up","ZeniMax Media, Inc.
3.4","Dallas, TX",Video Games,Media
Data Scientist,"Hope you are doing great!!

We have a Job openining for our Direct Client at below Location:

Â
Role: Data Scientist
Location: Irving,TX
Duration: 12+months
Visa: H1B, GC, USC

Need 5+ years of experience as Data Scientist.

The desired candidate would have an excellent understanding of Python Java R Robotic Process Automation (RPA)

Hands on working experience with below skill sets:

Artificial Intelligence
Machine Learning algorithms -
Google Tensol Flow
Amazon Sage Maker etc.

Supervised LearningÂ
Unsupervised LearningÂ
Reinforcement Learning
Data Science - Data Preparation and Feature Engineering

Software languages for Machine learning Python Java R Robotic Process Automation (RPA)

Job Description:

Able to integrate multiple data sources and databases into one system
Design and implement a microservice based application using python, Django and related frameworks.
Collaborate with product and business teams to define our product, balancing features with time to market.
Create a scalable, testable, documented application so that we can grow the product over time.
Understanding of the threading limitations of Python, and multi-process architecture
Good understanding of server-side templating languages
Basic understanding of front-end technologies, such as JavaScript, HTML5, and CSS3
Understanding of accessibility and security compliance
Knowledge of user authentication and authorization between multiple systems, servers, and environments
Understanding of fundamental design principles behind a scalable application
Familiarity with event-driven programming in Python
Understanding of the differences between multiple delivery platforms, such as mobile vs desktop, and optimizing output to match the specific platform
Able to create database schemas that represent and support business processes
Strong unit test and debugging skills
Proficient understanding of code versioning tools (GIT) and Continuous integration continuous deployment Requirements
Bachelor s degree in a technical discipline such as Computer Science, Software Engineering; or equivalent work experience required

Â
Thanks & Regards,
SANTOSH KUMAR | Sr.IT Recruiter
Xcelo Group Inc.
Contact by : cskumar@xcelogroup.com
M: 972-968-8512",Xcelo Group,"Irving, TX",-1,-1
Data Analyst,"The Opportunity


We're looking for a Data Analyst, working in the Banking/Finance industry in Plano, Texas.
Working in the AML (Anti Money Laundering Group).
Creating repository for customer information which will be hosted on AWS and used for regulatory activities.
Our Client


Our client provides agile consulting and staffing. Helping organizations fulfill their most important initiatives and opportunities. For 30 years. From coast-to-coast.

Developing long-term relationships. Successfully retaining clients and placing consultants through multiple engagements.

Providing you with the support, care, and attention you deserve. With advocates available 24x7 to help you with questions and concerns. This personal care together with great work has resulted in a 4.4 Glassdoor rating.

Join the most talented professionals in the industry working on strategic and world-class programs.

Experience Required for Your Success
Associate's Degree or Higher
5+ years of experience
Experience in AWS- S3 for Data Extraction
Experience in SQL
Experience in Tableau
Experience in Postgress in AWS
Must be used to working with very large Data Sets.
Details


The pay we are offering is 50 per hour. This position may present an opportunity to go permanent.

What Do You Think?


Does your experience reflect what it takes to be successful in this role? Do the work and challenges get you excited about what's possible? Apply here.

Not exactly? Join Our Talent Community, and we'll let you know of additional opportunities.","PSG Global Solutions
3.9","Plano, TX",Staffing & Outsourcing,Business Services
Statistician,"The U.S. Department of the Treasury has a distinguished history dating back to the founding of our nation. As the steward of U.S. economic and financial systems, Treasury is a major and influential leader in today's global economy. We have over 100,000 employees across the country and around the world. Come Join the Department of the Treasury and Invest in Tomorrow.
See Other Information for Locations
Positions are to be filled in the Large Business & International (LB&I), Data Solutions division.
Eight (8) positions are to be filled in any of the following locations:
Birmingham, AL
Fayetteville, AR
Little Rock, AR
Phoenix, AZ
El Monte, CA
Glendale, CA
Laguna Niguel, CA
Los Angeles, CA
Long Beach, CA
Oakland, CA
Sacramento, CA
San Diego, CA
San Francisco, CA
San Jose, CA
Santa Ana, CA
Lakewood, CO
Hartford, CT
New Haven, CT
Norwalk, CT
Washington, DC
Newark, DE
Miami, FL
Ft. Myers, FL
Jacksonville, FL
Maitland, FL
Plantation, FL
Tampa, FL
West Palm Beach, FL
Atlanta, GA
Honolulu, HI
Des Moines, IA
Chicago, IL
Downers Grove, IL
Schiller Park, IL
Springfield, IL
Indianapolis, IN
Wichita, KS
Louisville, KY
New Orleans, LA
Boston, MA
Brockton, MA
Stoneham, MA
Southborough, MA
Baltimore, MD
Lanham-Seabrook, MD
Rockville, MD
Ann Arbor, MI
Clinton Township, MI
Detroit, MI
Farmington Hills, MI
Flint, MI
Grand Rapids, MI
Pontiac, MI
Bloomington, MN
Chesterfield, MO
Lee's Summit, MO
Charlotte, NC
Greensboro, NC
Raleigh, NC
Omaha, NE
Edison, NJ
Iselin, NJ
Mountainside, NJ
Paterson, NJ
Las Vegas, NV
Albany, NY
Bethpage, NY
Buffalo, NY
New York, NY
Rochester, NY
Cincinnati, OH
Columbus, OH
Independence, OH
Oklahoma City, OK
Tulsa, OK
Portland, OR
Philadelphia, PA
Pittsburgh, PA
King Of Prussia, PA
Guaynabo, PR
Warwick, RI
Franklin, TN
Memphis, TN
Nashville, TN
Austin, TX
Farmers Branch, TX
Fort Worth, TX
Houston, TX
San Antonio, TX
Ogden, UT
Salt Lake City, UT
Norfolk, VA
Richmond, VA
Vienna, VA
Seattle, WA
Milwaukee, WI
Waukesha, WI
Kearneysville, WV
Martinsburg, WV
WHAT DOES A DATA SCIENTIST DO? The Data Scientist utilizes advanced analytical, statistical, and computer programming skills to develop data- driven solutions to difficult business challenges. As a data scientist, you are responsible for conducting data-centric projects to provide insight and informed decisions for mission- oriented programs of the Internal Revenue Service (IRS), which may impact multiple program segments, divisions, the Service, or segments of the taxpayer population. This is accomplished by utilizing a wide range of technical competencies such as statistics and machine learning, coding languages, data wrangling, and reporting and visualization techniques. The Data Scientist may lead team or cross functional projects, and will apply critical thinking, problem solving and ability to communicate complex analysis to advance the use of data-driven decision making in IRS operations.

WHAT IS THE LARGE BUSINESS AND INTERNATIONAL (LB&I) DIVISION OF THE INTERNAL REVENUE SERVICE? The Large Business and International (LB&I) business unit provides service and enforcement activities to support tax compliance of businesses and related entities with assets of $10 million or more, as well as small U.S. businesses engaged in international, U.S. citizens abroad, and foreign persons and businesses with a U.S. tax requirement.
As a Data Scientist, you will:
Serve as a technical expert with responsibility for the initiation, planning, implementation, controlling, modifying and executing of all or part of an entire project, including such tasks as formulation of workload estimates for program segments, specification of the methodology to be used, preparation of appropriate specifications and procedures, and review of computer systems specifications and materials and instructions needed for assuring the adequacy of the project’s design and objectives.
Explore novel methods of retrieving data and develop innovative recommendations to management and senior leadership as a means for making data driven decisions such as modification of processes and policies. Review, evaluate, validate, and document the results of the findings.
Assist the supervisor in determining the scope, goals and schedules for future programs in the Office. Collaborate with business or technology partners to understand business needs, identify opportunities, and develop and implement analytical solutions.
Identify and assess relevant data sources’ validity and reliability to meet project needs. Collate, clean, transform, analyze, and integrate structured and unstructured data from various sources in preparation for analysis.
Apply statistical methods and concepts including data mining, statistical theory and research procedures to test hypotheses using structured and unstructured data. Develop data product solutions to improve customer experiences, anomaly detection, and business outcomes. Develop proofs of concept or demonstrations to evaluate feasibility of project solutions and recommend visualization strategies.
Document project work and review deliverables for validity, reliability and timeliness. Communicate analytic solutions to technical and non-technical stakeholders, including during executive- level and/or cross-agency meetings, in a clear and effective manner using oral and written communications.
Maintain knowledge of state-of-the-art innovations in data science from both academic and industry sources and identify opportunities for implementation. Engage in general professional development to improve knowledge of IRS processes/programs.
Apply computer based mathematical/statistical techniques using software. Lead or participate in statistical projects or studies in survey sampling (design and estimation), modeling, or statistical research. Apply knowledge of programming/coding language (i.e., SQL, SAS, SPSS, RStudio) to develop scripts or applications.
Act as a troubleshooter in resolving bottlenecks at any step in a project by identifying and proposing solutions; this may include coordination with other project team members or stakeholders to mitigate issues.

WHERE CAN I FIND OUT MORE ABOUT OTHER IRS CAREERS? If you want to find out more about IRS careers, visit us on the web at www.jobs.irs.gov
#LI-POST
You must meet the following requirements by the closing date of this announcement
BASIC QUALIFICATION REQUIREMENTS:

GS-1530 Statistician All Grades:
You must have a Bachelor's degree that included 15 semester hours in statistics (or in mathematics and statistics, provided at least 6 semester hours were in statistics), and 9 additional semester hours in one or more of the following: physical or biological sciences, medicine, education, or engineering; or in the social sciences including demography, history, economics, social welfare, geography, international relations, social or cultural anthropology, health sociology, political science, public administration, psychology, etc. Credit toward meeting statistical course requirements should be given for courses in which 50 percent of the course content appears to be statistical methods, e.g., courses that included studies in research methods in psychology or economics such as tests and measurements or business cycles, or courses in methods of processing mass statistical data such as tabulating methods or electronic data processing. OR
Combination of education and experience -- courses as shown above, plus appropriate experience or additional education. The experience should have included a full range of professional statistical work such as (a) sampling, (b) collecting, computing, and analyzing statistical data, and (c) applying statistical techniques such as measurement of central tendency, dispersion, skewness, sampling error, simple and multiple correlation, analysis of variance, and tests of significance.
GS-13 LEVEL: You must have one year of specialized experience at a level of difficulty and responsibility equivalent to the GS-12 grade level in the Federal service. Specialized experience for this position includes all of the following:
Experience applying project management principles on a data science project
Experience planning and executing a variety of data science and/or analytics projects.
Experience using data mining process models (such as CRISP-DM, SEMMA, etc.,) to design and execute data science project.
Experience preparing and analyzing structured and unstructured datasets to explorations and evaluating data science centric models.
Experience working with multiple data types and formats as a part of a data science project.
Experience applying a range of analytic approaches, including (but not limited to) machine learning, text analytics, and natural language processing; graph theory, link analysis and optimization models; complex adaptive systems; and/or deep learning neural networks that are part of the exploration.
Experience coding in various programming languages (such as R, Python, SQL, or JAVA) to conduct various phases of data science projects.
Experience creating and querying different datastores and architectures (such as Sybase, Oracle, and open-source databases) to work with various types of data as part of the data science project.
Experience using tools for data visualization (graphs, tables, charts, etc.,) and end-user business intelligence.
-The experience may have been gained in the public sector, private sector or Volunteer Service. One year of experience refers to full-time work; part-time work is considered on a prorated basis.
-To ensure full credit for your work experience, please indicate dates of employment by month/year, and indicate number of hours worked per week, on your resume.","Internal Revenue Service
3.5","Farmers Branch, TX",Federal Agencies,Government
Data Scientist,"Job Description
Title: Data Scientist
Location: Dallas, TX
Type: Fulltime Permanent

Description:
we rely heavily on data to power our systems and bring to market innovative solutions that improve the transportation industry.
We are looking for a Data Scientist that will help us identify overarching patterns in large volumes of data to drive current product improvement and create new predictive modeling for the airline industry.
Our ideal team member will have the right combination of the computer science, mathematical and statistical expertise you’d expect, but also a natural curiosity and creative mind.
As you mine, interpret, and clean our data, we will rely on you to ask questions, understand the domain, connect the dots, and uncover opportunities that lie hidden within—realizing the data’s full potential. All with the ultimate goal of optimizing the aviation industry.
You will join a multi-disciplinary team of talented individuals and you will use your skills and experience to drive the present and create the future.

Job Description:
Apply Multivariate Statistical Analysis, Data Modeling, Predictive Analytics to solve transportation problems in the airline industry
Design, code, test and debug complex optimization & data science solutions using operations research & machine learning techniques.
Apply machine learning, data visualization and analytics to solve business problems
Pattern recognition, Statistical Inference, and model estimation using multiple big data sources
Develop data manipulation and machine learning algorithms in R, Python, SQL, Bash, C# etc.,

Qualifications:
MS. or Ph.D. degree in Computer Science, Statistics, Operations Research, Mathematics, Machine Learning
Ability to apply modeling and analytical skills to transportation problems
Apply regression (linear, nonlinear, logistic), decision trees, cluster analysis and other machine learning algorithms
Excellent programming skills using R, Python, SQL, C#
Experience in Big Data technologies such as Spark and Hadoop Platform (Hive, HDFS)
Excellent problem-solving and analytical skills
Deriving meaningful patterns and quantitative analysis using complex large datasets

Thank you,
Sachin Patil,
510-402-1063
sachin@apninc.com","APN Software Services Inc.
4.1","Dallas, TX",Computer Hardware & Software,Information Technology
Data Scientist,"BrightPoint Solutions is working with a client who is in search of a Data Scientist to join its growing Predictive Modeling team.

The ideal candidate will have previous Data Modeling experience. Strong preference will be given to candidates with an actuarial background in the property and casualty insurance space.

Responsibilities
Build predictive and/or Machine Learning models in SAS
Research new statistical and mathematical techniques that are suitable and helpful for solving business related problems
Prepare data for modelling and make best/creative use of applicable and available internal or external data
Identifying and integrating new datasets that can be leveraged for modeling efforts
Support related processes around effectively deploying model to business
Effectively communicate results in written, oral and presentation formats to technical and non-technical audiences
Qualifications
Bachelor’s degree in statistics, applied mathematics, or related discipline
3+ years of Data Modeling or similar experience.
Experience with predictive modeling (classification, regression, parameter tuning, optimization criteria, feature selection), preferably with multiple techniques
Experience in model validation techniques, model testing and continuous monitoring of model performance
Experience in Property & Casualty Insurance is strongly preferred.
Demonstrated experience working with large relational data sets.
Working knowledge in SAS, R, Python or another platform to develop and implement predictive models.
Ability and willingness to quickly gain knowledge of SAS enterprise guide and enterprise miner.
Ability to communicate complex technical information in common language to foster teaching and analytics guidance to internal customers.
Advanced experience in analytics, data cleaning, and predictive modeling.
Ability to write queries in SQL.
Detail-oriented and ability to work collaboratively
Job Type: Full-time

Pay: $75,406.00 - $158,767.00 per year

Benefits:
401(k)
Dental Insurance
Health Insurance
Paid Time Off
Vision Insurance
Experience:
Data Science: 1 year (Preferred)
Education:
Master's (Preferred)
Work authorization:
United States (Preferred)
Schedule:
Monday to Friday",BrightPoint Solutions,"Dallas, TX",-1,-1
Data Analyst,"Nokia is a global leader in the technologies that connect people and things. With state-of-the-art software, hardware and services for any type of network, Nokia is uniquely positioned to help communication service providers, governments, and large enterprises deliver on the promise of 5G, the Cloud and the Internet of Things.

Serving customers in over 100 countries, our research scientists and engineers continue to invent and accelerate new technologies that will increasingly transform the way people and things communicate and connect.

Nokia is an equal opportunity employer that is committed to diversity and inclusion.

At Nokia, employment decisions are made regardless of race, color, national or ethnic origin, religion, gender, sexual orientation, gender identity or expression, age, marital status, disability, protected veteran status or other characteristics protected by law.

Our Nokia Information Technology organization is looking for an CMDB & Service Catalog Data Analyst.

Role:



The CMDB & Service Catalog Data Analyst is accountable and responsible for creation, development, and maintenance of Nokia IT ServiceNOW based Configuration Management Data Base (CMDB) and Service Catalog (UPM-X). He/She will ensure information from across the IT ecosystem is represented in a cohesive a complete CMDB that supports Nokia’s IT Service Management operations impact assessment and decision-making ability.

He/she, together with the Configuration & Service Catalog Manager, Configuration & Service Catalog management Design Specialists, and IT Service Owners, will support maintaining Nokia’s IT CMDB for use in the end-to-end solution, program/project delivery, and ongoing service management operations. This responsibility includes definition, modification and addition to the data model, implementing Configuration Items (CI’s) and relationship changes to the CMDB repositories directly, data analysis and reporting, and process support.

He/she, in conjunction with IT stakeholders and Configuration Manager, will help make CMDB data model and tool decisions.

The CMDB & Service Catalog Data Analyst may also assist the Configuration Manager and CMDB & Service Catalog Data Specialists in their day-to-day configuration management change activities.

Main Responsibilities :
Maintain and build a coherent and accurate CMDB and Service Catalog.
Has a good understanding of IT Service Management and can interpret the requirements and requests raised by Service Owners that then get incorporated into CMDB and the Service Catalog.
Analyses IT landscape requirements and translates them to the technical requirements, specs, and solution proposal for Nokia’s CMDB and then implements them.
Writes requirements, specifications and other guiding documentation from technical area point of view for Nokia’s CMDB, and ensures it is understood by all stakeholders interfacing to the CMDB.
Analyzes and interprets complex digital data, its relationship to other data sets, and draws conclusions that can then be shared to both technical and non-technical teams to support data-based decisions.
Supports Configuration Manager in day-to-day activities to implement changes to the CMDB as well as supporting assurance on quality of CMDB content.
Participates and coordinates CMDB data audits with Service Owners.
Active CMDB status accounting through dashboarding and trend analysis.
Actively participates in the Continual Service Improvement (CSI) for Configuration Management.
Key Competencies:
At least 3 years of experience in CMDB & auto-discovery.
Familiarity of ServiceNOW administration, transformation concepts, and underlying data mechanisms.
Familiarity with ServiceNOW dashboards and reporting.
Familiarity with how DBMS operate and the ability to manipulate and create data within.
Strong fundamentals in data analytics.
Good understanding of Enterprise level IT environments with factual and theoretical knowledge to identify and retrieve information.
Experience in ITIL process management
Bachelor’s degree in engineering, Computer Science or related field from recognized university or equivalent
Highly independent and self-directed individual capable of working with minimal supervision
Has a broadly ""agile"" mindset, applying approaches as Agile, Scrum and DevOps to deliver IT projects/programs.
Show a dedication to learning, taking initiative, teaching others, and welcome feedback.
Fluent in written and spoken English
Nice to Have:
Knowledgeable of UPM-X, Power BI
ITIL V3 foundation certification
Familiarity with cloud computing/edge clouds as we hope to populate our CMDB with Nokia IT Cloud environments
Familiarity with ServiceNOW CSDM
Working knowledge of IT asset management
Software programming languages. Javascript, Python. Experience with ServiceNOW Glide API a big plus.
ServiceNOW Certifications in Administration, App developer a plus.
Database Administration Certification

Apply now.","Nokia
4.1","Dallas, TX",Telecommunications Services,Telecommunications
Machine Learning Engineer,"Tiger Analytics is an advanced analytics consulting firm. We are the trusted analytics partner for several Fortune 100 companies, enabling them to generate business value from data. Our consultants bring deep expertise in Data Science, Machine Learning and AI. Our business value and leadership has been recognized by various market research firms, including Forrester and Gartner.We are looking for a Machine Learning Engineers for our team. As part of this job, you will be responsible for:* Providing solutions for the deployment, execution, validation, monitoring, and improvement of data science solutions.* Creating high performance and scalable Machine Learning systems* Building reusable production data pipelines for machine learning models* Writing production quality code and libraries that can be packaged as containers, installed and deployed* Demonstrate up-to-date knowledge in software engineering practices and provides solutions for the development, implementation and scaling, execution, validation, monitoring, and improvement of data science solutions* Collaborate with Data Engineers and Data Scientist to build data and model pipelines and help in running machine learning tests and experiments* Manage the infrastructure and data pipelines needed to bring ML solution to production* Demonstrate end-to-end understanding of applications (including, but not limited to, the machine learning algorithms) being created and maintain scalable machine learning solutions in production* Abstracts complexity of production for machine learning through the use of containers* Troubleshoots production machine learning model issues, including recommendations for retrain, re-validate, and improvements* 3-5 years of experience with Big Data Projects using multiple types of structured and unstructured data* Ability to work with a global team, playing a key role in communicating problem context to the remote teams* Excellent communication and team work skills* Bachelor's degree or higher in computer science or relatedAdditional Skills Required:* Technologies used would include Python (multiple versions), Spark, Hadoop, Docker, with an emphasis on good coding practices in a continuous integration context, model evaluation, and experimental design* Test driven development (prefer py.test / nose), experience with Cloud environments* Proficiency in statistical tools, relational databases & expertise in programming languages like Python/SQL is desiredSignificant career development opportunities exist as the company grows. The position offers a unique opportunity to be part of a small, challenging, and entrepreneurial environment, with a high degree of individual responsibility.","Tiger Analytics
4.6","Dallas, TX",Consulting,Business Services
Data Analyst,"Are you interested in a new career? We may be looking for you!

TrinityRail is hiring a Data Analyst in our Dallas, TX, Corporate HQ!

The successful candidate will help engineer data solutions and provide visualizations to derive insights. The analyst should have experience in data mining and transformation, developing data pipelines, and creating visualizations. Presentation skills are required to explain data architecture, expose insights in the data, and lead conversations with the leadership team.

What you'll do:

• Work with partners and specialists to derive and understand business outcomes
• Work with data engineers to facilitate technical design of complex data sourcing, transformation and aggregation logic, ensuring business analytics requirements are met
• Assist in generating hypothesis that drives strategic questions about the leasing business

• Work with management to prioritize business and information needs
What you'll need:
• Bachelor’s Degree in Mathematics, Economics, Computer Science, Information Management, Statistics, Finance or Accounting, Masters preferred
• At least 1 year of relevant experience
• Intermediate skills in Data Architecting, Visualization, SQL, Microsoft Excel, PowerPoint
• Technical fluency regarding data models, database design/Development, data mining and other segmentation techniques
• Experience using cloud based data orchestration tools
• Possess proficiencies with SQL and data transformation tools to understand and prepare data
• Familiarity with ‘Modern Data Warehouse’ architecture using cloud based storage solutions and data orchestration (e.g. Blob storage, Azure Databricks, Azure Data Factory, etc.)
• Familiarity with data visualization tools such as Qliksense and techniques in translating business analytics needs into data visualization and semantic data access requirements
• Must possess effective interpersonal skills, both verbal and written
• Strong organizational, time management and multi-tasking skills
• Experience with data conversion, interface and report development
• Adept at queries, report writing and communicating findings
• Process improvement and automation a plus","Trinity Industries
3.0","Dallas, TX",Transportation Equipment Manufacturing,Manufacturing
Data Analyst,"SUMMARY:
The Data Analyst is a perceptive, mission-driven technician responsible for cultivating business intelligence for the organization, transforming data into valuable information for making strategic decisions. This individual identifies insights, gaps, and trends in the data. They design and troubleshoot performance metrics, collaborate with departmental staff to understand data, promote quality assurance, and assist in reporting design. This role is part of the Strategic Services division that performs the function of accelerating the organization through rigorous analysis, creative problem solving, and innovative idea development in order to assist Human Coalition achieve its mission. Human Coalition is an innovative, energetic, compassion-driven non-profit organization intent on making abortion unthinkable and unavailable.
ESSENTIAL FUNCTIONS:
Works with data to derive meaningful insights to address business problems or discover hidden trends/patterns that can be leveraged to meet the business objectives;
Use data to identify problems and solutions;
Collaborate with Business Analysts to design meaningful metrics and reports;
Navigate Salesforce, build reports and generate heat-maps;
Conduct, coordinate, and present financial, market, operational and related analyses/research to management for use in decision making and strategic planning;
Document and present findings, including analyses/trends/learnings, best practices, how-to guides, etc.;
Conduct insightful, ad hoc analyses to investigate ongoing or one-time operational issues; troubleshoot and educate stakeholders on findings and recommendations;
Evaluate current practices and usage against each systems' capabilities and design modification proposals;
Communicate and collaborate with both internal and external team stakeholders to meet appropriate deadlines
Reasonable accommodations may be made to enable individuals with disabilities to perform the essential functions of this position.

MINIMUM QUALIFICATIONS:
Ability to work in a fast-paced, changing environment
Desire to serve others
Ability to think on your feet and be creative
Excellent verbal and written communication skills
Exceptional critical thinking and analysis skills
Excellent organizational skills and attention to details
Inquisitive and self-motivated learner
Easily understands how things work
Ability to work independently and with others
Advanced knowledge of Microsoft Excel
Knowledge of logic and database languages such as SQL strongly preferred
Excellent with details and numbers
Excellent multi-tasking and time management skills
Passionately align with the mission and vision of Human Coalition
EDUCATION AND EXPERIENCE:
High school diploma or GED; College degree (preferred) in science, math, economics, statistics, programming, computer modeling, predictive analytics, or related disciplines (or equivalent working experience)
2-4 years of experience in the field
Previous Salesforce experience preferred
EEO STATEMENT:


Human Coalition is an equal opportunity employer and makes recruitment, employment, promotional, and all other Human Resource decisions without regard to race, color, national origin, age, sex, or marital, disability, or veteran status. Because our primary mission is religious, Human Coalition does lawfully require assent and adherence to our core doctrinal beliefs.

OTHER DUTIES:
Please note this job description is not designed to cover or contain a comprehensive listing of activities, duties or responsibilities that are required of the employee for this job. Duties, responsibilities and activities may change at any time with or without notice.","Human Coalition
2.9","Plano, TX",-1,-1
Data Analyst,"Job details

Title Data Analyst 1017
Company Yeti Technologies
Salary 0
Company type Information Technology
Published on 2017-10-24
Apply before 2017-10-24
Job Details
PRIMARY FUNCTION:

The Data Analyst is an entry level position and is responsible for processing the data obtained from experiments performed according to protocol, facility SOP and the appropriate regulations. The analyst will gain familiarity with advanced analytics tools and techniques and will be accountable for evaluating and communicating impacts of business decisions

ESSENTIAL FUNCTIONS OF THE JOB:
Analyze data and use analytical tools and techniques
Monitor and evaluate patterns and trends
Generate standard reports for consistency in data analysis
Develop insight into member and provider performance and the variables affecting performance
Write and modify basic SQL programs for data extraction.
Provide user specific ad hoc reporting as requested.
Proactively seeks training and builds knowledge/experience of analytic tools, languages, and data sources
Produce spreadsheets, documents and presentations that are well-documented and easy to follow (i.e. Excel & PowerPoint)
PERFORMANCE REQUIREMENTS:
Experience in writing SQL
Proficient with Microsoft Excel
Performs other duties as assigned
Ability to work independently and in a strong team environment
Ability to project a positive attitude and high degree of self-confidence
Ability to effectively manage time
Strong analytical, research, and problem solving skills
Strong verbal and written communication skills
Programming knowledge (Python, C# or R) a plus
EDUCATION: Bachelor’s degree or higher. Relevant major’s preferred (Finance, Economics, Computer Science, Mathematics or Information Technology.)",Yeti Technologies,"Irving, TX",IT Services,Information Technology
Data Scientist,"Date Posted
2018-10-22

Location
Various Locations

Job Title
Data Scientist

Job ID
IMGDS18
Apply this Job

Job Description

IMG Systems, Inc. seeks Master’s+1yr/Bachelor’s+5yrs exp/equiv. Data Scientist (IMGDS18): Data Visualization, Natural Language Processing (NLP), Machine Learning (ML), Python, Numpy. Mail resume with job ID to: HR, 400 Chisholm Place, Suite 414, Plano, TX 75075. Travel to unanticipated work sites throughout the U.S. Foreign equiv. accepted.","IMG Systems
2.7","Plano, TX",Consulting,Business Services
Data Analyst,"Financial Additions has partnered with a lead international Insurance company in Dallas, TX in search of a Data Analyst.

Data Analyst Responsibilities:
Use statistical methods to analyze data and generate useful business reports
Work with management team to create a prioritized list of needs for each business segment
Identify and recommend new ways to save money by streamlining business processes
Use data to create models that depict trends in the customer base and the consumer population as a whole
Work with departmental managers to outline the specific data needs for each business method analysis project
Data Analyst Qualifications:
Proven working experience in Data mining and Data Analyst role
Technical expertise regarding data models, database design development, data mining and segmentation techniques
Strong knowledge of and experience with reporting packages (Business Objects etc), databases (SQL etc), programming (XML, Javascript, or ETL frameworks)
Knowledge of statistics and experience using statistical packages for analyzing datasets (Excel, SPSS, SAS etc)
BS in Mathematics, Economics, Computer Science, Information Management or Statistics
#INDD","Financial Additions
4.6","Dallas, TX",Investment Banking & Asset Management,Finance
Data Analyst,"Job Description: Data Analyst Position in Dallas, TX. Hands on experience in designing, coding, and implementing database solutions. Good experience with table design, stored procedures using SQL programming. Design, develop and execute ETL packages using stored procedures, functions and SQL scripts. Perform basic troubleshooting and analysis to identify data patterns. Experience in Oracle and SQL databases and developing applications is preferred. Experience with Java/J2EE technologies. Clear and effective communicator.","TekniSMart Solutions
3.8","Dallas, TX",-1,-1
Data Analyst,"RESPONSIBILITIES:

Kforce has a client in search of a Data Analyst in Dallas, TX.

Overview:
The Data Analyst will support the organizations commitment to operational excellence and efficiency through the use of reporting, analytics and process improvement. The Data Analyst II will develop queries, key performance indicators, and call center metrics that will provide the business leaders insight. The Data Analyst II will be responsible for ensuring the business understands the effects of new product, process, or campaign launches in the environment. The incumbent will evaluate the data being produced to determine if formal business process improvement (BPI) projects need to be undertaken. The incumbent will also partner with the BPI team throughout the life of the project to ensure metrics and reporting is instilled in the process to drive long term benefits to the organization. The effectiveness of the position will be tied to partnering with business units to understand business direction and strategies; supports implementation of appropriate information systems to fulfill objectives.

Key Tasks:
Develops and maintains queries, reports, and metrics using available mediums to provide customized information for users to make decisions
Accepts a high level of responsibility for integrity of reports and data provided
Leads the creation of custom or standardized reporting decks for presentation of data to stakeholders
Presents reporting decks and integrated insights with confidence to the business and its stakeholders
Initiates and performs analysis of product/process/training/campaign launches in the environment
Relates findings and recommendations to the business owner(s)
Supports the partnership between various
REQUIREMENTS:
Strong SQL experience writing queries
To be considered for this position, candidates must have experience in a similar role, or they must possess significant knowledge, experience, and abilities to successfully perform the responsibilities listed
Relevant education and/or training will be considered a plus
Kforce is an Equal Opportunity/Affirmative Action Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, pregnancy, sexual orientation, gender identity, national origin, age, protected veteran status, or disability status.","Kforce
4.1","Dallas, TX",Staffing & Outsourcing,Business Services
Data Scientist,"Position Role/Tile: Data Scientist
Location: Plano, TX.

6+ months

Description:
Educational background in Math, Statistics or Economics.
Must have a strong background in AB testing.
Strong theoretical and applied background in mathematical optimization with a proven track record in computation and algorithm development in linear and nonlinear programming, combinatorial optimization, integer programming, dynamic programming, network flows and algorithms to design optimal or near optimal solution methodologies using statistical and optimization tools such as R to find both exact and heuristic solution strategies for optimization problems
Probability and statistics: Candidate should know basic probability, expectation and conditional expectation, common statistics, exploratory data analysis, linear regression, hypothesis testing. Additional knowledge of probability is a plus.
Scientific Computing: R, Python
Deep Learning frameworks: Keras, Tensorflow
Data Management Systems
Experience in the financial industry with capital markets or wealth management portfolios is a plus.
Central Business Solutions, Inc,
37600 Central Ct.
Suite #214
Newark, CA 94560","Central Business Solutions, Inc
3.0","Plano, TX",Consulting,Business Services
Data Scientist,"One of the world’s leading financial consultative service providers are looking for Data Sceintists to join their team. The Company provides financial advisory and consultations to more than 4,500 clients in more than 35 countries, worldwide.

Job Description

Maintaining business excellence for us means the acquisition of new talent that are experts in new technologies and sciences.

We are looking for an experienced Data Scientist to join our team of technologists and data scientists to help us deliver data-driven solutions to our clients.

We are looking for someone with experience in using machine learning and natural language processing technologies to isolate, identify and utilize relevant data and help in designing and implementing new technologies and solutions to both simple and complex financial problems.

Roles & Responsibilities
Liaise with clients and our senior management team to understand client needs
Identify and process various sources of client/third-party financial data
Analyse sets of data to identify structures, patterns and trends
Use patterns in data to propose solutions and strategies for client problems
Create and present findings to senior management team and other stakeholders, as and when required
Collaborate with our technical team to design and implement automated data collection tools/processes, using predictive analytics and machine learning algorithms
Collaborate with our product development team to make recommendations for service improvements
Essential Requirements
5+ years of relevant experience (e.g. Data Scientist, Data Analyst, Statistician, Economist, etc.)
Working knowledge of machine learning algorithms and technologies
A great knowledge and/or experience of business intelligence tools (e.g. VBA, SQL, Tableau, etc.)
MSc or higher in Data Science, Statistics, Economics or a related field
Experience delivering agile solutions to various small and large clients
Strong problem-solving skills
Excellent attention to detail
Impeccable listening skills
Excellent verbal and written communication skills
Able to create and maintain strong working relationships with both internal and external colleagues and clients
Great planning and organisational skills
A desire for continuous learning and professional improvement
Desirable Skills
Experience working within the financial services (or similar) sector
Knowledge of cloud computing technologies (MS Azure, Amazon AWS, etc.)
A working knowledge of Python programming
Experience providing advisory or consultation services to client
Apply directly at: https://prolancer.com/jobs/send-proposal/298

Benefits:
Work from home opportunities
Job Types: Full-time, Contract

Salary: $50,000.00 - $75,000.00 per year

Work Remotely:
Yes","Pro Lancer
5.0","Dallas, TX",-1,-1
Data Analyst,"Must Have Skills (Top 3 technical skills only) ETL and MDM ( Master Data Management) Experience in Data Integration testing through Master Data management (MDM) Experience in test data management and data governance using MDM and automation Nice to have skills Strong in SQL Querying Detailed Job Description Experience in Data Integration testing through Master Data management MDM. Experience in test data management and data governance using MDM and automation. Healthcare experience. Strong in SQL Querying. Experience in Data Integration testing through Master Data management MDM. Experience in test data management and data governance using MDM and automation. Minimum years of experience 5+ Top 3 responsibilities you would expect the Subcon to shoulder and execute Estimation Status Report Test Plan, Test Cases, Test Data ownership on all the projects.","InfoVision, Inc.
4.4","Irving, TX",IT Services,Information Technology
Data Scientist,"Brinks Home Security™ is a proven leader in the smart home technology and residential security industries, providing cutting-edge products and alarm monitoring services to more than one million customers throughout North America. We are currently seeking a motivated and dynamic Data Scientist.

Our brand promise delivers on 4 core principles:
Integrity in Action: Be True, Be Responsive, Be Accountable
Sense of Urgency: Every Moment Matters
Relentless Discipline: Rigor, Precision and Excellence in Every Single Action
Results Matter: Account to Customers, Employees & Stakeholders
Join our team of trusted security advisors and providers and help us create more secure smart home customers.

Summary:

Brinks Home Security’s Business Intelligence team is rapidly growing and is seeking a Data Scientist to advise on and implement machine learning models to improve customer acquisition and customer retention efforts across the organization.

Essential Duties and Responsibilities:
Develop, implement and evaluate machine learning and optimization models across multiple platforms to create actionable insights from complex data sets.
Work closely with data engineers to deploy models and systematically track model and data performance.
Understand and clearly communicate model performance to leadership team by translating the complex into the concise and clear
Collaborate with Operations, Marketing, Sales, and IT to utilize model findings to build and test programs that improve customer acquisition and retention efforts
Requirements:
Advanced degree in a quantitative discipline such as Computer Science, Engineering, Applied Mathematics, Statistics, Econometrics or Undergraduate degree with significant, demonstrative experience in data science
3+ years of demonstrated/hands-on experience required for the following:
Machine Learning and statistical analysis (text mining, sentiment analysis, gradient boosting, random forest, regression, etc.)
Designing and running experiments and extracting insights
Visualization/Dashboarding tools (Experience with Tableau preferred)
Proficiency in Python and relevant libraries
Thorough understanding of SQL
2+ years’ experience working with cloud infrastructure (Azure, AWS, Google Cloud etc.)
Excellent communication skills and the ability to collaborate with business stakeholders on use cases and requirements","Brinks Home Security
3.4","Farmers Branch, TX",Security Services,Business Services
Data Scientist,"Job Description
We are looking for a data scientist who will assist in Chatbot content curation.

Work hours can be flexible. Work location will be a mix of home and the office.

Responsibility
Strong experience using a variety of data mining/data analysis methods, using a variety of data tools, building and implementing models, using/creating algorithms and creating/running simulations
Research and devise innovative statistical models for data analysis
Mine and analyze data from databases to drive optimization and improvement of product development
Devise and utilize algorithms and models to mine big data stores, perform data and error analysis to improve models, and clean and validate data for uniformity and accuracy
Implement analytical models into production by collaborating with IV.AI, Big Data, and SR teams
Assess the effectiveness and accuracy of new data sources and data gathering techniques.
Create ad-hoc data sources on demand to find insights as needed.
Processing, cleansing, and verifying the integrity of data used for analysis
Minimum Qualifications
4 year degree in mathematics, data analytics, information systems, computer science or related field
5 years of experience in structuring, validating, analyzing and modeling data sets
2 years of experience with one of the following programming languages: R or Python
Proficiency with data mining, mathematics, and statistical analysis
Advanced pattern recognition and predictive modeling experience
Excellent communication/interpersonal skills",SJ Communication Design,"Plano, TX",-1,-1
Data Analyst,"Company Summary
Join our team! First American's Mortgage Solutions division provides lenders with solutions to originate, close and service quality loans. As a global leader in providing title insurance, settlement services and risk solutions for real estate transactions, First American (NYSE: FAF) is an ideal place to build your career. We have been entrusted with helping our customers achieve and protect their dream of homeownership since 1889. We believe that our people are the key to the company’s continued success, and we invest in diverse talents and backgrounds and empower our teams to achieve more than they could anywhere else. First American has created an award-winning culture and has been named to the Fortune 100 Best Companies to Work For® list for the fifth consecutive year and to more than 50 regional Best Places to Work lists. For more information, please visit www.firstam.com/mortgagesolutions/
Job Summary


Responsible for collecting and analyzing data - running various mathematical calculations to determine how the data samples might best be applied to profit the business.

Essentials Functions
Data Quality: Conduct data quality reviews using various tools and methodologies.

• Data Trending: Participate in projects involving new data aggregations and custom solutions.

• Fulfillment Support: Work with offshore support team that will be responsible for reoccurring fulfillments and/or QC processes
Knowledge and Skills/Technology Used
Ability to create queries in SQL and build new reports to support the business.
Experience with Power BI preferred
Experience performing data quality reviews and data gap analysis on county recorder content
Ability to enhance, edit and correct data content issues based on knowledge and experience
Excellent verbal and written communication skills, and abilty to interface effectively with product, development, data inquiry and data fulfillment teams
Ability to formulate conclusions and define next steps upon completion of a data quality review process
Typical Education
High School Diploma, Bachelor's degree preferred, or a combination of education and experience will be considered.
Typical Range of Experience
Minimum 5+ years experience working with public record data
First American invests in its employees' development and well-being, empowers them to provide superior customer service and encourages them to serve the communities where they live and work. First American is committed to diversity and inclusion. We are an equal opportunity employer. For more information about our Company and our dedication to putting People First, check out firstam.com/careers.","First American Financial Corporation
3.4","Irving, TX",Insurance Carriers,Insurance
Data Engineer,"Locations: TX - Plano, United States of America, Plano, Texas

At Capital One, were building a leading information-based technology company. Still founder-led by Chairman and Chief Executive Officer Richard Fairbank, Capital One is on a mission to help our customers succeed by bringing ingenuity, simplicity, and humanity to banking. We measure our efforts by the success our customers enjoy and the advocacy they exhibit. We are succeeding because they are succeeding.

Guided by our shared values, we thrive in an environment where collaboration and openness are valued. We believe that innovation is powered by perspective and that teamwork and respect for each other lead to superior results. We elevate each other and obsess about doing the right thing. Our associates serve with humility and a deep respect for their responsibility in helping our customers achieve their goals and realize their dreams. Together, we are on a quest to change banking for good.

Data Engineer
Are you a lead technologist that thrives in a vibrant, innovative and collaborative team? Do you want to work for a tech company that writes its own code, develops its own software, and builds its own products? We experiment and innovate leveraging the latest technologies, engineer breakthrough customer experiences, and bring simplicity and humanity to banking. We make a difference for 65 million customers.

At Capital One, you'll be part of a big group of makers, breakers, doers and disruptors, who love to solve real problems and meet real customer needs. We want you to be curious and ask what if? Capital One started as an information strategy company that specialized in credit cards, and we have become one of the most impactful and disruptive players in the industry. We have grown to see ourselves as a technology company in consumer finance, with great opportunities for engineers and architects who want to build innovative applications to give users smarter ways to save, transact, borrow and invest their money, as we seek to disrupt the industry again:

You will build data pipeline frameworks to automate high-volume and real-time data delivery for our Data Lake and streaming data hub
You will build data APIs and data delivery services that support critical operational and analytical applications for our internal business operations, customers and partners
You will transform complex analytical models into scalable, production-ready solutions
You will continuously integrate and ship code into our on premise and cloud Production environments
You will develop applications from ground up using a modern technology stack such as Scala, Spark, Postgres, Angular JS, and NoSQL
You will work directly with Product Managers and customers to deliver data products in a collaborative and agile environment


Responsibilities:

Develop sustainable data driven solutions with current new gen data technologies to meet the needs of our organization and business Customers
Ability to grasp new technologies rapidly as needed to progress varied initiatives
Break down data issues and resolve them
Build robust systems with an eye on the long term maintenance and support of the application
Leverage reusable code modules to solve problems across the team and organization
Utilize a working knowledge of multiple development languages


What we have:

A startup mindset with the backing of a top 10 bank
Monthly Innovation
Days dedicated to test driving cutting edge technologies
Flexible work schedules
Convenient office locations
Generous salary and merit-based pay incentives
Your choice of equipment (MacBook/PC, iPhone/Android Device)


Basic Qualifications:
Bachelors Degree
At least 2 years of experience developing software or data solutions
At least 2 years experience developing Java based software solutions or one scripting language (Python, Perl, JavaScript, Shell)
At least 2 years of experience in Spark


Preferred Qualifications:
Master's Degree
2+ years experience with Agile engineering practices
3+ years in coding in data management, data warehousing or unstructured data environments
3+ years experience working with big data technologies (Cassandra, Accumulo, HBase, Hadoop, HDFS, AVRO, MongoDB, or Zookeeper)
3+ years in coding in data management, data warehousing or unstructured data environments
3+ years experience with the Hadoop stack (MapReduce, Pig, Hive, Hbase)
3+ years experience with Relational Database Systems and SQL
3+ years experience designing, developing, and implementing ETL

At this time, Capital One will not sponsor a new applicant for employment authorization for this position.","Capital One
3.9","Plano, TX",Banks & Credit Unions,Finance
Data Engineer,"Job Description

Position: Data Engineer
Location: Dallas , TX
Total 4 candidates

VISA: USC and GC ONLY

Job Description: Detailed overview of functional and technical role expectations:
7+ years of experience in a Data Engineer role, who has attained a Graduate degree in Computer Science, Statistics, Informatics, Information Systems or another quantitative field.
Should also have working experience using the following software/tools:
Strong Programming experience with object-oriented/object function scripting languages: Python, PySpark, Scala, etc.
Experience with big data tools: Hadoop, Apache Spark, Kafka, etc.
Experience with AWS cloud services: S3, EC2, EMR, RDS, Redshift
Experience with stream-processing systems: Storm, Spark-Streaming, etc.
Experience with relational SQL, Snowflake and NoSQL databases, including Postgres and Cassandra.

Qualifications

null

Additional Information

All your information will be kept confidential according to EEO guidelines.",Iconic Technology Group,"Dallas, TX",-1,-1
Data Engineer,"Founded in 2014, Vinli is an automotive technology company based in the heart of Downtown Dallas. In just four years, our team has built the most advanced vehicle data computing platform and secured global partnerships with significant players in the telecom, automotive, and asset management industries. Vinli’s fully customizable platform has enabled sophisticated brands to easily engineer connected car services, allowing them to capitalize on both their vehicle data and other related data sources. Our passion is building products that unlock the true value of connected cars by showing drivers, passengers and organizations the potential hidden within their vehicles' data.

About the Role

The Vinli Data and Analytics team is looking to add a Data Engineer to design and manage all things big data. The team covers data governance, data strategy and partnerships, reporting, machine learning and much more. You will be the cornerstone for data solutions across each of these areas. The candidate must be able to communicate, work with and deliver across each discipline as well as the end business user and executive leadership.
Responsibilities:
Lead data architect for the Vinli analytics team.
Integrate multiple data sources and software tools within the Vinli analytics ecosystem.
Collaborate with tech leaders across Vinli to ensure data strategy continuously meets all needs both internal and for Vinli customer.
Create and deliver executive presentations explaining the complex data in simple easy-to-understand terms that resonates with an executive audience.
Must haves:
BS in a STEM field.
Advanced design, coding and analytics skills in a big data ecosystem.
Expert knowledge of SQL.
Experience with other languages such as Python, R, PySpark, Java or Scala.
Strong background of data structures and big data tools (Spark, Hive, HDFS, ect.).
Data wrangling and ETL tooling experience.
Exceptional communication skills between both business and technical teams.

Preferred:
MS or higher in a STEM field.
Experience managing teams or projects.
Demonstrated experience with AWS, GCP or Azure.
Experience handling confidential and sensitive data.
Demonstrated ability to independently influence and drive outputs, meet deadlines, and set clear expectations and roadmaps.

About You:
Able to work in a fast-moving environment with high stakes for the company’s success
You take pride and responsibility seeing the product you worked on meet the real world for the first time
You love to learn and embrace the opportunity to contribute in new areas.

Vinli Core Values

Integrity. Doing what you say you will do at Vinli is our way of building trust among our team members, partners, investors and vendors. We believe that maintaining integrity requires an openness and empathy in sharing goals and challenges with others.
Drive to Innovate. People at Vinli don’t just love to learn, they feel compelled to use their knowledge to make our Company and the world a better place. We believe in learning from our mistakes and always challenging ourselves to innovate - from the biggest product decisions to the smallest processes.
Joyful Work Environment. Loving where you work isn’t about ping pong tables and free snacks. It’s the feeling that you wouldn’t want to be on a project with any other team. It’s the feeling that you can get creative energy just by showing up to work. It’s the feeling that your entire team respects your life away from the job and understands how work impacts it. At Vinli, we believe in building camaraderie and joy in our environment by supporting and encouraging each other every day.

We are an equal opportunity employer. We strictly prohibit unlawful discrimination or harassment of any kind, including discrimination or harassment on the basis of race, color, national origin, ancestry, religion, veteran status, age, pregnancy status, sex, gender identity or expression, sexual orientation, marital status, mental or physical disability, medical condition, or any other characteristics protected by law. We also make all reasonable accommodations to meet our obligations under laws protecting the rights of the disabled.","Vinli
4.6","Dallas, TX",Computer Hardware & Software,Information Technology
Data Engineer,"Hi,

We have an urgent requirement for Data Engineer roles in multiple locations -ÂTexas (Lewisville, Plano, Dallas) & Chicago, IL & Jersey City, NJ & Columbus, OH. Please forward suitable resumes to rakesh@athreyainc.com or call me at 732-582-4977

Role: Data Engineer

Locations:ÂTexas (Lewisville, Plano, Dallas) & Chicago, IL & Jersey City, NJ & Columbus, OH

Duration: Long Term

Mandatory Skills:

Java - 8+ Years, Spark 4+ Years, Big Data 4+ Years

Desired Skills:

Kafka - 3+ Years andÂSQL - 6+ Years.

Regards
Rakesh Sharma
Direct : (732) 582-4977
Email:Ârakesh@athreyainc.com

ATHREYA INC.

100 Jersey Avenue, Suite# B-201,
New Brunswick NJ - 08901.

""Certified Minority Business Enterprise (MBE)""
""Certified Small Business Enterprise (SBE)""
""E-Verify Enrolled Employer""
URL:Âwww.athreyainc.com

STATEMENT OF CONFIDENTIALITY

The information contained in this electronic message and any attachments hereto are intended for the sole and exclusive use of the addressee(s), and contain confidential and/or privileged information. If you are not the intended recipient of this transmission you are hereby notified that any disclosure, copying, distribution or the taking of any action in reliance on the contents of this transmission is strictly prohibited. If you have received this in error, please notify the sender of this message immediately, and destroy all copies of this message and any attachments.

""There is no power on earth that can neutralize the influence of a high, simple, and useful life.""
~ Booker T. Washington

Â","Athreya Inc
4.5","Dallas, TX",IT Services,Information Technology
Data Analyst,"Job Description
ETL, SQL Queries, Data Modeling etc SAP experience is plus",1,"Dallas, TX",-1,-1
Data Analyst,"Job SummaryHilltop Holdings Inc. (NYSE:HTH) is a Texas-based diversified financial holding company specializing in banking, mortgage origination and financial advisory through its wholly owned subsidiaries, PlainsCapital Bank, PrimeLending and HilltopSecurities.We are looking to hire a Data Analyst to join our team. You will take responsibility for managing our master data set, developing reports, and troubleshooting data issues. Develop and implement data standards, ensuring metadata is captured correctly, and creating methods for monitoring and reporting any data incidents. To do well in this role you need a very fine eye for detail and have a deep understanding of the popular data analysis tools and databases.Essential Functions* Managing master data, including creation, updates, and deletion.* Managing users and user roles.* Provide data quality standards of imported data.* Commissioning and decommissioning of data sets.* Processing confidential data and information according to guidelines.* Helping develop reports and analysis.* Managing and designing the reporting environment, including data sources, security, and metadata.* Supporting the data warehouse in identifying and revising reporting requirements.* Supporting initiatives for data integrity and normalization.* Assessing tests and implementing new or upgraded software and assisting with strategic decisions on new systems.* Generating reports from single or multiple systems.* Troubleshooting the reporting database environment and reports.* Evaluating changes and updates to source production systems.* Training end users on new reports and dashboards.* Providing technical expertise on data storage structures, data mining, and data cleansing.* Facilitate effective elicitation, documentation, prioritization and validation of data solution requirements as necessary.Job Requirements* A bachelor's degree from an accredited university or college in computer science or related experience.* 5+ years' experience as a data governance analyst or in related field.* Experience with data and ETL modeling a plus.* Demonstrated experience utilizing Informatica, Azure Data Lakes and Power BI.* Ability to work with stakeholders to assess potential risks.* Ability to analyze existing tools and databases and provide software solution recommendations.* Ability to translate business requirements into non-technical, lay terms.* High-level experience in methodologies and processes for managing large scale databases.* Demonstrated experience in handling large data sets and relational databases.* Understanding of addressing and metadata standards.* High-level written and verbal communication skills.About the CompanyFounded in 1998 and headquartered in Dallas, Texas, Hilltop Holdings offers a diverse range of financial services through its primary subsidiaries, PlainsCapital Bank, PrimeLending and HilltopSecurities. PlainsCapital Bank is a leading commercial bank with locations throughout Texas. PrimeLending is a national mortgage provider focused on purchase mortgage originations. HilltopSecurities provides financial advisory, clearing, retail brokerage, and other investment banking services. Hilltop Holdings seeks to build the premier Texas-based diversified financial services holding company through acquisitions and organic growth. To learn more, please visit www.hilltop-holdings.com.","Hilltop Holdings
2.9","Irving, TX",Banks & Credit Unions,Finance
Data Analyst,"Hello Associates,

***Greetings from Conch Technologies***

Â

Position: Data Analyst

Location: Plano, TX

Â

Job Description:
Typical DA

3+ years of exp

AWS understanding

Tableau

SQL

Data analysis and data management

Â

Â

Â

Thanks & Regards.

Mallikharjun.
Recruitment Lead.
Mallikharjun@conchtech.com
Direct:( 901)-444-3153Â
6750 Poplar Ave # 711, Memphis, TN.Â
Web:Âwww.conchtech.com
""A Certified MBE Company""

Disclaimer: We respect your online privacy, if you are not interested in receiving our e-mails, then please reply with ""unsubscribe"" in the subject line.","Conch Technologies, Inc
4.6","Plano, TX",Consulting,Business Services
Data Engineer,"Data Engineer

ETL automation tools such as Informatica, Mulesoft, SSIS, Alooma, or Apache Airflow

Experience with traditional RDBMS solutions such as Microsoft SQL Server and Oracle

Experience with cloud-based platforms and tools

Familiarity with DevOps tools and practices such as Git, Jenkins, JIRA, Azure DevOps

Experience with integrating to both database systems and APIs

Experience with documenting technical requirements, designs and systems

Extensive experience building scalable and resilient data pipelines

Extensive experience writing SQL

Experience with a procedural, functional or object-oriented programming language such as Python, Java, Scala, R

Additionally, candidates should be able to perform at a high level in at least two of the following technology categories:
Big Data tools such as Apache Hadoop, Spark, and Hive including managed solutions such as Databricks, Amazon EMR, Azure HD Insight, and Google Cloud Dataproc
Cloud data storage solutions such as Amazon S3, Azure Blob Storage, or Google Cloud Storage
Data warehousing solutions such as Redshift, BigQuery, and Snowflake
Message broker solutions such as Kafka, Google Pub/Sub, Amazon Kinesis
Stream processing solutions such as Flume, Storm, Spark Streaming
NoSQL Databases such as HBase, Cassandra, Redis
Requirements

3-5+ years of experience in technology and/or consulting

Bachelor’s Degree in CS, MIS, CIS, or a comparable technical degree

US Citizen or GC Holder

Benefits

Sense Corp powers insight-driven organizations.

We turn data into actionable insights and transform organizations for the digital era.

Our people, culture, and how we engage with our clients are differentiators. Brilliant, Creative, Human, and Fun exemplify who we are. We are regularly recognized as a Best Place to Work by Austin, Houston, Dallas, and St. Louis Business Journals. With operations in Austin, Atlanta, Columbus, Dallas, Houston, San Antonio, and St. Louis we serve mid-market to Fortune 50 companies.

The Sense Corp Compass

We may be the only management consulting firm in the country where being brilliant isn’t enough to land you a job. Sense Corp people must be brilliant, creative, human, and fun all at once. In other words, we hire terrific, well-rounded people. It’s one reason clients love working with us. And it’s why we enjoy working with each other. We may not sound like typical consultants but that’s OK. We don’t think like them either.

Visit us at www.sensecorp.com.","Sense Corp
3.8","Dallas, TX",Accounting,Accounting & Legal
Data Analyst,"Data Analyst **job details:** + location:Plano, TX + salary:$25 - $37.50 per year + date posted:Tuesday, June 30, 2020 + job type:Permanent + industry:Professional, Scientific, and Technical Services + reference:788105 **job description** Data Analyst job summary: Randstad Technologies is the worlds largest workforce solutions company and we have an immediate need with a client of ours in the Telehealth industry. They are in need of a Data Analyst! This is a very exciting opportunity and will be a great job to have on your resume!! You will also have the ability to grow within the company. This is a Direct Hire role with a company that prides itself on innovation, work-life balance and diversity in the workplace. This client is located in the Plano area and is a rapidly growing company! They are ready to move quickly for the right professional. If you fit the description below, please apply and reach out to us today! location: Plano, Texas job type: Permanent salary: $25.00 - 37.50 per year work hours: 8am to 5pm education: Bachelors responsibilities: + Jr. position w/ some software and coding experience + Data analysis experience + SQL experience + Good written and verbal communication skills including technical writing skills qualifications: + Experience level: Entry Level + Minimum 2 years of experience + Education: Bachelors skills: + Data Analysis (2 years of experience is required) + SQL (1 year of experience is required) Equal Opportunity Employer: Race, Color, Religion, Sex, Sexual Orientation, Gender Identity, National Origin, Age, Genetic Information, Disability, Protected Veteran Status, or any other legally protected group status.","Randstad
3.6","Plano, TX",Staffing & Outsourcing,Business Services
Data Analyst,"Job Description
Seeking a candidate for an urgent contract opportunity.

The Data Analyst will support the organization's commitment to operational excellence and efficiency through the use of reporting, analytics and process improvement. The Data Analyst II will develop queries, key performance indicators, and call center metrics that will provide the business leaders insight. The Data Analyst II will be responsible for ensuring the business understands the effects of new product, process, or campaign launches in the environment. The incumbent will evaluate the data being produced to determine if formal business process improvement (BPI) projects need to be undertaken. The incumbent will also partner with the BPI team throughout the life of the project to ensure metrics and reporting is instilled in the process to drive long term benefits to the organization. The effectiveness of the position will be tied to partnering with business units to understand business direction and strategies; supports the implementation of appropriate information systems to fulfill objectives.

Key Tasks:

Develops and maintains queries, reports, and metrics using available mediums to provide customized information for users to make decisions

Accepts a high level of responsibility for the integrity of reports and data provided

Leads the creation of custom or standardized reporting decks for the presentation of data to stakeholders

Presents reporting decks and integrated insights with confidence to the business and its stakeholders

Initiates and performs analysis of product/process/training/campaign launches in the environment

Relates findings and recommendations to the business owner(s)

Supports the partnership between various

Requirements

Strong SQL experience writing queries

To be considered for this position, candidates must have experience in a similar role, or they must possess significant knowledge, experience, and abilities to successfully perform the responsibilities listed

Relevant education and/or training will be considered a plus

The Corporate Genius is an Equal Opportunity/Affirmative Action Recruitment Organization. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, pregnancy, sexual orientation, gender identity, national origin, age, protected veteran status, or disability status.",Corporate G. LLC,"Dallas, TX",-1,-1
Data Analyst,"Job Description
Job description
Interpret data, analyze results using statistical techniques and provide ongoing reports
Develop and implement databases, data collection systems, data analytics and other strategies that optimize statistical efficiency and quality
Acquire data from primary or secondary data sources and maintain databases/data systems
Identify, analyze, and interpret trends or patterns in complex data sets
Filter and “clean” data by reviewing computer reports, printouts, and performance indicators to locate and correct code problems
Work with management to prioritize business and information needs
Locate and define new process improvement opportunities
Requirements
Proven work experience as a data analyst or business data analyst
Technical expertise regarding data models, database design development, data mining and segmentation techniques
Strong knowledge of and experience with reporting packages (Business Objects etc), databases (SQL etc), programming (XML, Javascript, or ETL frameworks)
Knowledge of statistics and experience using statistical packages for analyzing datasets (Excel, SPSS, SAS etc)
Strong analytical skills with the ability to collect, organize, analyze, and disseminate significant amounts of information with attention to detail and accuracy
Adept at queries, report writing and presenting findings
Master's in Computer Science or Engineering Management or Project Management or Information Systems/Technology (Preferred)
Powered by JazzHR

HtD5S6CVCm","Staffigo Technical Services, LLC
5.0","Dallas, TX",IT Services,Information Technology
Data Engineer,"Description Could be equivalent to MgrSr. Mgr role. Job Description Minimum Requirements At least 3 years of experience developing Data Pipelines for Data Ingestion or Transformation using Java or Scala or Python At least 2 years experience in the following Big Data frameworks File Format (Parquet, AVRO, ORC etc..) At least 3 years of developing applications with Monitoring, Build Tools, Version Control, Unit Test, TDD, Change Management to support DevOps At least 3 years of experience with SQL and Shell Scripting experience At least 2 years of experience with software design and must have an understanding of cross systems usage and impact Nice to Have qualifications 2+ years of experience working with Dimensional Data Model and pipelines in relation with the same 2+ years' experience with Amazon Web Services (AWS), Microsoft Azure or another public cloud service 2+ years of experience working with Streaming using Spark or Flink or Kafka or NoSQL Intermediate level experienceknowledge in at least one scripting language (Python, Perl, JavaScript) Hands on design experience with data pipelines, joining data between structured and unstructured data Thanks Regards, Ubair Anwaar Ph (609)- 642 4135, Email ubairpalnar.com mailtoubairpalnar.com",Palnar,"Plano, TX",IT Services,Information Technology
Machine Learning Engineer,"Overview? Who we areImagine working in a place where continuous improvement and innovation is celebrated and rewarded; where fast-paced, high-impact teams come together to positively drive results for one of the largest & most iconic brands in the world.As the only rapidly growing retailer, you may know us as your friendly neighborhood store. You probably know our familiar name, have seen our pervasive logo, and have tried our highly sought-after products, such as Slurpee® and Big Bite®. ""Brain Freeze"" is a 7-Eleven registered trademark for our 53-year old Slurpee® and with over 67,000 stores globally (more than any other retailer or food service provider), we sell over 14 million a month.But there's a lot more to our story and much more left to be written. We are transforming our business, ensuring we are customer obsessed and digitally enabled to seamlessly link our brick and mortar stores with digital products and services.At 7-Eleven the entrepreneurial spirit is in our DNA and has been ever since our inception 90+ years ago. It's what drove us to invent the convenience industry in 1927 by envisioning how a simple ice dock could provide household staples such as milk and eggs to better serve the needs of our customers.Today we are redefining convenience and the customer experience in big ways...we are fundamentally changing our culture and we want talented, innovative, customer obsessed, and entrepreneurial people like you to come make history with us.? How we leadAt 7-Eleven we are guided by our Leadership Principles.Be Customer Obsessed Be Courageous with Your Point of View Challenge the Status Quo Act Like an Entrepreneur Have an ""It Can Be Done"" Attitude Do the Right Thing Be AccountableEach principle has a defined set of behaviors which help guide the 7-Eleven team to Serve Customers and Support Stores.? About This OpportunityDevelops Machine Learning and Data Science solution for 7-11 Retail problems. Automates Data pipelines and develops different libraries for Statistical Algorithms that helps interactions between 7-11 stores, customers and products.Responsibilities* Implementing different ML libraries and builds data pipelines to solve different problems related to supply chain management, dynamic pricing, customer preference etc.* Participating in designing new data applications* Expert knowledge of Big Data technologies including but not limited to Python and/or Databricks (Spark)* Strong Analytical and problem-solving skills with a preferred academic background in Mathematics/Statistics* Deep understanding of Machine Learning principles, available tools and libraries to fit the best solution for 7Eleven needs* Solid foundation and understanding of relational and NoSQL database principlesQualificationsYears of work exp: 0-5 yearsEducational Qualification: Master's Science OR Math","7-Eleven, Inc.
3.2","Irving, TX",Other Retail Stores,Retail
Machine Learning Engineer,"Basic Job Information

Joborder Id : 987656322
Title : Machine Learning Engineer
Location : Irving, tx
Position Type : Full Time
No of Opening : 1

Job Description

Job Title: Artificial Intelligence/Machine Learning Engineer

Location: Irving, TX

Duration: Full Time

Job Description:

Machine learning techniques

Hadoop

Java/Scala/Python

Statistical programming languages like Python, R

Required Experience:

Experience in designing scalable systems

Solid understanding of design & analysis of algorithms and data structures

Knowledge of operating system concepts – Multi threading / concurrency

Development skills in JavaScript / java or c# or Objective C

Debugging & troubleshooting the real-time issues.

Experience in Data Visualization using D3, Tableau, Shiny

Experience in Statistical programming languages like –Python, R, Torch

Knowledge and expertise with machine learning techniques

Proficient knowledge of Linux environment

Good communication and presentation skills

Vandana Tiwari |SYSMIND, LLC
Account Manager

Phone: 609-897-9670 x 2179
Cell: 203-694-0570

Email: vandanat@sysmind.com

Website: www.sysmind.com

Address:38 Washington Road, Princeton Junction, NJ 08550

Note: SYSMIND LLC is an Equal Employment Opportunity employer. All qualified applicants will receive consideration for employment without any discrimination. We promote and support a diverse workforce at all levels in the company. This is not an unsolicited mail and if it is not intended for you or you are not interested in receiving our e-mails please reply with a ""remove"" in the subject line and mention all the e-mail addresses to be removed. We are extremely sorry if our email has caused any inconvenience to you.

All job offers are contingent upon completion of a satisfactory background check and reference checks. Additionally passing the drug test may also be required. All contractors intending to work on SYSMIND's W2 are ""at will"" employees.

The information contained in this electronic message and any attachments to this message are intended for the exclusive use of the addressee(s) and may contain proprietary, confidential or privileged information. If you are not the intended recipient, you should not disseminate, distribute or copy this e-mail. Please notify the sender immediately and destroy all copies of this message and any attachments.","SysMind
4.1","Irving, TX",Enterprise Software & Network Solutions,Information Technology
Machine Learning Engineer,"Req ID: 90379

At NTT DATA Services, we know that with the right people on board, anything is possible. The quality, integrity, and commitment of our employees are key factors in our company’s growth, market presence and our ability to help our clients stay a step ahead of the competition. By hiring the best people and helping them grow both professionally and personally, we ensure a bright future for NTT DATA Services and for the people who work here.

NTT DATA Services currently seeks a Machine Learning Engineer to join our team in Irving, Texas (US-TX), United States (US).

In this role, you will have the opportunity to:
Work on predictive analytics and statistical tools, machine learning algorithms and big data tools
Identify, analyze and interpret trends or patterns in complex data sets using various regression, classification or clustering
Required skills and experience:

5+ years:
SQL, R or Python
3+ years:
Spark
Hadoop
Machine Learning experience
• Good familiarity with classic ML approaches
• Create visualizations to visually represent data for consumption by different audiences

Nice to have skills and experience:
Elastic Stack, Git
This position is only available to those interested in direct staff employment opportunities with NTT DATA, Inc. or its subsidiaries. Please note, 1099 or corp-2-corp contractors or the equivalent will NOT be considered. We offer a full comprehensive benefits package that starts from your first day of employment.

About NTT DATA Services

NTT DATA Services partners with clients to navigate and simplify the modern complexities of business and technology, delivering the insights, solutions and outcomes that matter most. We deliver tangible business results by combining deep industry expertise with applied innovations in digital, cloud and automation across a comprehensive portfolio of consulting, applications, infrastructure and business process services.

NTT DATA Services, headquartered in Plano, Texas, is a division of NTT DATA Corporation, a top 10 global business and IT services provider with 118,000+ professionals in more than 50 countries, and NTT Group, a partner to 88 percent of the Fortune 100. Visit nttdataservices.com to learn more.

NTT DATA, Inc. (the “Company”) is an equal opportunity employer and makes employment decisions on the basis of merit and business needs. The Company will consider all qualified applicants for employment without regard to race, color, religious creed, citizenship, national origin, ancestry, age, sex, sexual orientation, gender identity, genetic information, physical or mental disability, veteran or marital status, or any other class protected by law. To comply with applicable laws ensuring equal employment opportunities to qualified individuals with a disability, the Company will make reasonable accommodations for the known physical or mental limitations of an otherwise qualified individual with a disability who is an applicant or an employee unless undue hardship to the Company would result.","NTT DATA
3.4","Irving, TX",IT Services,Information Technology
Data Analyst,"Job Description
JOB RESPONSIBILITIES (in priority order): Extract data from various sources. Design and program SAS/SQL code to prepare data for analysis and modeling. Document existing and new SAS and SQL code processes. Prepare ad-hoc reports using MS Excel, Word and PowerPoint. Follow instruction, work independently, and manage both short and long-term projects through to completion.

QUALIFICATIONS REQUIRED:

• Master/Bachelor degree in Statistics, Economics, Industrial Engineering and/or Business.

• 1-3 years work experience in data analysis.

• Strong background in data creation, manipulation and analysis.

• Familiar with generalized linear model procedures.

• Experience in marketing research, direct marketing and/or marketing analytics.

• Significant demonstrated experience with data set creation and data manipulation (sorting, merging, variable creation).

• Proficiency in MS Office suite, Project and Access.

• SAS (2+ years required specifically strong SAS programming skills - wide range of experience with Data Steps, Procs Stats, Macros).

• Excellent written and verbal communication skills.

• Must be able to juggle multiple projects simultaneously with strong attention to detail.

Working conditions: Office environment, regular hours plus overtime as required/necessary.",StaffingSoft Inc.,"Irving, TX",-1,-1
Data Engineer,"Job Description: Detailed overview of functional and technical role expectations:
 7+ years of experience in a Data Engineer role, who has attained a Graduate degree in Computer Science, Statistics, Informatics, Information Systems or another quantitative field.
 Should also have working experience using the following software/tools:
 Strong Programming experience with object-oriented/object function scripting languages: Python, PySpark, Scala, etc.
 Experience with big data tools: Hadoop, Apache Spark, Kafka, etc.
 Experience with AWS cloud services: S3, EC2, EMR, RDS, Redshift
 Experience with stream-processing systems: Storm, Spark-Streaming, etc.
 Experience with relational SQL, Snowflake and NoSQL databases, including Postgres and Cassandra.

Job Type: Full-time

Pay: $45.00 per hour

Schedule:
Monday to Friday
Work authorization:
United States (Preferred)","DataSys Consulting and Software, Inc
3.7","Dallas, TX",Consulting,Business Services
Data Analyst,"Data Analyst
Our client, one of the largest banks in the US with wealth management, investment banking, and international business, is seeking a Data Analyst

Location: Plano, TX
Position Type: Contract

Job Description the Capital Management Data Analyst is responsible for:

-Research & Analysis – Supporting Traded Products Counterparty Capital Management team from a Treasury Data Management (TDM) perspective in analyzing, monitoring and improving critical Data Flow and Data Quality with the goal of ensuring the timeliness and accuracy of Capital calculations for the Bank. Understanding the overall flow and usage of information from upstream sources and consolidation points used for capital modeling, calculation and reporting processes.
-Subject Matter Expertise – Expert in the understanding of Data Flow, Data Quality and Data Usage of information from upstream sources and consolidation points into Capital for capital calculations and reporting. Be Subject Matter Expert in identifying, analyzing and solving complex data issues in an efficient, transparent and collaborative fashion within TDM.
-Data Controls - Ensuring process controls, data validation activities, Data Quality scripts and measurement processes remain timely and relevant
-Data Remediation - Meeting SLA timelines for Data Incident analysis, Defect or Enhancement classification, Action Plan creation and Target Date delivery for Monthly Data Governance Process compliance.

Required Skills and Experience:

-Minimum 5 years of experience within a financial institution with hands-on experience in Data Analysis
Understanding of Traded Products including Derivatives, Repo, Fixed Income, FX, Equities and their representation in data.
-Must be a self-motivated / self-starter and able to take ownership and self-accountability for ensuring that process controls, data validation activities, data quality scripts and measurement processes remain timely and relevant
-Hands-on experience querying and analyzing large sets of data.
-Strong analytical and problem-solving capabilities skills needed to perform complex data analysis.
-Ability to use SQL to perform complex data profiling activities and analysis of large amounts of data for logical understanding and problem.
-Ability to perform complex data lineage analysis spanning multiple source systems and data transformations from a Capital data perspective
-Strong ability to think logically and critically to develop actionable solutions that help resolve complex data issues for Capital.
-Must be able to build and maintain strong and collaborative working relationships with co-workers on the TDM team as well as Capital and Technology business partners
-Ability to thrive and be energized in a challenging and dynamic environment where priorities and challenges are changing
-Ability to provide clear oral and written communication to a variety of business and technical audiences.

Desired Skills and Experience:

-Hands-on experience querying and analyzing large sets of data.
-Ability to use advanced Excel functions such as pivot tables, VLOOKUP, macros, Visual Basic and more to supplement advanced SQL skills in data analysis exercises.
-Prior experience in performing detailed analysis of Traded Products Data defects to identify patterns or root-causes and recommend improvements to processes or data flows to prevent future defects.
-Working knowledge of SAS, Python, Tableau, and UNIX
-Experience with data projects in Bank system of records and authorized data sources for Traded Products (Derivatives, Repo, Fixed Income, FX, Equities)
-Knowledge and experience with General Ledger data and reconciliation.","Mitchell Martin
4.1","Plano, TX",Staffing & Outsourcing,Business Services
Data Analyst,"Category: Business Analyst
Location: Grapevine, Texas

Great opportunity for a Data Analyst to work with a leading global manufacturer located in Grapevine, TX! Employment: Full-Time/Direct-Hire Salary Expectation: $70K to $80K Location: Grapevine, TX Position Summary: The Data Analyst provides analytical and technical suppo...


Details Apply","Prudent Technologies & Consulting
4.2","Grapevine, TX",IT Services,Information Technology
Data Engineer,"Data Engineer As a Junior Big Data Engineer Data Analyst, you will be part of our team who build fast data solutions to address some of the many complex problems in the financial services industry. IQuest leverages full stack technology solutions including streaming big data, state of the art machine learning, micro-service architecture, distributed computation engines, and intuitive visualizations in the cloud. we work with several cutting-edge technologies and actively develop and contribute to the open source community. You will work alongside highly technical peers, with deep domain expertise. At IQuest, we hire, train, guide and empower professionals to adapt to and make the best use of opportunities that the changing business environment offers. Required Skills Data Engineering Skills, Big Data Technologies, Spark, Any Language- Python or Scala or Java, AWS Qualifications Experience working with unstructured datasets Experience in programing using Python or Java or Scala. Experience in Pyspark or Spark Experience with a streaming data platform including Apache Kafka and Spark Experience working with AWS platforms, services, and component technologies, including S3, RDS and EMR. Experience building data pipelines, CICD pipelines, and fit for purpose data stores. Note Must be legally authorized to work in USA. Location Will work remotely initially","IQuest Solutions Corp
3.4","Plano, TX",IT Services,Information Technology
Data Analyst,"Job Description
General Summary:

This position is responsible for understanding the current enterprise data model and providing support in helping maintain and improve it. This position will work with business and data analytics stakeholders to design, construct, test, optimize and deploy solutions, focusing specifically on back-end data integration. The company is looking for someone who is extremely sharp, detail-oriented, highly motivated, thrives in a fast-paced environment and able to work on multiple projects simultaneously.



RESPONSIBILITIES:
Analyze healthcare and financial data to design, model, develop and test integration scripts for the enterprise data warehouse (EDW) platform.
Implement, schedule, monitor and support all related processes and procedures.
Troubleshoot, repair and update the EDW as necessary.
Perform gap analysis on financial, operational and clinical data.
Develop ad-hoc reports, dashboards and simulations for the business as needed.


KNOWLEDGE, SKILLS, and ABILITIES:
Strong in MS Excel
Experience (0-1 year) in MS SQL (basic querying and joins)
Financial modeling experience a plus
Healthcare RCM/claims knowledge a plus
Highly analytical
Passion for solving complex problems


EDUCATION/EXPERIENCE:
Bachelor’s degree in Finance, Mathematics, Computer Science, Engineering, or similar field.
0-1 years of experience in decision support/business analysis
Excellent interpersonal and communication skills with ability to interact at all levels of the organization","National NeuroMonitoring
4.3","Addison, TX",Health Care Services & Hospitals,Health Care
Data Analyst,"Role Description/Expectations


Data Analyst

Must have requirements: Heavy claims/analysis experience, advanced oral and written skills, strong excel skills, SQL experience (nice to have but not mandatory).

Summary:

Conducts analysis around various claims payment processes to ensure accuracy of system configuration and provider payments. Investigates “problem” claims to determine root cause of problem and/or error to address both individual claim resolution and improvement to process to avoid issues from occurring in the future. Perform and execute various claims process testing requests to ensure desired results are met to support accurate claims payments. Testing categories include but are not limited to the following:• Benefit, Contract, and Fee Schedule Configuration• System Enhancements • Report Validation• Validation of electronic file loads Essential Functions:• Performs claims systems testing and/or system analysis to ensure accuracy of the system’s configuration and provider payments. Conducts research and root cause analysis on various claims issues to identify and resolve problem payment and configuration concerns. • Develops/creates test plans/scripts which to provide concise analysis and documented results of the testing outcomes based on configuration changes/updates to support new businesses, benefits, and contracts. • Applies knowledge of claims processing to provide feedback resulting in the improvement of claims processing by identifying configuration improvements and/or when manual interventions and workarounds are required for configuration/system limitations. • Complies with performance standards by completing assignments within the specified time.

Knowledge/Skills/Abilities:

• Excellent verbal and written communication skills •Maintain regular attendance based on agreed-upon schedule • Maintain confidentiality and comply with Health Insurance Portability and Accountability Act (HIPAA) • Ability to establish and maintain positive and effective work relationships with coworkers, clients, members, providers and customers Required Education: High School graduate (or GED) / AA preferred Required Experience: 5+ years of claims processing with advancement to auditing / claims analysis / claims research. Level of autonomy/decision making required – Mid-level decision making. Some project management skills. Good oral and written communication skills. Advanced Word and Excel skills.

ALLSTEM is proud to be an Equal Opportunity Employer. Pursuant to applicable state and municipal Fair Chance Laws and Ordinances, we will consider for employment qualified applicants with arrest and conviction records.


Responsibilities


Experience Level: 6-10 Years


Preferred Skills Profile

Claims

Claims Processing

Contracts

Data Analyst

Excel

Excellent Verbal And Written Communication Skills

Microsoft Excel

Payments

Process Testing

Root Cause Analysis

Sql

System Analysis

System Configuration

Taxonomy

Test Plans


Education

No Education Found


Preferred Certifications/Licensure


No Certifications/Licensure Found","AllSTEM Connections
5.0","Irving, TX",-1,-1
Data Analyst,"Performance Engineering Services – Data Analyst
Duration: 12 Months

Your principal responsibility is to participate within the Performance Assurance Monitoring assisting other team members with SQL queries automation necessary to extract, transform, or load data as part of integration and analysis development. You will be responsible to cooperate with Operations/ IT team to deploy software and hardware upgrades that make it possible for us to leverage big data use cases. You will be responsible for utilizing a variety of reporting tools and software (Tableau and Business Objects), develops queries to generate reports and/or gather data from multiple sources. Focuses on client needs in defining data requirements and retrieving accurate information reporting requirements from start to finish to minimize future revisions. Also, you will be responsible for the identification, analysis, and diagnostics of wireless telecommunications networks performance characteristics. You will be responsible for monitoring KPIs, spotting trends, and correlating metrics across a diverse network infrastructure. You will answer technical questions as well as day to day operational questions. You will work independently with limited guidance to accomplish goals and objectives.

Specific Responsibilities include:
• Comprehensive knowledge of database administration (design, installation & troubleshooting)
• Experience performing indexes and stored procedure tuning; handling security, backups and recovery.
• Extensive familiarity with SQL queries.
• Analyze and address database resource contention issues including inefficient queries.
• Analyze, design, build and support current and new data feeds from various data sources to the data warehouse.
• Writes and modifies SQL queries, Views and stored procedures for Automation producing reports that track KPIs performance metrics and systematizes automated reporting processes.
• Build dashboards (using Tableau, Python and other BI tools) that illustrate how key performance indicators (KPIs) and metrics are changing over time.
• Develop presentations to communicate findings to internal and external customers.
• Exercise judgment within generally defined practices and policies in selecting methods and techniques for obtaining solutions and results.
• Present ideas, technical and non-technical, in a logical, compelling manner in a written format and verbally in both small and large group settings
• Work with the Network Engineering and Operations Teams on the cell site’s antenna and RF equipment configuration and database parameters

Background & Competencies Required:
• Bachelor’s Degree in Computer Science or Electrical Engineering; Master’s Degree a plus; 5-10 years’ work experience in the wireless industry
• 3+ years of experience developing SQL/Oracle server objects e.g., store procedures, tables, triggers, views and functions.
• 3+ years of experience developing Oracle server objects e.g., store procedures, tables, triggers, views and functions.
• 3+ years of experience with at least one of the common industry data visualization tools (Tableau, Spotfire, Business Objects, Power BI, etc.) for data correlation, analysis, reporting, etc.
• 3+ years of experience of wireless network KPI monitoring, trouble shooting and optimization, prefer with wireless infrastructure providers and /or operators.
• Strong knowledge on 3G/4G/5G KPI definitions and formulas; good understanding of 3GPP protocols.
• 3+ years hands on working experience with one of more wireless EMS system; building analysis reports using CM/PM/FM data
• Advanced working knowledge of Base Station Vendor equipment (Samsung, Alcatel Lucent, Ericsson)
• Demonstrated problem solving skills via prior work experience.
• A solid understanding of RF fundamentals and data network protocols
• Must have a strong work ethic, integrity and work extremely well in a team environment
• Must have an aptitude for creativity and innovation
• Programming knowledge and experience a plus: SQL, Python, R
• Database design and administration a plus
• 3+ years working experience with one of more EMS system; Advanced working knowledge of Base Station Vendor equipment (Samsung, Alcatel Lucent, Ericsson)
• Advanced working experience on Microsoft Excel, PowerPivot, PowerPoint
• Strong interpersonal communication skills
• Proven ability to manage multiple priorities in a fast paced environment
• Tableau Desktop Certified Professional Certification (preferred)
• Python (preferred)
• Database Administration Certification(preferred)
• Bilingual in Korean (preferred)

Physical/Mental Demands and Working Conditions: The position requires the ability to perform the essential duties and responsibilities in the following environment:
• Excellent interpersonal and communication skills. Must be skilled in developing and maintaining good working relationships with all appropriate levels within and outside the company
• Operate a computer keyboard and view a video display terminal more than 75% of work time in an office work environment
• Frequently works additional hours beyond normal schedule
• Performs work under time schedules and stresses which are normally periodic or cyclical and include time sensitive job stress, fatigue, unpaid over-time, intellectual challenge, constant technical data feedback, language barriers, and project management stress.
• Machines, tools, equipment, and work aids include PC’s, printers, etc. most often associated with office work area equipment
• Travel to customer locations, etc. approximately 20% of time
• Under minimal supervision with a high level of responsibility to apply general policies and guidelines where decisions are seldom monitored, consequences of decisions may adversely affect operating results and management decisions. Position has complete access to confidential company data where disclosure may jeopardize the company’s competitive position

Thank you,
Sachin Patil,
510-402-1063
sachin@apninc.com","APN Software Services Inc.
4.1","Plano, TX",Computer Hardware & Software,Information Technology
Machine Learning Engineer,"One of the world’s leading financial service providers are looking for experts in Machine Learning to help them with development of predictive financial algorithms.

The company has more than 1,500 employees and 30+ years of experience, they are the perfect destination for the best and the brightest analytical minds in the world.

Job Description

Work with the Data Science team and the wider R&D teams to design and implement a new predictive data and information analytics system.

Key Responsibilities
Design and develop a new ML and deep learning system according to requirements
Implement ML algorithms and tools, as appropriate
Run ML tests and experiments to ensure everything runs smoothly
Ensure the new system runs in parallel with the new dashboard application
Extend our existing ML libraries, and migrate data to the library as and when required
Keep up to date with the latest developments and best practices in the ML field and implement new changes where appropriate
Education, Experience and Skills
An Advanced Degree/PhD in a related subject (such as Data Science, ML, Statistics, Mathematics, Computer Science etc.)
4+ years experience working with ML/deep learning systems
Expertise in coding/developing algorithms for ML/deep learning systems
Proven experience using deep learning, analytical, NLP, classifications or predictive modelling
Proficiency in Python, R, RStudios
A working knowledge of SQL/Postgresql servers
Familiarity with open source systems such as Linux, Unix or Shell
Excellent attention to detail
Ability to work as part of a team, as well as independently with minimal supervision
Great time management and organisational skills
Desirable Knowledge & Skills
Knowledge and/or experience using AWS cloud system and applications
Proficiency or a good understanding of Java programming
Great knowledge of statistical modelling
Benefits Package
Competitive pay
Remote-working opportunities
Company laptop
Apply directly at: https://prolancer.com/jobs/send-proposal/301

Benefits:
Work from home opportunities
Job Types: Full-time, Contract

Salary: $70,000.00 - $95,000.00 per year

Experience:
Machine Learning: 2 years (Preferred)","Pro Lancer
5.0","Dallas, TX",-1,-1
Data Analyst,"Job Description
Support multiple lines of business including bankruptcy claims trading and insurance commission financing
Monitor and approve weekly funding of insurance commission financing along with developing metrics to monitor and measure principal risk exposure and profitability timeline
Collaborate with Insurance IMOs to set up data analysis and reporting standards to improve visibility of key performance metrics and risk factors
Perform financial analysis on new projects to forecast financial metrics such as IRR, cash flow and profitability
Construct SQL queries to gather large datasets on marketing revenue and effectiveness history to create insights on future marketing strategies and generate forecasts on marketing revenue
Supervise data collection efforts by Sales Assistant and members of the diligence team as well as direct Sales Assistant by identifying viable leads in bankruptcy cases
Conduct analysis and reporting on revenue forecasts, trader performance, diligence team performance, etc. to evaluate and improve company efficiency/profitability and business intelligence
Design and update company database using MSSQL
Design business processes to streamline and optimize daily business tasks
Collaborate with software developers to implement proprietary business tools for daily trading and diligence operations
Design and compose marketing campaigns to effectively reach out to prospective leads.
*

Reach out to us for more details (609)-795-3901 (or) Mail parvez(@)precisiontechcorp.com

Reviews: Glass door: https://lnkd.in/ePyq7pM

My Visa Jobs https://lnkd.in/e9ZpD5J

Inc. 5000 Press Release https://lnkd.in/eqttaa4

Required Experience and Qualifications

Eligibility:

>>Masters/Bachelors in CS/IT/CIS/MIS/MBA

>>Experience:1-2 Years relevant experience.

>>Excellent written and verbal communications:

Reach out to us for more details (609)-795-3901 (or) Mail parvez(@)precisiontechcorp.com","Precision technologies corp
4.3","Plano, TX",IT Services,Information Technology
Data Engineer,"Role Developer - Data Engineer Location Irving, TX Type of Hire Full-time Job Details Role Description Analyze and understand data sources APIs bull Design and Develop methods to connect collect data from different data sources bull Design and Develop methods to filtercleanse the data bull Design and Develop SQL , Hive queries, APIs to extract data from the store bull Work closely with data Scientists to ensure the source data is aggregated and cleansed bull Work with product managers to understand the business objectives bull Work with cloud and data architects to define robust architecture in cloud setup pipelines and work flows bull Work with DevOps to build automated data pipelines Total Experience Required bull 4 years 10 of relevant experience bull The candidate should have performed client facing roles and possess excellent communication skills Business Domain knowledge Finance banking systems, Fraud, Payments Required Technical Skills bull Big Data-Hadoop, NoSQL, Hive, Apache Spark bull Python bull Java REST bull GIT and Version Control Personal Skills bull Experienced in managing work with distributed teams bull Experience working in SCRUM methodology bull Proven sense of high accountability and self-drive to take on and see through big challenges bull Confident, takes ownership, willingness to get the job done bull Excellent verbal communications and cross group collaboration skills","Object Technology Solutions, Inc.
4.0","Irving, TX",IT Services,Information Technology
Data Engineer,"SUMMARYThe SQL Database Engineer will provide will have an enterprise background using MS SQL Server and be able to understand complex SQL design concepts, as well as practices and procedures. This position involves identifying business requirements, developing data models, performing data analysis, writing advanced SQL queries, designing, and coding complex stored procedures and performance tuning existing database processes.

ESSENTIAL FUNCTIONS AND ACCOUNTABILITIES

• Design and develop database objects, stored procedures, views, functions, tables, triggers and SSIS packages; ensure their stability, reliability, and performance
• Troubleshoots escalated, complex problems; recommends, and reviews the implementation of associated fixes
• Design, develop, and maintain SSRS reports based on user requirements
• Write and optimize SQL statements for data access and retention
• Test databases for performance, fine-tune when necessary
• Collaborate with developers on database design, query tuning, and schema refinement
• Independently analyze, solve, and correct database related issues in real time while providing efficient resolutions
• Respond to feedback from users regarding performance and work with developers to improve the performance of queries and indexes
• Tune stored procedures and T-SQL queries to improve performance and sustainability
• Provide support for the deployment of database scripts in development, test, pre-production and production environments
• Study the technical requirements provided by product team and design databases to fulfill the requirements
• Migrate on-premises SQL databases and related workloads to Azure
• Ensures that the environment is suitable for any proposed business applications, or propose scaling the environment to meet requirements
• Utilize techniques to minimize operational costs
• Ensures that the operational team is actively monitoring the backup environment for all applicable instances
• Ensures that the operational team maintains compliance with established service level agreements

WORK EXPERIENCE

• In-depth knowledge of standard concepts, practices and procedures related to database management.
• 7+ years of experience in software development using Microsoft SQL Server 2008 R2, T-SQL and T-SQL language (queries, views, procedures), SQL Server database design, stored procedure design and implementation.
• Experience coding complex stored procedures (using T-SQL).
• Experience developing SSIS packages
• Experience with migrating on-premises databases to IaaS-based and PaaS-based SQL Databases
• Experience with Azure cloud environment strongly preferred including:
Azure Databricks
Azure Databox
Azure Synapse Analytics/SQL Data Warehouse
Azure Event Hubs
Azure Data Factory
Azure Data Lake Storage
Migrating On-Premises Databases to Azure IaaS and PaaS
• Proven analytical problem solving and debugging skills
• Experience in troubleshooting and resolving database integrity issues, performance issues, blocking and deadlocking issues, etc.
• Experience with performance tuning, query optimization, using Performance Monitor, SQL Profiler and other related monitoring and troubleshooting tools.
• Familiarity with BI technologies (e.g. Microsoft Power BI/Tableau)
• Excellent communications skills (written and verbal)

Job Requirements:","Vaco Financial
3.3","Dallas, TX",Consulting,Business Services
Data Engineer,"Key Responsibilities:End to end ownership of ETL data pipelines, from ingestion of data to consumption by business intelligence and advanced analytics teams
Experience in Cloud Data Warehouse Platform Snowflake, Spark processing and AWS foundational services.
Understanding of complete data analytics stack and workflow, from ETL to data platform design to BI and analytics tools.
Strong skills in data integration, data warehouses, and data processing
Design and build an automated, self-service data platform, freeing teams to focus on customer features and analysis.
Evolve existing tools and framework to support new scalability requirements as well new functionality as needed.
Identify and drive new solutions to enhance the development cycle to increase development productivity.
Work with product owners to identify and mature upcoming business needs and develop technical backlog to answer those needs in a timely manner.
Work with team to identify and resolve technical debt to improve the teams throughput.

Skills:

Strong communication skills.
Deep experience designing and implementing highly scalable, distributed application systems.
5+ years experience building data pipelines.
5+ years experience programming in Python
Extensive knowledge in fine tuning SQL, understanding optimizers, and execution plans.
Extensive experience architecting complex data models to handle millions of transactions.
Experience in application design and Implementation using agile practices & TDD.
Experience leveraging open source data infrastructure projects, such as Apache Spark, Kafka, Flink.
Strong understanding of software development life cycle and release management
Self-motivated, independent, team-player

Krishna | IT Minds LLC |

Phone: 949.534.3939 x 406 | Email: krishna@itminds.net |
: 23172 Plaza Pointe Dr, # 265 | Laguna Hills, CA 92653 |
www.itminds.net",IT Minds LLC,"Dallas, TX",-1,-1
Data Engineer,"Req ID: 89867At NTT DATA Services, we know that with the right people on board, anything is possible. The quality, integrity, and commitment of our employees are key factors in our company's growth, market presence and our ability to help our clients stay a step ahead of the competition. By hiring the best people and helping them grow both professionally and personally, we ensure a bright future for NTT DATA Services and for the people who work here.NTT DATA Services currently seeks a Data Engineer to join our team in Irving, Texas (US-TX), United States (US).Role Responsibilities:* Analyze and understand data sources & APIs* Design and Develop methods to connect & collect data from different data sources* Design and Develop methods to filter/cleanse the data* Design and Develop SQL, Hive queries, APIs to extract data from the store* Work closely with data Scientists to ensure the source data is aggregated and cleansed* Work with product managers to understand the business objectives* Work with cloud and data architects to define robust architecture in cloud setup pipelines and workflows* Work with DevOps to build automated data pipelinesBasic Qualifications:* 3+ years of Advanced knowledge of Hadoop ecosystem and Big Data technologies* 3+ years of Hadoop (Cloudera) or Cloud Technologies building pipelines using Spark /Pyspark* 3+ years of experience in programming in Scala and Python* 2+ years Hadoop eco-system (HDFS, MapReduce, Yarn, Hive, Pig, Impala, Spark, Kafka,)* 2+ years ETL tools* 1 year of HTTP and invoking web-APIs* 1 year of NLP and text processingPreferences:* Machine learning engineering* Ab Initio* Work with distributed teams* SCRUM methodologyINDFSThis position is only available to those interested in direct staff employment opportunities with NTT DATA, Inc. or its subsidiaries. Please note, 1099 or corp-2-corp contractors or the equivalent will NOT be considered. We offer a full comprehensive benefits package that starts from your first day of employment.About NTT DATA ServicesNTT DATA Services partners with clients to navigate and simplify the modern complexities of business and technology, delivering the insights, solutions and outcomes that matter most. We deliver tangible business results by combining deep industry expertise with applied innovations in digital, cloud and automation across a comprehensive portfolio of consulting, applications, infrastructure and business process services.NTT DATA Services, headquartered in Plano, Texas, is a division of NTT DATA Corporation, a top 10 global business and IT services provider with 118,000+ professionals in more than 50 countries, and NTT Group, a partner to 88 percent of the Fortune 100. Visit nttdataservices.com to learn more.NTT DATA, Inc. (the ""Company"") is an equal opportunity employer and makes employment decisions on the basis of merit and business needs. The Company will consider all qualified applicants for employment without regard to race, color, religious creed, citizenship, national origin, ancestry, age, sex, sexual orientation, gender identity, genetic information, physical or mental disability, veteran or marital status, or any other class protected by law. To comply with applicable laws ensuring equal employment opportunities to qualified individuals with a disability, the Company will make reasonable accommodations for the known physical or mental limitations of an otherwise qualified individual with a disability who is an applicant or an employee unless undue hardship to the Company would result.","NTT DATA Corporation
3.4","Irving, TX",IT Services,Information Technology
Data Engineer,"Position Role/Tile: Data Engineer
Location: Dallas, TX.

6+ months
Must Have

5+ years of work experience in a Data Engineer role

Advanced knowledge and experience in relational databases (Teradata preferred), Data Warehousing and ETL/ELT technologies

Proficiency with SQL, Hive-QL, UNIX/LINUX scripting

At least 3+ years of experience in Big Data technologies including Hadoop, Data Bricks, etc.

Hands-on experience with one or more cloud service providers (Azure preferred)

Proficient in analyzing and translating business requirements to technical requirements and modeling the Logical and Physical Data Models

Participated in performance Tuning, Data Analysis, Mapping, Loading & Validation

Should be able to work independently

Experience supporting and working with cross-functional teams in a dynamic environment.

Prior experience in working in SCALED AGILE framework

Strong Analytical skills

Nice to Have

Experience in Spark and Python is a plus

Experience with working with Teradata and Teradata utilities such as TPUMP, BTEQ, TPT

Good familiarity with the Software Development Life Cycle (SDLC) and Data Ingestion

Central Business Solutions, Inc,
37600 Central Ct.
Suite #214
Newark, CA 94560","Central Business Solutions, Inc
3.0","Dallas, TX",Consulting,Business Services
Machine Learning Engineer,"MUST HAVES:
"" Excellent Knowledge and experience on Spark / Pyspark
"" Excellent knowledge and experience on Hadoop
"" Good Knowledge of ML Ops

Role Description
"" Hands on experience in predictive analytics and statistical tools, machine learning algorithms and big data tools
"" Identify, analyze and interpret trends or patterns in complex data sets using various regression, classification or clustering

ML approaches
"" Good familiarity with classic ML approaches
"" Create visualizations to visually represent data for consumption by different audiences

Business Domain knowledge: Finance & banking systems, Fraud, Payments
Niches: Cognitive Computing, Natural Language Understanding

Total Experience Required
"" 2
"" NLP exposure beneficial
"" Deep Learning proficiency a plus

Required Technical Skills
"" SQL, R or Python, , Spark, Hive
"" Frameworks/libs: SciKit-learn, NLTK, Gensim, Pandas, NumPy, Matplotlib, SciKit

Desirable Technical Skills
"" Hadoop, Spark, Elastic Stack, Git
"" Frameworks/libs: TensorFlow, Keras, Spacy
"" Familiarity with HTTP and invoking web-APIs

Personal Skills
"" Experienced in managing work with distributed teams
"" Experience working in SCRUM methodology
"" Proven sense of high accountability and self-drive to take on and see through big challenges
"" Confident, takes ownership, willingness to get the job done
"" Excellent verbal communications and cross group collaboration skills","NTT DATA, Inc.
2.9","Irving, TX",Accounting,Accounting & Legal
Data Engineer,"Innovators Wanted!!!As an experienced member of our Software Engineering Group we look first and foremost for people who are passionate around solving business problems through innovation & engineering practices. You will be required to apply your depth of knowledge and expertise to all aspects of the software development lifecycle, as well as partner continuously with your many stakeholders on a daily basis to stay focused on common goals. We embrace a culture of experimentation and constantly strive for improvement and learning. You'll work in a collaborative, trusting, thought-provoking environment-one that encourages diversity of thought and creative solutions that are in the best interests of our customers globallyThis role requires a wide variety of strengths and capabilities, including:* BS/BA degree or equivalent experience* Expertise in application, data and infrastructure architecture disciplines* Advanced knowledge of architecture, design across all systems* Proficiency in multiple modern programming languages* Knowledge of industry wide technology trends and best practices* Keen understanding of financial control and budget management* Ability to work in large, collaborative teams to achieve organizational goals, and passionate about building an innovative culture4+ years' experience with building large scale big data applications* Provide technical leadership with solutions architecture and building frameworks* Experience building Data Lake using Cloudera or Hortonworks distributions* Hands-on experience in AWS Bigdata ecosystem including AWS Glue, EMR, Athena, Redshift, QuickSight and Lake Formation* Extensive experience in Spark leveraging Python, Scala or R.* In depth knowledge of Java 8* Experience working on 1 or more NoSQL Databases such as Cassandra, HBase, MongoDB, DynamoDB, Elastic Search* Hands on experience with building CI/CD* Experience in developing software solutions leveraging Test Driven Development (TDD)* Expertise in Data governance and Data Quality* Experience working with PCI Data is a plus* Experience working with Data Scientists* In depth knowledge of OO and SOLID design principles* Demonstrable experience of successfully delivering big data projects using Kafka, Spark, Cassandra and related stack on premise or cloud* Able to tune big data solutions to improve performance* Excellent understand of Spring frameworkJPMorgan Chase & Co. is an equal opportunity employer and affirmative action employer Disability/Veteran.","JPMorgan Chase & Co.
3.9","Lewisville, TX",Investment Banking & Asset Management,Finance
Data Engineer,"Title Data Engineer Location Plano, TX Translates technical specifications, andor design models into code for new or enhancement projects (for internal or external clients). Develops code that reuses objects, is well structured, includes sufficient comments, and is easy to maintain. Writes programs and reportsElevates code into the development, test, and Production environments on schedule. Participates in design, code, and test inspections throughout life cycle to identify issues and ensure methodology compliance. Participates in systems analysis activities, including system requirements analysis and definition, e.g. prototyping. Participates in other meetings, such as those for use case creation and analysis.Skills RequiredMust have expertise in spark, kafka, aws, and sql Regards, Chase Melton JNIT Technologies Inc Tel 903-292-4270 Email chasejnitinc.com mailtochasejnitinc.com","Jnit Technologies
3.9","Plano, TX",IT Services,Information Technology
Statistician,"Principal Research Scientist/ Statistician, Real World Evidence (RWE)/ Late Phase

Job Purpose / Summary:
Responsible for planning, implementing and reporting RWE or health economics and outcomes research projects within CTI. This includes working closely with pharmaceutical, medical device, and diagnostics clients, among others, in partnership with CTI business development personnel in the development of project-specific methods and project deliverables. The person in this role may conduct face-to-face client meetings, teleconference calls, and publication strategies autonomously and may serve as mentor for other Research Scientists.

What You'll Do
Provide leadership or management for Real-World Evidence (RWE) programs with responsibilities to include: business development, client interactions, developing research objectives and statistical methodology for clients, participating in and overseeing projects
Consult and design of RWE study protocols, to include retrospective studies (EMR, chart reviews, cohort) and cross-sectional and prospective observational studies
Apply knowledge of statistical theory, techniques and methods encompassing such areas as sampling, ratios and proportions, measures of dispersion and central tendency, reliability, validity, correlations, survival, trends, index numbers, forecasting, categorical data analysis, non-parametric methods
Design and conduct analyses of large- and small-scale healthcare databases, registries, and non-regulatory clinical study data including EMR, EPIC, marketscan or other large scale databases
Write statistical analysis plans for studies and work with programmers and analysts to create the necessary analyzable datasets
Effectively communicate with clients to develop and report RWE solutions during the course of business development or within the context of a project
Required Education/Experience
Bachelors in biostatistics, health services research, pharmacy, nursing, natural science, epidemiology, biostatistics, or closely related discipline
10 years experience in working in outcomes research design, epidemiology, or biostatistics
Master of Public Health (MPH), or PhD (or DrPH, ScD/PharmD/MD) level scientist in health services research, pharmacy, nursing, natural science, epidemiology, biostatistics, or closely related discipline preferred
Pharmaceutical / biotech and/or contract research organization (CRO) experience preferred
Knowledge of statistical software packages including SAS preferred
Data visualization software (e.g. Tableau) and other advanced data presentation methodology preferred
Economic modeling building experience preferred
Significant demonstrated experience with developing peer-reviewed publications in relevant medical/pharmacy journals
Why CTI?
We support career progression 25% of our global staff is promoted annually and we have a structured mentoring program to provide the support you need to move forward
We value education and training We provide tuition reimbursement, partner with universities and colleges to create programs in our field, and have a dedicated training department
We value our people - We have never had a layoff in our 20-year history, support a work-life balance with flexible schedules, and have provided cash bonuses every year for the past decade
Our culture is unparalleled Click here to learn more about The CTI Way
We think globally and act locally We have a global philanthropic program supporting our teams efforts to improve their local communities (Click here to learn more about our CTI Cares program)
We are looking toward the future We have had a consistent 15% growth rate over the last decade, invest in cutting-edge technology, and pride ourselves on our average 95% annual retention rate
Our work makes a difference We focus our work on treatments for chronically and critically-ill patients, who are depending on us to bring these life-changing therapies to market","CTI Clinical Trial Services, Inc
4.0","Dallas, TX",Health Care Services & Hospitals,Health Care
Data Engineer,"We are at the forefront of change in this rapidly evolving lending market. mello™, the Greek word for “future,” was the product of a recent $80+ million dollar investment in research & development to transform & streamline the home buying process into a digital experience like no other competitor offers. But mello™ is just the beginning… loanDepot will continue to invest in developing our own advanced technology ecosystem built around serving our customers & enabling our valued employees to provide exceptional service. We have funding, we have opportunities, you have ideas—it’s a perfect match. Come join us!

loanDepot — We are America’s Lender.

Position Summary:

Responsible for delivering senior-level innovative, compelling, coherent software solutions for our consumer, internal operations and value chain constituents across a wide variety of enterprise applications through the creation of discrete business services and their supporting components. The job duties and requirements are defined for the backend. The senior role provides technical leadership and mentorship to junior team members. This position ensures the performance of all duties in accordance with the company’s policies and procedures, all U.S. state and federal laws and regulations, wherein the company operates.

Responsibilities:
Designs, develops and delivers solutions that meet business line and enterprise requirements.
Creates enterprise-grade application services.
Participates in rapid prototyping and POC development efforts.
Advances overall enterprise technical architecture and implementation best practices.
Assists in efforts to develop and refine functional and non-functional requirements.
Participates in iteration and release planning.
Performs functional and non-functional testing.
Contributes to overall enterprise technical architecture and implementation best practices.
Informs efforts to develop and refine functional and non-functional requirements.
Demonstrates knowledge of, adherence to, monitoring and responsibility for compliance with state and federal regulations and laws as they pertain to this position.
Strong ability to produce high-quality, properly functioning deliverables the first time.
Delivers work product according to established deadlines.
Estimates tasks with a level of granularity and accuracy commensurate with the information provided.
Works collaboratively in a small team.
Excels in a rapid iteration environment with short turnaround times.
Deals positively with high levels of uncertainty, ambiguity, and shifting priorities.
Accepts a wide variety of tasks and pitches in wherever needed.
Constructively presents, discusses and debates alternatives.
Takes shared ownership of the product.
Communicates effectively both verbally and in writing.
Takes direction from team leads and upper management.
Ability to work with little to no supervision while performing duties.
Experience designing enterprise database systems using Microsoft SQL Server preferred.
Experience with advanced queries, stored procedures, views, triggers, etc.
Experience with indexing and normalization.
Experience of performance tuning queries.
Experience of both DDL and DML.
Experience of database administration
Experience in Visual Studio 2013/2015 and SSIS to develop enterprise ETL processes.
Understanding of data mart and data warehousing concepts including variant schemas (Star, Snowflake).
Deep understanding of one or more source/version control systems. Develops branching and merging strategies.
Working understanding of Web API, REST, JSON.
Working understanding of unit testing creation.
Knowledge of cubes and SSAS is a plus.
Requirements:
Experience in the Mortgage industry preferred.
Bachelor’s Degree preferred, and/or a minimum of four (4) + related work experience.
The Perks:
Competitive compensation reliant on ability & experience.
Excellent benefits package including multiple health, dental & vision options.
Company paid life and AD&D Insurance, as well as additional voluntary benefit possibilities.
401K with robust company match.
DTO in addition to 8 paid company holidays.
The opportunity to work for America’s Lender under the vision of industry legend, Anthony Hsieh.
We are an equal opportunity employer and value diversity in our company. We do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status.","loanDepot
3.3","Plano, TX",Lending,Finance
Data Engineer,"Data Engineer Ideal candidates should have experience with Data Ingestion and Consumption. That is transforming from source raw data, cleansing missing data and outliers and preparing the data ready for analytics processing. Key requirements Understanding of Kafka-Yarn-Spark-HDFS ecosystem for ingestion IS A MUST. In depth knowledge of preparing large scale data analytics for consumption's. Key knowledge on HIVE and query optimization in HIVE Banking experience related to risk management and analysis on Fraud is a plus Career progression must show initial work with Hadoop and moving on to include Kafka and Spark in the latter career Hands on experience with Spark implementation using either Spark in Scala or PySpark","Photon Infotech
3.0","Irving, TX",IT Services,Information Technology
Software Engineer,"Remote Senior Software Engineer, Data

Engineering | Remote: CA, TX, MI, PA, NY, IL


Our first API helps you programmatically send physical mail at scale. Our second is address verification—officially CASS-certified by the USPS. But our long-term goal is to provide the building blocks for developers to automate the offline world through APIs. We’re looking for great problem-solvers to help us figure out how. We offer remote working opportunities in California, Texas, Michigan, Pennsylvania, New York, and Illinois. You can also work onsite at our San Francisco headquarters.

As an early member of our data team, you will help lay the foundation for a trusted and performant data platform that enables the entire company to make rapid data-driven decisions and ship scalable data-driven features. You will work with stakeholders across the company such as Sales, Finance, Marketing, Operations in addition to Data Science and Product/Engineering.

The role includes significant autonomy towards defining problem spaces and a mandate to build viable systems that are both internally- and externally-facing. This is a great opportunity for someone who wants to have a large sense of ownership, grow extraordinarily in their career, and develop cross-functional skills to maximize impact in a fast-moving hypergrowth startup.

Our engineering team values agility, collaboration, and autonomy. We’re building a team of not just strong problem-solvers, but great collaborators—engineers who are excited to teach and learn from each other, share decisions and information freely, and work together on new problems that no other companies have solved before. Come join the best people in the business.

As a senior data engineer, you’ll...
Collaborate closely with data scientists, analysts and infrastructure engineers to translate business challenges into data architecture, pipeline and warehousing solutions.
Develop and maintain data infrastructure, libraries and services with software engineering best practices.
Champion data governance, security, privacy and retention policies to protect end users, customers and Lob.
Build and curate data model expertise and uphold data quality and freshness.
Work closely with multi-functional teams to build and ship data-driven product features.
Coach and mentor fellow engineers.
Be one of the founding engineers on the data team and help build an inclusive, innovative, and unique culture.
For this role, we’re looking for...
Empathy and effective communication skills: you can walk in the shoes of and advocate for collaborators such as data scientists and product managers. You can explain complex technical issues to both technical and non-technical audiences.
Pragmatic and outcome-oriented: track-record of taking projects from inception to completion autonomously.
Growth mindset to learn new technologies, dive into unfamiliar problem domains and challenge assumptions.
Production experience with Spark, Python and SQL.
Experience with event-driven systems and time-series analysis a plus.
5+ years of full-time, relevant industry experience.
We’re not just building a platform to make the world programmable. We’re also designing a great place to work.

Our team loves working at Lob because...
Lob was built by technical co-founders with a vision to make the world programmable. We offer two flagship APIs (print & mail and address verification)
Our business model is incredibly sustainable and Lob has thousands of customers ranging from startups to Fortune 100 companies. Customers use Lob’s suite of APIs to mail fully dynamic and personalized customer communications with print media
Venture-backed by the most reputable investors in tech, we have the funding to invest in fast growth
We are a small but dynamic and passionate team based in San Francisco. We give our employees a lot of responsibility and ownership of their work. You will have fun at work while engaging in challenging projects with the best and brightest
Our perks include:
Health benefits for you and your dependent(s)
Flexible Spending Accounts
Open vacation policy
Commuter benefits
Wellness program
Paid parental leave
Ground floor opportunity as an early member of the Lob team; you’ll directly shape the direction of our company
Free lunch, dinner, and snacks
401K
Our Commitment to Diversity

Lob is an equal opportunity employer and values diversity of backgrounds and perspectives to cultivate an environment of understanding to have greater impact on our business and customers. We encourage under-represented groups to apply and do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, disability status, or criminal history in accordance with local, state, and/or federal laws, including the San Francisco’s Fair Chance Ordinance.","Lob
4.3","Dallas, TX",Computer Hardware & Software,Information Technology
Data Engineer,"Job Description
Our firm has been retained by a SaaS & Data company in Allen, TX to help find a Data Engineer to join their team. The Data Engineer will be an integral part of the development team designing strategies for database systems and setting standards for operations, programming and security. This role comes with 100% of both individual and family health premiums covered. We are searching for an engineer with creative problem solving- the type of engineer who not only knows what code to write but when and how to write that code. Looking for a team member with a hunger to constantly improve and suggest innovative solutions. This person will be a team player open to collaborating and sharing resources with other team members. We are looking for developers with strong job tenure.

Roles
• Design databases and ensure their stability, reliability, and performance
• Design, create, and implement database systems based on end user requirements
• Design and create large relational databases and database tables to store applicant data
• Investigate exceptions with application, refine system performance and functionality
• Prepare documentation for database applications
• Develop database schemas, tables and dictionaries
• Ensure the data quality and integrity in databases
• Fix any issues related to database performance and provide corrective measures
• Create complex functions, scripts, stored procedures and triggers to support application development
• Review and analyze existing SQL queries for performance improvement, optimize code and suggest new queries
• Write queries used by applications and work with application developers to create optimized queries
• Perform data modeling to visualize database structure
• Integrate new systems with existing in-house structure
• Program views, stored procedures, and functions
• Develop, implement and optimize stored procedures and functions using T-SQL
• Review and interpret ongoing business report requirements, build appropriate and useful reporting deliverables and provide scheduled reports to management
• Develop procedures and scripts for data migration
• Perform security assessment for potential risks
• Provide architecture guidance and support to technical leads
• Develop best practices for database design and development activities
• Research new technologies and develop proofs of concept

Requirements
• BS/MS degree in Computer Science, Engineering or a closely related subject
• At least 5 years of experience as a Data Engineer, SQL Developer, or similar role
• At least 5 years of experience working with SQL Server Reporting Services and SQL Server Integration Services
• Excellent understanding of T-SQL programming and Microsoft SQL Server
• Knowledge of HTML and C#, .Net, Visual Studio
• Sense of ownership and pride in your performance and its impact on company’s success
• Critical thinking and problem-solving skills
• Team player with strong interpersonal and communication skills
• Effective time-management skills and deadline-oriented","HumCap, Inc.
4.6","Allen, TX",Consulting,Business Services
Data Engineer,"Minimum Requirements:

At least 3 years of experience developing Data Pipelines for Data Ingestion or Transformation using Java or Scala or Python

At least 2 years experience in the following Big Data frameworks: File Format (Parquet, AVRO, ORC etc..)

At least 3 years of developing applications with Monitoring, Build Tools, Version Control, Unit Test, TDD, Change Management to support DevOps

At least 3 years of experience with SQL and Shell Scripting experience

At least 2 years of experience with software design and must have an understanding of cross systems usage and impact

Nice to Have qualifications:

2+ years of experience working with Dimensional Data Model and pipelines in relation with the same

2+ years’ experience with Amazon Web Services (AWS), Microsoft Azure or another public cloud service

2+ years of experience working with Streaming using Spark or Flink or Kafka or NoSQL

Intermediate level experience/knowledge in at least one scripting language (Python, Perl, JavaScript)

Hands on design experience with data pipelines, joining data between structured and unstructured data

Job Type: Full-time","DISYS
3.4","Plano, TX",IT Services,Information Technology
Data Engineer,"Position-Data Engineer
Client: USAA (IBM)
Location: Plano, TX

Duration: 04 May 2020 - 27 Nov 2020

Experience in working Data Integration teams on Data Analytics and Data Warehousing engagements.
Minimum of 5 years Data Integration experience working in medium to large sized projects
Strong understanding of data warehousing, data integration, reporting and advanced analytics technologies
Strong communication skills
Experience managing client relationship and expectations
Specific knowledge of Datastage 9.X/11.x and UNIX
Prior Data integration experience with the following IBM software products:
DB2
SQL Server
UNIX scripting
Scheduling tool Control-M
Experience in Unix/Linux/Redhat
Experience leading Technical teams
Experience with ETL tool Datastage","Georgia IT Inc.
5.0","Plano, TX",-1,-1
Data Engineer,"Hello

We are looking for a Data Engineer for a client in Plano,TX

Role: Data Engineer

Location: Plano TX

Interview: Phone/Skype

ÂMUST HAVE hands on experience in building data ingestion pipelines that ingest data from multiple sources into Data lake (Azure HdInsight with Hive).

<u>
8+ years of experience in Hadoop eco system
3 to 5 years of hands on experience in architecting, designing, and implementing data ingestion pipes for batch, real-time, and streams.
3 to 5 years of hands on experience with proven track record in building data lakes on HDInsight (Azure) platform.
3 to 5 years of hands on experience in Bigdata tools such as Sqoop, Hive, Spark, Scala, hBase, Mapreduce etc.
1 to 3 years of experience in Java/Python/Scala.
2 to 5 years of hands on experience in using Infoworks / Nifi/ any other tool.
2 to 4 years of experience in leading, guiding, and coaching data engineers.
Having exposure to R and ML technologies are a plus.
Experience in data wrangling, advanced analytic modeling, and AI/ML capabilities is preferred
BA/BS required; preferably in Computer Science, Data Analytics, Data Science or Operations Research
Highly analytical, motivated, decisive thought leader with solid critical thinking able to quickly connect technical and business 'dots'
Has strong communication and organizational skills and has the ability to deal with ambiguity while juggling multiple priorities and projects at the same time
Able to understand statistical solutions and execute similar activities
</ul>

ÂIf interested, please send resumes to bhavna@tekleaders.com or call 469-436-8433

Â

Thank you.

Â

Â

Bhavna Singh
Sr. IT Recruiter,Tek Leaders Inc

469-436-8433Â|Âbhavna@tekleaders.com

Gtalk: bhavnatek20

4975 Preston Park Blvd Suite #500 Plano, TX 75093

Â

Â

Â

Â","Tek Leaders
3.5","Plano, TX",IT Services,Information Technology
Data Engineer,"Role: Data Engineer
Location: San Antonio/Plano, TX

Contract Position

Skills required:
Should have ETL/ELT, Snowflake, DBT (Data Build Tool) and Agile experience.
Role:
Collaborate with Business team to gather requirement, Identify KPI
Convert Business requirements , KPIs to data requirement
Design, Build, Integrate and Lead the development of ETL/ELT to load Snowflake CWH(DL3) and Subject Area Marts(DL4)
Support Service Enablement Team for API creation by providing required details
Perform technical code review of deliverables
Desirable Skills:
Good to have skills AWS Glue & S3, Kafka, Streamsets
Diverse Lynx LLC is an Equal Employment Opportunity employer. All qualified applicants will receive due consideration for employment without any discrimination. All applicants will be evaluated solely on the basis of their ability, competence and their proven capability to perform the functions outlined in the corresponding role. We promote and support a diverse workforce across all levels in the company.","Diverse Lynx
3.9","Plano, TX",IT Services,Information Technology
Data Engineer,"Title: Data EngineerLocation: Plano, TX

Duration: 12 Months

Job Description:

Responsibilities for Data Engineer:

Job Description from Beeline:

Minimum Requirements:

At least 3 years of experience developing Data Pipelines for Data Ingestion or Transformation using Java or Scala or Python
At least 2 years experience in the following Big Data frameworks: File Format (Parquet, AVRO, ORC etc..)
At least 3 years of developing applications with Monitoring, Build Tools, Version Control, Unit Test, TDD, Change Management to support DevOps
At least 3 years of experience with SQL and Shell Scripting experience
At least 2 years of experience with software design and must have an understanding of cross systems usage and impact

Nice to Have qualifications:

2+ years of experience working with Dimensional Data Model and pipelines in relation with the same
2+ years experience with Amazon Web Services (AWS), Microsoft Azure or another public cloud service
2+ years of experience working with Streaming using Spark or Flink or Kafka or NoSQL
Intermediate level experience/knowledge in at least one scripting language (Python, Perl, JavaScript)
Hands on design experience with data pipelines, joining data between structured and unstructured data

Regards,

Karthik (KP)

Resource Development Manager

Direct: 469-533-7270

Cell: 469-717-0141

Email: karthik@infovision.com","InfoVision
4.4","Plano, TX",IT Services,Information Technology
Data Engineer,"Job Description
Job Summary:

Fairway is looking for a technology professional specializing in data engineering, with an emphasis on SQL Server database modeling and scripting. Responsible for expanding, optimizing, and modeling our existing data, as well as optimizing our current data flows utilizing both on premise and cloud based architecture. Support the data architect, data analysts, and mobile development team, and other cross functional teams on their data initiatives.

Essential Functions:

· Create, Improve, and modernize existing SSIS packages

· Working understanding of big data and big data modeling concepts

· Work closely with the Principal Data Architect to Develop, construct, test and maintain various data models for OLTP and OLAP Systems

· Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using SQL and Azure ‘big data’ technologies

· Provide SQL tuning suggestions when necessary

· Build data pipelines from multiple 3rd part sources utilizing cloud based technology

Non-essential Job Functions:

· Participates in and leads proactive team efforts to achieve departmental and company goals.

· Adopts Fairway values in personal work behaviors, decision making, contributions and interpersonal interactions.

· Contributes to a positive work environment by demonstrating cultural expectations and influencing others to reward performance and value ""can do"" people, accountability, diversity and inclusion, flexibility, continuous improvement, collaboration, creativity and fun.

· Performs other duties as assigned.

Required Knowledge, Skills and Abilities:

· Advanced working SQL knowledge and experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases.

· Experience building and optimizing ‘big data’ data pipelines, architectures and data sets.

· Ability to communicate effectively

· Ability to follow tasks assigned in Agile environment

· Strong analytic skills related to working with unstructured datasets.

· Experience supporting and working with cross-functional teams in a dynamic environment.

· Demonstrates high personal integrity and ability to earn trust from others

Required Education/Experience:

· Bachelor’s degree in computer science or a related field or equivalent work experience.

· 7+ years’ experience in Data Engineering or Database Development

· 2+ years’ experience in Cloud Services such as Azure/AWS/Google

Physical Environment:

· This position is primarily an in office position

Normal office environment
Company Description
Whether you’re looking to advance your career as a mortgage professional in our branch network or in a corporate support role, we offer a variety of opportunities to help you grow personally and professionally. Here at Fairway, we strongly believe the way we do things is just as important as what we do. Our Core Values define how we work together as a team, support individual growth, and guide us in determining how we can best serve our customers, team members and communities.

We believe that success is determined by the depth of our commitment to perform as a unified team, which is why we could not succeed without every person at Fairway. We also understand that loan originators, also known as “The Street,” are the true driving force for our company.

Our horizontal management structure provides our branch network with some of the fastest turn times in the industry giving a clear advantage in each market. We are a team-oriented, sales-minded organization that truly respects The Street’s needs by providing:
•Entrepreneurial branch platforms
•Extensive loan products and programs
•Competitive and flexible pricing
•Fast Underwriting turn times
•Exceptional Rush Team
•Knowledgeable Support Teams
•Employee Stock Ownership Plan (ESOP)
•Cutting-edge marketing resources, including free access to Home Buyers Marketing (HBM)","Fairway Independent Mortgage
3.7","Carrollton, TX",Lending,Finance
Data Scientist,"About Netskope

Today, there's more data and users outside the enterprise than inside, causing the network perimeter as we know it to dissolve. We realized a new perimeter was needed, one that is built in the cloud and follows and protects data wherever it goes, so we started Netskope to redefine Cloud, Network and Data Security.

Since 2012, we have built the market-leading cloud security company and an award-winning culture powered by hundreds of employees spread across offices in Santa Clara, San Francisco, Seattle, Bangalore, London, Melbourne, and Tokyo. Our core values are openness, honesty, and transparency, and we purposely developed our open desk layouts and large meeting spaces to support and promote partnerships, collaboration, and teamwork. From catered lunches and office celebrations to employee recognition events and social professional groups such as the Awesome Women of Netskope (AWON), we strive to keep work fun, supportive and interactive. Visit us at netskope.com/company/careers and follow us on Twitter @Netskope and Facebook.

Data Scientist


Within Netskope Engineering, the Security Services organization is responsible for building core security products and features, such as Data Loss Prevention, Malware and Threat Prevention, Cloud Confidence Index, Breach and Anomaly Detection. We apply Artificial Intelligence and Machine Learning technologies across Netskope cloud security platform. We are looking for talented data scientists with security domain knowledge. A successful candidate has deep technical expertise in applying AI/ML technologies in security applications and/or adjacent domains, ideally has been through the entire lifecycle of an award winning security product, and must be passionate about cloud security. You will have the opportunity to work with a team of talented engineers, researchers and data scientists to solve the most challenging cloud security problems.

Responsibilities:
Identify strong AI/ML use cases in cloud security, data security and adjacent domains, leveraging Netskope's rich set of data sources;
Define scalable data acquisition and labeling strategy for specific use cases;
Work with data engineers to retrieve, clean and normalize data. Ensure scalable and continuous high-quality data stream;
Work closely with threat research and development team in feature engineering. Make sure high-quality feature sets are chosen in a systematic way;
Select ML models for defined use cases. Implement KPIs to ensure optimal algorithms and results;
Conduct strict internal testing to ensure high efficacy, low false positive and false negative rate;
Interpret results and communicate findings;
Document use case, data acquisition, feature engineering, training, validation, deployment, future improvement opportunity and other important aspects;
Work closely with development and QE team in productization;
Be an evangelist of AI/ML within Netskope. Promote AI/ML wherever applicable, beyond security use cases;
Collaborate with data analytics team to define new platform requirements and continuously improve our horizontally scalable data lake.
Qualifications/Requirements:


First of all, must have true startup spirit. Be willing to wear multiple hats and deliver end-to-end;
Ability of thinking out-of-box and evaluating results based on customer value;
5+ years of industry experience in applying AI/ML, preferably on well-known security products or services, such as malware detection, anomaly detection, security analytics and data security;
Experience of applying AI/ML in more than one domains highly desirable;
Hands-on experience with relevant technology stacks such as CUDA, Python, R, Spark, Flink, Tensorflow;
Hands-on experience using modern big data pipeline;
Natural language process (NLP) and data mining experience highly desirable;
Security research experience and strong security domain knowledge highly desirable;
Energetic self-starter, with the desire to work in a dynamic fast-paced environment;
Excellent verbal and written communication skills;
Ability to influence without authority
Education:


PhD in Computer Science, Statistics, Electrical Engineering or equivalent technical degree.
#LI-NW1","Netskope
4.1","Santa Clara, CA",Enterprise Software & Network Solutions,Information Technology
Data Engineer,"About the Position


Mist, a Juniper Company, is the first vendor to bring enterprise-grade Wi-Fi, BLE and IoT together through a highly scalable cloud architecture. Our mission is to deliver personalized location-based wireless services by making Wi-Fi predictable, reliable and measurable. At Mist, we built the first AI-empowered platform to provide an unprecedented visibility into the user experience. Mist is the new global standard for many fortune 500 companies.

The mission of the Data Science team at Mist is to deliver AI driven self-driving network solution. We build analytics infrastructure, insights, models and tools, to empower our AI platform. Data Engineers on the team will be the enabler and amplifiers. This position offers limitless opportunities for an ambitious data science engineer to make an immediate and meaningful impact within a hyper growth team.

We are looking for a talented and driven individual to partner closely with data scientists, build and scale our self-driving network solution. He/she is encouraged to think out of the box and play with the latest technologies while exploring their limits. Successful candidates will have strong technical capabilities, a can-do attitude, and are highly collaborative.

Minimum Qualifications:
Fluent with Python, Java, or Scala
5+ years of experience of developing and managing streaming or batch data pipelines. Hands on experience with either one or all, Storm, Spark, Kafka and Flink .
Familiarity with cloud based platforms - AWS or GCP
Working knowledge of message queuing, stream processing, and highly scalable ‘big data’ data stores.
Highly motivated to build a great product and great codebase in a fast-paced environment
Strong communication skills with a growth and learning mindset
Preferred Qualifications:

MS in Computer Science, Electrical Engineering or other Engineering majors with 10+ years of total experience.
Knowledge and experiences of using machine learning tools such as Numpy, ScikitLearn, MLlib, Tensorflow
Juniper Networks is enrolled in E-Verify® and will be participating in E-Verify in addition to our Form I-9 process. www.dhs.gov/E-Verify
Juniper Networks is an Equal Opportunity/Affirmative Action Employer.","Juniper Networks
3.8","Cupertino, CA",Telecommunications Services,Telecommunications
Data Scientist,"C3.ai is a leading enterprise AI software provider for accelerating digital transformation. The comprehensive and proven C3 AI Suite uses a model-driven abstraction layer to enable organizations to develop, deploy, and operate enterprise scale AI applications 40x to 100x faster than alternative approaches. www.c3.ai

As a Data Scientist, you will participate in the definition of new analytics capabilities able to provide our customers with the information they need to make proper decisions to support our customers in operating the internet of things (IoT). In addition, you will help find the appropriate machine learning / data mining algorithms to answer these questions. Finally, you will be responsible for implementing this into the product and making it available to our customers.

Qualified candidates will have an in-depth knowledge of most common machine learning techniques and their application. You will also understand the limitations of these algorithms and how to tweak them or derive from them to achieve similar results at large-scale.

Your Responsibilities:
Driving adoption of Deep Learning systems into next-generation of C3.ai products.
Designing and deploying Machine Learning algorithms for industrial applications such as fraud detection and predictive maintenance.
Collaborating with data and subject matter experts from C3.ai and its customer teams to seek, understand, validate, interpret, and correctly use new data elements.
Requirements:
MS or PhD in Computer Science, Electrical Engineering, Statistics, or equivalent fields.
Applied Machine Learning experience (regression and classification, supervised, and unsupervised learning).
Strong mathematical background (linear algebra, calculus, probability and statistics).
Experience with scalable ML (MapReduce, streaming).
Ability to drive a project and work both independently and in a team.
Smart, motivated, can do attitude, and seeks to make a difference.
Excellent verbal and written communication.
Preferred
Experience with JavaScript and prototyping languages such as Python and R. Experience with Java and Scala is a plus.
Knowledge in electrical engineering and cyber-physical systems is a plus.
A portfolio of projects (GitHub, papers, etc.) is a plus.
C3.ai provides a competitive compensation package and excellent benefits including:
Competitive salary, generous stock options, 401K, medical, dental, and vision benefits. At the office, we offer a fully stocked kitchen with catered breakfast and lunch, table tennis and pool table, free membership at our on-site gym, Friday evening social hours with food, drink and music and a fun team of great people.
C3.ai is proud to be an Equal Opportunity and Affirmative Action Employer. We do not discriminate on the basis of any legally protected characteristics, including disabled and veteran status.","C3.ai
4.7","Redwood City, CA",Enterprise Software & Network Solutions,Information Technology
Data Scientist,"At Waymo, we're focused on bringing self-driving technology to the world. Our mission is to make it safe and easy for people and things to move around. Today, our driverless cars are serving our first customers with no drivers behind the wheel. To experience our self-driving technology, see this 360-degree video.

In this data science role, you will:
Safety evaluation is of fundamental importance to Waymo, and measuring it is subtle. This role works with a wide variety of teams across the company (onboard software engineering, product, safety, systems engineering) to evaluate the driving and safety performance of Waymo's self driving car. This is based on a wide variety of data from real and simulated driving from Waymo's self-driving system as well as from external data sources.
The Planner Team is responsible for ""motion planning"" for the self driving car. This includes gracefully handling many complex situations involving social interactions (merging, negotiating narrow roads, etc), while dealing with a noisy and uncertain environment. Evaluation of this onboard decision-making system is a complex, open-ended problem with tremendous potential impact. The quality of the road maneuvers we execute is subjective, contextual, and geometrically subtle, and evaluation needs apply to a wide variety of conditions with an extremely long tail.
Additionally:
Analysis and improvement of existing data sources and metrics
Development of novel approaches to measuring and improving
Self-driving performance (either generally, or for motion planning specifically)
Collaborate with engineers and other data scientists to evaluate and improve core
Waymo technologies, with a focus on bringing statistical depth, general analytical rigor, and accurate causal interpretation of data.
We'd like you to have:
PhD in statistics, math, or other quantitative area
Progressive statistics background either in academia or industry
Data science and system evaluation experience
Willingness to understand a complex system and its various components
Experience with tools for manipulating big data
Experience with R/Python and statistical libraries
It's preferred if you have experience in:
Experience with C++
Familiarity with Spark/MapReduce
Training or interest in geometry or classical physics","Waymo
2.8","Mountain View, CA",Computer Hardware & Software,Information Technology
Data Scientist,"Qualifications

We are looking for individuals with a Master's Degree or higher in:
Computer Science
Engineering
Physics
Statistics
You must have experience with / in:
Bayesian Networks
Probabilistic Modeling
Machine Learning Algorithms:
Training
Tuning
Optimization
R, Python, Statistics or Machine Learning Tools
Java or C/C++
NoSQL Databases
Relational Databases
When you are ready to take your career to a new level, we'd love to talk to you!

With over 35 years of experience, Architecture Technology Corporation (ATCorp) offers our customers demonstrated results and solutions through proven and effective technology development and application. As a small business, we do very big things. We have the advantage and ability to quickly adapt. This allows us to provide our customers with flexibility in creating, custom, cutting edge, systems with features that meet their next generation requirements.

We currently have offices in Minneapolis MN, Washington DC, Falls Church VA, San Jose CA (Silicon Valley) and Ithaca NY. This position will be located in sunny San Jose CA.

If you are ready to do something BIG we want to talk to you!

Why work with us?

First, we don't just talk about our great work life balance and work culture, we truly live it. For the last seven years, we have won the When Work Works Award. In 2018 we were one of only ninety seven companies in the US who received the When Work Works Award. When Work Works, recognizes employers that excel at offering a variety of employee initiatives such as work-life fit policies, flexible scheduling and transition to parenthood programs. Two-thirds of an organization's winning score is based on a survey of its employees. In short our employees love working here.

Second, our benefits package is great! We offer; Award Winning Work Place, 40 Hour Work Week, Flexible Work Schedule, Competitive Pay ($80k - $150k), Generous Paid Time Off (PTO), Floating Holidays, Paid Holidays, Extended Leave Bank (ELB) (can be used for Paternity leave), 401(k) with employer matching, Health and Dental Insurance, Flexible Spending Account (FSA), Fitness Discounts, Long Term Disability (LTD), Short Term Disability (STD), Life Insurance, Jury Duty Pay, Bereavement Pay, Pet Bereavement Pay, Employee Assistance Program and Relocation (where applicable).

Work Authorization/Security Clearance:

This contractor and subcontractor shall abide by the requirements of 41 CFR §§ 60-1.4(a), 60-300.5(a) and 60-741.5(a). These regulations prohibit discrimination against qualified individuals based on their status as protected veterans or individuals with disabilities, and prohibit discrimination against all individuals based on their race, color, religion, sex, sexual orientation, gender identity or national origin. Moreover, these regulations require that covered prime contractors and subcontractors take affirmative action to employ and advance in employment individuals without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, protected veteran status or disability.

Candidates will be required to pass a background check. Per government contract requirements, candidates for these positions must be a citizen of the United States or an alien lawfully admitted for permanent residence.

Reports to Technical Director

Job summary
Design and or innovate new idea and technologies
Programming and research
Confirms product performance by designing and conducting tests
Extensive regular contact with assigned project clients
Participating in client/contractor meetings and resolving client/engineering and management project issues
Creating system and software architectures
Developing, testing, and deploying software
Large-scale Software Systems Integration and test
Building commercial products
Conduction research and development
Providing customized consulting services
Application of systems analysis techniques and procedures
Determine hardware, software or system functional specifications
Assist in achieving project goals
Work with multiple projects
Interface with various departments
Other jobs as assigned by supervisor
Abilities Required
Self-starter, able to drive projects to completion in circumstances where little guidance and support is available
Knowledge of Microsoft Office
Must play well with others
Status
Full-time
Exempt","Architecture Technology Corporation
4.5","San Jose, CA",Computer Hardware & Software,Information Technology
Data Scientist,"The Opportunity

Eversight is the recognized leader in AI-powered price and promotions. Eversight's proprietary cloud-based SaaS solution brings AI and continuous experimentation to consumer brands and retailers. Our software acts as a coach, enabling market leaders to transform pricing and promotion strategy for the $3.4 trillion spent in consumer goods retail using intelligent, real-time data and insights.

Reporting directly to the Head of Data Science, you will be at the center of what determines Eversight's success as a company. You will analyze the data and develop production code using the newest Data Science and Machine Learning techniques to determine the optimal prices and promotions for major product manufacturers and retailers that sell these products.

Responsibilities
Research, implement and modify modern Data Science techniques. More specifically:
Build Statistical and Machine Learning models that describe the impact of prices and promotions on shopper behavior, including behavioral pricing effects. You'll need to find middle ground between using flexible modern AI methods and proven classical methods.
Develop Optimization and Experiment Design systems, which determine the best prices to set for each product in each store each week. Finding a good balance on the exploration-exploitation tradeoff will be crucial.
Design and run pricing experiments across hundreds of stores and tens of thousands of products
Create model validation methods to make sure that our models are accurate and to quantify the impact of our solutions on the clients' bottom line
Work with Product Management to generate ideas and quickly turn them into efficient, well-tested, functioning code (we mostly use Python)
Partner with the Engineering team to create highly scalable solutions
Serve as Data Science expert both within Eversight and for our clients
Lead custom analyses and connect them to actionable Business and Product insights
Help prioritize new feature development by assessing potential impact
Be a go-to resource for science-related questions about the product
Behavioral Profile
Analytical, framework thinker
Comfortable in a fast-paced environment
Highly collaborative
Strong at translating Data Science concepts to non-technical audiences
Business focused; measures work in its contributions to business outcomes and prioritizes effort against deliverables accordingly
Skills and Experience
M.S. in Operations Research, Machine Learning, Statistics, Mathematics, Engineering, Economics, Computer Science or relevant quantitative field
2+ years of experience in Data Science or Machine Learning. Ph.D. experience accepted
Elite ability in : Linear Algebra, Hypothesis Testing, Bayesian Methods, Regressions, Calculus, Maximum Likelihood Estimation
Experience in Machine Learning methods: Neural Networks (Deep Learning, Embeddings, Sequence Modeling, CNN), Tree-based methods (GBDT, Random Forest), Regressions (Linear, GLM), Regularization Methods (L1/L2 penalties, Feature Selection, Dimensionality Reduction)
Experience in A/B testing and Design of Experiments preferred
Demand Modeling, Pricing, and Causal Inference experience preferred but optional
Knowledge of common data structures and ability to write efficient code in Python
Agile experience preferred
Location

Palo Alto, CA

About the Company

Eversight is the recognized leader in AI-powered pricing and promotions. Global brands and retailers rely on the Eversight platform to optimize pricing in response to market conditions and to deliver higher ROI on promotional spend. Eversight's Pricing Suite and Offer Innovation Suite solutions are driving strong margin and sales volume improvements for leading companies such as Coca-Cola, Frito-Lay, Raley's, and Rite Aid. Founded in 2013, Eversight is headquartered in Palo Alto, California, with offices in Chicago and New York.","Eversight
4.2","Palo Alto, CA",Enterprise Software & Network Solutions,Information Technology
Machine Learning Engineer,"Entefy’s Machine Learning Engineer is a highly visible position internally and externally. This is where your deep experience and great insights intersect with an amazing opportunity to shape the future of communication and digital interaction.
Skills and Experience:
We’re not looking for “good;” Entefy is on a mission for best. The success of this mission depends on its team members to be creatively analytical, insatiably curious, and absolutely fearless in tackling big challenges.
Requirements
5+ years of experience in Machine Learning tools and algorithms specially in unstructured data classification and clustering.
Demonstrable expertise in MATLAB.
Proficient knowledge of and experience with AI systems.
Demonstrable expertise in multiple programming languages such as Python, C++, Java, etc.
Fluency in English and, at least, 1 other language.
Masters or PhD in Computer Science in Machine Learning or related field preferred.
Proficiency in Machine Learning open source tools.
Proficiency in Machine Translation.
Proficiency in Social Text Mining.
Proficiency in SQL and non-SQL database.
Proficiency in Data Visualization tools.
Visit www.entefy.com and www.blog.entefy.com","Entefy
4.3","Palo Alto, CA",Internet,Information Technology
Software Engineer,"During the current global health crisis, the priority for Siemens Digital Industries Software is the health and well-being of our entire community including current and future employees, which may add time to our hiring processes. We appreciate your patience and invite you to visit our website to learn more about how Siemens is responding to the pandemic.
Company: SISW - MG
Job Title: Software Engineer (Data Scientist, C,C++,Linux) - 189288
Job Location: USA - CA - Fremont
Job Category: R&D SW Engineering

Job Description:

We are looking for a highly motivated engineer to work in the RET team in the Calibre business unit. In this role you will be responsible for analyzing modeling data (experimental and synthetic/simulated) and coming up with novel ways to organize it, while deriving meaningful operations and extracting maximum information from this data.

You will also be expected to develop supporting software that will be properly integrated in the modeling suite of tools that are used specifically in modeling of semiconductor manufacturing.

You will be teaming up with a group of senior software engineers contributing to final production-level quality of new components and algorithms and to support existing components.

This is a unique role that will challenge you and allow you to grow in interdisciplinary areas of software engineering and data analysis.

Knowledge and experience in the area of data science/data analysis is preferred.

Some familiarity with physical modeling of any discipline (e.g. from fields in electrical or mechanical engineering) will be very useful for the suitable candidate.

Job
Qualifications:

The successful candidate will possess the following
combination of education and experience:
BS or
MS in Data Sciences, Computer Science, Electrical Engineering, Physics or
Applied Mathematics.
Working
knowledge in development of C and C++ on UNIX and/or LINUX platforms.
Excellent
programming skills in at least one mainstream scripting language, preferably
Python.
Experience/knowledge
in data analysis.
Experience/knowledge
in machine learning technology.
Experience
with Python, Keras and Tensorflow.
Demonstrated
ability to learn and explore new technologies.
Excellent
analysis and problem-solving skills.
Must
have the ability to collaborate closely with other members of the team and
develop critical components consistently and in a timely manner.
Experience
with MATLAB/R or equivalent mathematical package is expected.
This position may require access to export-controlled technology. If an export license is required and Mentor Graphics elects to apply for such a license, then candidates must be approved and licensed by the applicable government authorities as a condition of employment.

#LI-MGRP
#LI-JE1

Organization: Digital Industries

Company: Mentor Graphics Corporation

Experience Level: Recent College Graduate

Job Type: Full-time

Equal Employment Opportunity Statement
Siemens is an Equal Opportunity and Affirmative Action Employer encouraging diversity in the workplace. All qualified applicants will receive consideration for employment without regard to their race, color, creed, religion, national origin, citizenship status, ancestry, sex, age, physical or mental disability unrelated to ability, marital status, family responsibilities, pregnancy, genetic information, sexual orientation, gender expression, gender identity, transgender, sex stereotyping, order of protection status, protected veteran or military status, or an unfavorable discharge from military service, and other categories protected by federal, state or local law.

EEO is the Law
Applicants and employees are protected under Federal law from discrimination. To learn more, Click here.

Pay Transparency Non-Discrimination Provision
Siemens follows Executive Order 11246, including the Pay Transparency Nondiscrimination Provision. To learn more, Click here.

California Privacy Notice
California residents have the right to receive additional notices about their personal information. To learn more, click here.","Mentor Graphics
4.2","Fremont, CA",Computer Hardware & Software,Information Technology
Data Scientist,"Western Digital®

The next big thing in data is you!

Data Analytics team at Western Digital’s Recording Sub-System (RSS) division is looking for a Data Scientist who has a passion to build data products and data systems.

The Data Analytics team makes the most use of a vast data (>10TB/day) acquired from our HDD manufacturing tests. As our experience and vision expand, the opportunity to make important contributions to the company and to our customers through data analytics is also expanding. We seek a Data Scientist with practical experience in exploring big data opportunity at Western Digital. As a Data Scientist, you will be responsible for utilizing disparate data sources in novel ways, with the aim of generating actionable insights. The insights can create new offerings or improve the product reliability and performance and the efficiency of existing processes.

ESSENTIAL DUTIES AND RESPONSIBILITIES:
Understand existing business flow and product features, dive into the underlying data including numeric/categorical data, images and text, apply relevant Data Mining techniques and/or Machine Learning algorithms and propose data analytic approach to improve product quality and process efficiency.
Implement the applicable Machine Learning or statistics-based algorithm for prediction and optimization and deliver the trained model to production
Design, build and support algorithms of data transformation, conversion, computation on Hadoop and other distributed Big Data Systems
Work closely with key business stakeholders.
Communicate key analytic findings within the business and to senior stakeholders.
Research, explore, and enable new quantitative techniques and technologies in data science.
Drive thought leadership and embrace emerging industry innovation.


ABOUT WESTERN DIGITAL®

The future. It’s on you. You & Western Digital.

We’ve been storing the world’s data for more than 50 years. Once, it was the most important thing we could do for data. Now we’re helping the world capture, preserve, access and transform data in a way only we can.

The most game-changing companies, consumers, professionals, and governments come to us for the technologies and solutions they need to capture, preserve, access, and transform their data.

But we can’t do it alone. Today’s exceptional data challenges require your exceptional skills. It’s You & Us. Together, we’re the next big thing in data.

Western Digital® data-centric solutions are found under the G-Technology™, SanDisk®, Upthere™, and WD® brands.

Western Digital is an equal opportunity employer.

Western Digital does not discriminate on the basis of race, color, ancestry, religion (including religious dress and grooming standards), sex (including pregnancy, childbirth or related medical conditions, breastfeeding or related medical conditions), gender (including a person’s gender identity, gender expression, and gender-related appearance and behavior, whether or not stereotypically associated with the person’s assigned sex at birth), age, national origin, sexual orientation, medical condition, marital status (including domestic partnership status), physical disability, mental disability, medical condition, genetic information, protected medical and family care leave, Civil Air Patrol status, military and veteran status, or other legally protected characteristics. We also prohibit harassment of any individual on any of the characteristics listed above. Our non-discrimination policy applies to all aspects of employment. We comply with the laws and regulations set forth in the ""Equal Employment Opportunity is the Law"" poster.

Western Digital participates in the E-Verify program in the US. For more information click here. Este empleador participa in E-Verify.

#LI-AD1","Western Digital
3.6","San Jose, CA",Computer Hardware & Software,Information Technology
Data Scientist,"About Joby
Located in Northern California, the Joby Aviation team has been steadily working toward our goal of providing safe, affordable, fully electric air transportation that is accessible to everyone. Imagine an air taxi that takes off vertically, then quietly and quickly carries you over the congestion below, giving you back that time you’d otherwise spend sitting in traffic. Technology has advanced to the point where designing and operating an all-electric aircraft is completely viable. Our team has been discreetly designing and flight testing this vehicle and is looking for talented individuals to see it through certification and high rate production.
About the Job
Working as a Data Scientist you will be responsible for developing analytical tools and reporting results from numerous tests and flight operations centered around the powertrain. You should be able to work cohesively inside of an engineering team, understand both data systems and physical systems, and have an eye for anomalies in physical test data. You will also need to work closely with your colleagues across a broad set of highly technical disciplines who depend on data. The ideal candidate is energetic, has a positive attitude, is flexible and excited about learning and using new technologies.
Responsibilities:
Wrangle data from a multitude of formats and systems (TDMS, AVRO, PostgreSQL, AWS, etc).
Make sense of and “clean” data from a number of physical tests (the aircraft, reliability test equipment, subsystem tests, etc.).
Work closely with engineers to understand the test and clearly present on the results.
Work with the data engineering team to develop and maintain efficient data pipelines.
Develop tools to make processing and reporting on data as consistent and easy as possible.
Leverage statistics, numerical fitting methods, and a fundamental knowledge of powertrain systems to draw conclusions.
Required:
University degree in computer science, engineering, physics, or similar field.
Expert knowledge of python and data libraries (pandas, scipy, etc.).
Experience with data system architectures in relation to how to store, fetch, and manipulate data (SQL, custom APIs, etc).
Experience with data visualization tools (matplotlib, bokeh, plotly, etc.).
Experience with physical systems and an intuition around powertrain components and data.
Excellent communication skills.
Ability to support and work closely with a myriad of colleagues who are experts in aircraft design, systems engineering, test engineering, flight test operations, and machine learning.

Desired
Experience with Spark or other big data tools is a big plus.
Experience with anomaly detection.
Experience with streaming architectures (Kafka, Kinesis, etc.).
Experience with machine learning techniques and methodologies.","Joby Aviation
4.3","San Carlos, CA",-1,-1
Data Scientist,"Requisition ID: 255385Work Area: Software-ResearchExpected Travel: 0 - 10%Career Status: ProfessionalEmployment Type: Regular Full TimeCareer Level: T2Posting Date : 6/10/2020COMPANY DESCRIPTIONSAP started in 1972 as a team of five colleagues with a desire to do something new. Together, they changed enterprise software and reinvented how business was done. Today, as a market leader in enterprise application software, we remain true to our roots. That's why we engineer solutions to fuel innovation, foster equality and spread opportunity for our employees and customers across borders and cultures.SAP values the entrepreneurial spirit, fostering creativity and building lasting relationships with our employees. We know that a diverse and inclusive workforce keeps us competitive and provides opportunities for all. We believe that together we can transform industries, grow economics, lift up societies and sustain our environment. Because it's the best-run businesses that make the world run better and improve people's lives.Purpose and Objective:Ariba Inc. seeks a Data Scientist at Palo Alto, CA location to execute the mathematical modeling of our customers' business problems, develop algorithms, data mining flows and applications to solve these problems, and help our customers directly to understand and implement the results of the analysis.Expectations and Tasks:Work with industry experts and technology experts to translate our customers' business needs into mathematical models and present and deliver a solution to the client. Integrate or implement data mining/ mathematical methods into products. Evaluate and test data mining methods and maintains a high level of quality. Work with the senior data scientist to prototype new innovations and eventually get them into the product. Contribute to data definitions, data storage infrastructure for data mining purposes and to Data Mining architectures. Resolve data mining performance issues and monitor data mining system performance and implements efficiency improvements. Implement data mining algorithms if required. Work with product management, application developers, information developers and end users. Performs functional and empirical analysis on data mining topics. Conduct research on data mining tools and algorithms, implement prototypes and data mining algorithms and validates them on real data. Contribute to best practices for data mining topics and collaborate with development, universities and research institutes. 5% travel required.Education and Qualifications/Skills and Competencies:Bachelor's degree in Computer Science, Mathematics, Statistics, Economics, or a related field and 5 year of experience required. The company will also accept a Master's degree and 1 years of experience.Work Experience:Experience must include 1 year with: Databases; Data exploration including data discovery, data cleansing, data analysis, and feature engineering, including key performance indicators (KPIs); Model discovery including model exploration, model development, including training and validation, and model implementation; Modelling, including univariate and multivariate regression, logistic regression, natural language processing, machine learning and clustering & classification methodologies; preparation of design documents and functional requirements documents (FRDs); Familiarity with at least two of the following languages - Python, R, Java, C++, SQL. 5% travel required.Travel: 5% travel required.Internal use only: reference code lhrs0000EX:OUTSAP'S DIVERSITY COMMITMENTTo harness the power of innovation, SAP invests in the development of its diverse employees. We aspire to leverage the qualities and appreciate the unique competencies that each person brings to the company.SAP is committed to the principles of Equal Employment Opportunity and to providing reasonable accommodations to applicants with physical and/or mental disabilities. If you are interested in applying for employment with SAP and are in need of accommodation or special assistance to navigate our website or to complete your application, please send an e-mail with your request to Recruiting Operations Team (Americas: Careers.NorthAmerica@sap.com or Careers.LatinAmerica@sap.com, APJ: Careers.APJ@sap.com, EMEA: Careers@sap.com). Requests for reasonable accommodation will be considered on a case-by-case basis.EOE AA M/F/Vet/Disability:Qualified applicants will receive consideration for employment without regard to their age, race, religion, national origin, gender, sexual orientation, gender identity, protected veteran status or disability.Additional Locations :","Gigya
3.6","Palo Alto, CA",Enterprise Software & Network Solutions,Information Technology
Data Scientist,"Who we are


Fueled by a fundamental belief that having access to financial services creates opportunity, PayPal (NASDAQ: PYPL) is committed to democratizing financial services and empowering people and businesses to join and thrive in the global economy. Our open digital payments platform gives PayPal’s 286 million active account holders the confidence to connect and transact in new and powerful ways, whether they are online, on a mobile device, in an app, or in person. Through a combination of technological innovation and strategic partnerships, PayPal creates better ways to manage and move money, and offers choice and flexibility when sending payments, paying or getting paid. Available in more than 200 markets around the world, the PayPal platform, including Braintree, Venmo and Xoom, enables consumers and merchants to receive money in more than 100 currencies, withdraw funds in 56 currencies and hold balances in their PayPal accounts in 25 currencies.

When applying for a job you are required to create an account, if you have already created account - click Sign In.

Creating an account will allow you to follow the progress of your applications.

Note:

Provide full legal first Name/Family Name
DO: Capitalize first letter of First and Last Name. Example: John Smith
DON'T: Capitalize entire First and/or Last Name. Example: JOHN SMITH
NOTE: Use correct grammar for Names with multiple cases. Example: McDonald or O'Connell
Provide full address details

Resume is required

Multiple attachments can be uploaded including Resume and Cover Letter for each application

Job Description Summary:

• Design, develop and implement advanced predictive models using advanced machine learning techniques inlcluding neural network, and tree-based models .
• Collaborate with other data scientists and engineers to formulate innovative solutions to experiment and implement advanced data mining techniques
• Being able to work with large volumes of data; including extracting and analyzing big data using high-level languages such as Python, SQL, Pig, Hive, R.
• Communicate complex concepts and the results of the analyses in a clear and effective manner through creative visualization

Job Description:

PayPal’s Global Data Sciences team is responsible for developing and enhancing machine learning capabilities, which are key in PayPal’s top-of-the-line data-driven decisions. We are a group of data scientists and problem solvers with strong analytical, mathematical, and programming skills and like to approach various kinds of challenges in complex environments. This role offers a unique opportunity to innovate and improve PayPal’s Data Science capabilities for fraud detection problems

• Design, develop and implement advanced predictive models using advanced machine learning techniques inlcluding neural network, and tree-based models .
• Collaborate with other data scientists and engineers to formulate innovative solutions to experiment and implement advanced data mining techniques
• Being able to work with large volumes of data; including extracting and analyzing big data using high-level languages such as Python, SQL, Pig, Hive, R.
• Communicate complex concepts and the results of the analyses in a clear and effective manner through creative visualization

Qualification:
· Advanced degree (MS or PhD) in science or engineering field. Level will be determined based on experience.
· Expertise in developing neural network and tree-based models required.
· Machine learning experience in Python, Java, R, Scala and/or other Big Data techniques.
· Ability to deal with a large amount of data and fluency with SQL or SQL-like tools
· Strong problem solving and clear communication skills
· Passion in working on big data and professional experience in machine learning, statistical analysis, predictive modeling, and data manipulation
· Experience in developing recurrent neural network and Convolutional neural network is a strong plus

Subsidiary:

PayPal

Travel Percent:

0

Primary Location:

San Jose, California, United States of America

Additional Locations:

We're a purpose-driven company whose beliefs are the foundation for how we conduct business every day. We hold ourselves to our One Team Behaviors which demand that we hold the highest ethical standards, to empower an open and diverse workplace, and strive to treat everyone who is touched by our business with dignity and respect. Our employees challenge the status quo, ask questions, and find solutions. We want to break down barriers to financial empowerment. Join us as we change the way the world defines financial freedom.

PayPal provides equal employment opportunity (EEO) to all persons regardless of age, color, national origin, citizenship status, physical or mental disability, race, religion, creed, gender, sex, pregnancy, sexual orientation, gender identity and/or expression, genetic information, marital status, status with regard to public assistance, veteran status, or any other characteristic protected by federal, state or local law. In addition, PayPal will provide reasonable accommodations for qualified individuals with disabilities. If you are unable to submit an application because of incompatible assistive technology or a disability, please contact us at paypalglobaltalentacquisition@paypal.com.","PayPal
3.9","San Jose, CA",Internet,Information Technology
Data Scientist,"At Jabil, we empower the brands who empower the world - it's our reason for being and the guiding force that's driving us to become the most technologically advanced manufacturing solutions provider on the planet. Whether we're serving one of the world's biggest and best known brands or the coolest tech startups, our resolve never wavers. We share common desires with these brands: to make the world a better, safer and cleaner place.

JOB QUALIFICATIONS

KNOWLEDGE REQUIREMENTS

? Advanced Statistics, operations research/ management, mathematics or business analytics with experience, courses, or project work in an analytic methods such as linear, mixed linear, constraint programming, modeling, simulation, time series analysis, pattern recognition, queuing theory, multivariate analysis, and other various predictive analytics techniques

? Strong written and verbal communication skills and the ability to work effectively in teams and under pressure. Multi-lingual capability is a plus.

? Ability to draw conclusions from data and prescribe actionable and measurable activities.

? Highly motivated and creative, thinking ""out of the box"".

? Familiarity with non-relational data frameworks (aka NoSQL, eg. Hive).

? Experience with Apache Pig, Spark systems.

? Strong team mentality, interpersonal and communications skills

? Preferred working directly with management and executives

Jabil, including its subsidiaries, is an equal opportunity employer and considers qualified applicants for employment without regard to race, color, religion, national origin, sex, sexual orientation, gender identify, age, disability, genetic information, veteran status, or any other characteristic protected by law.","Jabil Circuit
3.7","San Jose, CA",Electrical & Electronic Manufacturing,Manufacturing
Data Scientist,"We are looking to hire an analytics & insights Data Scientist to partner with the eBay core product team. As a critical member of the Product Insights team, this data scientist will have the unique opportunity to influence decision making of the product roadmap with their insights

With a vision to identify opportunities to drive transformative change in the customer experience and result in significant business growth, we mine the largest datasets in the world of e-Commerce and use best in class analytic and big data techniques to extract impactful insights. We achieve this by partnering closely with the product and engineering teams and identify opportunities that are accretive to the product roadmaps.

To be successful in this role:
You would have to strike a balance between strategic thinking and actual hands-on analyses using tools & packages such as SQL, R, Python, Tableau etc.
You possess super strong technical skills to turn big data in Hadoop into actionable insights by using product analytics skills and machine learning skills, e.g. NLP, image detection, etc;
At the same time, you also have the ability to think about the big picture and connect the dots to evaluate how the insights impact eBays ecosystem.
In addition to delivering insights on existing Product & Tech initiatives, you will come up with innovative product growth opportunities based on insights and create momentum through influence.
Proactive collaboration and effective communication are critical
Additionally, the following background and experience is preferred:
Ability to present complex analyses and insights effectively in simple terms
Good experience with both descriptive and inferential statistics ability to build basic prototype models
Strong quantitative background with bachelors degree in Computer Science, Math, Economics, Physics, Engineering, or related. Masters degree is a plus.
Experience with site experimentation (A/B testing) is a plus
Familiar with ecommerce product experience is a plus
This website uses cookies to enhance your experience. By continuing to browse the site, you agree to our use of cookies

View our privacy policy

View our accessibility info

eBay Inc. is an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, national origin, sex, sexual orientation, gender identity, veteran status, and disability, or other legally protected status. If you are unable to submit an application because of incompatible assistive technology or a disability, please contact us at talent@ebay.com. We will make every effort to respond to your request for disability assistance as soon as possible.

For more information see:

EEO is the Law Poster

EEO is the Law Poster Supplement","eBay
3.6","San Jose, CA",Internet,Information Technology
Data Scientist,"Palo Alto, California

Data Scientist


Next Insurance is a fast-growing 290+ person startup based in Silicon Valley and is led by a team of experienced entrepreneurs with a history of successful outcomes. Our mission is to transform insurance for small businesses by combining world-class technology and phenomenal customer service to offer better insurance at a lower price. Next has raised over $380 million from top tier investors and is the valley’s latest unicorn, valued at over $1 billion.

Next is well-positioned to become the leader in the $140 billion small business insurance market because we offer a 100% online experience that is tailored to unique business needs and we get customers insured in minutes - something no one else does. Despite the size of the market, the experience of buying small business insurance has not caught up with best practices instituted in other industries like banking, lending, and even personal lines insurance. There is still a lot of paper involved, purchasing a policy can take days or even weeks, and the coverage is so complex that it’s hard for entrepreneurs to understand what they are buying. We're here to change that. Our goal is to make insurance simple, affordable, and transparent for small businesses so they can stop worrying about insurance and focus on running their businesses.

We are looking for a driven Data Scientist to help us bring machine learning to the insurance industry. As a data scientist at Next Insurance, you will work on a wide range of projects, including building predictive risk models, fine-tuning user experience and optimizing internal operations. You will enable us to make the best use of our proprietary data, supplemented with novel data sources which you get to assemble creatively.

You will report directly to our Head of Data Science and have day-to-day exposure to multiple members of the company leadership team. You will be joining a small, nimble team of 5+ scientists, with lots of room for growth and impact.
Responsibilities:


Research and develop predictive models (we typically start with a POC and then work with Product and Engineering counterparts to transition to production).

Iterate and pivot quickly to deliver MVP solutions. Design quick experiments to maximize learning.

Understand the data and dig deep to extract actionable insights.

Think creatively and outside the box to answer desired experimental questions.

Work cross-functionally with engineering, product, marketing, business intelligence, insurance operations, customer support, senior management, and external partners.

Desired Skills and Experience:


4+ years of hands-on experience in data mining, machine learning, and/or statistical analysis.

MS/Ph.D. in Computer Science, Statistics, Applied Math, or related areas from a top university.

Experience in writing both agile exploratory analyses as well as production-level code in a fast-paced environment.

Ability to communicate the results of analyses clearly and effectively.

Fluency with an analytical programming language (preferably python) and the standard numerical packages.

Fluency with data extraction/manipulation tools (preferably SQL and pandas).
Apply For This Position

Upload","Next Insurance
4.5","Palo Alto, CA",Insurance Carriers,Insurance
Data Scientist,"Responsibilities·
Analyze large datasets to glean actionable insights and identify emerging opportunities·
Create metrics to measure the success of products, services, and features.·
Use data mining and machine learning skills to design and develop products which drive engagement, growth, retention, and monetization.·
Develop and deploy scalable classification, regression, ranking, and optimization algorithms.·
Work with data engineers and other stakeholders in data products pipeline to enable automation of the data-driven products.·
Communicate both routine and ad-hoc data analysis results in a clear, insightful and actionable way.
Minimum Qualifications ·
BA/BS in Statistics, Computer Science, Math or other related technical fields.·
2+ years prior research, data science, or engineering experience in building and implementing recommender systems, machine learning models/algorithms, etc.·
Excellent programming skills - ability to prototype effective simple or complex algorithms and collaborate with engineering team to implement them in the production system·
Familiarity with or willingness to learn large-scale distributed computing tools (Hadoop, Hive, etc.)
Preferred Qualifications ·
PhD or MSc degrees in Statistics, Computer Science, Math or other related technical field. ·
Proficient in R or Python. ·
Familiar with or have contributed to open source machine learning tools/platforms.·
First author publications in top-tier conferences or journals.
Powered by JazzHR","IntelliPro Group Inc.
4.1","Santa Clara, CA",-1,-1
Data Scientist,"Job Description


Job #: 1075054

Please send all resumes to ekingery@apexsystems.com for further consideration.

Title: Data Scientist

Location: Sunnyvale

Duration: 6 month contract

Position Description:

We are looking for a passionate, creative data scientist professional to join our Data Science team. You will have the unique opportunity to work with massive business and social data generated by our unparalleled online and offline commerce. You will be responsible to use cutting-edge machine learning, data mining, and optimization techniques to design and prototype robust, scalable predictive models and analytics solutions. You will be a part of a cross-functional team of scientists, engineers, product managers, and business professionals that sit at the intersection of data science, big data, IT infrastructure, and business operations.

Responsibilities:
Perform hands-on data exploration, processing, and analysis on massive data sets.
Use machine learning, deep learning and data mining techniques to develop robust predictive models in areas such as seller risk management, fake rating & review detection, account linking, and anomaly detection.
Pull data from warehouse, perform feature engineering, back-test models, compare model performances and communicate the results to stakeholders.
Research and develop state-of-the-art algorithms that address complex business problems.
Minimum Qualifications:
Technical expertise in data mining, machine learning, and statistical analysis.
Proficient in machine learning and data mining packages in Python.
Experience working with large data sets and distributed computing tools (Map/Reduce, Hadoop, Hive, or Spark).
Programming skills in one of the following languages: SQL, Java, or JavaScript on a UNIX or Linux platform.
Advanced degree (Master or PhD) in any STEM field plus two years of related experience.
Ability to work in a fast-paced, iterative development environment.
Good communication skills, ability to work with cross functional teams of technical and non-technical members.
Additional Preferred Qualifications:
2+ years seller risk management experience
EEO Employer

Apex Systems is an equal opportunity employer. We do not discriminate or allow discrimination on the basis of race, color, religion, creed, sex (including pregnancy, childbirth, breastfeeding, or related medical conditions), age, sexual orientation, gender identity, national origin, ancestry, citizenship, genetic information, registered domestic partner status, marital status, disability, status as a crime victim, protected veteran status, political affiliation, union membership, or any other characteristic protected by law. Apex will consider qualified applicants with criminal histories in a manner consistent with the requirements of applicable law. If you have visited our website in search of information on employment opportunities or to apply for a position, and you require an accommodation in using our website for a search or application, please contact our Employee Services Department at employeeservices@apexsystemsinc.com or 844-463-6178.","Apex Systems
3.8","Sunnyvale, CA",Staffing & Outsourcing,Business Services
Data Scientist,"Due to COVID-19, applicants will be interviewed remotely.

Learn how candidates are getting hiring during COVID.
https://match-relevant.com/your-story

Do you love working for companies that make the world a better place? We recently received FDA approval on our medical device that is saving lives. We love people who have challenged the status quo, disrupt industries and have brought innovation into market. We are looking for Data Scientists with experience in signal processing, time-series analysis, pattern recognition and machine learning. To improve your odds of an interview, schedule here: https://calendly.com/jake-villarreal/calendar

The Work:
Working with the founders and Data Scientist team, focused on biological signal processing and algorithm development for biomedical applications.
The Role:

6+ years of experience in signal processing, statistical data analysis, pattern recognition and machine learning
Proficient in one of the following: Matlab, Python, R or similar programming language
Experience and interest in biological signal processing and algorithm development for biomedical applications
Strong analytical skills, detail-oriented and collaborative
MS or PhD in Electrical Engineering, Computer Science, Statistics, or equivalent disciplines","Match Relevant
4.3","Mountain View, CA",Advertising & Marketing,Business Services
Data Scientist,"COMPANY OVERVIEWProudly Farmers First?!What do you get when you cross the best of Silicon Valley innovation and technology with the value driven mission of Family Farmers around the world?Farmers Business Network, Inc. (FBN?)!FBN? was created by farmers for farmers and is on a mission to power the prosperity of Family Farmers around the world by leveling the playing field through insights, commerce and community. Our goal is to enable them to make smart business decisions that maximize their farms profit potential for generations to come, helping to ensure the fundamental economic viability and sustainability of family farms and rural communities.We are a dynamic, and innovative AgTech company that offers competitive compensation and benefits and is backed by top investors including Google Ventures, Kleiner Perkins, DBL Partners, T Rowe Price and Temasek.THE ROLEHow can we sustainably feed the world? With the population set to reach nine billion by 2050 and available farmland decreasing, the odds are stacked against us. This problem falls squarely on the shoulders of farmers, who are increasingly working harder for less. FBN helps farmers to solve these problems.Farmers are often forced to make key decisions in the face of significant uncertainty about their impact. FBN applies technology and data science to this challenge. We're building the world's largest agronomic dataset - made up of billions of data points, gathered from sophisticated sensors on farm equipment. The network effect of farmers sharing their data allows us to deliver unprecedented analyses that help farmers make data-driven decisions - we're not just building new technology, we're also making new agricultural scientific discoveries.We're looking for data scientists who are enthusiastic about applying big data to help farmers!Data science underlies every product that we build at FBN, so you'll see your work directly translate into new products for our farmers. The data science team at FBN:* Explores one of the world's most unique, interesting, and diverse datasets.* Furthers scientific understanding about what affects agricultural production.* Uncovers insights that help farmers efficiently support a growing population.* Makes meaningful improvements in the world by translating data science into products that help farmers increase yield and efficiency.Required Skills* Deep understanding of statistical modeling concepts.* Familiarity with machine learning algorithms.* Excellent programming skills (R or Python preferred).* Preferred: understanding of agricultural systems (soil chemistry, plant physiology, entomology, etc).Required Experience* MS or greater in statistics or related discipline, OR MS or greater in agronomy or related discipline with strong data analysis skills.Farmer's Business Network, Inc. is an equal opportunity employer and participates in U.S. Citizenship and Immigration's E-Verify program.","Farmers Business Network
3.5","San Carlos, CA",Farm Support Services,Agriculture & Forestry
Data Scientist,"Data Scientist
Our Data Scientists perform research and analysis that allows the company to make optimal product decisions.

Because we are such a data-driven company, our data scientists play a central role in the product development process by uncovering key insights from our data. As a data scientist, you will work closely with product managers, product designers, and engineers to devise appropriate measurements and metrics, design randomized controlled experiments, build visualizations, and tackle hard, open-ended problems that uncover usage patterns and opportunities for the company. You may also develop tools and infrastructure to scale and automate the analyses that enable rapid product iteration. We have a wide range of rich data, giving you ample room for exploration and creativity. Examples of some projects our data scientists have worked on include modeling our long-term growth, improving the relevance and personalization of the homepage feed, and exploratory factor analysis of user behavior.
Things we look for include:

B.S., M.S., Ph.D. in a scientific or quantitative field
2+ years work experience
Excellent statistical intuition and knowledge of various analytical approaches
Superb communication skills and ability to explain your analysis clearly
Proficiency in SQL
Familiarity with Python or similar scripting language
Passion for learning and always improving yourself and the team around you
Experience in working with large data sets and distributed computing tools (Hive, Redshift) is a plus

Email your resume to hala.hillo@motektech.com","MoTek Technologies
3.1","Mountain View, CA",IT Services,Information Technology
Data Scientist,"Posted: Jun 12, 2020
Weekly Hours: 40
Role Number:
200175199
We are the Computer Vision Testing Group responsible for quality of many exciting projects (ARkit, Animoji, FaceID, etc.), that have been shipped on Apple products. We are now seeking a Camera Image Quality Engineer to stress test and provide responsible image quality feedback to developers. You will do hands-on image quality testing work, collaborate with developers, continuously track camera algorithm bugs and be able to represent image quality from a user's perspective.
Key Qualifications
A curious mind
An obsession for quality
Background in Data science, Data mining, Multivariate statistics, Computer vision, Machine learning
Experience working with large scale data sets
Solid programming skills including:
Python
C/C++
Experience with data visualization and presentation, familiar with data analysis tools such as Tableau
Excellent problem solving and communication skills
Description
The Data Scientist will work closely with other members of the Video Engineering group to mine data, implement model evaluation pipeline, analyze large scale data, visualize data, and ensure the delivery is of the highest quality. This position will also require strong coding skills, presentation skills, and collaborating with multiple teams (ex: machine learning, cloud infrastructure support).

The responsibilities of this position includes but not limited to the following for current and future products:
Implement algorithm evaluation methods
Analyze data and build data analysis tools
Deep-dive failure analysis
Discover new perspectives for old data
Produce / Present meaningful data visualization to higher-ups and across various involved teams
Education & Experience
PhD or Masters in Computer Science","Apple
4.1","Santa Clara, CA",Computer Hardware & Software,Information Technology
Data Scientist,"This is what you'll do:You'll take the adventure of a lifetime. Rivian is pushing the boundaries of what can be done in a vehicle; you'll help us do that. You'll work with a team of top-notch engineers and scientists to build in-vehicle tools tracking vehicle performance and reliability metrics. You'll create a framework for monitoring and assessing vehicle health that has never been done.* Aid development of models to predict vehicle wear based on vehicle diagnostic signals* Work closely with engineers to scale physics-based models from a vehicle prototype to entire Rivian fleet* Support development of models describing vehicle and drive unit performance based on manufacturing data* Create performance-based metrics and acceptability thresholds at the edge* Work with available in-vehicle signals to provide early detection of unique wear mechanisms* Create the foundation for a data driven, edge-based fault detection platform that will run on all Rivian vehiclesThis is what you'll need:* Awesomeness* Passion for building an amazing product* Interest in working on a unique team with diverse technical backgrounds to create a ground-breaking vehicle application* BS/MS in Computer Science, Mechanical Engineering, Physics, or related field* 1-2 years experience working with hardware systems, automotive preferred* Strong Python and/or R programming skills* Experience with weakly supervised and unsupervised learning methodologies* Ability collaborate with firmware and mechanical engineers working alongside you; thrive in a close-knit cross-functional environment.* Experience with mechanical and/or audio systems a plus* Excellent communication skills, ability to explain complex concepts to non-data science teammatesThis is where you'll work:Department: Reliability DiagnosticsLocation: Palo Alto, CARivian description:Rivian is on a mission to keep the world adventurous forever. This goes for the emissions-free Electric Adventure Vehicles we build, and the curious, courageous souls we seek to attract.As a company, we constantly challenge what's possible, never simply accepting what has always been done. We reframe old problems, seek new solutions and operate comfortably in areas that are unknown. Our backgrounds are diverse, but our team shares a love of the outdoors and a desire to protect it for future generations.We operate development centers in Plymouth, MI, Irvine CA and San Jose, CA, and Surrey, England, as well as a manufacturing facility in Normal, Illinois.Rivian is an Equal Opportunity Employer and Prohibits Discrimination and Harassment of Any Kind: Rivian is committed to the principle of equal employment opportunity for all employees and to providing employees with a work environment free of discrimination and harassment. All employment decisions at Rivian are based on business needs, job requirements and individual qualifications, without regard to race, color, religion or belief, family or parental status, or any other status protected by the laws or regulations in the locations where we operate. Rivian will not tolerate discrimination or harassment based on any of these characteristics. Rivian encourages applicants of all ages.","Rivian
4.1","Palo Alto, CA",Transportation Equipment Manufacturing,Manufacturing
Data Scientist,"Entefy’s Senior Data Scientist is a highly visible position both internally and externally. Join the intelligence revolution, where we can push the state-of-the-art boundaries of data science. This is where deep experience and multi-dimensional insights intersect with an amazing opportunity to shape the future of productivity for people everywhere.

Skills and Experience:

We’re not looking for “good.” Entefy is on a mission to find exceptional talent. The success of our mission depends on our team’s ability to be creatively analytical, insatiably curious, and absolutely fearless in tackling big challenges.
Requirements
Master's degree in Computer Science, Mathematics, Statistics, Engineering, or a compatible field. PhD is preferred.
3+ years of applicable work experience.
Demonstrable proficiency in Python, Scala, SQL, or R.
Strong data visualization and reporting skills.
Proven track record delivering high-value, advanced analytics.
Experience leading the work of other data scientists or analysts is preferred.
World-class ability to extract and communicate insights from real-world datasets.
Startup agility and versatility.
Visit www.entefy.com and www.blog.entefy.com.","Entefy
4.3","Palo Alto, CA",Internet,Information Technology
Data Scientist,"Requisition ID: 255385
Work Area: Software-Research
Expected Travel: 0 - 10%
Career Status: Professional
Employment Type: Regular Full Time
Career Level: T2
Posting Date : 6/10/2020

COMPANY DESCRIPTION

SAP started in 1972 as a team of five colleagues with a desire to do something new. Together, they changed enterprise software and reinvented how business was done. Today, as a market leader in enterprise application software, we remain true to our roots. That’s why we engineer solutions to fuel innovation, foster equality and spread opportunity for our employees and customers across borders and cultures.
SAP values the entrepreneurial spirit, fostering creativity and building lasting relationships with our employees. We know that a diverse and inclusive workforce keeps us competitive and provides opportunities for all. We believe that together we can transform industries, grow economics, lift up societies and sustain our environment. Because it’s the best-run businesses that make the world run better and improve people’s lives.

Purpose and Objective:

Ariba Inc. seeks a Data Scientist at Palo Alto, CA location to execute the mathematical modeling of our customers’ business problems, develop algorithms, data mining flows and applications to solve these problems, and help our customers directly to understand and implement the results of the analysis.

Expectations and Tasks:

Work with industry experts and technology experts to translate our customers’ business needs into mathematical models and present and deliver a solution to the client. Integrate or implement data mining/ mathematical methods into products. Evaluate and test data mining methods and maintains a high level of quality. Work with the senior data scientist to prototype new innovations and eventually get them into the product. Contribute to data definitions, data storage infrastructure for data mining purposes and to Data Mining architectures. Resolve data mining performance issues and monitor data mining system performance and implements efficiency improvements. Implement data mining algorithms if required. Work with product management, application developers, information developers and end users. Performs functional and empirical analysis on data mining topics. Conduct research on data mining tools and algorithms, implement prototypes and data mining algorithms and validates them on real data. Contribute to best practices for data mining topics and collaborate with development, universities and research institutes. 5% travel required.

Education and Qualifications/Skills and Competencies:

Bachelor's degree in Computer Science, Mathematics, Statistics, Economics, or a related field and 5 year of experience required. The company will also accept a Master's degree and 1 years of experience.

Work Experience:

Experience must include 1 year with: Databases; Data exploration including data discovery, data cleansing, data analysis, and feature engineering, including key performance indicators (KPIs); Model discovery including model exploration, model development, including training and validation, and model implementation; Modelling, including univariate and multivariate regression, logistic regression, natural language processing, machine learning and clustering & classification methodologies; preparation of design documents and functional requirements documents (FRDs); Familiarity with at least two of the following languages – Python, R, Java, C++, SQL. 5% travel required.

Travel:5% travel required.

Internal use only: reference code lhrs0000

EX:OUT

SAP'S DIVERSITY COMMITMENT

To harness the power of innovation, SAP invests in the development of its diverse employees. We aspire to leverage the qualities and appreciate the unique competencies that each person brings to the company.

SAP is committed to the principles of Equal Employment Opportunity and to providing reasonable accommodations to applicants with physical and/or mental disabilities. If you are interested in applying for employment with SAP and are in need of accommodation or special assistance to navigate our website or to complete your application, please send an e-mail with your request to Recruiting Operations Team (Americas: Careers.NorthAmerica@sap.com or Careers.LatinAmerica@sap.com, APJ: Careers.APJ@sap.com, EMEA: Careers@sap.com). Requests for reasonable accommodation will be considered on a case-by-case basis.

EOE AA M/F/Vet/Disability:

Qualified applicants will receive consideration for employment without regard to their age, race, religion, national origin, gender, sexual orientation, gender identity, protected veteran status or disability.

Additional Locations :","SAP
4.6","Palo Alto, CA",Computer Hardware & Software,Information Technology
Data Scientist,"You must have experience in build and evaluate predictive and decision models to be deployed in production systems, or for research.
You should have experience with one or more statistical or machine learning software such as R, Python.
You should have experience in analysis of large amounts of historical data, determining suitability for modeling, data clean-up and filtering, pattern identification and variable creation, selection of sampling criteria, generating performance definitions and variables.
You must have experience to Conducting experiments with different types of algorithms and models, analyzing performance, to identify the best algorithms to employ.
Architect and develop operational models that run at scale thru partnership with data engineer teams.
You should be background in applied statistical modeling on large experimental or observational data sets.
Must have experience extracting data from a variety of sources, and a desire to expand those skills (working knowledge SQL is required, Spark is a plus).","Lorven Technologies Inc
4.0","Santa Clara, CA",Accounting,Accounting & Legal
Data Scientist,"About Our AI/ML Team

Our mission is to build the best model-driven businesses. To do this, we make investments in industries where machine learning can be the most transformative. Beyond our initial investments, we give our portfolio companies a meaningful edge by helping them acquire and integrate incumbent businesses in order to enable such transformation. Essential to this approach is our Foundry team of experienced product managers, engineers, data scientists, and other specialists who take an active role to help portfolio companies execute on transformation initiatives while supporting our investment team with industry research and due diligence.

About This Role

As a data scientist on the AI/ML team you will be building models that transform our portfolio companies and entire industries. You will be involved in all parts of the data science lifecycle. That starts in partnership with the investment team where you'll learn about new industries and work with them to understand they key workflows and how ML can be applied. After an investment, you will partner with our portfolio companies combining their domain expertise with your ML knowledge to instrument their workflows, build representative datasets, and deploy trained models. All of these actions will be taken with an eye towards the goal of iterative, data-driven transformation of our portfolio companies while retaining and growing the strengths that were the basis of the original investment.

Primary Responsibilities
Developing a deep understanding of a portfolio company and identifying the correct business problem to address with ML
Train and evaluate machine learning models
Build datasets that support the training and evaluation of ML models
Analyze existing data assets to understand their scope, quality, and gaps
Requirements
Demonstrated experience building ML models to solve business problems
Strong software development background
Familiarity with common ML frameworks
Strong verbal and written communication ability
Passion for understanding quickly developing an understanding of new companies and industries
Travel up to 25% of the time",Point72 Ventures,"Palo Alto, CA",-1,-1
Data Scientist,"Data Scientist

We are a disruptive technology startup, building an innovative
energy monitoring solution that is radically changing consumer
perspective on energy efficiency. We have developed
ground-breaking analytics that can itemize home energy usage data
to the appliance level without using any plug-level monitors.
Now, we are setting out to deliver this technology to millions of
households across the world and capture a market that is
predicted to be billions of dollars in next few years. The
combination of big data in energy, data mining and consumer
advertising come together to make this world a greener place by
helping reduce energy consumption at a massive scale. We are
funded by one of the top cleantech VCs in Silicon Valley.

Position

We are looking for extraordinary Data Scientists to add to its
core team. The ideal candidate must enjoy diving deep into data
sets and finding interesting patterns through analytical
experiments run in a methodical way. Be part of a highly
energetic and innovative team that believes nothing is impossible
with some creativity and hard work. This is an unparalleled
opportunity to work with incredibly smart people.

What you can look forward to
Research and develop advanced statistical and machine
learning models for analysis of large-scale, high-dimensional
data.
Dig deeper into data, understand characteristics of data,
evaluate alternate models and validate hypothesis through
theoretical and empirical approaches.
Productize proven or working models into production quality
code.
Collaborate with product management, marketing and
engineering teams to understand requirements and develop
potential solutions.
Stay current with latest research and technology trends;
share knowledge by clearly articulating results and ideas to
key decision makers.
File patents for innovative solutions that add to company's
IP portfolio.

What you'll bring
MS/PhD in Computer Science, Statistics, Applied Math, or
related areas. Exceptionally strong candidates with a BS and
relevant work experience welcome.
Strong background in data mining, machine learning and
statistical analysis.
Expert pattern recognition and predictive modeling skills
(time series analysis, logistic regression, decision trees,
etc.).
Keen aptitude for large scale data analysis with a knack for
identifying key insights from data.
Fluency in programming languages like Java/Python.
Experience using Big Data
(Hadoop/Cassandra/HDFS/HBase/HIVE/Pig) is a plus.
3+ years hands-on practical experience with large scale data
analysis.
Fluency in analytical tools such as Matlab/R.
Strong communication and collaboration skills.",Stride Search,"Sunnyvale, CA",-1,-1
Data Scientist,"What you'll need:

Education
Master's/PhD (preferred) or Bachelor's (required) in CS/ML/AI or relevant computational/engineering discipline

Machine Learning/Data Science:
Solid theoretical understanding of ML fundamentals: linear algebra, probability, statistics (as relevant to ML), optimization
Knowledge of different ML techniques and when/how to use them: classification, regression, clustering, outlier detection, dimensionality reduction, etc.
Comfortable manipulating and analyzing complex, high-volume, high-dimensionality data from varying, heterogeneous sources
Experience with messy real-world data -- handling missing/incomplete/inaccurate data
Proficient in the Python ML ecosystem: NumPy, Pandas, SciPy, Scikit-Learn
Strong understanding of relational databases like PostgreSQL is a plus

Programming experience:
At least 2+ years of experience writing production-quality Python code
Version control: Git, GitHub/Bitbucket
Experience delivering large-scale deployable projects

Great to have
We deal with large volumes of geospatial data, so experience working with geospatial data at scale is a big plus
Knowledge of Python (Shapely, GeoPandas, Fiona, CartoPy, etc) and/or database (PostGIS) geometry/geospatial tools
Domain experience in building models for location-based services, transportation, scheduling, vehicle routing","Miles
2.3","Redwood City, CA",Internet,Information Technology
Data Scientist,"Data Scientist
Mountain ViewR&D - Machine learningExperienced
Responsibilities
Are you ready to take your career to the next level with a move to a fast-paced, audacious company and massive impact to the business productivity and collaboration space using the latest technologies? If yes, this is an opportunity of a lifetime!

What you'll do:
Team up with engineers to design learning solutions.
Develop processes and tools to monitor and analyze model performance and data accuracy.
Develop company A/B testing framework and test model quality.
Mine and analyze data from company databases to drive optimization and improvement of product development, marketing techniques and business strategies.
Use predictive modeling to increase and optimize customer experiences, revenue generation, ad targeting and other business outcomes.
Assess the effectiveness and accuracy of new data sources and data gathering techniques.
Create custom data models and algorithms to apply to data sets.
Coordinate with different functional teams to implement models and monitor outcomes.
Partner with international stakeholders in different time zones
Qualifications
- BS degree in Computer Science, Computer Engineering, Electrical Engineering or other relevant majors with 2+ years of work experience
2+ years of industry experience in predictive analytics and/or statistical modeling role
Ability to think critically and to formulate solutions to problems in a clear, concise and timely manner
Experience building data science models (Regression, Decision Trees, K-Means, etc.)
Experience with large data sets and analytical tools (e.g. Hive, Spark)
Proficiency in scripting languages (SQL, Python, R, etc.)
Experience working with international partners in different time zones
Apply
Share to","ByteDance
3.8","Mountain View, CA",Internet,Information Technology
Data Scientist,"Join us and make YOUR mark on the World!

Come join Lawrence Livermore National Laboratory (LLNL) where we apply science and technology to make the world a safer place; now one of 2020 Best Places to Work by Glassdoor!

We have multiple openings for Data Scientists to provide solutions for various projects. You will work in a dynamic, multidisciplinary team of independent/entrepreneurial computer scientists and engineers who research, develop, and integrate state-of-the-art algorithms, software, hardware, and computer systems solutions to challenging research and development problems. These positions are in the Computing Directorate.

These positions will be filled at either the SES.2 or SES.3 level depending on your qualifications. Additional job responsibilities (outlined below) will be assigned if you are selected at the higher level.

Essential Duties
Collaborate with scientists and researchers in one or more of the following areas: data intensive applications, text processing, graph analysis, machine learning, statistical learning, information visualization, low-level data management, data integration, data streaming, scientific data mining, data fusion, massive-scale knowledge fusion using semantic graphs, database technology, programming models for scalable parallel computing, application performance modeling and analysis, scalable tool development, novel architectures (e.g., FPGAs, GPUs and embedded systems), and HPC architecture simulation and evaluation.
Work with other LLNL scientists and application developers to bring research results to practical use in LLNL programs.
Assess the requirements for data sciences research from LLNL programs and external government sponsors.
Carry out development of data analysis algorithms to address program and sponsor data sciences requirements.
Engage other developers frequently to share relevant knowledge, opinions, and recommendations, working to fulfill deliverables as a team.
Design technical solutions independently, participate as a member of a multidisciplinary team to analyze sponsor requirements and designs, and implement software and perform analyses to address these requirements.
Develop and integrate components-such as web-based user interfaces, access control mechanisms, and commercial indexing products-for creating an operational information and knowledge discovery system.
Perform other duties as assigned.
In Addition at the SES.3 Level
Lead multiple parallel tasks and priorities of customers and partners to ensure complex deadlines are met.
Responsible for various complex projects, use team members’ skills to complete complex projects/tasks, and solve abstract complex problems/ideas and convert them into useable algorithms/software modules.
Provide solutions that require in-depth analysis of multiple factors and the creative use of established methods.
Qualifications
Bachelor’s degree in computer science, computer engineering, or related field, or the equivalent combination of education and related experience.
Comprehensive knowledge of one or more of the following: high performance computing, scientific data analysis, statistical analysis, knowledge discovery, computer security, systems programming, large-scale data management, and big data technologies.
Skilled in all aspects of the software project life cycle: feasibility, requirements, design, implementation, integration, test and deployment.
Experience developing software with C++, C, Java, Python, R, or Matlab, software applications in Linux, UNIX, Windows environments, data analysis algorithms, data management approaches, relational databases, or machine learning algorithms.
Demonstrated ability to effectively handle concurrent technical tasks with conflicting priorities, to approach difficult problems with enthusiasm and creativity and to change focus when necessary, and to work independently and implement research concepts in a multi-disciplinary team environment, where commitments and deadlines are important to project success.
Effective interpersonal skills necessary to interact with all levels of personnel.
Proficient verbal and written communication skills necessary to effectively collaborate in a team environment and present and explain technical information.
In Addition at the SES.3 Level
Effective advanced analytical, problem-solving, and decision-making skills to develop creative solutions to complex problems.
Significant experience with demonstrated expertise in the following technical languages, concepts, or constructs and in one or more of the following advanced areas: high performance computing, scientific data analysis, statistical analysis, knowledge discovery, computer security, systems programming, large-scale data management or big data technologies.
Advanced verbal and written communication skills necessary to effectively collaborate in a team environment and present and explain technical information and provide advice to management.

Pre-Employment Drug Test: External applicant(s) selected for this position will be required to pass a post-offer, pre-employment drug test. This includes testing for use of marijuana as Federal Law applies to us as a Federal Contractor.

Security Clearance: This position requires a Department of Energy (DOE) Q-level clearance.

If you are selected, we will initiate a Federal background investigation to determine if you meet eligibility requirements for access to classified information or matter. In addition, all L or Q cleared employees are subject to random drug testing. Q-level clearance requires U.S. citizenship. If you hold multiple citizenships (U.S. and another country), you may be required to renounce your non-U.S. citizenship before a DOE L or Q clearance will be processed/granted.

Note: This listing has multiple openings; these are Career Indefinite positions. Lab employees and external candidates may be considered for these positions.

About Us

Lawrence Livermore National Laboratory (LLNL), located in the San Francisco Bay Area (East Bay), is a premier applied science laboratory that is part of the National Nuclear Security Administration (NNSA) within the Department of Energy (DOE). LLNL's mission is strengthening national security by developing and applying cutting-edge science, technology, and engineering that respond with vision, quality, integrity, and technical excellence to scientific issues of national importance. The Laboratory has a current annual budget of about $1.8 billion, employing approximately 6,500 employees.

LLNL is an affirmative action/ equal opportunity employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, marital status, national origin, ancestry, sex, sexual orientation, gender identity, disability, medical condition, protected veteran status, age, citizenship, or any other characteristic protected by law.","Lawrence Livermore National Lab
4.7","Livermore, CA",Federal Agencies,Government
Data Scientist,"About the Role
We are seeking a Data Scientist who will be responsible designing, modeling and developing algorithms for Genalyte’s analytics platform. This position supports, gathers, creates and maintains data and workflows for data analysis, handling and management. We need an individual ready to develop scripts to analyze data from multiple data sources and recommends enhancements to data workflow processes, designs, builds, implements, improves and maintains high performance and highly scalable automated data pipelines.
Role is responsible for:
Design, develop, and maintain algorithms and models used in the health analytics platform that reflect the functional needs of the business.
Gather and maintain appropriate data required for the models.
Perform analysis of data for evaluation, validation and optimization.
Present analysis and results using charts, tables, and reports to functional technical and non-technical leaders.

About You
This role requires you to be a proficient technical expert with at least 3 years of working experience in a Data Scientist role. This role also requires a PhD or Master’s degree in Biostatistics, Statistics, Mathematics or a related field. Beyond education and years of experience, you should be experienced with multiple statistical programming languages such as Python, R or Matlab.

The most successful candidates will be those who are self-motivated and enthusiastic for working in fast-paced and collaborative environment.

About Genalyte
Since 2007, Genalyte has been guided by the vision of performing panels of tests and receiving results within a few minutes. As we look to the future, Genalyte’s technology will transform health care- moving lab testing from the lab into the physician’s office.

We are well funded with outstanding growth potential. We are looking for individuals inspired by our technology and vision, who are eager to be at the ground level of this collaborative and entrepreneurial company.

We want to hire individuals who are interested in creating an innovative, fast-paced and dynamic work setting. We offer a competitive salary and benefits package to attract, motivate, and retain the highest caliber of employee.","Genalyte
2.6","Sunnyvale, CA",Biotech & Pharmaceuticals,Biotech & Pharmaceuticals
Data Scientist,"Job Description
Title: Data Scientist

Location: San Jose, CA
Visa Type: US Citizen, Green Card and H4- EAD Only
Tax Terms: W2- Contract

Duration: 12+ Months

Job Description:

· Proven experience as a Data Scientist.

· Understanding of machine-learning and operations research

· Knowledge of R, SQL and Python; familiarity with Scala, Java or C++ is an asset

· Experience using business intelligence tools and data frameworks

· Strong math skills (e.g. statistics, algebra)

· Excellent communication and presentation skills

· BSc/BA in Computer Science, Engineering or relevant field; graduate degree in Data Science or other quantitative field is preferred",Plexova,"San Jose, CA",-1,-1
Data Scientist,"Job Description
Data Scientist – Simply Biotech

Are you looking for a new career opportunity with an exciting biotech company?! Then we have got the right team for you! In this role, you are responsible for the duties listed below.

Immediate opening for a Data Scientist in Palo Alto, CA who possess:
PhD in a quantitative field in the natural or social sciences e.g. statistics, economics, genetics, political science, etc.
Significant experience in R or Python
Proficiency working in Linux environment
Strong fundamentals in machine learning
Email your resumes to ajones@simplybiotech.com or call 858.251.3562

FULL DESCRIPTION: As a (Senior) Data Scientist, you will lead the development of modern statistical and experimental methodologies to discover actionable insights in our clinical and biological data. These insights will feed directly into our products and support our research and development efforts. You will work closely with an inter-disciplinary team of laboratory scientists, data scientists, and engineers to ensure the company meets its key milestones and objectives as well as identify additional opportunities where data science can bring real business value. You will also have the advantageous opportunity to collaborate on the data generation process itself.

The selected candidate will further possess:
Expertise in applied statistics
Experience working with datasets that cannot fit in a typical personal computer’s memory
Proficiency writing high-quality code, using version control, and maintaining documentation
Ability to communicate and collaborate with an inter-disciplinary team
Ability to translate business-level objectives to data science objectives
Experience with clinical or biological data e.g. genomics, proteomics, imaging, EMR
Experience with association studies in biological domains e.g. GWAS
Experience with study designs for assessing diagnostic tests
For immediate and confidential consideration, please email your resume to ajones@simplybiotech.com or call 858.251.3562

More information can be found at www.SimplyBiotech.com
Company Description
We are Kinetic Personnel Group! As our name implies, we are dedicated to keeping your career in motion by connecting exceptional candidates with great companies. We work with companies across a variety of industries both, locally and nationwide to keep their businesses moving forward. Our customers are established Organizations; large and small; in the private, public, and municipalities sectors. We partner with them to staff for a broad range of positions and across various functionalities, such as:

Accounting/Finance

Information Technology

Sales/ Customer Service

Engineering Disciplines

Manufacturing

Administration

Logistics

Benefits offered by Kinetic Personnel Group: Medical, Dental, Vision, Sick Pay, Longevity Pay, and Holiday Pay","Simply Biotech
4.8","Palo Alto, CA",-1,-1
Data Scientist,"Job TITLE: Data Scientist

Location: Santa Clara, CA

Term: Full Time

Skill: We are looking for a Data Scientist who has passion for data and can help us make smarter decisions to deliver even better products by discovering hidden information in vast amount of data. Primary focus will be on improving customer business outcomes through optimization and applying data-mining techniques, doing statistical analysis and building high quality prediction systems. Strong verbal and written communication, thoroughness and self-check personality are critical for success in this role.

• Build statistical & predictive analytics models that can be translated into various product strategy and marketing decisions
• Deep dive into data, understand hidden patterns and trends, build prediction models.
• Perform data analysis, gap analysis and drive to enhance data collection procedures by coordinating with the product team
• Coordinate with the infrastructure team for prediction model integration and to establish feedback loops thru machine learning and recalibration.
• Perform various analyses: sentimental analysis, market bucket analysis, cohort analysis, churns analysis.
• Build & monitor visually appealing real-time dashboards, as well as, develop Splunk queries & Splunk custom inputs.
• Drive for success across teams and customers
• Maintain and manage SLA
• Analyze individual issues in the context of overall platform to proactively identify larger problems
• Documentation of issues, resolutions and processes
• Contribute in data engineering efforts
• Coordinate and collaborate with development team to remain current on code and technology

Experience: • 4+ years of strong experience in Predictive Analysis, Machine Learning & Statistical Modeling using languages like Python, R, Ruby
• 5+ years of strong SQL and RDBMS experience
• 2+ years of strong experience of programming in languages like Python, C++, Java, Ruby
• 2+ years of experience working with AWS including services like RDS, Redshift, DynamoDB, Postgress, data pipeline
• 2+ years of experience in data visualization such as D3.js etc.
• 1+ years of experience working with cloud and web technologies including XML, JSON, HTML5, Web frameworks (Django, Flask), Elastic Search
• Experience with Splunk
• Experience with data analysis
• Desire and ability to learn new technologies
• Good applied statistics skills, such as distributions, statistical testing, regression, etc.
• Strong written and verbal communications skills
• Experience working with off-shore teams
• Passion of data and data driven decisions

Education: BIG PLUS:

• Experience with map-reduce paradigm with hadoop-hive environment
• Experience with NoSQL databases, MongoDB, Cassandra, HBase, Redis, Unstructured data
• Any type of contribution to open source community
• Experience with reporting tools Tableau, Pentaho BI
• Experience with ETL and Data-Warehouse","Flexton
4.0","Santa Clara, CA",IT Services,Information Technology
Data Scientist,"Facebook's mission is to give people the power to build community and bring the world closer together. Through our family of apps and services, we're building a different kind of company that connects billions of people around the world, gives them ways to share what matters most to them, and helps bring people closer together. Whether we're creating new products or helping a small business expand its reach, people at Facebook are builders at heart. Our global teams are constantly iterating, solving problems, and working together to empower people around the world to build community and connect in meaningful ways. Together, we can help people build stronger communities - we're just getting started.In this role, your primary responsibility will be to partner with key stakeholders and lead the development of an analytics program to support and enable the continued growth critical to Facebook's Data Center organization. You will be responsible for creating end to end analytics programs, from data sourcing to surfacing insights and driving action, for various aspects of Facebook's global data center operations. You will also help translate data and identify efficiency opportunities. You will be expected to use data to provide meaningful recommendations and actionable strategies to key stakeholders, and develop best practices, including streamlining of data sources and related programmatic initiatives.
The ideal candidate will have a passion for working in white space and creating impact from the ground up in a fast-paced environment. Additionally, you will have a proven track record of thought leadership and impact in developing similar analytics and metrics-based programs. This position is part of the Infrastructure Data Center team and located in Menlo Park, CA.

Responsibilities:

Leverage data and business principles to create and drive large scale FB Data Center programs
Define and develop the program for metrics creation, data collection, modeling, and reporting the operational performance of Facebooks data centers
Work cross-functionally to define problem statements, collect data, build analytical models and make recommendations
Be a self-starter, motivated by a passion for developing the best possible solutions to problems
Identify and implement streamlined processes for data reporting and communication
Use analytical models to identify insights that are used to drive key decisions across the organization
Routinely communicate metrics, trends and other key indicators to leadership
Provide leadership and mentorship to other members of the team
Lead and support various ad hoc projects, as needed, in support of Facebooks Data Center strategy
Build and maintain data driven optimization models, experiments, forecasting algorithms and capacity constraint models
Leverage tools like R, Tableau, PHP, Python, Hadoop & SQL to drive efficient analytics
Mininum Qualifications:

Degree in an analytical field (e.g. Computer Science, Engineering, Mathematics, Statistics, Operations Research, Management Science)
3+ years of experience in a role with data analysis and metrics development
3+ years of hands-on experience analyzing and interpreting data, drawing conclusions, defining recommended actions, and reporting results across stakeholders
3+ years of SQL development experience writing queries
3+ years of hands-on project management experience
3+ years of experience with data visualization tools
3+ years of experience with packages such as R, Tableau, SPSS, SAS, STATA, etc.
2+ years of experience with scripting in Python or PHP
Experience leveraging data driven models to drive business decisions
Experience using data access tools and building visualizations using large datasets and multiple data sources
Experience thinking analytically
Experience communicating data to all organizational levels
Experienced with packages such as NumPy, SciPy, pandas, scikit-learn, dplyr, ggplot2
Knowledge of statistics and optimization techniques
Hands-on experience with medium to large datasets (i.e. data extraction, cleaning, analysis and presentation)
Preferred Qualifications:

Technical knowledge of data center operations
Facebook is proud to be an Equal Opportunity and Affirmative Action employer. We do not discriminate based upon race, religion, color, national origin, sex (including pregnancy, childbirth, or related medical conditions), sexual orientation, gender, gender identity, gender expression, transgender status, sexual stereotypes, age, status as a protected veteran, status as an individual with a disability, or other applicable legally protected characteristics. We also consider qualified applicants with criminal histories, consistent with applicable federal, state and local law.

Facebook is committed to providing reasonable accommodations for candidates with disabilities in our recruiting process. If you need any assistance or accommodations due to a disability, please let us know at accommodations-ext@fb.com.","Facebook
4.5","Fremont, CA",Internet,Information Technology
Data Scientist,"Job Description
Are you an experienced Data Scientist with 2+ years’ experience who likes solving complex problems? Do you want to work for a rapidly-expanding technology division within a top Fortune 500 company that is driven by Data Science? Would you like to be part of a high caliber team who have access to huge volumes of real-time data?

An exciting, top Fortune 500 company in Sunnyvale is looking for a talented Data Scientists to join their growing team. This is a fantastic opportunity to join a vibrant company and work as part of a diverse and talented Data Science team.

As a Data Responsibilities will include:
Perform hands-on data exploration and modeling work on massive data sets.
Use data mining and machine learning techniques to develop robust models in areas such as segmentation and profiling, churn assessment, customer loyalty prediction, retention analysis, and product recommendation.
Pull data from warehouse, back-test models, perform feature engineering, compare model performances and communicate the results.
Architect, develop, and maintain data analytics platforms that visualize data and drive business insights that can be translated into product strategies and marketing decisions.
Research state of the art modeling techniques and implement them.
For this role you will need:
Technical expertise in data mining, machine learning, NLP, Information Retrieval, and statistical analysis.
Proficient in machine learning and data mining packages in R, Python, or Weka.
Experience working with large data sets and distributed computing tools (Map/Reduce, Hadoop, Hive, or Spark).
Expertise with shell scripting and automation.
Capabilities of managing end-to-end machine learning pipeline from data exploration, feature engineering, model building, performance evaluation, and online testing with big data set.
Experience with reporting tools such as Tableau and D3.js.
PhD in Computer Science, Statistics or related field; OR a Master’s degree or equivalent in Computer Science, Statistics or related field and 2 years of related experience.
Ability to work independently in a fast-paced, iterative development environment.
Exemplary communication skills, ability to work with large cross functional teams of technical and non-technical members.
Preferred Qualifications
Programming skills in one of the following languages: Java, Scala, C/C++ preferably on a UNIX or Linux platform.
Experience with ETL and Data-Warehouse.
Prior experience in eCommerce or Online Retail.
PROPRIUS is an AI Industry recruiting firm. We’re lucky enough to recruit the best candidates into the most exciting companies all over the United States. We deliver performance.","PROPRIUS
5.0","Sunnyvale, CA",Enterprise Software & Network Solutions,Information Technology
Data Scientist,Experiment engineers will be expected to help define and develop our core software for designing and deploying advanced experiments.,Gayathri's Sandbox,"Menlo Park, CA",-1,-1
Data Scientist,"Job Description
Role: Data Scientist.
Location: Foster City, CA
Hire Type: 12 Months Contract

Job Description:
Advanced degree in Data Science, Statistics, Computer Science, or similar.
Extensive experience as a Data Scientist.
Proficiency in R or Python, where the former is preferred.
In-depth understanding of SQL.
Competent in machine learning principles and techniques.
Demonstrable history of devising and overseeing data-centered projects.
Ability to relay insights in layman's terms, such that these can be used to inform business decisions.
Outstanding supervision and mentorship abilities.
Capacity to foster a healthy, stimulating work environment that frequently harnesses teamwork.","Centraprise
4.2","Redwood City, CA",IT Services,Information Technology
Data Analyst,"Data Analyst
If you are a Data Analyst with experience, please read on!

Job Title: Data Analyst
Job Locations: Redwood City, CA
Job Type: $45-$50/hr
Requirements:
1.) 3+ years experience creating dashboards in Business Intelligence (BI) tools (i.e. Tableau)
2.) Experience writing code in Python, R or similar language
3.) Bachelor's Degree
4.) Experience writing SQL Queries, and Excel Formulas
What You Will Be Doing
As a member of our team, you will be writing code that is readable in flat files, and processing data in several different ways and you will responsible for summarizing data results into files, charts, and graphs.
What You Need for this Position
Requirements:
1.) 3+ years experience creating dashboards in Business Intelligence (BI) tools (i.e. Tableau)
2.) Experience writing code in Python, R or similar language
3.) Bachelor's Degree
4.) Experience writing SQL Queries, and Excel Formulas

Preferred Skills:
1.) Salesforce experience
2.) Healthcare/Health Plan Analytics experience
What's In It for You
- Competitive Compensation $40 - $50/hr
- Benefits (Medical, Dental)
- PTO
So, if you are a Data Analyst with experience, please apply today!
-
Applicants must be authorized to work in the U.S.


CyberCoders, Inc is proud to be an Equal Opportunity Employer

All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, disability, protected veteran status, or any other characteristic protected by law.

Your Right to Work In compliance with federal law, all persons hired will be required to verify identity and eligibility to work in the United States and to complete the required employment eligibility verification document form upon hire.","CyberCoders
4.2","Redwood City, CA",Staffing & Outsourcing,Business Services
Machine Learning Engineer,"Machine Learning Engineer
Are you a Data Scientist with a strong Machine Learning background and want to join a profitable start-up? If so, please read on!

Based in the Palo Alto area, we are a leading AI SaaS Company! Our cutting edge software suite empowers businesses of all sizes to optimize their data on a secure platform! We are using the latest Machine Learning and Data Science technologies to help our clients see anywhere from 30-40% performance improvement over traditional methods! With these off-the-chart metrics, the demand for our innovative software solutions and services has gone through the roof! We now have an urgent need for talented Machine Learning Engineers to join our team!
Top Reasons to Work with Us
1. We are dedicated to building meaningful products that are changing lives!
2. Talented Technical Team utilizing the the latest technologies
3. Tons of room for career growth and Industry stability!
What You Will Be Doing
Join our collaborative team of talented Engineers as we continue to build and enhance new features for our dynamic applications!
- Work closely with cross-functional teams on generating ideas that you will then turn into efficient and functional code (python)
- Build and implement ML and statistical models based on pricing and behavioral analytics
-Develop design experiments, optimization systems and A/B testing
- Serve as the go-to resource for all data science related questions
What You Need for this Position
- 3+ years of professional experience in Data Science or Machine Learning
- Proficiency with Python and/or R
- Preferred experience with A/B Testing and Experiment Design
- Experience building practical Machine Learning solutions (ie. Neural Networks, xgboost, Gradient Boosted Decision Trees, Regression, etc.)
- Strong background in Pricing, Behavioral Economics and/or Demand Models
- Advanced Degree in Computer Science or related field
What's In It for You
EXCELLENT benefits including:
- Competitive salaries (DOE)
- Vacation/PTO
- Medical, Dental, Vision
- 401(k) and matching
- Catered meals and much more!
So, if you're a Machine Learning Engineer with strong experience, please apply today!

OR send your resume AND salary requirements to me directly at: brenna.boies@cybercoders.com
-
Applicants must be authorized to work in the U.S.


CyberCoders, Inc is proud to be an Equal Opportunity Employer

All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, disability, protected veteran status, or any other characteristic protected by law.

Your Right to Work In compliance with federal law, all persons hired will be required to verify identity and eligibility to work in the United States and to complete the required employment eligibility verification document form upon hire.","CyberCoders
4.2","San Jose, CA",Staffing & Outsourcing,Business Services
Statistician,"Statistical Scientist
ID

4135

Location


Menlo Park, CA

Practice/Center


Statistical and Data Sciences

Apply Now

Exponent is a leading engineering and scientific consulting firm that brings together more than 90 different disciplines to solve the most pressing and complicated challenges facing stakeholders today. Our vision is to engage the brightest scientists and engineers to empower clients with solutions for a safe, healthy, sustainable and technologically complex world. We leverage over 50 years of experience in analyzing accidents and failures to advise clients as they innovate their technologically complex products and processes, ensure the safety and health of their users, and address the challenges of sustainability.

We offer opportunities for you to expand your engineering or scientific knowledge amidst experts from top programs at over 500 universities. At Exponent, you will apply your experience, technical skills, and prior academic research to a fulfilling career in consulting. You will have the opportunity to develop continuously through formal and informal development programs, coaching and mentoring, and involvement in a wide array of projects. We are excited about your interest in joining our growing team!

Key statistics:
1100+ Team members
900+ Consultants
550+ Ph.D.’s
30+ Offices globally
We are currently seeking Statistical Scientists for our Statistical & Data Sciences Practice in our Menlo Park, CA office.

Your responsibilities will include:
Participation in diverse projects involving exploratory data analysis, statistical modeling, study design and analysis, and expert testimony
Application of risk analysis methodologies to problems in engineering, health, finance, ecology, and the environment
Development and management of projects
You will have the following skills and qualifications:
Ph.D. (or M.S. degree with two years' experience) in Statistics, Biostatistics, or a related field
Excellent communication skills and the ability to communicate statistical concepts to non-technical audiences
Experience or capabilities in such subject areas as statistical data mining, analysis of reliability and life data, experimental design, or quality control/improvement
Familiarity with one or more statistical software packages (knowledge of SAS is a plus)
Programming and data management skills (e.g., C++, SQL, Visual Basic, Python, Access) are especially desirable
To learn more about life at Exponent, check out our Graduate Students page at www.exponent.com/careers/grad-students!

We value and encourage diversity and inclusivity across all facets of our firm. Having a team built of people with different backgrounds, skills and perspectives allows us to provide better value to our clients and enjoy an enriched work environment.

Our firm is committed to offering a variety of programs and resources to support health and well-being. We believe that providing competitive benefits as well as compensation and recognition programs empowers our staff to do work that makes a difference.

Exponent is a proud equal opportunity employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, veteran status, disability, sexual orientation, gender identity, or any other protected status.

If you need assistance or accommodation due to a disability, you may call us at +1 (650) 688-6968 or email hr@exponent.com.","Exponent
3.5","Menlo Park, CA",Consulting,Business Services
Data Engineer,"Slalom is a purpose-driven consulting firm that helps companies solve business problems and build for the future, with solutions spanning business advisory, customer experience, technology, and analytics. We partner with companies to push the boundaries of what’s possible—together.

Founded in 2001 and headquartered in Seattle, WA, Slalom has organically grown to over 8,000 employees. We were named one of Fortune’s 100 Best Companies to Work For five consecutive years from 2016 - 2020 and are regularly recognized by our employees as a best place to work. You can find us in 35 cities across the U.S., U.K., Australia, and Canada.

The Data & Analytics teams across Slalom Northern California are all hiring! Come make an impact with our East Bay, Sacramento, San Francisco, or Silicon Valley markets.

Data Engineer Consultant

As a Data Engineer for Slalom Consulting, you'll work in small teams to deliver data pipelines and data models for our clients. You will design and build highly scalable and reliable modern data platforms including data lakes and data warehouse using Amazon Web Services, Azure, Google Cloud. Your work will include a variety of core data warehousing tools, Hadoop, Spark, event stream platforms, and ETL tools such as Airflow. In addition to building the next generation of data platforms, you'll be working with some of the most forward-thinking organizations in data and analytics.

Who are you?
You have passion for data!
You’re a smart, collaborative person who is excited about technology and driven to get things done.
You’re not afraid to be bring your authentic self to work.
You embrace a continuous learner mentality.
Who are we?
We are engineers, makers, planners, architects, and designers.
We choose to imagine things made better, and then set out on a journey to realize what’s possible.
We’ll never trade the upside of wonder for the comfort of the familiar or the safety of convention.
What technologies will you be using?

Every element of a modern data & analytics stack. It’s about using the right technologies to solve problems and playing with new technologies to figure out how to apply them intelligently. We work with technologies across the board.

Why do we work here?

Each of us came to Slalom because we wanted something different. We wanted to make a difference, we wanted autonomy to own and drive our future while working with some of the best companies in Silicon Valley leveraging the coolest technologies. At Slalom, we found our people.

Qualifications:
Bachelor’s degree in Computer Engineering, Computer Science, Information Systems or related discipline
3+ years relevant experience
Experience in capturing end users requirements and align technical solutions to the business objectives
Understanding of different types of storage (filesystem, relation, MPP, NoSQL) and working with various kinds of data (structured, unstructured, metrics, logs, etc.)
Understanding of data architecture concepts such as data modeling, metadata, workflow management, ETL/ELT, real-time streaming), data quality
3+ years of experience working with SQL
Experience with setting up and operating data pipelines using Python or SQL
1+ years of experience working on AWS, GCP or Azure
Experience working with data warehouses such as Redshift, BigQuery and Snowflake
Exposure to open source and proprietary cloud data pipeline tools such as Airflow, Glue and Dataflow
Experience working with relational databases
Experience with data serialization languages such as JSON, XML, YAML
Experience with code management tools (e.g. Git, SVN) and DevOps tools (e.g. Docker, Bamboo, Jenkins)
Strong analytical problem-solving ability
Great presentation skills, written and verbal communication skills
Self-starter with the ability to work independently or as part of a project team
Capability to conduct performance analysis, troubleshooting and remediation
Slalom is an equal opportunity employer and all qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, disability status, protected veteran status, or any other characteristic protected by law.","Slalom LLC.
4.1","San Jose, CA",Consulting,Business Services
Data Analyst,"Hi Associate, Role Name DataSystem Analyst Location San Jose, CA Duration Longterm Job Description Bachelor's degree in computer science or information technology, or equivalent experience Experience working with information technologies and systems analysis Strong computer, hardware, software, and analytical skills Proven ability to assess business needs and translate them into relevant solutions Strong understanding and knowledge of the principles and practices associated with database maintenance and administration Experience installing, configuring, documenting, testing, training, and implementing new applications and systems Working knowledge of a wide variety of programming languages Excellent analytical skills bull Meet and coordinate with internal and external stakeholders to establish project scope, system goals, and requirements Develop, analyze, prioritize, and organize requirement specifications, data mapping, diagrams, and flowcharts for developers and testers to follow Translate highly technical specifications into clear non-technical requirements Should be able to write complex PLSQL queries ------- Ankur Kumar Xcutives Global Headhunting Firm Sr. Talent Acquisition Specialist Ph no 1-470-891-5813 E-mail ankur at xcutives dot com www.xcutives.com httpwww.xcutives.com",Xcutives.com Inc,"San Jose, CA",-1,-1
Machine Learning Engineer,"At Liftoff, we're solving one of the core problems faced by every mobile app: growth. To do so, we build Machine Learning models and infrastructure that can accurately predict which apps a user will like and how to connect them in a compelling way. Our systems operate at a scale unseen outside of the largest Internet companies -- processing over a million requests per second and interacting with over a billion users. Our technology is creative and we have strong product-market fit; as a result, we've already reached profitability and are seeing tremendous growth.

As a Machine Learning Engineer at Liftoff, you will:
Own both the ML models and the underlying software tooling and infrastructure. Our ML Engineer role combines the classic ""ML Scientist"" and ""Data Engineer"" role at other companies.
Have a closed feedback loop from hypothesis generation to live AB testing, with no cross-team friction and sub-day iteration cycles.
Take on unique modeling challenges not covered in the scientific literature, like extreme positive sample sparsity and labelling delay.
Work with modeling techniques at the state-of-the-art of probability prediction, as well as a multitude of other ML areas from NLP to CNNs.
Become an expert in Clojure, Go, and the many other cutting-edge open source technologies that maximize our development velocity.
Join a nimble, consistently excellent, and experienced engineering team (former Google/LI/Ooyala/etc).
Desired qualities and experiences:
Very strong coding ability (experience in Go and Clojure is a plus).
2+ years of industry experience applying Machine Learning to large scale problems.
Strong core CS fundamentals (data structures, algorithms, architecting systems).
A passion for quality and excellence, and the ability to temper it when necessary to ship.
Sets ego aside in pursuit of finding the best solution, no matter where it comes from.
Self-motivated and a great ability to hustle.
B.S. or higher in Computer Science. PhD a big plus.
We are an equal opportunity employer and value diversity at our company. Come join our team and help us shape the future of mobile growth!","Liftoff
4.7","Redwood City, CA",Advertising & Marketing,Business Services
Statistician,"The U.S. Department of the Treasury has a distinguished history dating back to the founding of our nation. As the steward of U.S. economic and financial systems, Treasury is a major and influential leader in today's global economy. We have over 100,000 employees across the country and around the world. Come Join the Department of the Treasury and Invest in Tomorrow.
See Other Information for Locations
Positions are to be filled in the Large Business & International (LB&I), Data Solutions division.
Eight (8) positions are to be filled in any of the following locations:
Birmingham, AL
Fayetteville, AR
Little Rock, AR
Phoenix, AZ
El Monte, CA
Glendale, CA
Laguna Niguel, CA
Los Angeles, CA
Long Beach, CA
Oakland, CA
Sacramento, CA
San Diego, CA
San Francisco, CA
San Jose, CA
Santa Ana, CA
Lakewood, CO
Hartford, CT
New Haven, CT
Norwalk, CT
Washington, DC
Newark, DE
Miami, FL
Ft. Myers, FL
Jacksonville, FL
Maitland, FL
Plantation, FL
Tampa, FL
West Palm Beach, FL
Atlanta, GA
Honolulu, HI
Des Moines, IA
Chicago, IL
Downers Grove, IL
Schiller Park, IL
Springfield, IL
Indianapolis, IN
Wichita, KS
Louisville, KY
New Orleans, LA
Boston, MA
Brockton, MA
Stoneham, MA
Southborough, MA
Baltimore, MD
Lanham-Seabrook, MD
Rockville, MD
Ann Arbor, MI
Clinton Township, MI
Detroit, MI
Farmington Hills, MI
Flint, MI
Grand Rapids, MI
Pontiac, MI
Bloomington, MN
Chesterfield, MO
Lee's Summit, MO
Charlotte, NC
Greensboro, NC
Raleigh, NC
Omaha, NE
Edison, NJ
Iselin, NJ
Mountainside, NJ
Paterson, NJ
Las Vegas, NV
Albany, NY
Bethpage, NY
Buffalo, NY
New York, NY
Rochester, NY
Cincinnati, OH
Columbus, OH
Independence, OH
Oklahoma City, OK
Tulsa, OK
Portland, OR
Philadelphia, PA
Pittsburgh, PA
King Of Prussia, PA
Guaynabo, PR
Warwick, RI
Franklin, TN
Memphis, TN
Nashville, TN
Austin, TX
Farmers Branch, TX
Fort Worth, TX
Houston, TX
San Antonio, TX
Ogden, UT
Salt Lake City, UT
Norfolk, VA
Richmond, VA
Vienna, VA
Seattle, WA
Milwaukee, WI
Waukesha, WI
Kearneysville, WV
Martinsburg, WV
WHAT DOES A DATA SCIENTIST DO? The Data Scientist utilizes advanced analytical, statistical, and computer programming skills to develop data- driven solutions to difficult business challenges. As a data scientist, you are responsible for conducting data-centric projects to provide insight and informed decisions for mission- oriented programs of the Internal Revenue Service (IRS), which may impact multiple program segments, divisions, the Service, or segments of the taxpayer population. This is accomplished by utilizing a wide range of technical competencies such as statistics and machine learning, coding languages, data wrangling, and reporting and visualization techniques. The Data Scientist may lead team or cross functional projects, and will apply critical thinking, problem solving and ability to communicate complex analysis to advance the use of data-driven decision making in IRS operations.

WHAT IS THE LARGE BUSINESS AND INTERNATIONAL (LB&I) DIVISION OF THE INTERNAL REVENUE SERVICE? The Large Business and International (LB&I) business unit provides service and enforcement activities to support tax compliance of businesses and related entities with assets of $10 million or more, as well as small U.S. businesses engaged in international, U.S. citizens abroad, and foreign persons and businesses with a U.S. tax requirement.
As a Data Scientist, you will:
Serve as a technical expert with responsibility for the initiation, planning, implementation, controlling, modifying and executing of all or part of an entire project, including such tasks as formulation of workload estimates for program segments, specification of the methodology to be used, preparation of appropriate specifications and procedures, and review of computer systems specifications and materials and instructions needed for assuring the adequacy of the project’s design and objectives.
Explore novel methods of retrieving data and develop innovative recommendations to management and senior leadership as a means for making data driven decisions such as modification of processes and policies. Review, evaluate, validate, and document the results of the findings.
Assist the supervisor in determining the scope, goals and schedules for future programs in the Office. Collaborate with business or technology partners to understand business needs, identify opportunities, and develop and implement analytical solutions.
Identify and assess relevant data sources’ validity and reliability to meet project needs. Collate, clean, transform, analyze, and integrate structured and unstructured data from various sources in preparation for analysis.
Apply statistical methods and concepts including data mining, statistical theory and research procedures to test hypotheses using structured and unstructured data. Develop data product solutions to improve customer experiences, anomaly detection, and business outcomes. Develop proofs of concept or demonstrations to evaluate feasibility of project solutions and recommend visualization strategies.
Document project work and review deliverables for validity, reliability and timeliness. Communicate analytic solutions to technical and non-technical stakeholders, including during executive- level and/or cross-agency meetings, in a clear and effective manner using oral and written communications.
Maintain knowledge of state-of-the-art innovations in data science from both academic and industry sources and identify opportunities for implementation. Engage in general professional development to improve knowledge of IRS processes/programs.
Apply computer based mathematical/statistical techniques using software. Lead or participate in statistical projects or studies in survey sampling (design and estimation), modeling, or statistical research. Apply knowledge of programming/coding language (i.e., SQL, SAS, SPSS, RStudio) to develop scripts or applications.
Act as a troubleshooter in resolving bottlenecks at any step in a project by identifying and proposing solutions; this may include coordination with other project team members or stakeholders to mitigate issues.

WHERE CAN I FIND OUT MORE ABOUT OTHER IRS CAREERS? If you want to find out more about IRS careers, visit us on the web at www.jobs.irs.gov
#LI-POST
You must meet the following requirements by the closing date of this announcement
BASIC QUALIFICATION REQUIREMENTS:

GS-1530 Statistician All Grades:
You must have a Bachelor's degree that included 15 semester hours in statistics (or in mathematics and statistics, provided at least 6 semester hours were in statistics), and 9 additional semester hours in one or more of the following: physical or biological sciences, medicine, education, or engineering; or in the social sciences including demography, history, economics, social welfare, geography, international relations, social or cultural anthropology, health sociology, political science, public administration, psychology, etc. Credit toward meeting statistical course requirements should be given for courses in which 50 percent of the course content appears to be statistical methods, e.g., courses that included studies in research methods in psychology or economics such as tests and measurements or business cycles, or courses in methods of processing mass statistical data such as tabulating methods or electronic data processing. OR
Combination of education and experience -- courses as shown above, plus appropriate experience or additional education. The experience should have included a full range of professional statistical work such as (a) sampling, (b) collecting, computing, and analyzing statistical data, and (c) applying statistical techniques such as measurement of central tendency, dispersion, skewness, sampling error, simple and multiple correlation, analysis of variance, and tests of significance.
GS-13 LEVEL: You must have one year of specialized experience at a level of difficulty and responsibility equivalent to the GS-12 grade level in the Federal service. Specialized experience for this position includes all of the following:
Experience applying project management principles on a data science project
Experience planning and executing a variety of data science and/or analytics projects.
Experience using data mining process models (such as CRISP-DM, SEMMA, etc.,) to design and execute data science project.
Experience preparing and analyzing structured and unstructured datasets to explorations and evaluating data science centric models.
Experience working with multiple data types and formats as a part of a data science project.
Experience applying a range of analytic approaches, including (but not limited to) machine learning, text analytics, and natural language processing; graph theory, link analysis and optimization models; complex adaptive systems; and/or deep learning neural networks that are part of the exploration.
Experience coding in various programming languages (such as R, Python, SQL, or JAVA) to conduct various phases of data science projects.
Experience creating and querying different datastores and architectures (such as Sybase, Oracle, and open-source databases) to work with various types of data as part of the data science project.
Experience using tools for data visualization (graphs, tables, charts, etc.,) and end-user business intelligence.
-The experience may have been gained in the public sector, private sector or Volunteer Service. One year of experience refers to full-time work; part-time work is considered on a prorated basis.
-To ensure full credit for your work experience, please indicate dates of employment by month/year, and indicate number of hours worked per week, on your resume.","Internal Revenue Service
3.5","San Jose, CA",Federal Agencies,Government
Data Analyst,"We are hiring Data Analyst for our client in Redwood City, CA.

Job Title: Data Analyst

Duration: 12 Months
Job Location: Redwood City, CA

* Candidates must have 9+ years of experience.

* Candidates preferable USC, GC & H1B.

Job Description:

The ideal candidate will have worked in depth in data analysis, including experience extracting and manipulating data using SQL and Python. The candidate will have the opportunity to redefine the CRM Analytics for Auto Industry which will include data from multiple sources like telematics, campaigns, web, Service OLTP. The candidate will have the full opportunity for showing their creativity by owning the analysis, design and QA of data exploration and ETL. This is a hands-on individual contributor role. The candidate will be part of the Data Engineering team and work very closely with various product and engineering team members including the Product owners, Architect, DBA, and Application developers. To be successful, the candidate will have to be self-driven and a very strong team player.

Principle Responsibilities:
5+ years experience in SQL and manipulating large data sets in a database
2+ years of expertise of data analysis using Python, Spark in AWS Cluster.
2+ year of expertise analyzing and developing ETL data map for Oracle DB as source and target.
5+ year of QA expertise in ensuring quality of data in Data Warehouse loaded from various data sources.
Preferred expertise in building key data pipelines using AWS analytical services like S3, EC2, EMR, Glue, Athena.
2+ year of experience in working with DBA team to fix query performance issues in Oracle Data Warehouse.
2+ year of experience in providing production support for any data quality issues in Data Warehouse.
Expert level knowledge of both OLTP and Dimensional schema.
Excited to learn new technologies and analytical methodologies relating to business intelligence and data analysis.
Bonus Skills:
Knowledge of AWS cloud configuration.
Knowledge of full and incremental ETL using Informatica Power Center.
Knowledge of multi-tenant data warehouse for SaaS.
Application Requirements:
Interested candidates should submit resume/CV in both plaintext and PDF format, including desired salary range.
BS in Engineering and 10+ years development experience.
Position is on-site in the Redwood City/Redwood Shores area of California.
Thanks & Regards,

Raghu Singh","TechNet Inc.
5.0","San Jose, CA",Staffing & Outsourcing,Business Services
Software Engineer,"eBay is a global commerce leader that allows you to shape how the world buys, sells, and gives. Youll be part of a work culture thats been genuinely committed to diversity and inclusion since its founding more than 24 years ago. Here, you can just be yourself, do your best work, and have a meaningful impact on people across the globe. We are looking for people with drive, ideas, and a passion for helping small businesses succeed to help shape the future of eBaydoes this sound like you? If so, wed love to talk to you!

As a valued member of the team at eBay that develops outstanding behavior analytics products as well as generate insights through data science, you will make important contributions. You will design and build our behavioral data insights platform, deliver analytics product, combine qualitative and quantitative data to convince people with your actionable insights, and thus improve the user experience.

This role sits within the Data- and Tech- organization and works directly with partner analysts, data scientists, and engineers. We're looking for a highly skilled engineer, who is passionate about building and scaling a data platform for analytical and product uses cases.

People in the team are friendly, highly motivated, and very forward-thinking. Our team tries to maintain a work climate of integrity, innovation, career growth, and fun. We provide you with the best opportunity to work in a challenging, highly visible environment.

Key Responsibilities include:
Be a part of setting up a new generation of data framework involving real time, batch and micro-batch
Implement proof-of-concept prototypes for data governing, collection, analysis, and presentation.
Enable data-driven decision-making by collecting, transforming and visualizing data
Technical owner for new and existing product initiatives, assist with definition of product direction
Analyze data to gain insights to support business users optimize business process
Work with product managers and business analysts to build new analysis tools and metrics for measuring product performance
Estimate engineering effort, plan execution cycles, and roll out system changes.
Qualifications:
MS in Computer Science or a related technical discipline (or equivalent)
5+ years work experience in software development area
Excellent understanding of computer science fundamentals, data structures, and algorithms;
Extensive programming experience in Java/Scala/Python
Excellent problem solving skills
Experience of Spark, Hadoop, Map/Reduce, Kafka, Storm, etc is preferred
Working experience of ETL and data visualization is plus
Proven results oriented person with a delivery focus in a high velocity, high quality environment
Benefits:

Benefits are an essential part of your total compensation for the work you do every day. Whether youre single, in a growing family, or nearing retirement, eBay offers a variety of comprehensive and competitive benefit programs to meet your needs. Including maternal & paternal leave, paid sabbatical, and plans to help ensure your financial security today and in the years ahead because we know feeling financially secure during your working years and through retirement is important.

Here at eBay, we love creating opportunities for others by connecting people from widely diverse backgrounds, perspectives, and geographies. So, being diverse and inclusive isnt just something we strive for, it is who we are, and part of what we do each and every single day. We want to ensure that as an employee, you feel eBay is a place where, no matter who you are, you feel safe, included, and that you have the opportunity to bring your unique self to work.. To learn about eBays Diversity & Inclusion click here: https://www.ebayinc.com/our-company/diversity-inclusion/.

This website uses cookies to enhance your experience. By continuing to browse the site, you agree to our use of cookies

View our privacy policy

View our accessibility info

eBay Inc. is an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, national origin, sex, sexual orientation, gender identity, veteran status, and disability, or other legally protected status. If you are unable to submit an application because of incompatible assistive technology or a disability, please contact us at talent@ebay.com. We will make every effort to respond to your request for disability assistance as soon as possible.

For more information see:

EEO is the Law Poster

EEO is the Law Poster Supplement","eBay
3.6","San Jose, CA",Internet,Information Technology
Data Analyst,"""PL/SQL and SQL, to debug, understand and identify the issues which come up day to day. b. 1. Have strong communication & Analytical skills who can articulate very well with business and cross functional teams. 2. Candidate should know how the system works from integration perspective . For example : Systems will communicate via REST API, messengers , dB links etc.. 3. Communicating to India team’s with crystal clear explanation without any confusion. 4. MDM knowledge and Prior to Cisco experience would be great advantage to candidate. 5. Person should be in a position to debug the issue if we countered any issues while integrating with other systems. 6. Having Java , SQL , PL/SQL , REST API from integration perspective ,etc., who can quickly understand & debug the code.

“LTI values diversity and inclusion and is committed to the principles of Equal Employment Opportunity EEO/Minority/Female/Veteran/Disabled/Sexual Orientation/Gender Identity.”

Nearest Major Market: San Jose
Nearest Secondary Market: Palo Alto
Job Segment:
Database, SQL, Developer, Java, Cisco, Technology","LTI
3.5","San Jose, CA",IT Services,Information Technology
Statistician,"Lightup enables data-driven businesses to achieve their full potential. Modern businesses are dealing with unprecedented volumes of real-time data, operating in environments that are constantly changing internally and externally. To get the most out of data-driven operations, businesses need the ability to continuously measure the performance of their data-driven operations at fine granularity across the entire pipeline. Lightup is enabling businesses to continuously track vitals of their data-driven operations at the finest granularity, catch problems before their customers do, and fix them before they impact business.

The founding team brings together a unique combination of experience in big data, stream processing and rigorous statistical signal processing - crucial for building a data stability platform. We have over three decades of industry experience in multiple game changing startups and industry stalwarts like Google, GlobalFoundries and VMware. Lightup is funded by Andreessen Horowitz (a16z) and Spectrum28.

Lightup is looking for systematic stats cats
Masters or PhD in a quantitative discipline (e.g., Statistics, Mathematics, EE, Physics, Computer Science) or equivalent practical experience.
2 years of work experience in data science / analysis related fields

You are well-versed in the following:
Statistical data analysis such as linear models, multivariate analysis, stochastic models, sampling methods
Statistical software like R, Python Pandas, MATLAB
Applied experience with machine learning on large datasets
Understand engineering performance requirements and translate that to implementation

You also have some experience in:
Ability to use Spark (PySpark, SparkSQL) to run data analysis quickly.
Articulating and translating business questions and using statistical techniques to arrive at an answer using available data.
Striking a balance between statistical rigor and practicality; mastery of deep theory and love for simple stats
Designing model performance validation schemes and dealing with lack of labeled data
Instrumenting data-driven pipelines for continuous accuracy validation
Setting up data experiments and A/B tests in production setting

You might also have experience in:
Database query language like SQL
Work with streaming data pipelines like Kafka, Flink.
Knowledge and experience with Tensorflow, Pytorch etc.
Understanding of AI/ML techniques

Non-technical attributes:
Demonstrated leadership and self-direction.
Willingness to both teach others and learn new techniques.
Demonstrated skills in selecting the right statistical tools given a data analysis problem.
Effective written and verbal communication skills.
Ability to navigate under ambiguity.","Lightup Data, Inc.","Mountain View, CA",-1,-1
Data Analyst,"Data Analyst
10744
Menlo Park, CA
6/2/2020 2:54:00 PM

Learning
Contractor - W2

Job Description
Responsibilities

Primary
Query data and provide reports/query results to stakeholders
Manage requests and priorities independently
Provide documentation of queries/inbound requests for future use in improving GBM’s data infrastructure
Create new or improve existing dashboards by adding new metrics to support Business Education and other teams within the company

Secondary
Communicate with internal stakeholders about dashboards, and provide support about which metrics are available and from where
Understand existing data policy restrictions and determine if queries are possible to run/share
Skills

Minimum Qualifications

· 4+ years of experience in analytics or similar field

· Advanced proficiency in SQL

· Experience problem solving and providing business insights and recommendations from data

· Ability to manage multiple concurrent projects and drive initiatives in a cross-functional environment

· Ability to communicate complex data issues to audiences of different levels of technical expertise

Preferred Qualifications

· Experience building out large data sets and pipelines

· Python or similar scripting experience

Education

Minimum Qualifications

· Bachelor’s degree in a technical focus area

Preferred Qualifications

· MBA or graduate degree in a quantitative field

Job Requirements","IntraEdge
3.8","Menlo Park, CA",IT Services,Information Technology
Data Analyst,"As the leader in Lead-to-Account Matching, Routing and Marketing Attribution solutions, LeanData drives growth for business. We help many of the world’s fastest-growing enterprises automate, simplify and accelerate revenue.

As a key part of our Operations team, you’ll be our first Business Intelligence hire. You will be able to manipulate and analyze large data sets to find trends, identify errors, and solve business challenges that are presented. You’ll be a key member in maintaining high level Company Metrics and Dashboards to ensure that goals and targets are being met. You’ll build insightful dashboards and provide expert analysis and forecasting using LeanData’s technology stack. You’ll have exceptional analytical skills, strong collaboration and communication skills. You will have the opportunity to work directly with the executive team and make a large impact via data driven analyses.
What you'll be doing:
Review data dumps and reports to identify opportunities for business improvements
Assist Revenue Operations to insure that sales data remain accurate as new processes are applied
Create a single source of truth for ARR, renewals, pipeline, and other revenue related data
Assist Engineering and Product to analyze trends in product usage
Build and deploy standardized Metrics and Dashboards for the Company leadership team
Support the Customer Success team in accurately tracking quarterly net retention metrics and expiring ARR
Define, track and create key business metrics to help assess the overall health of the business
Work effectively with cross-functional teams
Perform ad-hoc and in-depth analysis
Requirements:
2-5 years experience in business or data analytics
Experience in building dashboards and models
Strong capabilities in using Excel to manipulate data sets and identify errors
Ability to work independently and as a member of various cross-functional teams
Proven ability leveraging analytical and problem-solving skills in a fast paced environment
Strong communicator, both written and verbal
Bonus points if you have:
Experience working with Salesforce.com
Experience working at growth-stage company
Why work at LeanData:
LeanData covers employee insurance premiums up to 90%
Stock options in LeanData for all full-time employees
Flexible PTO
401K plan
We warmly welcome into the LeanData family all persons without regard to ethnic and racial identity, indigenous heritage, national origin, religion, gender, gender identity, gender expression, sexual orientation, age, disability, marital status, veteran status, genetic information, or any other legally protected status.","LeanData
4.0","Santa Clara, CA",Enterprise Software & Network Solutions,Information Technology
Data Analyst,"Job Description
Job description

• Interpret data, analyze results using statistical techniques and provide ongoing reports

• Develop and implement databases, data collection systems, data analytics and other strategies that optimize statistical efficiency and quality

• Acquire data from primary or secondary data sources and maintain databases/data systems

• Identify, analyze, and interpret trends or patterns in complex data sets

• Filter and “clean” data by reviewing computer reports, printouts, and performance indicators to locate and correct code problems

• Work with management to prioritize business and information needs

• Locate and define new process improvement opportunities

Requirements

• Proven work experience as a data analyst or business data analyst

• Technical expertise regarding data models, database design development, data mining and segmentation techniques

• Strong knowledge of and experience with reporting packages (Business Objects etc), databases (SQL etc), programming (XML, Javascript, or ETL frameworks)

• Knowledge of statistics and experience using statistical packages for analyzing datasets (Excel, SPSS, SAS etc)

• Strong analytical skills with the ability to collect, organize, analyze, and disseminate significant amounts of information with attention to detail and accuracy

• Adept at queries, report writing and presenting findings

• Master's in Computer Science or Engineering Management or Project Management or Information Systems/Technology (Preferred)

Powered by JazzHR

SfTXVuhhoM","Staffigo Technical Services, LLC
5.0","San Jose, CA",IT Services,Information Technology
Data Analyst,"The Document Cloud Insights & Analytics team is looking for a Data Analyst who is passionate about using big data to deliver phenomenal customer experiences and to inform business decisions. Youll develop algorithms that analyze and derive insights from our massive product usage dataset, working in collaboration with the Journey team, product marketing, product managers, and engineering teams.

The Document Cloud Insights & Analytics team is looking for a Data Analyst who is passionate about using big data to deliver phenomenal customer experiences and to inform business decisions. Youll develop algorithms that analyze and derive insights from our massive product usage dataset, working in collaboration with the Journey team, product marketing, product managers, and engineering teams.

Key Responsibilities
Partner with various cross-functional teams (Engagement & Retention Journey, Data Science, Product, and marketing) to understand projections and target setting requirements through our Data Driven Operating Model, provide in-depth data analytics support and share associated business insights
Gather, synthesize and interpret disparate quantitative information sources using advanced statistical tools and techniques
Clean and prune data to discard irrelevant information, design analysis-ready datasets, and document all aspects of the data life cycle
Implement engagement and retention business models, test and optimize the customer experience, and monitor the outcomes in support of the Journey teams initiatives
Identify trends and make projections based on relevant metrics
Perform regular ad-hoc SQL data querying in Hadoop to provide analysis to better understand customer behaviors including acquisition, engagement, conversion, and retention
A strong proficiency in querying and manipulating large data sets for analytical purposes using SQL-like languages (Hive/Hadoop experience preferred)
Data Engineering experience
Familiarity with big data platforms such as Hadoop
Experience with programming language such as Python, R
Experience with data visualization tools such as Tableau/Power BI
Modelling in Excel or Power Pivot
Understanding of statistical modeling, machine learning, or data mining concepts, and a record of solving problems with these methods.
BA/BS in Engineering, Mathematics or other quantitative fields. Master is preferred. 3+ Years of industry experience
Excellent communication (verbal and written), relationship skills, and a strong team player
BA/BS in Engineering, Mathematics or other quantitative fields. Master is preferred.

Powered by JazzHR","IntelliPro Group Inc.
4.1","San Jose, CA",-1,-1
Software Engineer,"At the intersection of technology, science, business and sports, Strivr offers an end-to-end, VR-based immersive learning platform that changes the way people around the world train, learn, and perform. With a mission to elevate performance through immersive experience, we are redefining an industry in real time and shaping the future of learning.

Strivr was founded in 2015 out of Stanford University’s Virtual Human Interaction Lab, using the football field as our proving ground. Since then, we have quickly expanded from the athlete to the enterprise, partnering with leading Fortune 500 companies including Walmart, Verizon, and Fidelity to innovate and elevate employee development.

At Strivr, our engineering teams develop immersive experience software and a cloud-based software platform that powers the creation, management, and experience of immersive learning with a unique level of insights and predictive analytics. The platform is scalable, secure, and compliant which is critical to making our customers and users successful on our platform. The engineering team is distributed and located in offices in Seattle and Palo Alto. In addition to the five company values of teamwork, grit, transparency, impact, and passion, we index on strong communication skills, a growth mindset, responsibility and ownership, and a collaborative and respectful work culture.

We capture and analyze device, usage, sentiment, and assessment data, attention and engagement data based on spatial (gaze, hand) and voice data over tens of millions of in-headset immersive learning and training sessions. We are developing a streaming analytics platform that will allow us to process, join, aggregate, reform, and query data across these very large structured and unstructured datasets to produce immersive analytics with deep insights on learning sessions. Consumers include customers and external users for insights on their learning and training performance, and internal users like Data Scientists and Analysts who need access to raw and processed data from pipelines using notebooks and machine learning frameworks to develop, experiment with, and train learning models.

We are hiring software engineers who are passionate about data engineering and analytics, and developing secure, scalable, and reliable data pipelines and platforms. As an engineer working on the Strivr’s data platform, you will have the opportunity to own the full cycle development of distributed services, data pipelines, and infrastructure that needs to scale to process petabytes of data and deliver insights and immersive analytics to hundreds of thousands of users and devices, all in real-time access. You will be expected to prioritize scalability, reliability, and security in your designs and implementation. You will work cross-functionally with other engineering teams, Product Managers and Data Scientists to deliver end-to-end user-facing functionality and experience.

Your responsibilities:
Systems architecture, design, implementation, and support of the following platform areas and capabilities:
Real-time and batch processing pipelines to process data into logical data sets in data lakes and analytical databases
Business and semantic layer services to transform data into reports, insights, and immersive analytics
APIs for querying raw and processed data for consumption by user-facing visualizations and dashboards in web applications
Tooling and infrastructure for machine learning frameworks, notebooks, and pipelines for querying raw and processed data for training and experimentation
Tooling and infrastructure for data validation in the different phases of the pipeline and in the data stores
Tooling and infrastructure to implement and enforce security and compliance policies for data protection and governance
Write secure, reliable, and performant code and add monitoring for everything you develop
Be data-driven, use instrumentation and monitoring to make improvements to the platform, functional or for-performance, or otherwise
Be a visible technical leader in the organization. Influence engineers by advocating for and practicing a culture of engineering excellence. Mentor and coach lesser experienced engineers to make a positive impact on their career development
Minimum Qualifications:
5+ years of software engineering experience, specifically with development of data pipelines and platforms, and a solid background in software development with one or more of C#, Java, Go
Experience with development and operationalization of large-scale data pipelines and distributed services for structured and unstructured data using streaming frameworks and systems like Kafka, Beam, Spark
Strong database fundamentals including SQL and operational experience with relational (like Postgres) and non-relational databases (like Druid, BigQuery, Elastic)
Experience with development of a data platform with tools and infrastructure for machine learning, training models, and experimentation
Strong written and verbal communication skills, both technical and non-technical
Ability to apply concepts from computer science, data-structures, and algorithms in order to solve problems in a pragmatic and efficient way
Passion for writing secure, readable, modular, and maintainable code and a drive for shipping high quality software with an emphasis on testing, data validation, monitoring, and SLOs to ensure data accuracy with high availability
Bachelors in Computer Science or related field, or equivalent experience
Preferred Qualifications:
Experience developing secure and scalable API services based on GraphQL or REST for web applications
Experience developing on public cloud platforms (Google Cloud, AWS, or Azure) including experience with orchestration using Kubernetes and Docker
Experience with one or more of the following: Natural Language Processing, text understanding, classification, pattern recognition, or similar","Strivr
4.5","Palo Alto, CA",Computer Hardware & Software,Information Technology
Software Engineer,"Senior/Staff Software Engineer, Data Infrastructure job posting

Every year, while Americans wait for their paychecks, more than $1 trillion of their hard-earned money is held up in the pay cycle. As a result, we accumulate over $50 billion in late and overdraft fees and turn to high-interest loans. Overdraft charges and bank fees often trap people in a cycle of debt that can lead to unhealthy decisions and falling victim to predatory businesses disguised as helpful services. We don't accept that.

Earnin is an app that creates products that help people gain control of their finances. Cash Out lets people get paid as soon as they leave work, with no fees, interest, or hidden costs. With Health Aid, Earnin negotiates on behalf of community members to lower their total unpaid medical bill and work out a budget-friendly payment plan. Cash Back Rewards is a way for members to earn up to 10% cash back on purchases from over a thousand local and national businesses without needing a credit card or having to reach spend thresholds to earn cash rewards — and they can withdraw the money at any time. We also offer free tools to help avoid overdrafts, to remind people when recurring bills are due, and we're working on more! There is never any required cost to use any of these products or services, users can choose to tip what they think is fair to support the service and pay it forward to keep the movement going.

Earnin is supported by funding partners including Andreessen Horowitz, Matrix Partners, Ribbit Capital, Felicis Venture, Thrive Capital, and others. Join us and help build a new financial system focused on fairness and people's needs.

You can help make a difference.

About the Team:

We are a data driven mobile financial tech company. The Data Infrastructure team builds the data services and data infrastructure that powers data science, analytics, and product development throughout Earnin. We are looking for a product-minded, self-driven Senior Software Engineer to own multiple large-scale projects that advance our mission of enabling people to gain access to their paycheck on demand.

What sets us apart:
High impact roles at a relatively small company that's aggressively growing our user base.
We are a collaborative team and genuinely enjoy working with each other.
We believe in empowering our people to be successful.
We're building a product that inspires fairness across the financial world and helps people not get taken advantage of.
As a Senior Engineer you will:
Break down complex problems into their bare essentials, translate this complexity into elegant design and create high quality, maintainable code.
Build massively scalable, production-grade data services.
Champion data quality and governance throughout the organization.
Build a world class data lake and data warehouse.
Design and develop new systems and tools to enable all of Earnin to consume and understand data faster.
Own the end to end design, build, and maintenance of platform services, data pipelines, and data products.
Implement comprehensive monitoring, logging, and alerting across our data infrastructure.
Work cross functionally with other teams (data science, design, product, marketing, and analytics) in high visibility roles as an engineering leader.
Build and deploy the data architecture that supports machine learning model development and actionable analytics.
Work with product engineering and data science teams to design scalable, performance model deployment architectures.
Communicate the tradeoffs of technical decisions to multiple stakeholders, including non-technical audiences.
Collaborate with and mentor other engineers and provide engineering direction to data scientists and analysts.
Actively engage and drive design reviews and code reviews.
Some skills we consider critical to being a Senior Engineer:
BS or MS degree in Computer Science, Engineering, or a related technical field.
8+ years of development experience in a fast-paced environment, especially startups.
5+ years of experience working with data systems.
Strong Python and SQL skills.
Strong programming and architecture skills.
Excellent written and verbal communication skills, including the ability to identify and communicate data driven insight.
Taking pride in your code quality and helping others elevate their own code quality.
Substantial experience with testing, data validation, and data quality assurance.
You can articulate the tradeoffs of different deployment architectures (e.g. streaming vs. batch vs. service-based).
Experience designing data platforms and services on cloud infrastructure, preferably AWS.
Hands-on experience designing and building large-scale solutions with the Hadoop stack and/or Spark.
Experience tuning and optimizing Spark-based applications.
Experience deploying and/or using query engines like AWS Athena, Presto, and Impala.
Experience with AWS analytical services like Redshift.
Hands-on experience working with a varied set of data storage technologies (e.g. Mysql, Postgres, DynamoDB, S3, etc.). You know where and when to use each.
Extensive experience with data modeling for multiple use cases and application styles, including NoSQL data modeling.
Experience working with data formats such as Avro and Parquet.
Experience working with alerting and monitoring tools like DataDog and PagerDuty.
Nice to haves:
You have experience building and deploying machine learning models.
You have experience using Terraform.
You have substantial experience working at a startup.
You have experience with data modeling in Redshift.
Experience with streaming infrastructure like Kafka.
Experience working with Kubernetes.
Experience building and deploying AWS Lambda applications.","Earnin
3.1","Palo Alto, CA",IT Services,Information Technology
Data Analyst,"Job Description
Accounting Principals is hiring a Data Analyst for a six month project in San Jose, CA. As an Engineering Operations Data analyst you will collect, monitor and analyze data/ This includes financial Forecasts and budgets, contracts and purchasing.

Responsibilities:
Assess financial status by analyzing actual results in comparison with forecasts
Produce reports, which include key metric trends, financial results, and variance reporting to engineering leaders
Lead budgeting and forecasting processes for the engineering departments
Support engineering leaders with managing contracts and purchasing for equipment, services and contractors
Optimize contract management processes for the engineering departments
Assemble and summarize data on operational metrics such as cost of services, project accounting, and product quality
Develop data models, perform analysis, identify trends and risks, and recommend actions on operational metrics
Skills:
2+ years of relevant experience in corporate business or financial planning & analysis, or other related fields
Proficient in spreadsheets, data models and large datasets
Hands on experience with statistical analysis
Excellent analytical and problem solving skills
Outstanding verbal and written communication skills
Bachelor’s degree in business, economics, computer science or similar experience
Employment Type: Temporary, 40 hours per week
Company Description
Allow us to introduce ourselves, We're Accounting Principals--a leader in finance and accounting staffing. In fact, since 2010, we've been part of Adecco Group, a Global 500 company and leader in staffing services around the world. But this isn't staffing as usual. We take quite a different approach than most staffing agencies. A people-focused approach. We believe in forming real relationships with both our clients and our candidates. We want to understand the needs on both sides. It's not enough to match a resume to a job opening. We want to find the right balance between skills and requirements, career goals and business objectives, and personality and team culture. That way, everyone wins.

Equal Opportunity Employer/Veterans/Disabled
To read our Candidate Privacy Information Statement, which explains how we will use your information, please visit https://www.accountingprincipals.com/privacy-policy/
The Company will consider qualified applicants with arrest and conviction records.","Accounting Principals
3.9","San Jose, CA",Staffing & Outsourcing,Business Services
Machine Learning Engineer,"AppZen delivers the world’s leading AI platform for modern finance teams. Starting with business spend, we automate manual process, uncover problems, and optimize decision making for enterprises around the globe, including one-fourth of the Fortune 500. Our platform combines patented deep learning, computer vision, and semantic analysis with intelligence from thousands of online data sources to understand financial transactions in business context and make decisions before those transactions happen. AppZen is a must have for CFOs and their teams to reduce spend, achieve compliance, and streamline process.

We’ve taken off this year! Since we released our platform in 2016, over 1,800 enterprises have standardized on AppZen, including three of the top ten banks, four of the top ten media companies, three of the top ten pharmaceutical manufacturers, two of the top five aerospace companies, and five of the top ten software providers. We were a Gartner Cool Vendor last year, have been recognized as one of the fastest-growing technology companies in the market, and we just announced $50 million in Series C funding.

We are looking for a Machine Learning Engineer to come and work on our growing AI stack. You will be working with a team of highly skilled machine learning engineers. If you are excited about computer vision and natural language processing, AppZen is the right place for you to apply and grow your skills.

Must-Have:
Solid understanding of machine learning fundamentals, and familiar with standard algorithms and techniques
Ability to analyze a wide variety of data: structured and unstructured, observational and experimental, to drive system designs and product implementations Expert knowledge of a statistical computing language such as Python
You should have a knack to solve problems in a creative manner: when annotation is not available, identify how to use the existing data and get going
Knowledge of probability and statistics, including experimental design, predictive modeling, optimization, and causal inference. Experience in design and deployment of real-world, large-scale, user-facing systems
Ensure data quality throughout all stages of acquisition and processing, including such areas as data sourcing/collection, ground truth generation, normalization, transformation, cross-lingual alignment/mapping, etc.
Manage your own process: identify and execute on high impact projects, triage external requests, and make sure you bring projects to conclusion in time for the results to be useful
Must have 4+ years of industry experience
Preferred:
Excellent written and verbal technical communication skills; communicate proposals and results in a clear manner backed by data and coupled with actionable conclusions to drive business decisions
M.S. or equivalent experience in Computer Science/Engineering with graduate level experience in ML and/or Statistics, or other relevant technical field
Come as you are, we do not discriminate! We celebrate, support, and thrive upon our diverse customer and employee base.","AppZen, Inc.
3.8","San Jose, CA",Financial Transaction Processing,Finance
Data Engineer,"Get your career started at eHealth


eHealthInsurance has many exciting career opportunities in a number of locations, across various functions. Come join us today!

Data Engineer

At eHealth, we are passionate about solving our nation's toughest problems to bring more suitable, accessible, and affordable health insurance to Americans. We are seeking a talented data engineer to join our growing data team, which is already making a valuable impact on the entire company. This person will help us develop cutting-edge data tools and pipelines to drive better and faster decision making within our company and to better serve our customers. This is a fast-paced, collaborative, and iterative environment requiring quick learning, agility, and flexibility.

Responsibilities:
Become the subject matter expert on our data and its capabilities. Your scope of knowledge will need to include various data systems that are specialized to internal departments and 3rd party data platforms.
Design and build highly scalable data integration / ETL pipelines to improve data accessibility and consumption.
Automate data processing using workflows tools to schedule and manage dependency of various data pipelines.
Work directly with data scientists to develop scalable implementation of statistical and machine learning models in production, and work with software engineers to design, build, and maintain APIs to interact with those models.
Recommend ways to improve data reliability, efficiency, and quality.
Assist eHealth’s data architect with logical and physical data model designs and documentation.
Work with data infrastructure team to triage issues and support issue resolution.
Minimum Qualifications:
Bachelors or Masters in Computer Science, Engineering, or a related quantitative field.
2+ years of experience with designing, implementing and maintaining scalable and reliable data pipelines
Mastery of SQL in writing complex and high performance queries
Working experience with MPP systems (Snowflake, Spark SQL, Hive) and NoSQL systems (MongoDB, etc).
Production coding experience with Python, Scala or Java and scripting languages (Unix shell) as well as solid experience with git.
Expertise with relational databases and experience with schema design and dimensional data modeling.
Working experience with various ETL technologies and frameworks (Pentaho, Informatica, Matillion, etc.)
Knowledge of AWS data tools.
Excellent communication skills.
Highly motivated problem-solver who enjoys working in a fast-paced environment and can also be patient with the pace of highly regulated industries like healthcare.
Nice to Have:
Experience collaborating with data science team.
Strong experience in designing and implementing data APIs.
Product familiarity with Adobe Analytics, Cisco systems, Snowflake.
Familiarity with workflow management tools (Airflow).
Working experience with data warehousing.
Ability to create beautiful data visualizations using D3, Tableau, or similar tools.
Working experience with large healthcare related datasets, including EHRs, medical claims data, and health population surveys. Experience in building healthcare data pipelines would be a big plus.
Knowledge of healthcare insurance industry, products, systems, business strategies, and products.
Experience working with call center operations.
eHealth is an Equal Employment Opportunity employer. It is our policy to provide equal opportunity to all employees and applicants and to prohibit any discrimination because of race, color, religion, sex, national origin, age, marital status, sexual orientation, genetic information, disability, protected veteran status, or any other consideration made unlawful by applicable federal, state or local laws. The foundation of these policies is our commitment to treat everyone fairly and equally and to have a bias-free work environment.

If you are interested in applying for employment with eHealth and need special assistance or an accommodation to apply for a posted position contact us at: accommodations@ehealthinsurance.com.","eHealth
3.8","Santa Clara, CA",Insurance Agencies & Brokerages,Insurance
Machine Learning Engineer,"The Opportunity


The machine learning effort is part of the Data Science team at Livongo and works closely with product managers, engineering and operations to identify, build, ship and maintain machine learning models and pipelines to personalize how our members manage chronic conditions.

This is an opportunity to use technical rigor to apply machine learning to real-world business problems, and engineer, deploy, measure and iterate ML in production, for every Livongo member.

Responsibilities:
Design, develop, deploy and maintain production grade data processing, machine learning and deep learning code, pipelines and systems.
Study and transform data science prototypes. Use Python, Tensorflow, PyTorch, and Keras to run exploratory analyses using both traditional and deep-learning techniques. This includes feature engineering, unsupervised learning, supervised learning, reinforcement learning.
Run machine learning tests and experiments; measure the performance of deployed models; work with data scientists to propose improvements and iterate to improve performance.
Manage machine learning model lifecycle: develop, deploy, monitor, maintain and update models in production.
Research and implement appropriate ML algorithms and tools.
Develop machine learning applications and services according to requirements.
Select appropriate datasets and data representation methods
Perform statistical analysis and fine-tuning using test results
Train and retrain systems when necessary
Extend existing ML libraries and frameworks
Keep abreast of developments in the field.
Collaborate closely with product management and engineering teams to drive requirements and define new product features and architecture.
Candidate Profile
Advanced degree in computer science, math, statistics or a related discipline
Proven experience as a Machine Learning Engineer or similar role
Deep knowledge of math, probability, statistics and algorithms
Ability to write robust code in Python, Spark, SQL, R or Java.
Familiarity with machine learning frameworks (like Keras or PyTorch) and libraries (like scikit-learn)
Knowledge of Hadoop or other distributed systems.
Experience with ML systems, recommendation engines, NLP, etc.
Extensive understanding of data structure, data modeling and software architecture
Experience in end-to-end machine learning model development, deployment and production.
Experience with agile sprint processes to deliver ML work.
Experience in ML CI/CD process; and familiar with Jenkins, dockers, Databricks, git code management, etc.
Experience designing and building useful, maintainable code for model training, evaluation and interpretation.
Familiarity with the entire ML algorithm life-cycle (modeling approach ideation, POC, data exploration, data processing, feature extraction, feature construction, model development, evaluation, iteration).
Willingness to learn new ML platforms and tools, as well as propose and help teams adopt new tools.
Experience in close collaboration with backend software engineer, data engineering team; as well as business owners to establish ML A/B testing platform.
Great active listening skills to infer product needs and underlying context.
Ability to collaborate effectively with peers, and respect for member privacy
Why Join Livongo?


The Transformative Name in Healthcare: The transformative industry forces in Community, Content and Commerce are now household names. As Amazon is to Commerce, Livongo is to Healthcare. With our Applied Health Signals engine, AI+AI, we've transformed how care is delivered.

Our Work Truly Matters: Livongo's proprietary, consumer-first technology is revolutionizing the experience of living with a chronic health condition. Our data-driven digital health engine enables our Members to seamlessly manage multiple health conditions on one empowering platform. We use smart, connected devices, personalized digital guidance, and 24x7x365 access to health professionals to make it easier for people to stay healthier.

Make an Impact: Do you want to accomplish something meaningful? To create results that matter? Livongo's innovative solution produces industry-leading member satisfaction, measurable clinical outcomes and proven healthcare costs savings. Here you can truly improve lives.

The Largest Digital Health IPO in History: We are at a milestone period in our history. On July 25, 2019 we took our company public, in order to elevate and expand the way the industry views us, thus ushering us into a whole new set of mission-critical conversations that will help us accomplish the work still to be done. As we reach new levels of achievement, we accelerate our ability to deliver life-changing services.

Focus on PEOPLE: Livongo has been voted one of the Best Places to Work in healthcare, by Fortune Magazine and Best Place to Work! Talented, passionate individuals make the difference, in this fast-moving, collaborative and inspiring environment.

Diversity and Inclusion: At Livongo we believe that personal and professional diversity is the key to innovation. We hire based solely on your strengths and qualifications, and the way in which those strengths can directly contribute to your success in your new position.

Growth and Innovation: We've already made healthcare history, yet we remain on the threshold of very big things. Leading the industry with our Applied Health Signals category, we have cracked the code to transforming healthcare. Come grow with us and support our mission to make a tangible difference in the lives of our Members.

See photos, watch videos and learn more about Livongo: follow us on Glassdoor.

As an Equal Opportunity Employer, we never have and never will discriminate against any job candidate or employee due to age, race, religion, color, ethnicity, national origin, gender, gender identity/expression, sexual orientation, membership in an employee organization, medical condition, family history, genetic information, veteran status, marital status, parental status or pregnancy (including breastfeeding we have a mother's room in both our offices). In our innovative and inclusive workplace, we prohibit discrimination and harassment of any kind.

#LI-Remote","Livongo
4.6","Mountain View, CA",Health Care Services & Hospitals,Health Care
Data Engineer,"Grow your career at AppLovin.

AppLovin is a global leader in mobile entertainment. Its studios create popular, immersive mobile games and its technology brings games to more players around the world. Since 2012, the company's platform has been instrumental in driving the explosive growth of mobile games, resulting in a richer ecosystem and more games played by millions of people every day. AppLovin is headquartered in Palo Alto, California with several offices globally. Learn more at applovin.com.

AppLovin is one of Inc.'s Best Workplaces and a recipient of the 2019 Glassdoor Top CEO employee's choice award. The San Francisco Business Times awarded AppLovin one of the Bay Area's Best Places to Work in 2019 and 2020, and the Workplace Wellness Award in 2019 which recognizes businesses that are leaders in improving worker well-being.

About You:
Have 1-3 years of experience and a minimum of a BS and/or MS in Computer Science
Have excellent knowledge of computer science fundamentals including data structures, algorithms, and coding
Experience independently creating and maintaining projects
Product focused mindset
Have experience working with big data systems (Spark, Hadoop, Pig, Impala, Kafka)
Experience designing, building, and maintaining data processing systems
Experience with a backend language such as Java or Scala
About the Role:
Collaborate with various engineering teams to meet a wide range of technological challenges
Work closely with product and business teams to improve data models that feed business intelligence tools
Define company data models using Spark
Perks:
Free medical, dental, and vision insurance
Daily lunches and fully stocked kitchen
Free public transit
Free laundry service (wash/dry clean)
Free gym membership
401k matching
Fun company parties and events
Autonomy to make decisions in a rapidly growing company
Flexible Time Off - work hard and take time when you need it
Interested? Send us your resume and let's talk!

#LI-JZ1","AppLovin
4.8","Palo Alto, CA",Video Games,Media
Data Engineer,"Data Engineer
If you are a Data Engineer with experience, please read on!

+ Biotech/Pharma/Life Science experience strongly preferred +

We are a life sciences company working on providing liquid biopsies, tests that look for key molecular signatures of disease in blood, and other patient samples, without the need to take a tissue sample. We want to develop tests that diagnose or screen patients before they show any symptoms. A huge goal that other academic groups and companies are also pursuing, with large clinical trials enrolling many thousands of patients already underway. We do it for a fraction of the cost. Our main focus is early disease detection because thats what we see as the biggest need in patient care. If you want to be part of a trailblazing company read on.
Top Reasons to Work with Us
+ We are well funded. Our series D back on December 19' was $55 million.
+ We are a team of industry-leading experts in our field!
+ Be part of a 2-year-old start-up that is growing exponentially over the next few years.
+ Competitive pay and full benefits package
What You Will Be Doing
- Design, develop, and maintain performance measure visualizations and reports using data visualization tools.
- Work with the Data Science team to understand the business needs to design an effective and dynamic visualization.
- Work the Product Management team to understand and gather the user experience data.
What You Need for this Position
3-5 years of experience in the following required:

- Python, Django, AWS, SQL
- Data Visualization tools such as Qlik Sense, Power BI, Tableau.
What's In It for You
Competitive Pay
Full Benefits Package
So, if you are a Data Engineer with experience, please apply today!

1. Apply directly to this job opening here!

Or

2. E-mail directly for more information to Marcus.Quigley@cybercoders.com
-
Applicants must be authorized to work in the U.S.


CyberCoders, Inc is proud to be an Equal Opportunity Employer

All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, disability, protected veteran status, or any other characteristic protected by law.

Your Right to Work In compliance with federal law, all persons hired will be required to verify identity and eligibility to work in the United States and to complete the required employment eligibility verification document form upon hire.","CyberCoders
4.2","Redwood City, CA",Staffing & Outsourcing,Business Services
Statistician,"Roche Sequencing Solutions (RSS) is getting ready to push the boundaries of medical diagnostics with a bleeding-edge new DNA sequencer. We use biophysics and biochemistry to read DNA at the single molecule level, attaining exquisite resolution and accuracy at a massive throughput. Developing our unique platform requires expertise across a range of fields: biophysics, biochemistry, software engineering, data science, machine learning, protein engineering, and circuit design, just to name a few. We combine the entrepreneurial spirit and agility of a startup with the stability and long-term view of Roche.

The Statistical Modeling team’s primary mission is to mathematically model the sequencer and use those models to guide research and development within RSS. This is a tremendous responsibility and we are seeking an equally talented Principal Data Scientist II. As an integral part of our team, you will contribute your creativity, expertise and relationships to develop biophysical and electrochemical mathematical models for the sequencer, and use those models to improve internal R&D pipelines and simulate future performance and designs. You will also perform deep dives into data and distill both experiments and simulations to help guide experimental teams in hitting both near-term development targets and multi-year moonshots.

Our culture is very open, innovative and supportive. Join us in driving the genomic revolution!

Responsibilities Include:
Build strong working relationships with experimental teams to provide guidance
Develop biophysics and electrochemical models
Commit to work proactively and collaboratively, find opportunities to enhance processes
Write elegant, readable code
Contribute to our evolving simulation and inference pipelines
Assist experimental groups with statistical modeling and analysis
Perform deep analyses on experimental data using a variety of internal pipelines
Collaborate with bioinformatics, signal processing, deep learning, and software engineering teams
Responsible for planning and timely delivery of assigned projects.
Minimum Qualifications:
PhD degree in Physics, Biophysics, or related scientific discipline, plus a minimum of 5 years of experience
Very strong foundation in modeling, simulation, inference, with an academic or industry track record
Very strong foundation in Data Science and analytics
Strong algorithms development skills: Python, C++
Track record in cloud and cluster computing
Fluency with modern software engineering practices: version control, code reviews, automated testing, etc.
Previous experience in DNA sequencing or bioinformatics
Clear thinker and communicator, verbal and in-writing; collaborative attitude
Roche is an equal opportunity employer.

Research & Development, Research & Development > Modelling & Simulation","Roche
4.1","Santa Clara, CA",Biotech & Pharmaceuticals,Biotech & Pharmaceuticals
Data Analyst,"Please call me at 510-962-9661 or send me your updated resume at amit.kumarradiansys.com. Job Title Data Analyst Location Santa Clara CA Duration Contract on W2 Only Job Description below. Meet and coordinate with internal and external stakeholders to establish project scope, system goals, and requirements Develop, analyze, prioritize, and organize requirement specifications, data mapping, diagrams, and flowcharts for developers and testers to follow Translate highly technical specifications into clear non-technical requirements Should be able to write complex PLSQL queries","Radiansys, Inc.
3.4","Santa Clara, CA",Advertising & Marketing,Business Services
Data Analyst,"Zipongo sits at the forefront of how we eat, made exponentially more important during the ongoing pandemic -- we all need help with eating well, getting groceries or restaurant meals delivered, cooking with family, or supporting elderly family members' eating. Zipongo serves the broader community closely partnered with leading health plans and Fortune 100 companies, and we take a data-based approach and strategy to everything we do. We are constantly evolving our strategy, platform, and how we support our clients with data, and we are looking for a Strategic Data Lead that can help us scale our efforts.
capacity to use technical tools/language and systems to systematically clean data
capacity to create clean ontologies of data and update as needed
capacity to create self-sustaining/updating data feeds
capacity to ask intelligent questions of the data and identify data opportunities
capacity to understand business/customer needs and evolve data ontology and data processes (with help of devs) to reinforce needs
capacity to create dynamic reports via lookr or other tools that serve baseline and higher level info/insights purposes","Zipongo
4.0","San Jose, CA",Health Care Services & Hospitals,Health Care
Data Analyst,"System Analyst (from pure data side, no business side) Location Santa Clara, CA Duration Long term Required skillset data analysis, data mapping, restful API, SQL (very strong in SQL) Job Description - Meet and coordinate with internal and external stakeholders to establish project scope, system goals, and requirements Develop, analyse, prioritize, and organize requirement specifications, data mapping, diagrams, and flowcharts for developers and testers to follow Translate highly technical specifications into clear non-technical requirements Should be able to write complex PLSQL queries Qualifications Bachelor's degree in computer science or information technology, or equivalent experience 4-6 yearsrsquo experience working with information technologies and systems analysis Strong computer, hardware, software, and analytical skills Proven ability to assess business needs and translate them into relevant solutions Strong understanding and knowledge of the principles and practices associated with database maintenance and administration Experience installing, configuring, documenting, testing, training, and implementing new applications and systems Working knowledge of a wide variety of programming languages Excellent analytical skills Thanks Mohit","ITMC Systems, LLC
4.0","Santa Clara, CA",-1,-1
Data Analyst,"KAYGEN is an emerging leader in providing top talent for technology based staffing services. We specialize in providing high-volume contingent staffing, direct hire staffing and project based solutions to companies worldwide ranging from startups to Fortune 500 and Managed Service Providers (MSP) across a wide variety of industries

Job Description.
Key Responsibilities
Define, measure and track key metrics to guide execution across multiple teams in the org
Build dashboards and reports for teams and business leaders and stakeholders to promote transparency and enable smart decisions
Build qualitative and quantitative models to deepen understanding of platform operational performance, and predict potential delivery risks
Leverage analytics to drive process improvement
Communicate in clear and concise manner for actionable changes focused on improving velocity, predictability, and efficiency

Qualifications
7+ years' experience in data analysis within tech industry
Technical expertise in data modeling, system and data base design development, and data mining techniques
Proficient in writing SQL queries on SQL Server, MySQL , Oracle.
Strong experience working on Business Intelligence tools: Power BI is a MUST, Tableau desired.
Need to have experience in creating calculated measures and columns with DAX in Power BI Desktop. (Aggregate, Date, Logical, String, Level of Detail etc)
Expert in setting up the necessary connection details and scheduling reports on Power BI Report Server, providing row level security, creating bookmarks etc.
Strong knowledge of programming/scripting language highly desirable
Strong analytical skills and detail oriented: ability to get to the root cause of problems and devise an analytical approach to reach actionable answers

At KAYGEN, we are always looking for dynamic, talented and experienced individuals. We invite you to join our team of talented IT professionals, consulting at client locations across the globe. Our culture is team-orientated; we strive to stand by our core values of respect, honesty and integrity. Our team of experienced staffing experts will work with you to find you the best opportunity. For more information please visit us at www.kaygen.com.","Kaygen Inc.
3.9","San Jose, CA",Consulting,Business Services
Data Engineer,"1. RESTFUL API Testing

2. Should possess large data testing skills on cloud databases SQL and NoSQL. Possess excellent query writing skills

3. Trigger performance tests on end devices

4. Have knowledge of cloud testing automation tools, possess strong test automation and data validation capability using any one -Spark(preferred) or Python

Good to have skills with High Preference :

Any previous Customer Premises Equipment (CPE) , Routers preferred. Knowledge of TR-069, 802.11 protocol","Resource Logistics, Inc.
4.7","San Jose, CA",Logistics & Supply Chain,Transportation & Logistics
Data Engineer,"Posted: Apr 26, 2020
Weekly Hours: 40
Role Number:
200166746
At Apple, excellent ideas have a way of becoming extraordinary products, services, and customer experiences very quickly. Bring passion and dedication to your job and there's no telling what you could accomplish. Would you like to work in a fast-paced environment where your technical abilities will be challenged on a day-to-day basis? If so, Apple's Global Business Intelligence (GBI) team is seeking a hardworking Data Engineer to build high quality, scalable and resilient distributed systems that power apple's analytics platform and data pipelines.

Apple's Enterprise Data warehouse system cater to a wide variety of real-time, near real-time and batch analytical solutions. These solutions are integral part of business functions like Sales, Operations, Finance, AppleCare, Marketing and Internet services enabling business drivers to make critical decisions. We use a diverse technology stack such as Teradata, HANA, Vertica, Hadoop, Kafka, Spark, and Cassandra and beyond. Designing, Developing and scaling these Big Data technologies are a core part of our daily job. The team member will be able think outside of the box and should have passion for building analytics solutions to enable business in making time sensitive and critical decisions.
Key Qualifications
We would like for you to have In-depth understanding of data structures and algorithms
We are looking for experience in designing and building dimensional data models to improve accessibility, efficiency, and quality of data
Database development experience with Relational or MPP/distributed systems such as Oracle/Teradata/Vertica/Hadoop
We are seeking programming experience in building high quality software in Java, Python or Scala preferred
Experience in designing and developing ETL data pipelines. Should be proficient in writing Advanced SQLs, Expertise in performance tuning of SQLs
You will demonstrate excellent understanding of development processes and agile methodologies
Strong analytical and interpersonal skills
Enthusiastic, highly motivated and ability to learn quick
Experience with or advance courses on data science and machine learning is ideal
Work/project experience with Big Data and advanced programming languages is a plus
Experience developing Big Data/Hadoop applications using java, Spark, Hive, Oozie, Kafka, and Map Reduce is a huge plus
Description
You will build and design data structures on MPP platform like Teradata, Hadoop to provide efficient reporting and analytics capability.

Design and build highly scalable data pipelines using new generation tools and technologies like Spark, Kafka to induct data from various systems.

Translate complex business requirements into scalable technical solutions meeting data warehousing design standards.

Strong understanding of analytics needs and proactive-ness to build generic solutions to improve the efficiency.

Build dashboards using Self-Service tools like Tableau and perform data analysis to support business.

Collaborate with multiple multi-functional teams and work on solutions which has larger impact on Apple business.

We seek a self starter, forward-thinking person with strong leadership capabilities.

Ability to communicate effectively, both written and verbal, with technical and non-technical multi-functional teams.

You will interact with many other group’s internal team to lead and deliver elite products in an exciting rapidly changing environment.
Education & Experience
Bachelors Degree","Apple
4.1","Santa Clara, CA",Computer Hardware & Software,Information Technology
Data Engineer,"On April 1, 2020, Rubicon Project and Telaria, Inc. merged to create one company. The combined company will rebrand as one in the coming months. In the interim, each company will operate under its existing brand name. The ticker symbol for the combined public entity will remain NYSE: RUBI.

We are looking for Data Engineers to help us build tools, enhance our platform, and leverage our vast amounts of advertising data to make informed decisions around business optimizations and efficiencies. We're close to the customers and have the reward of seeing our work being used immediately. We take pride in the reliability and scalability of our platform, as well as our pace of implementation. We are a small and efficient team building out a solution in a new space with lots of green field ahead of it.

Why You'll Be Excited
Having a large stake and impact on the product and business direction and bottom-line
Collaborating with innovative and goal-focused engineering and business teams
Working with data scientists, data analysts, and product managers to identify and use the data that is most relevant to the problem at hand
Building systems that can effectively stream, store, and crunch vast amounts of data to help inform customers and power business analytics
Solving complex problems revolving around real-time strategic decision-making and large data systems
Developing, deploying, and maintaining robust and high-performance systems and features
Why We'll Be Excited About You
You have strong verbal and written communication skills that help you express your work in meaningful ways to cross functional teams
You are passionate about learning different technologies, exploring engineering challenges, and working in a dynamic and collaborative environment
You have working experience and skills designing and coding in Java/Scala and/or Python
You are proficient in writing efficient and well-structured SQL queries and have experience with database schemas and design
You have experience with big data technologies (Spark, Presto, Druid, etc.)
You have knowledge of UNIX/Linux and scripting with Perl, Shell, etc.
Degree in Computer Science or a related field
Bonus: Experience working in a data science / machine learning environment
Bonus: Experience working with AWS Services (Redshift, Kinesis, Glue, etc.)
Why We (and You'll) Love It Here
We are a technology and data-driven business
We embrace analytical thinking, kind, and results driven people
We have a plethora of challenging and interesting problems to solve
We help and support each other in creating a productive work/life balance
Perks and Benefits:

At Telaria we place an emphasis and importance on ensuring our total rewards are competitive, aligned with industry and to help you create a productive work/life balance. Benefits are highly subsidized and include medical, company paid dental, vision, employer contributed Health Savings Account, 401k matching, corporate gym discounts, pre-tax health and commuter savings, life insurance, 5 and 10-year Sabbatical programs, Discretionary Time Off (a.k.a. open vacation policy!), Paid Parental Leave, an Employee Referral Program, Employee Stock Purchase Plan (ESPP), and much more! All this is within a collaborative work environment you can personalize and topped with engaging programs like Micro-Mentorship, and Team Sports.

Telaria values diversity and is proud to be an equal opportunity employer. We do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status.","Telaria
4.4","Mountain View, CA",Advertising & Marketing,Business Services
Data Analyst,"Sunnyvale, California
Skills : Data Analyst,SQL,Data Pipeline
Description :
Position Description

Development and maintenance support for key data infrastructure supporting the Chrome OS GTM team, specifically the channel/customer sales teams. The Analyst will have very strong SQL skills, strong time management and self-direction, be comfortable cleaning up tech debt and maintaining pipelines, strong attention to detail, and strong documentation skills.

Top 3 Daily Responsibilities

Skill/Experience/Education

Mandatory

1-3 years developing SQL workflows.
Project management experience.
Must be a strong self-directed contributor.


Data Analyst,SQL,Data Pipeline","Collabera
4.1","Sunnyvale, CA",IT Services,Information Technology
Data Analyst,"PDS Tech, Inc. is seeking a Data Analyst, in Cupertino, CA.Summary:
• Strong data and analytic skills, knowledge of excel, numbers and data modeling.
• Knowledge of or experience working on subscription businesses a plus.
• Reporting and presentation skills a must. Looking for a person who has a passion for data and numbers.
• The successful candidate will turn data into information and insights that will help support business decisions.
• Work closely with the Data Anlytics team and cross functionally in marketing to produce monthly & quarterly data driven marketing reports.
• Interpret data, analyze results using statistical techniques and provide ongoing reports.
• Develop and implement databases, data collection systems, data analytics and other strategies that optimize statistical efficiency and quality.
• Acquire data from primary or secondary data sources and maintain databases/data systems.
• Identify, analyze, and interpret trends or patterns in complex data sets.
• Filter and clean data by reviewing computer reports, printouts, and performance indicators to locate and correct code problems.
• Work with management to prioritize business and information needs.
• Locate and define new process improvement opportunities.

Requirement:
• Candidates MUST be fluent in German.
Skills required:
• Data Analyst
• MacOS
• iOS
• 0 - 2 years of experience.
Education:
• Bachelor's Degree or equivalent work experience preferred.

PDS Tech, Inc. is an Equal Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, color, sex, sexual orientation, gender identity, religion, national origin, disability, veteran status, age, marital status, pregnancy, genetic information, or other legally protected status.

Founded in 1977, PDS Tech, Inc. is one of the nation's premier specialty staffing firms with 31 offices nationwide. We offer a full range of benefits including:

• Health insurance
• Paid holidays
• Weekly payroll
• Immediate 401(k) eligibility
• Completion Bonuses
• Training
• Please note availability of benefits may vary by position

PDS specializes in Engineering and IT arenas including Aerospace, Defense, Electronics, Telecommunications, Automotive, and Energy just to name a few. Our reputation, track record, and years of continuous growth reflect the commitment to quality that our employees and clients experience first-hand. To find out more about PDS, please visit www.pdstech.com

$$$ PDS pays for referrals! $$$

Job Requirements:","PDS Tech, Inc.
3.8","Cupertino, CA",Staffing & Outsourcing,Business Services
Machine Learning Engineer,"Passage AI is the leading conversational AI platform in the world. Our mission is to make it trivial for a business to launch a conversational interface on a website, mobile app, or as a chatbot on Facebook Messenger, SMS, Slack, WhatsApp or WeChat, or as a skill on Amazon Alexa or Google Home devices.

If you are excited by artificial intelligence, deep learning and natural language understanding and processing, Passage AI is the place for you! You get to work at an early-stage startup that's backed by some of the leading investors in Silicon Valley.

Job Description

You will work with the Core Algorithms team at Passage AI to apply neural networks and advanced machine learning algorithms to enhance the natural language understanding and processing capabilities of our platform. Apply knowledge and expertise of machine learning technologies to improve our software prototypes and analytic models. Work with some of the best AI and Machine Learning Engineers and Data Scientists in the industry to understand and interpret end-users intent and respond back with precise answers to their questions.
Key Qualifications

2-4 years experience in machine learning and data science.
Understanding of deep learning algorithms and workflows.
Strong background in algorithms development for mining patterns from large scale data.
Excellent understanding of key metrics that impact machine learning algorithms.
Expertise in common neural network architectures.
Strong ability to leverage complex technologies to solve real world problems and consumer use cases.
Good communications skills
Experience in Python, Java or C/C++
M.S. or PhD in Computer Science, preferably with strong coursework in Machine Learning and Data Science.

Job Type: Full-time",Passage AI,"Mountain View, CA",Enterprise Software & Network Solutions,Information Technology
Data Engineer,"Greetings from HCL America!!! We are seeking a "" Data Engineer"" to be a part of our team for an esteemed customer based out of San Jose, CA. Reach out for more information. Key technical skill requirements for this role Working experience with Spark, Apache Kafka, Solr, Hadoop Experience in building Data Pipelines, with hands-on development of scripts using various programming languages including SQL, Python, Unix Shell, Scala Programming Understanding and experience with structuredunstructured database environments and Big Data environments Good to have Experience with Dashboards visualization tools (specifically, DOMO), and underlying tool data formats Statistical analysis products, specifically R, Python.","HCL America Inc.
3.5","San Jose, CA",Computer Hardware & Software,Information Technology
Data Analyst,"JOB DESCRIPTION:
Summary
Will work alongside RnD staff to extract, process, plot and interpret data collected from variety of chemical and sensor experiments. Data may also come from deployed sensor networks.

Required Skillsets
• Seeking 1-5 years of experience in Data collection and analytics
• BS or equivalent in CS, Electrical Engineering, Data Sciences. Candidates should have a range of courses on statistics, SPC and databases
• Comfortable with python programming
• Experience with JMP and interpreting / working with Matlab
• Experience with Excel and Powerpoint would be desirable
• A team player

CONTACT INFORMATION:
Sandra Montes
Sandra@OSIEngineering.com
220.2800 x 108
OSIJOBS","OSI Engineering
4.5","Newark, CA",Staffing & Outsourcing,Business Services
Data Analyst,"Data Analyst

Share

Job ID: FA-0100-618

Open Since: 2020-02-05

City: San Jose
State: California
Country: United States of America

Job Description:


Frontend Arts brings together the brightest minds to create breakthrough technology solutions, helping our customers gain a competitive advantage. At Frontend Arts, we are continuously evolving how we work and how we look at the business challenges, so we can continue to deliver measurable, sustainable solutions to our clients.

We are looking for a self-motivated ""Data Analyst"" with excellent communication and customer service skills.

Job Skills:
Experience with data management, specifically with validating and auditing data and reports from multiple systems
Experience manipulating large data sets through statistical software
Experience processing and analyzing data sets, interpreting them for making business decisions
3+ years of experience with R, Python, or a similar scripting language
Minimum Experience: 8 Yrs

Education:

Bachelor’s degree from an accredited college/university or equivalent work experience","Frontend Arts
4.5","San Jose, CA",Enterprise Software & Network Solutions,Information Technology
Data Analyst,"Job Description
Hi

Hope you are doing great
Please go through the below JD and let me know your Interest

Job Role : Data Analyst

Location : Santa Clara, CA

Description/ Required Skills:

We are currently looking for a Data Analyst with 9 plus years of experience.
Candidate must have banking experience.
Can write BRD and FRD with UAT testing.
8+ years of Data Analytics experience with Data Mapping, Data Lineage.
Must have 8+ years of Informatician and SQL experience.
AWS is nice to have.
The Data Analyst will gather data from Various lines of business and transfer from the Data Lake to the AWS cloud platform.
They will be required to complete the data lineage, data quality, and data mapping to ensure that none of the data is lost in the transfer.","Adwait Algorithm
4.4","Santa Clara, CA",IT Services,Information Technology
Data Analyst,"Prior experience in using Tableau and different DB data sources.
Ability to understand technical issues at a high level.
Problem-Solving and Critical Thinking Skills.
Create clear and concise documentation.
Experience working with virtual and remote team participants.
Strong interpersonal and written communication and presentation skills.","Lorven Technologies Inc
4.0","San Jose, CA",Accounting,Accounting & Legal
Data Analyst,"Title : Data AnalystLocation : Cupertino, CA

Duration : Long Term Contract

Job Description:

• Candidates MUST be fluent in German
• Strong data and analytic skills, knowledge of excel, numbers and data modeling.
• Knowledge of or experience working on subscription businesses a plus.

Job Requirements:

• Reporting and presentation skills a must.
• Looking for a person who has a passion for data and numbers.
• The successful candidate will turn data into information and insights that will help support business decisions.
• Work closely with the Data Analytics team and cross functionally in marketing to produce monthly & quarterly data driven marketing reports.
• Interpret data, analyze results using statistical techniques and provide ongoing reports.
• Develop and implement databases, data collection systems, data analytics and other strategies that optimize statistical efficiency and quality.
• Acquire data from primary or secondary data sources and maintain databases/data systems.
• Identify, analyze, and interpret trends or patterns in complex data sets.
• Filter and ""clean data by reviewing computer reports, printouts, and performance indicators to locate and correct code problems.
• Work with management to prioritize business and information needs.
• Locate and define new process improvement opportunities.","Zolon Tech Solutions Inc.
4.0","Cupertino, CA",IT Services,Information Technology
Data Analyst,"PETADATA is looking for a Data Analyst to work with one of our Clients in San Joes, CA. Experience 7-10 Years of Education Work Authorization Those authorized to work in the United states are encouraged to apply.We are able to sponsor H1-B at this time. Job Description As a Data Analyst in the Commerce product management team, you responsible for leading this data-driven movement to change the way we operate radically. You need to be able to rise above the numbers and focus on the most important questions and insights. You enjoy finding relationships among disparate data and generate absolute clarity out of a muddied data environment. You are highly proficient in statistical methods, well-versed in visualization techniques, building dashboards, and feel at ease with a cloud-based big data environment. While you rely on data to prove your point, you also love to solve problems creatively. You thrive operating in an ambiguous environment, and you are excited by the challenge of unveiling new insights. To be successful, you regularly ask essential questions, remove noise in the data, always learning and fine-tuning your analysesdashboards, and seek opportunities to share knowledge with others. If you fit the description, join us on this exciting journey! Responsibilities Acquire data from primary or secondary sources, and maintain databases and dashboards to unlock operational and exploratory analyses Dig in deep to analyze root causes to unusual trends, dips, and spikes for all Commerce metrics Summarize your findings in an accurate, concise, easy-to-understand manner Handle the detail execution of data gathering, dashboard implementation, and bug fixing Foster a culture of having easy access to data and autonomy in obtaining answers by implementing tools that help others Maintain existing data visualizations, data pipelines, and dashboards Requirements Proven track record as a high-performing data analyst, and can thrive in a fast-paced environment Comfortable working with proxy data, incomplete data, normalizing and joining datasets from different sources Well verse with databases (MySQL, SQL Server, Hadoop) and adept with modern Business Intelligence and Visualization tools (Microsoft Power BI, Tableau, Amazon QuickSight) Familiar with web analytics technologies and techniques (Adobe Analytics, Google Analytics, digital pixel tracking, site tagging, etc.) Strong analytical abilities Collect, prioritize, analyze, and disseminate critical information with attention to detail and accuracy Excellent communication skills with expertise in data visualizations, trend analysis, forecasts, statistical testing and data-storytelling Collaborate with others to understand, identify and translate business challenges into data projects Bachelors and Masters degree specializing in Statistics or Data Science. If you are interested and meet the above job requirements, please submit your resume. After carefully reviewing your experience and skills, one of our Hiring team members will contact you on the next steps.",PETADATA,"San Jose, CA",-1,-1
Data Analyst,"Data Analyst
San Jose, CA
Fulltime

Job Description:-

Key Responsibilities
• Define, measure and track key metrics to guide execution across multiple teams in the org
• Build dashboards and reports for teams and business leaders and stakeholders to promote transparency and enable smart decisions
• Build qualitative and quantitative models to deepen understanding of platform operational performance, and predict potential delivery risks
• Leverage analytics to drive process improvement
• Communicate in clear and concise manner for actionable changes focused on improving velocity, predictability, and efficiency

Qualifications
• 7+ years' experience in data analysis within tech industry
• Technical expertise in data modeling, system and data base design development, and data mining techniques
• Proficient in writing SQL queries on SQL Server, MySQL , Oracle.
• Strong experience working on Business Intelligence tools: Power BI is a MUST, Tableau desired.
• Need to have experience in creating calculated measures and columns with DAX in Power BI Desktop. (Aggregate, Date, Logical, String, Level of Detail etc)
• Expert in setting up the necessary connection details and scheduling reports on Power BI Report Server, providing row level security, creating bookmarks etc.
• Strong knowledge of programming/scripting language highly desirable
• Strong analytical skills and detail oriented: ability to get to the root cause of problems and devise an analytical approach to reach actionable answers

Diverse Lynx LLC is an Equal Employment Opportunity employer. All qualified applicants will receive due consideration for employment without any discrimination. All applicants will be evaluated solely on the basis of their ability, competence and their proven capability to perform the functions outlined in the corresponding role. We promote and support a diverse workforce across all levels in the company.","Diverse Lynx
3.9","San Jose, CA",IT Services,Information Technology
Data Engineer,"Hello,
Â
Position:ÂData EngineerÂ
Location:ÂBay Area, CA
Duration:Â12+ months
Â
Â
Job Descrption:

Must-Have strong experienceÂonÂSQLÂ,Python,ÂETL.

RequiredÂSkills:

Â

Experience with building scalable and reliable data pipelines using Data engine technologies like Matillion, Python, and SQL based programming.
8+ years of experience with and detailed knowledge of AWS based data warehouse technical architectures, data modeling, infrastructure components, ETL/ ELT and reporting/analytic tools and environments, data structures, and hands-on SQL coding.
4+ years of experience designing and developing complex ETL/ELT programs with the following Matillion, Python, etc
8+ year's experience developing complex SQL
Experience using Cloud database technologies such as RedShift, Snowflake
3+ years' experience programming in Python, and/or Java
2+ year's experience in data quality testing; adept at writing test cases and scripts, presenting and resolving data issues
2+ years implementing and programming data ingestion and ETL programs with large datasets (Terabytes sized analytical environment)
Experience with integration of data from multiple data sources
Experience developing and implementing streaming data ingestion solutions
Experience in Agile methodology (2+ years)","Conch Technologies, Inc
4.6","San Jose, CA",Consulting,Business Services
Statistician,"Job Description
Our client a bay area based Data Science and BigData service provider is looking for a Lead Data Scientist/ Applied Statestician. This is a permanent postion based in Bay Area with a requirement to travel 25% in US.

Responsibilities:
Work on small and large data sets of structured, semi-structured, and unstructured data to discover hidden knowledge about the client’s business and develop methods to leverage that knowledge for their business.
Identify and solve business challenges working closely with cross-functional teams, such as Delivery, Business Consulting, Engineering and Product Management.
Develop prescriptive and predictive statistical, behavioral or other models via machine learning and/or traditional statistical modeling techniques, and understand which type of model applies best in a given business situation.
Drive the collection of new data and the refinement of existing data sources.
Analyze and interpret the results of product experiments.
Collaborate with the engineering and product teams to develop and support our internal data platform to support ongoing statistical analyses.
Competencies:
A proven passion for generating insights from data.
Comfort manipulating and analyzing complex, high-volume, high-dimensionality data from varying sources.
Expertise in mathematics and applied statistics, computer science, and visualization capabilities.
Curious and an excellent learner. Able to research, explore and acquire working knowledge in new areas.
A complete understanding of standard statistical techniques like MLE/QMLE, GMM, OLS/GLS, univariate and multivariate time series models (e.g. ARIMA, DLM's, VAR's), regression model diagnostics for time series and cross sectional data, along with Machine Learning methodologies like Random Forests, SVM's and Boosting/Bagging. The ideal candidate would know when and how to apply these alternative methodologies, and the relative advantages/disadvantages of each for a particular business case.
Expert knowledge of an analysis tool/statistical package such as R, JMP, Stata, SPSS, SAS, Matlab
Highly effective communicator; able to communicate complex quantitative analysis in a clear, precise & actionable way that is meaningful to general business audience and credible to client’s data scientists.
Fluency with at least one scripting language such as Python, Java, or C/C++.
Expertise with relational databases and SQL. NoSQL is a big plus.
REQUIREMENTS:
MS or Ph.D. preferred in a quantitative Social Science (e.g. Economics) or Statistics with a substantive field interest.
At least 5 years’ experience in business, consulting or applied field research with project lead responsibilities for solving analytics problems using quantitative approaches.
Demonstrated track record producing models and actionable insights using advanced statistical methods.
Experience working with large data sets using distributed computing tools, e.g. Map/Reduce, Hadoop, Hive, etc.",Staffwing Inc,"San Jose, CA",-1,-1
Data Analyst,"Job Description

Data Analyst

The Data Analyst will utilize analysis and visualization software to assist various engineering groups with evaluation of Semiconductor Wafer Foundry, Assembly, and Wafer Sort and Final Test data for New Products introduction and sustaining products support and business needs.

Responsibilities:
Generating yield reports, TC analysis reports of initial product lots, parametric analysis reports, and data analyses to enhance new product introductions.
Generating engineering reports based on testing and characterization of products in support of ongoing wafer facility management as well as a wafer facility transfers.
Interactively manage and enhance a suite of analysis templates as well as generated new templates upon demand and business needs.
Generation and support of analysis for Operations Support.
Performing other duties upon request
Qualifications:
S. in Electrical Engineering or Computer Science/ Engineering or an equivalent technical discipline is required
Knowledge of R, S, or Python is desirable.
Knowledge of Tibco Spotfire or another semiconductor yield analysis software package is desired.
Knowledge of database structures, big data analysis, and a sound fundamental understanding of statistics is desirable.
Ability to work independently is required.
2-5 years of experience in production/engineering data analysis is desirable.
5+ years of experience in the semiconductor industry is preferred but a suitable new graduate should apply.
Candidates with electronics manufacturing experience are preferred
Clear written and verbal communication skills in English are required","Power Integrations
3.8","San Jose, CA",Electrical & Electronic Manufacturing,Manufacturing
Data Analyst,"Connor Group is a specialized advisory firm of Big 4 alumni and industry executives. We provide high-value services to assist companies with Financial Accounting and Operations, IPO Services, and M&A Services. Connor Group is a team of big brains helping financial executives with their most complex and significant matters. Our clients are the world's top growth companies. We support them as they change the world!

Here at Connor Group we value competence, discipline, courage and likeability. We also believe that work/life balance is an essential factor in professional and personal success. Connor Group is a fantastic place to work, filled with highly competent and likable people!

Are you someone who
has over 3.5 GPA in computer science Bachelors or Masters?
has 0 to 2 years of software development experience?
has good hands on experience using at least one programming language like Java / Java script / C# / Phython / Ruby?
has a good understanding of SaaS-based products and web technologies like SOAP, REST, XML, WSDL, XSD, UDDI and JSON?
has good analytical and problem solving skills?
is a team player with strong communication skills and a can-do attitude?
is a creative problem solver?
If so, we want you on our team!

Connor Group currently has offices in Silicon Valley, San Francisco, Reno, Salt Lake, and New York. But the majority of Connor Group professionals work from remote client premises. Our unique and exciting environment requires someone who will apply creative thinking to support ever-changing needs.

Job Responsibilities:
Hands on design, development, deployment and maintenance of integration processes between 3rd party applications across cloud and/or on premise using 'Dell Boomi AtomSphere' platform or using Workato.
Managing, Monitoring, Sustaining, Troubleshooting and supporting existing integration implementations for our clients.
supporting developers and architects in managing and creating design, development, and maintenance documentation related to each client.
Adapt and implement the methodologies and processes.","Connor Group
4.0","Santa Clara, CA",Accounting,Accounting & Legal
Data Analyst,"????????????????????????Hi Folks ,

Greetings from Logic Planet,

We are pleased t introduce you Logic Planet as a leading recruitment and staffing company,

Regarding I have an exciting new opportunity???s that I wanted to share with you and your network. Our top client, located San Jose, CA is currently seekingData Analyst Joins their organization. I have included a complete job description below in case you or someone you know might be interested in learning more


Job Title: Data Analyst
Location: San Jose, CA 95101
Work Authorizations: Authorized to Work, Citizen, Green Card, H4-EAD,
Position Type: Full Time
No: of Positions: 1
Duration: 6 + months

Job Description:

??? Define, measure and track key metrics to guide execution across multiple teams in the org
??? Build dashboards and reports for teams and business leaders and stakeholders to promote transparency and enable smart decisions
??? Build qualitative and quantitative models to deepen understanding of platform operational performance, and predict potential delivery risks
??? Leverage analytics to drive process improvement
??? Communicate in clear and concise manner for actionable changes focused on improving velocity, predictability, and efficiency

Qualifications :

??? 7+ years' experience in data analysis within tech industry

??? Technical expertise in data modeling, system and data base design development, and data mining techniques

??? Proficient in writing SQL queries on SQL Server, MySQL , Oracle.

??? Strong experience working on Business Intelligence tools: Power BI is a MUST, Tableau desired.

??? Need to have experience in creating calculated measures and columns with DAX in Power BI Desktop. (Aggregate, Date, Logical, String, Level of Detail etc)

??? Expert in setting up the necessary connection details and scheduling reports on Power BI Report Server, providing row level security, creating bookmarks etc.
??? Strong knowledge of programming/scripting language highly desirable
??? Strong analytical skills and detail oriented: ability to get to the root cause of problems and devise an analytical approach to reach actionable answers

Regards,

Vinay

Logic Planet Inc
4525 Route 27,Princeton, NJ 08540

Ph: 732 512 0009 Ext: 134 Direct : 609 256 4342
Email: vinay@logicplanet.com | www.logicplanet.com

Certified Minority Women Based Enterprise

18 years in IT. 300 employees. $30M in revenues","Logic Planet
3.1","San Jose, CA",IT Services,Information Technology
Data Analyst,"Looking for a Data Analyst for our direct client located in Sunnyvale, CA. The duration is 6-12 months. The job description is as follows

Description:

Job Duties:

Analyze, document and design data objects, data quality rules, and data quality tests to be landed and executed. Create resilient, and sustainable and Data Object Designs and Data Quality Rules. Be a product-oriented Data Analyst creating and experimenting with new ideas that will engage and excite our customers

Experience/Skills required:
Bachelor's degree in Computer Science or related technical field. MS/PhD would be a strong plus.
3+ years experience in Data Design, Dimensional Modelling, Teradata, HiveQL, Hadoop HDFS, Confluence, Jira.
Strong understanding of data design techniques and principles
Strong leadership and communication skills
Must be able to work effectively both on teams as well as be self-motivated, task oriented and organized.
Strong customer focus and obsession with quality
Ability to work in a fast-paced and agile development environment
Please Share Resumes to chandra@ebasetek.com / 510-803-4762","E Base Technologies
4.0","Sunnyvale, CA",Advertising & Marketing,Business Services
Data Engineer,"Responsibilities Responsible for building and automating an end-to-end data pipeline from data collection to data lake. Creating various data engineering components to support strategic initiatives and ongoing business processes. Understanding logicalphysical data models and ways to extract and curate the required data and communicate effectively. Writing and validating scripts for data munchingdata wrangling using PythonSQL or equivalent. Assisting in Data Analytics and Visualizations using SQL, Python (Numpy, Pandas, Scipy, etc.) as needed. Qualifications 8+ years of industry experience 5+ years of experience in data engineeringpreparation Solid understanding of the core principles of Data engineering and Data warehousing Experience with Data Collection, Integration, Analysis, AWSGCP, Google Analytics and ETL toolsmethods Ability to work with MPP databases like Netezza or Redshift or Teradata Data pipeline concepts (worked in Informatica, Data Stage, SSIS, etc.)","BayOne Solutions
4.1","San Jose, CA",IT Services,Information Technology
Machine Learning Engineer,"Machine Learning Engineer12+ Months ContractDirect ClientCupertino, CA Responsibilities Study and transform data science prototypes Design machine learning systems Research and implement appropriate ML algorithms and tools Develop machine learning applications according to requirements Select appropriate datasets and data representation methods Run machine learning tests and experiments Requirements Proven experience as a Machine Learning Engineer or similar role. 4+ years of experience in machine learning. Understanding of data structures, data modeling and software architecture. Ability to write robust code in Python and Java. Familiarity with machine learning frameworks. Excellent communication skills. Ability to work in a team. Outstanding analytical and problem-solving skills. BSc in Computer Science, Mathematics or similar field Masterrsquos degree is a plus.","BayOne Solutions
4.1","Cupertino, CA",IT Services,Information Technology
Machine Learning Engineer,"Posted: May 7, 2020
Role Number:
200169384
Apple is looking for ML/Deep Learning engineers to develop and integrate machine learning technologies for autonomous systems. You will work on a hardware/software product enabled by the ML technologies you build.

WHAT YOU’LL DO
Develop features and models to improve the capabilities of systems that use machine learning.
Scale up models, build training datasets and tune parameters to improve system performance.
Build software that improves your rate of experimentation and helps you make better decisions about what to try next.
Build analysis tools and simulations to understand the performance of complex systems. - Conduct original research to solve hard problems applying machine learning in new areas - Work with the team to deploy models in a mission critical environment.
Key Qualifications
Able to train and debug deep learning systems: Defining metrics and datasets, performing error analysis, training models in a modern DL framework (such as TensorFlow, PyTorch, Keras, etc.)
Familiar with current DL literature and the math of machine learning: optimization methods, common types of models and layers, etc.
Strong background in Python development with Linux. You write clean, correct code while iterating on experiments in Python. Ability to understand and contribute to C++ based software is a plus.
Excellent verbal and written skills. You collaborate effectively with other teams and communicate clearly about your work.
Description
WORKING WITH OUR TEAM

You’ll join a phenomenal team of hardworking engineers and researchers with deep experience in robotics, machine learning, and software engineering. We hope you’re passionate about the values that drive us:
Passion for the mission: We’re here to make something great. We take on whatever work is right for the product and strive for the best possible results.
Modesty: The right answer is more important than being right. We search for solutions as a team and value clear-eyed feedback.
Lean habits: You can’t grow without limits. Time constraints and big goals encourage us to sharpen our focus and learn to make phenomenal decisions.
Education & Experience
Bachelors, Masters, or PhD Degree in Computer Science/Machine Learning or equivalent professional experience.","Apple
4.1","Santa Clara, CA",Computer Hardware & Software,Information Technology
Data Analyst,"Data Analyst

Location : San Jose, CA

Contract Type: W2 Contract

Duration: 12 Months+

Responsibilities:
2+ Experience with customer experience data reporting and analytics
Deep subject matter expertise with Tableau is a must
Experience with SQL and Python.
Proactive and inquisitive learner seeks out and capitalizes on opportunities for change that enhance the business, rather than reacting to circumstances
Strong analytical and problem-solving skills able to develop and use structured approaches to identify root causes and recommend resolutions.",enexusglobal,"San Jose, CA",-1,-1
Machine Learning Engineer,"If interested, submit your updated resume in WORD(.doc) format with following details Full Name Current Location Expected Hourly rateSalary Work Authorization Bachelor or Masterrsquos (preferred) degree in Computer Science, Math, Data ScienceAnalytics, Business Intelligence. bull At least 4 years of experience in working with modern enterprise data architectures, integrations and data toolsets (ex datamarts, modeling tools, profiling tools) bull Well-versed with SQL language. bull Extensive hands-on experience with development of predictive models and machine learningAI-based solutions using relevant statistical packages. bull Experience in developing machine learning and artificial intelligence algorithms using Python, R, and Java. bull Ability to extract, process, and analyze large volumes of diverse structured and unstructured data to produce meaningful insights that can be linked to business results.","Dew Software
2.9","San Jose, CA",IT Services,Information Technology
Data Engineer,"The Business

GradTests.com is a leading provider of practice psychometric tests to graduates, students and young professionals.

The Role

The core purpose of the role is to make high quality, high availability, accurate data available for our data analysts and data scientists to do their analysis, derive their insights and build their models. You are the Scotty Pippin to the Michael Jordans. You are the Xavi to the Messis.

You'll do things like:
Ensure our data warehouse is well structured, running smoothly and efficiently for all business intelligence
Set up and maintain various data pipelines used for customer analytics, marketing analytics and product analytics
Skills and experience

Non negotiables:
SQL
Python
Strong knowledge of traditional relational databases - we don't mind which
Some experience with cloud technologies - again we don't mind if it's AWS, GCP or Azure
Experience in any streaming technology
Great experience in using third party APIs at scale
Some web scraping experience
An obsession with data quality
Strong communication skills
Nice to haves:
Experience in working with analysts
Any basic knowledge of advanced analytics techniques
Experience in a visualisation tool like Tableau
Job Types: Full-time, Contract

Salary: $100,000.00 /year

Work Remotely:
Yes",GradTests (gradtests.com.au),"San Jose, CA",-1,-1
Data Engineer,"Jobs Itility-US

Data Engineer

Working in teams (consisting of Hadoop data engineers, Hadoop data warehouse engineers, and platform engineers) that are building and managing Hadoop stacks. The teams install, configure and manage Hadoop ecosystem components.

As Hadoop data engineer, you are responsible for the functional part of provisioning data – e.g. building data ingestion pipelines and data connectors. You work closely with the data scientists and business intelligence engineers who are using this data to create analytical models.

After taking inventory of an application, all found servers, storage, network and database configurations will be transferred to the new data center. To efficiently execute this migration, we use a strict step-by-step plan, as one might find in a factory.

We need your expertise


You are well acquainted with the complete Hadoop stack. In addition, you have practical experience of being part of a DevOps team. Further requirements:
Bachelor of Science / master’s degree in Computer Science, System Administration, or any other IT infrastructure or software related study with a passion for the automation side of IT infrastructure
Minimum two to three years of relevant work experience
Capable of building/operating highly available, distributed systems of data extraction, ingestion, and processing of large data sets of structured, semi-structured and unstructured data
Experience in building data products incrementally and integrating and managing data sets from multiple sources
Data quality oriented
Familiar with data architecture including data ingestion pipeline design, Hadoop information architecture
Hortonworks Certified Hadoop Developer and/or Cloudera Certified Hadoop Developer and/or Certified Hadoop Administrator
Knowledge of continuous integration & delivery tooling: e.g. Jira, Git, Jenkins, Bamboo
Coding proficiency in at least one modern programming language (Python, Ruby, Java)
Strong verbal and written communication skills
Good documenting capabilities
You have a hands-on mindset, a strong customer focus, a problem-solving orientation and can show fast results
You have a clear focus on results and quality.
Willingness to travel to the Netherlands if required for training or project work
Bachelor of Science / master’s degree
Minimum 3-5 years of relevant work experience within an enterprise environment
Advanced knowledge of RHEL 6 & 7
Advanced knowledge of VMWare 5 & 6; VCAP5-DCD, VCDX5-DCV preferred
Experience with Cisco UCS manager and NetApp FAS / ScaleIO storage solutions
Experience with databases (MSSQL, Oracle) preferred
Strong verbal and written communication skills
Good documenting capabilities
Willingness to travel to the Netherlands if required for training or project work

Meet Itility


At Itility we believe in merging technology and data to drive our customers one step beyond. Itility digital consultants are experts in data, cloud, software, and IT infrastructure.

Our culture can be described as ‘no-nonsense, with passion’. Working at Itility is about working with people, staying close to our customers.

We work for large enterprises and innovative startups. Acting as the ‘digital twin’ of customers, we work shoulder-to-shoulder to exceed business goals and push the boundaries of what you thought was possible.

Do you like to go above and beyond? Do you want to work with passion for what you do, in a team of people fueled by the same passion?

Then we would love to meet you!

You believe in
Build efficient and highly reliable data ingestion pipelines for the Hadoop stack
Own data quality and data knowledge around all data that you touch
Work side-by-side with software engineers and data scientists in designing modeled data sets to be used in many different applications, from proof-of-concept to production
Understand the entire life cycle of data that flows through any systems for which you are responsible
Pay constant attention and effort to the reliability of your pipelines
Reports to the Itility project manager, working in close harmony with team members and interfacing with the standing IT organization.

Location


San Jose, CA.


Contact person


Apply now

Share:


Share on linkedin

Share on twitter

Share on facebook

Share on whatsapp

Share on email","Itility
3.3","San Jose, CA",Aerospace & Defense,Aerospace & Defense
Data Engineer,"Amick Brown is seeking an experienced Data Engineer for our direct client.

Location: Sunnyvale, CA
Duration: 6 Months +

Roles and Responsibilities
Design and build data models to conform to our existing EDW architecture.
Design and build data pipelines using tools - SAP SLT, SAP Data Services, Python and Microsoft SSIS.
Design and development of data warehouse using T-SQL, SQL, and python
Work with teams to deliver effective, high-value reporting solutions by leveraging an established delivery methodology.
Implement data structures using best practices in data modelling, processes, and technologies.
Design and development of data warehouse using Microsoft SQL Server, SAP HANA and Snowflake databases.
Writing analytics programs (transformations/calculations) in T-SQL, R, Python or comparable
Knowledge and understanding of Enterprise applications like SAP ECC and SAP CRM, Salesforce etc.
Knowledge and functional understanding of Finance, Global Supply Chain business processes
Perform data mining and analysis to uncover trends and correlations to develop insights that can materially improve our decisions.
Development with one or more data visualization/reporting tools (Tableau, Business Objects, Hana Analytics, Microsoft PowerBI)
Work with various product owners to ensure applications are instrumented with proper tracking mechanisms to enable analytics.
Continually recommend, develop, and implement process improvements and tools to collect and analyse data, and visualize/present insights.
Skill/Job Requirements:
Bachelors degree in Business, MIS or related area. Masters degree a plus.
8+ years Business Intelligence / Data Warehouse development experience
3+ years of experience in ETL development tools, preferably with knowledge of Microsoft Integration Services 2005 or greater (SSIS), SAP Data Services, SAP SLT and Python.
5+ years of experience in design and development using Microsoft SQL Server, SAP HANA and Snowflake databases.
Strong experience in full life cycle development, implementation, management and performance tuning of the Enterprise Data Warehouse
Experience in database development (T-SQL, PLSQL, and/or SQL scripts)
Experience in building data pipelines using python, C# and JSON
Experience in Microsoft BI development in Integration Services (SSIS), Analysis Services (SSAS) or Reporting Services (SSRS)
Experience building and managing data flows to and from cloud applications
Demonstrated experience in utilizing R, Python, SPSS or comparable to develop analyses
Experience visualizing data in business intelligence tools such as Tableau, Business Objects or Hana Analytics
Experience and functional understanding with Enterprise applications like SAP ECC and SAP CRM, Salesforce etc.
Strong experience with performance and scalability design and testing
Experience creating test plans, testing and resolving data discrepancies
Must be a self-motivated, energetic, detail-oriented team player passionate about producing high quality BI & Analytics deliverables
Strong sense of customer service for internal customers
Medical robotics has unique characteristics that will require immersion in clinical and technical training and he or she must come up to speed quickly an interest and desire to learn are critical
Amick Brown, LLC is an Information Technology consulting company providing IT staffing and managed solutions. Founded in 2010, we are a certified woman-owned small business headquartered in San Ramon, CA with an additional office in Sacramento, CA. Amick Browns experienced IT professionals support customers nationwide in both the commercial and public sectors. We are SBA 8(a) and IS0 9001:2015 certified and are an SAP Services Silver Partner.

Regular full-time employees are eligible for the following Amick Brown provided benefits:
Health
Vision
Dental
401k with company match
Paid time off
Sick Leave
Short-Term Disability
Life Insurance
Wellness & Discount Programs","Amick Brown, LLC
4.9","Sunnyvale, CA",-1,-1
Data Analyst,"Data Analyst**job details:**+ location:Sunnyvale, CA+ salary:$30 - $49 per hour+ date posted:Thursday, July 2, 2020+ job type:Contract+ industry:Professional, Scientific, and Technical Services+ reference:788444**job description**Data Analystjob summary:**Job Duties:**Analyze, document and design data objects, data quality rules, and data quality tests to be landed and executed. Create resilient, and sustainable and Data Object Designs and Data Quality Rules. Be a product-oriented Data Analyst creating and experimenting with new ideas that will engage and excite our customerslocation: Sunnyvale, Californiajob type: Contractsalary: $30 - 49 per hourwork hours: 8am to 5pmeducation: Bachelorsresponsibilities:**Experience/Skills required:**+ Bachelor's degree in Computer Science or related technical field. MS/PhD would be a strong plus.+ 3+ years experience in Data Design, Dimensional Modelling, Teradata, HiveQL, Hadoop HDFS, Confluence, Jira.+ Strong understanding of data design techniques and principles+ Strong leadership and communication skills+ Must be able to work effectively both on teams as well as be self-motivated, task oriented and organized.+ Strong customer focus and obsession with quality+ Ability to work in a fast-paced and agile development environmentqualifications:**Experience/Skills required:**+ Bachelor's degree in Computer Science or related technical field. MS/PhD would be a strong plus.+ 3+ years experience in Data Design, Dimensional Modelling, Teradata, HiveQL, Hadoop HDFS, Confluence, Jira.+ Strong understanding of data design techniques and principles+ Strong leadership and communication skills+ Must be able to work effectively both on teams as well as be self-motivated, task oriented and organized.+ Strong customer focus and obsession with quality+ Ability to work in a fast-paced and agile development environmentskills: **Experience/Skills required:**+ Bachelor's degree in Computer Science or related technical field. MS/PhD would be a strong plus.+ 3+ years experience in Data Design, Dimensional Modelling, Teradata, HiveQL, Hadoop HDFS, Confluence, Jira.+ Strong understanding of data design techniques and principles+ Strong leadership and communication skills+ Must be able to work effectively both on teams as well as be self-motivated, task oriented and organized.+ Strong customer focus and obsession with quality+ Ability to work in a fast-paced and agile development environmentEqual Opportunity Employer: Race, Color, Religion, Sex, Sexual Orientation, Gender Identity, National Origin, Age, Genetic Information, Disability, Protected Veteran Status, or any other legally protected group status.Qualified applicants in San Francisco with criminal histories will be considered for employment in accordance with the San Francisco Fair Chance Ordinance.We will consider for employment all qualified Applicants, including those with criminal histories, in a manner consistent with the requirements of applicable state and local laws, including the City of Los Angeles' Fair Chance Initiative for Hiring Ordinance.","Randstad
3.6","Sunnyvale, CA",Staffing & Outsourcing,Business Services
Data Engineer,"Position Senior Data Engineer Location Menlo Park, CA Duration 6 Months to Long Term Job Description 6+ yearsrsquo experience in data engineering and data warehouse Technologies 4+ years of experience Python experience Must be extremely strong with SQL Must Have experience with PrestoHiveHadoop Clear understanding of testing methodologies and Best Practices Experience with any of Elastic Search, Aurora, MySQL, Postgres, Redshift, Snowflake, DynamoDB, or Redis Experience with one or more MPP databases (Redshift, Bigquery, Snowflake, etc) Experienced in working collaboratively across different teams and departments Strong technical and business communication collaboratively across different teams and departments Strong technical and business communication","Indrasol
5.0","Menlo Park, CA",-1,-1
Machine Learning Engineer,"Job Description
We are a multinational conglomerate holding company specializing in e-commerce, retail, Internet, and technology. Founded on 4 April 1999 in Hangzhou, Zhejiang, the company provides consumer-to-consumer (C2C), business-to-consumer (B2C), and business-to-business (B2B) sales services via web portals, as well as electronic payment services, shopping search engines and cloud computingservices. It owns and operates a diverse array of businesses around the world in numerous sectors, and is named as one of the world's most admired companies by Fortune.

Machine Learning Engineer

Minimum Qualifications:
Bachelor's in Computer Science, Electrical Engineering, Statistics or related field
Ability to run experiments and analyze results scientifically
Must have working experience and be expert in building AI Models
Solid understanding in algorithms and data structure
A breadth of technical skills and know how to use the right tool for the job
Have a passion for solving very difficult technology challenges and learning new technologies and domains
Ability to work independently and multi-task effectively
Ability to understand business requirements and translate them into technical requirements
Flexible and willing to accept a change in priorities as necessary
Strong attention to detail
Experience working in a collaborative environment with designers and researchers
Desired Skills & Experience:
Experience in data analysis is a plus
Good understanding of ML application design principles
Experienced in exploring a new field
Responsibilities:
Invent and build solutions to real-world customer problems through close collaborations with design, research and engineering teams
Ability to quickly change and iterate based on the team's needs
Multi-task and change from one task to another without loss of efficiency or composure
Required:
On location in Sunnyvale, California
Experience: 3+ years
Powered by JazzHR

K1tIoLmBoT","IntelliPro Group Inc.
4.1","Sunnyvale, CA",-1,-1
Data Engineer,"Company Overview

An American multinational company headquartered in Redwood City, California, that specializes in internet connection and data centers. The company leads in global colocation data center market share, with 200 data centers in 24 countries on five continents.

Job Responsibilities:

We are looking for a Senior Data Engineer with advanced knowledge of SQL and intermediate knowledge of Python. Nice to have (but not required) beginner or intermediate level java experience. Your primary focus will be the writing complex SQL queries, optimizing them and development of all server-side backend data processing logic, ensuring high performance using Python and SQL.
Develop and maintain scalable ETL pipelines, build new pipelines and facilitate API integrations to support new requirements.
Writing complex SQL queries to serve new requirements for ETL, data analysis and debugging.
Writing SQL functions, procedures as required based on the requirements
Finetune or optimize queries to support the increasing volume of data.
Debug Python code, modify and enhance Python ETL applications based on the requirements on Linux environment.
Writing reusable and efficient code in Python and SQL.
Write unit, functional, regression tests for enhanced feature, maintain engineering documentation.
Communicate closely with all product owners, Business and engineering teams to develop approaches for data platform architecture.
Skills:
Basics of Computer Science - OOPS, Data Structures and Algorithms.
Basic understand of regular Linux commands and usage.
5+ years of experience having hands on experience in writing, debugging and optimizing SQL queries, function and stored procedures.
3+ years of experience with hands on experience in writing, debugging Python code on Linux.
Experience writing python applications that interact with ORM (Object Relational Mapper) libraries.
Knowledge of XML and JSON parsing with unit test and debugging skills.
Willingness and ability to learn new tools/languages as needed.
Process oriented with excellent oral and written communication skill with a desire for customer service.
An excellent team player and communicator who can work effectively with cross functional teams and ability to navigate ambiguity.
Powered by JazzHR","IntelliPro Group Inc.
4.1","Sunnyvale, CA",-1,-1
Data Analyst,"Analyze, document and design data objects, data quality rules, and data quality tests to be landed and executed. Create resilient, and sustainable and Data Object Designs and Data Quality Rules. Be a product-oriented Data Analyst creating and experimenting with new ideas that will engage and excite our customers ExperienceSkills required - Bachelor's degree in Computer Science or related technical field. MSPhD would be a strong plus. - 3+ years experience in Data Design, Dimensional Modelling, Teradata, HiveQL, Hadoop HDFS, Confluence, Jira. - Strong understanding of data design techniques and principles - Strong leadership and communication skills - Must be able to work effectively both on teams as well as be self-motivated, task oriented and organized. - Strong customer focus and obsession with quality - Ability to work in a fast-paced and agile development environment","BayOne Solutions
4.1","Sunnyvale, CA",IT Services,Information Technology
Data Analyst,"Job DescriptionUS Tech Solutions is seeking a Data Analyst for a Long Term contract with a client in Sunnyvale, CA

Core Functions include:
• Design and build reports, scorecards and dashboards to support all Compliance functions.
• Generate insights, trends and actionable recommendations to support Operations, Product and Business teams.
• Generate reports and create presentations for key stakeholders, including Compliance and Executive leadership team.

Position Description:
• This position is part of Analytics team responsible for performing analytics to support the business. An individual in this position is expected to perform additional responsibilities and duties as assigned and/or necessary.
• Analyze and interpret information related to risk mitigation by identifying industry data trends (ex: reputational metrics, seller scorecard indicators) and benchmarks.
• Analyze data to identify trends, patterns, insights, and discrepancies in data; ensure data accuracy, synthesize compliance data in support of strategic business objectives; translate results into actionable recommendations/plans.
• Utilize industry new technologies and best practices to provide insights to key stakeholders based on your research.
• Communicate compliance data insights and global trends related to the business; design, coordinate, and implement new reporting, analysis, and data-management solutions; provide recommendations based on insights and research.
• Propose improvements for strategic and tactical initiatives (ex: driving experience scores, risk mitigation measures).
• This role is required to work in both San Bruno (Temporarily replaced by San Mateo) and Sunnyvale locations.

Minimum Qualifications:
• Bachelor's degree in Statistics, Analytics, Mathematics, Systems, Information Technology, Computer Science, or related field.
• 2+ years experience in analytics, systems, information technology (IT), data management.
• 1+ year experience with Python/R (Python preferred).
• 1+ year experience in Tableau/Looker or any other visualization tools (Tableau preferred).
• Knowledge on predictive modeling is a plus.
• Experience with Hadoop, Hive, Spark, Kafka.
• 2+ year experience with SQL, RDBMS, Hive and No-SQL databases (for example Cassandra) is a plus.
• Masters degree or certificate in business analytics, data mining, or statistical analysis is a strong plus.
• Prior eCommerce experience is a plus.

About US Tech Solutions:

Your talent, our opportunities - This is the premise behind US Tech Solutions.

You have the skill we have the opportunity. As a team, we work passionately for you to get the right career opportunity across industry verticals and functions. For past sixteen years, leading Global

Companies and Fortune 500 come to us to get the right talent. Whether you want to work as full-time, contractor or part-time, technical or non-technical our talent consultants will connect with the right career opportunity globally.

Connect with our talent team today.

USTECH was founded in 2000 by Manoj Agarwal. Today, we are a global firm offering talent solutions to 150 customers including 20% of Fortune 500 across Financial Services, Healthcare, Life Sciences, Aerospace, Energy, Retail, Telecom, Technology, Manufacturing, and Engineering. We are headquartered in New Jersey with 40 global locations across the USA, Canada, Europe, and India. Deloitte has recognized USTECH as one of the fastest growing private businesses for the past five consecutive years and INC 500 for the past three. We have also been rated The Top Business in the US"" by Diversity Business since 2011. To learn more about how US Tech Solutions visit our website: www.ustechsolutions.com.

US Tech is an Equal Opportunity Employer"" and US Citizens & all other parties authorized to work in the US are encouraged to apply.""

Apply: Interested candidates are requested to send their resume to Pawan at pawans@ustechsolutionsinc.com

Job Requirements:

Job Description

US Tech Solutions is seeking a Data Analyst for a Long Term contract with a client in Sunnyvale, CA

Core Functions include:
• Design and build reports, scorecards and dashboards to support all Compliance functions.
• Generate insights, trends and actionable recommendations to support Operations, Product and Business teams.
• Generate reports and create presentations for key stakeholders, including Compliance and Executive leadership team.

Position Description:
• This position is part of Analytics team responsible for performing analytics to support the business. An individual in this position is expected to perform additional responsibilities and duties as assigned and/or necessary.
• Analyze and interpret information related to risk mitigation by identifying industry data trends (ex: reputational metrics, seller scorecard indicators) and benchmarks.
• Analyze data to identify trends, patterns, insights, and discrepancies in data; ensure data accuracy, synthesize compliance data in support of strategic business objectives; translate results into actionable recommendations/plans.
• Utilize industry new technologies and best practices to provide insights to key stakeholders based on your research.
• Communicate compliance data insights and global trends related to the business; design, coordinate, and implement new reporting, analysis, and data-management solutions; provide recommendations based on insights and research.
• Propose improvements for strategic and tactical initiatives (ex: driving experience scores, risk mitigation measures).
• This role is required to work in both San Bruno (Temporarily replaced by San Mateo) and Sunnyvale locations.

Minimum Qualifications:
• Bachelor's degree in Statistics, Analytics, Mathematics, Systems, Information Technology, Computer Science, or related field.
• 2+ years experience in analytics, systems, information technology (IT), data management.
• 1+ year experience with Python/R (Python preferred).
• 1+ year experience in Tableau/Looker or any other visualization tools (Tableau preferred).
• Knowledge on predictive modeling is a plus.
• Experience with Hadoop, Hive, Spark, Kafka.
• 2+ year experience with SQL, RDBMS, Hive and No-SQL databases (for example Cassandra) is a plus.
• Masters degree or certificate in business analytics, data mining, or statistical analysis is a strong plus.
• Prior eCommerce experience is a plus.","US Tech Solutions, Inc
3.8","Sunnyvale, CA",Staffing & Outsourcing,Business Services
Data Analyst,"Importing and exporting data to a database, and writing SQL queries to extract the appropriate data
Writing code in R, Python, or similar languages that reads in flat files, processes the data in various ways, and summarizes results in output files, charts, and graphs
Writing formulas in Excel and Google Sheets
Communicating with senior management and other internal stakeholders to quickly grasp reporting requirements, and present results must be self-driven to take on new tasks and deliver results on time.
Requirements

Bachelor's Degree In Data Science preferred

Healthcare knowledge required

3-5 years of experience creating dashboards and views in Business Intelligence (BI) tools like Tableau

Strong Analytical and Communication Skills required

Detail orientated, self-driven to take on new tasks and deliver results timely.

Benefits

Health, Dental, and Paid Time off

Opportunity to make the world a better place","Wider Circle
2.4","Redwood City, CA","Health, Beauty, & Fitness",Consumer Services
Data Analyst,"Data AnalystLocation: Sunnyvale, CADuration: 6 monthsPosition Overview:* Development and maintenance support for key data infrastructure supporting the Chrome OS client team, specifically the channel/customer sales teams. The Analyst will have very strong SQL skills, strong time management and self-direction, be comfortable cleaning up tech debt and maintaining pipelines, strong attention to detail, and strong documentation skills.Top 3 Daily ResponsibilitiesSkill/Experience/Education:Mandatory:* 1-3 years developing SQL workflows.* Project management experience.* Must be a strong self-directed contributor.Skill Matrix:Skill Name: SQLLevel: 4Years: 0-3 yearsMandatory: YesDescription: Must have a high level of comfort writing and maintaining SQL pipelinesAs an equal opportunity employer, ICONMA prides itself on creating an employment environment that supports and encourages the abilities of all persons regardless of race, color, gender, age, sexual orientation, citizenship, or disability.","Iconma, L.L.C.
3.6","Sunnyvale, CA",Staffing & Outsourcing,Business Services
Data Engineer,"NG - 014
Data Engineer

San Jose, California, USA

JOB TITLE


Data Engineer

Job Duties


Create databases optimized for performance, implement schema changes, and maintain data architecture standards in the project. Develop and implement scripts for database maintenance, monitoring, performance. Define and implement data stores based on system requirements and consumer requirements. Responsible for enabling and running data migrations across different databases and different servers. Perform thorough testing and validation to support the accuracy of data transformations and data verification. Troubleshoot data issues and provide solutions to the issues. Analyze and evaluate the business's databases to identify and recommend improvements and optimization. Analyze complex data elements and systems, data flow, dependencies, and relationships in order to contribute to conceptual physical and logical data models. Integrate new data management technologies and software engineering tools into existing structures. Build high-performance algorithms, prototypes, predictive models and proof of concepts.

Job Requirements


Requires Bachelors or foreign equivalent in Computer Science, Commerce, Information Technology, Information Systems, MIS, Engineering (Any), CIS or related field plus 2 years of experience with the same or similar job duties but given another designation. Any suitable combination of education, training or experience is acceptable. Must be able to travel/relocate to various client sites throughout the U.S.

Location of Work


San Jose, CA.

Please email or mail resumes to HR, Nextgen Technologies Inc.,1735 North 1st Street #308, San Jose, CA 95112 or email to resumes@nextgentechinc.com.","Nextgen Technologies
4.2","San Jose, CA",IT Services,Information Technology
Data Engineer,"Who we are


Fueled by a fundamental belief that having access to financial services creates opportunity, PayPal (NASDAQ: PYPL) is committed to democratizing financial services and empowering people and businesses to join and thrive in the global economy. Our open digital payments platform gives PayPal’s 305 million active account holders the confidence to connect and transact in new and powerful ways, whether they are online, on a mobile device, in an app, or in person. Through a combination of technological innovation and strategic partnerships, PayPal creates better ways to manage and move money, and offers choice and flexibility when sending payments, paying or getting paid. Available in more than 200 markets around the world, the PayPal platform, including Braintree, Venmo and Xoom, enables consumers and merchants to receive money in more than 100 currencies, withdraw funds in 56 currencies and hold balances in their PayPal accounts in 25 currencies.

When applying for a job you are required to create an account, if you have already created an account - click Sign In.

Creating an account will allow you to follow the progress of your applications. Our system does have some requirements that will help us process your application, below are some guidelines for creation of your account:
Provide full legal First Name/Family Name – this is important for us to ensure our future hires have the right system set up.
Please Capitalize first letter of your First and Last Name.
Please avoid using fully capitalized text for your First and/or Last Name.
NOTE: If your name is hyphenated or has multiple capitalization, please use the same format as your government ID.
Job Description Summary:

The Data Engineer will be based out of PayPal San Jose office and will support in the development and execution of strategic transformation programs & initiatives, strategic engineering architecture design, development. Ideal candidate is a technologist who believes that use of technology is in its infancy and the best is yet to come. The nature of role is strategic, analytical and highly collaborative, working with team members across the World and as a liaison for Global projects.

Job Description:

Responsibilities:
Build scalable systems, lead technical discussions, participate in code reviews, guide the team in engineering best practices. Must be able to write quality code and build secure, highly available systems. 75% of the job requires production quality coding.
Provide technical insights and contribute to the definition, development, integration, test, documentation, and support across multiple platforms
Highly detailed with a systematic approach, sense of responsibility and strong, positive customer focus. Must be results focused and highly energetic to drive the defined team and organizational goals
Establish a consistent, project management framework and development processes to deliver high quality software, in rapid iterations, for business partners in multiple geographies
Work in a team that designs, develops, troubleshoots and debugs software programs for databases, applications, tools, networks etc.
Must have demonstrably strong interpersonal and communication skills (both written and verbal), to include speaking clearly and persuasively in positive or negative situations
Eat, sleep, and breathe services. Experienced in balancing production platform stability, feature delivery, and retirement of technical debt across a broad landscape of technologies
Qualifications:
Undergraduate degree in Computer Engineering or equivalent from a leading university and preferably with a Masters or MBA
8+ years of post-college working experience as a developer and architect in Engineering, or Data analytics organization
4+ years of Hadoop experience is required
4+ years of strong SQL / ETL working experience is required
4+ years of SPARK/HIVE experience is required
2+ years of Linux/Unix/Python coding experience (including scripting) is required
Strong conceptual and creative problem-solving skills; ability to work with considerable ambiguity; ability to learn new and complex concepts quickly. Relentlessly resourceful and scrappy
A great communicator, strong project management skills, and superb attention to details
Subsidiary:

PayPal

Travel Percent:

0

Primary Location:

San Jose, California, United States of America

Additional Locations:

We're a purpose-driven company whose beliefs are the foundation for how we conduct business every day. We hold ourselves to our One Team Behaviors which demand that we hold the highest ethical standards, to empower an open and diverse workplace, and strive to treat everyone who is touched by our business with dignity and respect. Our employees challenge the status quo, ask questions, and find solutions. We want to break down barriers to financial empowerment. Join us as we change the way the world defines financial freedom.

PayPal provides equal employment opportunity (EEO) to all persons regardless of age, color, national origin, citizenship status, physical or mental disability, race, religion, creed, gender, sex, pregnancy, sexual orientation, gender identity and/or expression, genetic information, marital status, status with regard to public assistance, veteran status, or any other characteristic protected by federal, state or local law. In addition, PayPal will provide reasonable accommodations for qualified individuals with disabilities. If you are unable to submit an application because of incompatible assistive technology or a disability, please contact us at paypalglobaltalentacquisition@paypal.com.","PayPal
3.9","San Jose, CA",Internet,Information Technology
Data Analyst,"Job Summary:
Company: Artech Information Systems LLC
Position: Data Analyst
Duration: 12 months with possible extension
Location: Sunnyvale, CA
Job Reference Code: 20-23449

Position Overview:
Development and maintenance support for key data infrastructure supporting the GTM team, specifically the channel/customer sales teams. The Analyst will have very strong SQL skills, strong time management and self-direction, be comfortable cleaning up tech debt and maintaining pipelines, strong attention to detail, and strong documentation skills.

Skill/Experience/Education
Mandatory: 1-3 years developing SQL workflows.
Project management experience.
Must be a strong self-directed contributor.
Niyaz Ansari
Assistant Manager – Staffing
Artech Information Systems LLC
360 Mt. Kemble Avenue, Suite 2000 | Morristown, NJ 07960
Office: 973.967-3588 | Fax: 973.998.2599
Email: Niyaz.Ansari@artechinfo.com | Website: www.artechinfo.com
LinkedIn: https://www.linkedin.com/in/niyazansari/

Connect with us on - LinkedIn | Facebook | Twitter

About Artech Information Systems LLC
Artech is an employer-of-choice for over 5,800 consultants across the globe. We recruit top-notch talent for over 65 Fortune and Government clients coast-to-coast across the U.S., India, and China. We are one of the fastest-growing companies in the U.S. and this may be your opportunity to join us!
Want to read more about Artech?
Click here to visit our website or click on the following links to read what others are saying about us: The Wall Street Journal, Forbes (1) (2), BusinessWire, Entrepreneur, Better Business Bureau, Hoovers, Diversity Careers(1) (2), The Artech Circle, NJTVOnline, The Business Forum Show, and SIA: “Above the Crowd.”
Connect with Artech through Social Media
Learn more about our company including the latest events at Artech, new job opportunities, jobseeker tips, and more. Follow us on Facebook, Google+, LinkedIn, Pinterest, Twitter, and YouTube.\","Artech LLC
3.9","Sunnyvale, CA",Staffing & Outsourcing,Business Services
Data Engineer,"Job Details:

Job Title: Data Engineer

Location: San Jose, CA

Duration: 9-12 Months Contract

• 6-8 years of overall experience

• Excellent SQL and data querying skills.

• Experience with SQL Tuning using good sql coding practices

• Experience with Data Warehousing development, preferably Teradata is a plus

• Experience with Cloud Data Warehouse, preferably Snowflake is a plus.

• Background to ANSI SQL

• Sound knowledge of Database concepts and database architecture

Thanks & Regards

Ram Kishor

Phone: 732-452-1006*238

ram.kishor@diverselynx.com

Diverse Lynx LLC is an Equal Employment Opportunity employer. All qualified applicants will receive due consideration for employment without any discrimination. All applicants will be evaluated solely on the basis of their ability, competence and their proven capability to perform the functions outlined in the corresponding role. We promote and support a diverse workforce across all levels in the company.","Diverse Lynx
3.9","San Jose, CA",IT Services,Information Technology
Data Engineer,"Job Title: Data EngineerLocation: Santa Clara, CACompanyWork matters. It's where we spend a third of our lives. And the workplace of the future is going to be a great place. We're dedicated to bringing that to life for people everywhere. That's why we put people at the heart of everything we do.People matter. Our people have a passion for learning, building, and innovating. Whether you're an engineer, a sales professional, a finance professional, or anything in-between, our roles aim to provide each person with meaningful impact and plenty of space to grow.TeamThis is a new team within the Data and Analytics organization. The team is fast-paced while managing highly accurate detailed information. We collaborate and support every business unit within ServiceNow.RoleWe are looking for a dynamic, perennially curious, self-motivated, and data-centric individual to drive Business Intelligence endeavors for the Business. A candidate to nurture, execute, and deploy BI projects to direct our investments, manage business levers, track progress against guidance, predict, and prescribe targeted opportunities. The role entails collaborative engagements with Field & Product Line Sales Teams, Global Services, Alliances & Channels, and FP&A to deploy insightful analytic products, establish alignment on processes teams and deliver strategic metrics for current and future business initiatives.What you get to do in this role:* You will provide insights and deep analysis being sought by users/business stakeholders* Work with Cross-Functional Analytics team members to curate and assimilate insights* Grow into being SME on business functions* Gather business requirements from stakeholders on various analytics initiatives* Analyze requirements, determine optimal solutions and determine gap from the current state, dependencies and ways to mitigate risks* Develop business requirements documentation, process workflow diagrams, functional specifications, user acceptance test scripts and other supporting documentation for Business Intelligence and Analytics initiatives* Assist stakeholders with data analysis, design data models & develop DB Views, procs, models in SAP HANA to meet the business need* Develop dashboard and report prototypes and mockups with respect to the UX/UI Best Practices and have impactful UI Design* Communicate status regularly with stakeholders* Define required data integration requirements between various systems and work with extended team to get them created* Collaborate with India Development Center BI team to translate business requirements and get appropriate data solutions developed to meet the business need* Partner with Global BI team to help implement solutions for end-user adoptionIn order to be successful in this role, we need someone who has:* Bachelor's Degree in Information System, Analytics, Business Intelligence or related field required* 0 to 3+ years of documented experience in writing strong SQL, PLSQL in data warehouse technologies (Hana, Snowflake, or any modern database).* Ability to analyze data coming from myriad data sources, mine and analyze and derive value from it to improve business SQL and other computer programs (Python, R is preferred)* Ability to visualize the results in the previous step by putting together simple and easily consumable dashboards using reporting tools* Working knowledge Tableau, Power BI is a plus* Strong analytical and problem-solving ability and be able to dive into technical details and design analytics solutions* Expertise in database design & development, writing optimized queries, handling Facts, dimension data effectively* Must have good communication, presentation, and documentation skills* Capable of using Microsoft Project, Excel, Word, PowerPoint, and Visio or similar products* Business process design, project management, and/or Agile SDLC experience a plus* 1-2 years of SAP HANA experience is a plus","ServiceNow
3.7","Santa Clara, CA",Enterprise Software & Network Solutions,Information Technology
Data Engineer,"Responsibilities Develop and maintain scalable ETL pipelines, build new pipelines and facilitate API integrations to support new requirements. Writing complex SQL queries to serve new requirements for ETL, data analysis and debugging. Writing SQL functions, procedures as required based on the requirements Finetune or optimize queries to support the increasing volume of data. Debug Python code, modify and enhance Python ETL applications based on the requirements on Linux environment. Writing reusable and efficient code in Python and SQL. Write unit, functional, regression tests for enhanced feature, maintain engineering documentation. Communicate closely with all product owners, Business and engineering teams to develop approaches for data platform architecture. Skills Basics of Computer Science - OOPS, Data Structures and Algorithms. Basic understand of regular Linux commands and usage. 5+ years of experience having hands on experience in writing, debugging and optimizing SQL queries, function and stored procedures. 3+ years of experience with hands on experience in writing, debugging Python code on Linux. Experience writing python applications that interact with ORM (Object Relational Mapper) libraries. Knowledge of XML and JSON parsing with unit test and debugging skills. Willingness and ability to learn new toolslanguages as needed. Process oriented with excellent oral and written communication skill with a desire for customer service. An excellent team player and communicator who can work effectively with cross functional teams and ability to navigate ambiguity.","Sonus Software Solutions Inc.
3.0","Sunnyvale, CA",-1,-1
Data Analyst,"Ref ID: 00420-9502600417Classification: Data Analyst

Compensation: DOE

Emphasis query codes experience. Python, R and SQL.
BA with coding experience. Data transformation

Please send resumes to Trupti Deshpande.

Job Requirements:
This individual will create, run, maintain and review a variety of reports including enrollment/sales, forecast, grading, business trend, and financial. The position requires a strong understanding of systems, applications, and data structure with an ability report solutions for evolving business needs. This individual should thrive in a fast-paced, collaborative and dynamic environment. • Data transformation experience with Python libraries such as Numpy, SciPy and pandas • Successfully and quickly fulfill requests for development of ad-hoc reports. • Quickly learn business and system data structures for customized applications.

Robert Half Technology matches IT professionals with some of the best companies on a temporary, project or full-time basis. From roles in software and applications to IT infrastructure and operations, we provide you unparalleled access to exciting career opportunities. Our personalized approach, innovative matching technology and global network with local market expertise help you find the technology jobs that match your skills and priorities fast. By working with us, you have access to challenging opportunities, competitive compensation and benefits, and training to enhance your skill sets.

From philanthropy to environmental stewardship to employee programs, Robert Half is proud to have an active role in the communities in which we live and work. Our company has appeared on FORTUNEs Most Admired Companies list every year since 1998.

Download our mobile app to take your job search on the go!

Contact your local Robert Half Technology office at 888.490.4429 or visit www.roberthalf.com/jobs/technology to apply for this job now or find out more about other job opportunities.

All applicants applying for U.S. job openings must be authorized to work in the United States. All applicants applying for Canadian job openings must be authorized to work in Canada.

© 2020 Robert Half Technology. An Equal Opportunity Employer M/F/Disability/Veterans.

By clicking 'Apply Now' you are agreeing to Robert Half Terms of Use.","Robert Half
3.5","Sunnyvale, CA",Staffing & Outsourcing,Business Services
Data Scientist,"Why We Work at Dun & Bradstreet


We are at a transformational moment in our company journey - and we’re so excited about it. Each day, we are finding new ways to strengthen our award-winning culture, and to accelerate creativity, innovation and growth. Our purpose is to help customers improve business performance with Dun & Bradstreet’s Data Cloud and Live Business Identity, and we’re wildly passionate and committed to this purpose. So, if you’re looking to make an immediate impact at a company that welcomes bold and diverse thinking, come join us!



As a Data Scientist, you will develop novel solutions to market-driven problems using knowledge of the latest ML techniques, rigorous statistical analysis, and practical experience on previous data science projects. You will collaborate with internal and external stakeholders (external customers, other D&B data scientists, sales team members, business unit product leaders, development teams, and global partners) to understand business needs and technical requirements.

You will also:
Serve as a Subject Matter Expert on internal D&B data, and estimation of business size.
Participate and support other teams as needed for all aspects of model development, including design, model implementation, validation, calibration, documentation, product implementation, monitoring, and reporting
Research complex business issues and recommend solutions, including customer data input requirements, other required data sets, modeling approaches, and end products
Basic Qualifications:
Masters in a quantitative / applied field (Engineering, Computer Science, Operations Research, Mathematics, Data Science, Economics, Statistics).
2+ years of experience in data science roles.
Strong knowledge of programming and modeling using Python, R, or SAS.
Strong SQL skills and experience working with large data sets.
Experience working collaboratively, including building and maintaining relationships with internal and external stakeholders/clients.
Experience advising a team on innovative methodologies, data science tools, and environments.
Experience communicating complex ideas to both a technical and non-technical audience.
Experience applying modern machine learning techniques.
Preferred Qualities
Creative and inquisitive in nature, flexibility to learn and apply new methodologies.
Strong writing skills.
Dun & Bradstreet is an Equal Opportunity Employer and all qualified applicants will receive consideration for employment without regard to race, color, religion, creed, sex, age, national origin, citizenship status, disability status, sexual orientation, gender identity or expression, pregnancy, genetic information, protected military and veteran status, ancestry, marital status, medical condition (cancer and genetic characteristics) or any other characteristic protected by law.

We are committed to Equal Employment Opportunity and providing reasonable accommodations to applicants with physical and/or mental disabilities. If you are interested in applying for employment with Dun & Bradstreet and need special assistance or an accommodation to use our website or to apply for a position, please send an e-mail with your request to TalentAcquisitionTeam@dnb.com. Determination on requests for reasonable accommodation are made on a case-by-case basis.

Please note that all Dun & Bradstreet job postings can be found at https://dnb.wd1.myworkdayjobs.com/Careers and all communication from Dun & Bradstreet will come from an email address ending in @dnb.com.","Dun & Bradstreet
3.1","Austin, TX",IT Services,Information Technology
Data Analyst,"The Role:

AlertMedia is looking for a Data Analyst to join the Engineering team. In this role you will have the opportunity to use your data mining and analysis skills to help us answer questions about product usage and trends. Responsibilities for this role include writing SQL queries and creating Excel reports to respond to data requests, working with the Engineering team to leverage AWS tools and services to make high-value data readily available, and creating tools that give stakeholders easy access to current data. Strong creative and technical abilities are vital for success in this role, with the ideal candidate being an independent problem solver and critical thinker. You will have the opportunity to show who you are throughout our interview process, we don't ask any trick questions, or expect you to perform a whiteboard exercise. We want to see you shine by showing us work you are most proud of!

Who you are:

You love data. You love digging for it, slicing and dicing it, and figuring out what it all means. You know the database schema better than anyone. You create quick ad hoc reports to provide your stakeholders with a rough idea of what the data can show and then get to work on making them efficient, performant, and accessible. You have AWS experience and love collaborating with engineers to architect and build data pipelines. You believe in the value of pictures and are a master at creating graphs and charts.

Who we are:

AlertMedia has disrupted the mass notification industry and become its technology leader, now serving some of the largest and most respected companies in the world. Our emergency communication software and monitoring services enable organizations to keep their people safe, informed, and connected. Customers in telecom, healthcare, transportation, energy, manufacturing, government and education are using the AlertMedia platform for emergency communication, regular business communication, and operational activities such as scheduling, dispatching, and other logistics.

This is an amazing opportunity to be part of our wave of momentum and take our company, and your career, to the next growth stage. We'd love to get to know you better and share how we serve our amazing customers. For more information please visit www.alertmedia.com.

What you will do:
Write queries to support data requests from a variety of stakeholders, including Engineering, Product Management, and Customer Success
Work with the Engineering team to develop a data mining strategy and architecture and then build it, leveraging AWS services
Become an expert in the database schema supporting the AlertMedia platform
Streamline reporting by using ETL tools to transform data as needed
Build reports in Excel
Contribute to AlertMedia's culture, values and vision for the future
Requirements:
Bachelor's degree in a technical field such as computer science, computer engineering or related field preferred
2+ years experience with data mining and analysis, reporting, and visualization
Advanced SQL knowledge, Postgres preferred
Strong Excel skills, including visualization
Experience with Amazon AWS data analysis tools, e.g. Redshift
The ability and desire to work in a fast-paced challenging environment
What we offer:
Base salary + Company-Wide Bonus program
Stock options - Be a shareholder in the company
Competitive PTO + holidays to enjoy balance
Health benefits - Medical, Dental, Vision and Life Insurance 100% paid for employees
Amazing rewards and incentives
An exciting and positive work environment
Commitment to community service with opportunities to give back
A Best Places to Work company three years in a row
AlertMedia is proud to be an equal opportunity employer, seeking to create a welcoming and diverse environment.

All qualified applicants will receive consideration for employment without regard to race, color, religion, gender, gender identity or expression, sexual orientation, national origin, genetics, disability, age, or veteran status.

AlertMedia does not currently sponsor applicants for work visas.","AlertMedia
5.0","Austin, TX",Computer Hardware & Software,Information Technology
Data Engineer,"The Job Details are as follows:

OVERVIEW

We are looking for creative and enthusiastic Data Engineers to join our team in building the best Data Platform on the street and enabling our investment teams to monetize data assets. We treat our data systems as software systems and engineer them accordingly. In your role, you will:
Develop cloud-first data ingestion processes using Python, SQL, and Spark
Engineer data models and infrastructure for a wide variety of market and alternative datasets
Design and build services and plugins to enhance our Data Acquisition Platform
Maintain alerting systems to ensure smooth day-to-day operations for hundreds of datasets
Author tests to validate data quality and the stability of the platform
Investigate and defuse time-sensitive data incidents
Communicate with data providers to onboard new datasets and troubleshoot technical issues
Evangelize best practices to our partners throughout the firm
Work directly with Analysts, Quants, and Portfolio Managers to understand requirements and provide end-to-end data solutions
WHAT YOU’LL BRING
Bachelors/Masters degree in Computer Science or a related field
3+ years experience with at least one of Spark, Airflow, data warehousing
Strong analytical, data and programming skills (Python/SQL/NoSQL/Spark)
Ability to understand and contribute to our existing data system software
Experience containerizing workloads with Docker (Kubernetes a plus)
Aptitude for designing infrastructure, data products, and tools for Data Scientists a plus
Strong oral and written communication skills, most importantly, must be a team player","Balyasny Asset Management
3.9","Austin, TX",Investment Banking & Asset Management,Finance
Data Scientist,"At Jabil, we empower the brands who empower the world - it's our reason for being and the guiding force that's driving us to become the most technologically advanced manufacturing solutions provider on the planet. Whether we're serving one of the world's biggest and best known brands or the coolest tech startups, our resolve never wavers. We share common desires with these brands: to make the world a better, safer and cleaner place.

JOB QUALIFICATIONS

KNOWLEDGE REQUIREMENTS

? Advanced Statistics, operations research/ management, mathematics or business analytics with experience, courses, or project work in an analytic methods such as linear, mixed linear, constraint programming, modeling, simulation, time series analysis, pattern recognition, queuing theory, multivariate analysis, and other various predictive analytics techniques

? Strong written and verbal communication skills and the ability to work effectively in teams and under pressure. Multi-lingual capability is a plus.

? Ability to draw conclusions from data and prescribe actionable and measurable activities.

? Highly motivated and creative, thinking ""out of the box"".

? Familiarity with non-relational data frameworks (aka NoSQL, eg. Hive).

? Experience with Apache Pig, Spark systems.

? Strong team mentality, interpersonal and communications skills

? Preferred working directly with management and executives

Jabil, including its subsidiaries, is an equal opportunity employer and considers qualified applicants for employment without regard to race, color, religion, national origin, sex, sexual orientation, gender identify, age, disability, genetic information, veteran status, or any other characteristic protected by law.","Jabil Circuit
3.7","Austin, TX",Electrical & Electronic Manufacturing,Manufacturing
Data Scientist,"At eBay, you will be part of a purpose driven community dedicated to creating a bold and versatile work environment. In eBay Payments, you will be an integral member of a growing organization that inspires passion, courage and inventiveness - creating the future of global commerce and making an important, positive impact on millions of eBay sellers and shoppers around the world. If you are looking for a special place to take your Payments career to the next level, we want to talk with you!

Risk Management is at the core of Payments done well and we are hiring curious, driven, and courageous experts to transform our business unit to enable eBay's next generation Payments strategy. Our focus is to ensure the integrity of our marketplace for buyers and sellers who transact with us every single day. The scope of our charter includes Risk Management Strategy, Policy, Decision Sciences, and Policy Operations.

We are looking for a highly talented and self-motivated data scientist to join our Decision Science team. Decision Science contains both data scientists and software engineers responsible for creating and implementing state of the art machine learning algorithms for fraud detection and risk assessment in support of Risk Management. The primary responsibility of this role is to assist in algorithm development inside of a high throughput, low latency, big data environment.

Primary Job Responsibilities

The data scientist will support the risk department, leveraging big data technologies to aggregate, transform, and perform meaningful feature engineering that includes structured transactional data, unstructured natural language data, and image-based data. You will perform feature engineering and statistical analysis across heterogeneous sources of structured/text/images, and build algorithmic solutions to reduce fraud, monitor our buyers and sellers, and intermediate payments to improve the overall eBay experience. As a member of the decision science team, you will research and develop new methodologies and techniques to improve the overall effectiveness of risk management. You will mine and analyze massive amount of unique internal and external data to gain deep business knowledge and insight on customer activity and usage behaviors and their relationships with fraud, credit risks, and other types of behaviors. You will act as the technical owner of projects that may require significant customization of existing analytic tools, techniques, processes or development of new ones. Perform statistical data analysis and understanding, ensure data quality, and develop tracking and reporting systems to determine the effectiveness of models, rules, and other risk initiatives and programs. Design and create systems to structure, aggregate, and turn petabytes of messy information into statistically significant features for modeling purposes. Problem sets are focused around fraud and risk management to include models to prevent fraudsters from listing and monetizing on the platform, thwarting registration attacks, and risk scoring our customers.

Required Skills and Experience:
Advanced degree in Computer Science or quantitative field, MS/PHD preferred
Entry to mid-level role.
Experience in SQL, relational databases
Experience with Big Data technology: Hadoop framework: Hive, Spark, CUDA, etc. a plus.
Expertise in machine learning packages Python, R
Strong knowledge of 1 or more scripting and programming languages (Python, Java, Scala, etc.)
Proven background and applied knowledge of Natural Language Processing (NLP), Computer Vision and low-level vision. Modern Frameworks such as Google BERT, OpenNLP.
Strong Background in Image Feature Engineering
Background in a variety of modeling techniques: LSTM, Convolutional Neural Network, Deep Neural Networks, Statistical NLP, Gradient Boosted Trees.
Strong analytical skills with good problem-solving ability

This website uses cookies to enhance your experience. By continuing to browse the site, you agree to our use of cookies

View our privacy policy

View our accessibility info

eBay Inc. is an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, national origin, sex, sexual orientation, gender identity, veteran status, and disability, or other legally protected status. If you are unable to submit an application because of incompatible assistive technology or a disability, please contact us at talent@ebay.com. We will make every effort to respond to your request for disability assistance as soon as possible.

For more information see:

EEO is the Law Poster

EEO is the Law Poster Supplement","eBay
3.6","Austin, TX",Internet,Information Technology
Data Scientist,"About UsAt Cloudflare, we have our eyes set on an ambitious goal: to help build a better Internet. Today the company runs one of the world's largest networks that powers trillions of requests per month. Cloudflare protects and accelerates any Internet application online without adding hardware, installing software, or changing a line of code. Internet properties powered by Cloudflare have all web traffic routed through its intelligent global network, which gets smarter with every request. As a result, they see significant improvement in performance and a decrease in spam and other attacks. Cloudflare was recognized by the World Economic Forum as a Technology Pioneer and named to Entrepreneur Magazine's Top Company Cultures list.We realize people do not fit into neat boxes. We are looking for curious and empathetic individuals who are committed to developing themselves and learning new skills, and we are ready to help you do that. We cannot complete our mission without building a diverse and inclusive team. We hire the best people based on an evaluation of their potential and support them throughout their time at Cloudflare. Come join us!About the departmentCloudflare is looking to build and grow our Business Intelligence team responsible for building large-scale enterprise data lake and EDW from different sources and enabling various product and business teams such as Marketing, Customer Support, Sales, Finance with key business dashboards/reporting, insights and recommendation models.About the roleAs part of this initiative, we are looking for a strong Data Scientist to join Cloudflare and help us drive predictive analytic insights and best practices at scale from the ground up. This is a high visibility role and success in this role comes from marrying a strong data & modeling background with acute product and business acumen to deliver highly strategic and compelling insights that accelerate our business growth and influence our product decisions within Cloudflare. This person will also play a crucial role in hiring and growing the data science team in Austin in a rapid manner.What we look for: predictive modeling techniques, machine learning, model creation and deployment, storytelling and visualization, strong business & product acumen, cross-functional collaboration, creative problem solving, agile mindsetWhat you'll do* Partner and align with business leaders, stakeholders, product managers and internal teams to understand the business and product challenges and goals and address them using predictive analytics in a globally distributed environment.* Understand data landscape i.e tooling, tech stack, source systems etc. and work closely with the data engineering team to improve the data collection and quality.* Understand business/product strategy and high-level road map and align analysis efforts to enable them with data insights and help achieve their strategic goals.* Use your strong audience focused presentation and storytelling skills focused on key takeaways in a crisp and concise manner.* Define, implement, and train statistical, machine learning, and deep learning models.* Use software engineering best practices to publish model scores/insights/learnings at scale within the company.* Ability to define and spot macro and micro levels trends with statistical significance on a regular basis and understand key drivers driving those trends.* Active role in hiring, growing, and mentoring the data scientist team in Austin.Examples of desirable skills, knowledge and experience* M.S or Ph.D in Computer Science, Statistics, Mathematics or other quantitative field.* 5+ years of data scientist experience with proven industry experience in a large scale environment (petabyte scale, globally distributed teams).* 2+ years experience with a fast-growing SaaS business based company is preferred.* Strong experience in scientific computing using Python, R, or Scala.* Experience with Spark, SQL, Tableau, Google Analytics, Hive and BigQuery (or any other Big data/Cloud equivalent) etc.* Experience working with and processing structured, unstructured, and semi-structured data.* Work closely with data engineering team to ensure robust data pipelines and model deployment.* Proven track record of applying data insights and machine learning in order to address business needs and drive revenue.* Strong communication and presentation skills catered to different audience within the company.* Capable of working closely with business, engineering, and product teams to ensure data initiatives are aligned with business needs.* Experience in hiring data scientists and establishing team best practices is preferred.What Makes Cloudflare Special?We're not just a highly ambitious, large-scale technology company. We're a highly ambitious, large-scale technology company with a soul. Fundamental to our mission to help build a better Internet is protecting the free and open Internet.Project Galileo: We equip politically and artistically important organizations and journalists with powerful tools to defend themselves against attacks that would otherwise censor their work, technology already used by Cloudflare's enterprise customers--at no cost.Athenian Project: We created Athenian Project to ensure that state and local governments have the highest level of protection and reliability for free, so that their constituents have access to election information and voter registration.Path Forward Partnership: Since 2016, we have partnered with Path Forward, a nonprofit organization, to create 16-week positions for mid-career professionals who want to get back to the workplace after taking time off to care for a child, parent, or loved one.1.1.1.1: We released 1.1.1.1 to help fix the foundation of the Internet by building a faster, more secure and privacy-centric public DNS resolver. This is available publicly for everyone to use - it is the first consumer-focused service Cloudflare has ever released. Here's the deal - we don't store client IP addresses never, ever. We will continue to abide by our privacy policy and ensure that no user data is sold to advertisers or used to target consumers.Sound like something you'd like to be a part of? We'd love to hear from you!Cloudflare is proud to be an equal opportunity employer. We are committed to providing equal employment opportunity for all people and place great value in both diversity and inclusiveness. All qualified applicants will be considered for employment without regard to their, or any other person's, perceived or actual race, color, religion, sex, gender, gender identity, gender expression, sexual orientation, national origin, ancestry, citizenship, age, physical or mental disability, medical condition, family care status, or any other basis protected by law. We are an AA/Veterans/Disabled Employer.Cloudflare provides reasonable accommodations to qualified individuals with disabilities. Please tell us if you require a reasonable accommodation to apply for a job. Examples of reasonable accommodations include, but are not limited to, changing the application process, providing documents in an alternate format, using a sign language interpreter, or using specialized equipment. If you require a reasonable accommodation to apply for a job, please contact us via e-mail at hr@cloudflare.com or via mail at 101 Townsend St. San Francisco, CA 94107.","CloudFlare
3.7","Austin, TX",Internet,Information Technology
Data Scientist,"Job Description

What Youll Get to Do

Be part of a high-performing, multi-disciplinary team supporting rapid and innovative prototype development of warfighting capabilities that increase lethality, survivability, and warfighter effectiveness in support of the Air Force Tactical Exploitation of National Capabilities (AF TENCAP) mission to exploit national systems, educate warfighters, and influence development of future requirements. As a member of the team you will integrate with cross-functional teams to conduct research, design, development, prototyping, systems engineering, integration, testing and evaluation, transitioning, and training across multiple technology areas to include: Geolocation and Tagging, Tracking, Locating; Sensor, Data Fusion, and Dissemination; Unconventional / Asymmetric Warfare / Support to Special Operations; Situational Awareness; Cyberspace and Spectrum Warfare Operations; Air Superiority; Command, Control and Spectrum Utilization; Real-Time/Near Real Time Large Data Analytics and Virtualization. Projects in the portfolio will range in quantity, scope, duration, and complexity. Projects are designed to transition to warfighters and/or national intelligence agencies for operational use, sustainment and appropriate acquisition Programs of Record for further development.

More About the Role
Identify and develop actionable insights through problem definition, application of statistical models, and analysis against existing and future data
Assists in identification of important data sets for exploitation and analysis, and prepare briefings, analyses, and visualizations in support of leadership
Apply data mining, data modeling, and machine learning to extract and analyze information from large structured and unstructured datasets.
Assists in the visualize, interpret, and report data findings.
Youll Bring These Qualifications
Top Secret
Possess a bachelors or masters degree.
Hands-on experience creating algorithms and engineering tools for data processing and modeling and simulation.
Practical understanding in modeling and simulation with a focus on optimization, including theoretical and numerical methods for analysis of current and future systems.
Fundamental knowledge in applying ML and AI to image processing and information discovery Software development experience using C++, Python, Java or equivalent.
These Qualifications Would be Nice to Have
Eligibility for TS/SCI clearance with Polygraph (U.S. Citizenship required for clearance)
What We Can Offer You:
Weve been named a Best Place to Work by the Washington Post.
Our employees value the flexibility at CACI that allows them to balance quality work and their personal lives.
We offer competitive benefits and learning and development opportunities.
We are mission-oriented and ever vigilant in aligning our solutions with the nations highest priorities.
For over 55 years, the principles of CACIs unique, character-based culture have been the driving force behind our success.

Job Location

US-Washington-DC-AUSTIN

CACI employs a diverse range of talent to create an environment that fuels innovation and fosters continuous improvement and success. At CACI, you will have the opportunity to make an immediate impact by providing information solutions and services in support of national security missions and government transformation for Intelligence, Defense, and Federal Civilian customers. CACI is proud to provide dynamic careers for employees worldwide. CACI is an Equal Opportunity Employer - Females/Minorities/Protected Veterans/Individuals with Disabilities.","CACI International
3.6","Austin, TX",Aerospace & Defense,Aerospace & Defense
Data Scientist,"The Business

GradTests.com is a leading provider of practice psychometric tests to graduates, students and young professionals.

The Role

A data science all rounder role. The core purpose of the role is to build models to improve the product, the customer experience and ultimately the business. We're looking for someone with a nice blend of technical skills, and softer skills like business acumen, decision making and communication skills.

You'll do things like:
Conceive, devise, create, implement and fine tune data science models to solve a range of business problems, from customer churn through to
Set up, run and analyse A/B experiments for the website and email marketing campaigns
Help devise and layout a high quality infrastructure, upon which future data science can flourish
Help up skill other analytical team members into advanced data science techniques
Produce ad hoc analyses
And let's be honest, a whole load of data wrangling!
Skills and experience

Non negotiables:
SQL
Python or R
Data science models (K-means, random Forrest, neural nets etc.)
Strong foundational knowledge in stats and maths
Experience in actually productionising models and exposing to real customers
Business acumen
Strong communication skills, both written and verbal
Nice to haves:
Experience in working with developers, especially on experimentation
Some kind of cloud based experience (AWS preferred)
Some basic knowledge of source control with Git
Our application process consists of some online testing with Alooba, video call interview and then a case study. We expect the process to take about 10 business days end to end.

Job Types: Full-time, Contract

Salary: $120,000.00 /year

Experience:
Analytics: 1 year (Preferred)
Work Remotely:
Yes",GradTests (gradtests.com),"Austin, TX",-1,-1
Statistician,"The U.S. Department of the Treasury has a distinguished history dating back to the founding of our nation. As the steward of U.S. economic and financial systems, Treasury is a major and influential leader in today's global economy. We have over 100,000 employees across the country and around the world. Come Join the Department of the Treasury and Invest in Tomorrow.
See Other Information for Locations
Positions are to be filled in the Large Business & International (LB&I), Data Solutions division.
Eight (8) positions are to be filled in any of the following locations:
Birmingham, AL
Fayetteville, AR
Little Rock, AR
Phoenix, AZ
El Monte, CA
Glendale, CA
Laguna Niguel, CA
Los Angeles, CA
Long Beach, CA
Oakland, CA
Sacramento, CA
San Diego, CA
San Francisco, CA
San Jose, CA
Santa Ana, CA
Lakewood, CO
Hartford, CT
New Haven, CT
Norwalk, CT
Washington, DC
Newark, DE
Miami, FL
Ft. Myers, FL
Jacksonville, FL
Maitland, FL
Plantation, FL
Tampa, FL
West Palm Beach, FL
Atlanta, GA
Honolulu, HI
Des Moines, IA
Chicago, IL
Downers Grove, IL
Schiller Park, IL
Springfield, IL
Indianapolis, IN
Wichita, KS
Louisville, KY
New Orleans, LA
Boston, MA
Brockton, MA
Stoneham, MA
Southborough, MA
Baltimore, MD
Lanham-Seabrook, MD
Rockville, MD
Ann Arbor, MI
Clinton Township, MI
Detroit, MI
Farmington Hills, MI
Flint, MI
Grand Rapids, MI
Pontiac, MI
Bloomington, MN
Chesterfield, MO
Lee's Summit, MO
Charlotte, NC
Greensboro, NC
Raleigh, NC
Omaha, NE
Edison, NJ
Iselin, NJ
Mountainside, NJ
Paterson, NJ
Las Vegas, NV
Albany, NY
Bethpage, NY
Buffalo, NY
New York, NY
Rochester, NY
Cincinnati, OH
Columbus, OH
Independence, OH
Oklahoma City, OK
Tulsa, OK
Portland, OR
Philadelphia, PA
Pittsburgh, PA
King Of Prussia, PA
Guaynabo, PR
Warwick, RI
Franklin, TN
Memphis, TN
Nashville, TN
Austin, TX
Farmers Branch, TX
Fort Worth, TX
Houston, TX
San Antonio, TX
Ogden, UT
Salt Lake City, UT
Norfolk, VA
Richmond, VA
Vienna, VA
Seattle, WA
Milwaukee, WI
Waukesha, WI
Kearneysville, WV
Martinsburg, WV
WHAT DOES A DATA SCIENTIST DO? The Data Scientist utilizes advanced analytical, statistical, and computer programming skills to develop data- driven solutions to difficult business challenges. As a data scientist, you are responsible for conducting data-centric projects to provide insight and informed decisions for mission- oriented programs of the Internal Revenue Service (IRS), which may impact multiple program segments, divisions, the Service, or segments of the taxpayer population. This is accomplished by utilizing a wide range of technical competencies such as statistics and machine learning, coding languages, data wrangling, and reporting and visualization techniques. The Data Scientist may lead team or cross functional projects, and will apply critical thinking, problem solving and ability to communicate complex analysis to advance the use of data-driven decision making in IRS operations.

WHAT IS THE LARGE BUSINESS AND INTERNATIONAL (LB&I) DIVISION OF THE INTERNAL REVENUE SERVICE? The Large Business and International (LB&I) business unit provides service and enforcement activities to support tax compliance of businesses and related entities with assets of $10 million or more, as well as small U.S. businesses engaged in international, U.S. citizens abroad, and foreign persons and businesses with a U.S. tax requirement.
As a Data Scientist, you will:
Serve as a technical expert with responsibility for the initiation, planning, implementation, controlling, modifying and executing of all or part of an entire project, including such tasks as formulation of workload estimates for program segments, specification of the methodology to be used, preparation of appropriate specifications and procedures, and review of computer systems specifications and materials and instructions needed for assuring the adequacy of the project’s design and objectives.
Explore novel methods of retrieving data and develop innovative recommendations to management and senior leadership as a means for making data driven decisions such as modification of processes and policies. Review, evaluate, validate, and document the results of the findings.
Assist the supervisor in determining the scope, goals and schedules for future programs in the Office. Collaborate with business or technology partners to understand business needs, identify opportunities, and develop and implement analytical solutions.
Identify and assess relevant data sources’ validity and reliability to meet project needs. Collate, clean, transform, analyze, and integrate structured and unstructured data from various sources in preparation for analysis.
Apply statistical methods and concepts including data mining, statistical theory and research procedures to test hypotheses using structured and unstructured data. Develop data product solutions to improve customer experiences, anomaly detection, and business outcomes. Develop proofs of concept or demonstrations to evaluate feasibility of project solutions and recommend visualization strategies.
Document project work and review deliverables for validity, reliability and timeliness. Communicate analytic solutions to technical and non-technical stakeholders, including during executive- level and/or cross-agency meetings, in a clear and effective manner using oral and written communications.
Maintain knowledge of state-of-the-art innovations in data science from both academic and industry sources and identify opportunities for implementation. Engage in general professional development to improve knowledge of IRS processes/programs.
Apply computer based mathematical/statistical techniques using software. Lead or participate in statistical projects or studies in survey sampling (design and estimation), modeling, or statistical research. Apply knowledge of programming/coding language (i.e., SQL, SAS, SPSS, RStudio) to develop scripts or applications.
Act as a troubleshooter in resolving bottlenecks at any step in a project by identifying and proposing solutions; this may include coordination with other project team members or stakeholders to mitigate issues.

WHERE CAN I FIND OUT MORE ABOUT OTHER IRS CAREERS? If you want to find out more about IRS careers, visit us on the web at www.jobs.irs.gov
#LI-POST
You must meet the following requirements by the closing date of this announcement
BASIC QUALIFICATION REQUIREMENTS:

GS-1530 Statistician All Grades:
You must have a Bachelor's degree that included 15 semester hours in statistics (or in mathematics and statistics, provided at least 6 semester hours were in statistics), and 9 additional semester hours in one or more of the following: physical or biological sciences, medicine, education, or engineering; or in the social sciences including demography, history, economics, social welfare, geography, international relations, social or cultural anthropology, health sociology, political science, public administration, psychology, etc. Credit toward meeting statistical course requirements should be given for courses in which 50 percent of the course content appears to be statistical methods, e.g., courses that included studies in research methods in psychology or economics such as tests and measurements or business cycles, or courses in methods of processing mass statistical data such as tabulating methods or electronic data processing. OR
Combination of education and experience -- courses as shown above, plus appropriate experience or additional education. The experience should have included a full range of professional statistical work such as (a) sampling, (b) collecting, computing, and analyzing statistical data, and (c) applying statistical techniques such as measurement of central tendency, dispersion, skewness, sampling error, simple and multiple correlation, analysis of variance, and tests of significance.
GS-13 LEVEL: You must have one year of specialized experience at a level of difficulty and responsibility equivalent to the GS-12 grade level in the Federal service. Specialized experience for this position includes all of the following:
Experience applying project management principles on a data science project
Experience planning and executing a variety of data science and/or analytics projects.
Experience using data mining process models (such as CRISP-DM, SEMMA, etc.,) to design and execute data science project.
Experience preparing and analyzing structured and unstructured datasets to explorations and evaluating data science centric models.
Experience working with multiple data types and formats as a part of a data science project.
Experience applying a range of analytic approaches, including (but not limited to) machine learning, text analytics, and natural language processing; graph theory, link analysis and optimization models; complex adaptive systems; and/or deep learning neural networks that are part of the exploration.
Experience coding in various programming languages (such as R, Python, SQL, or JAVA) to conduct various phases of data science projects.
Experience creating and querying different datastores and architectures (such as Sybase, Oracle, and open-source databases) to work with various types of data as part of the data science project.
Experience using tools for data visualization (graphs, tables, charts, etc.,) and end-user business intelligence.
-The experience may have been gained in the public sector, private sector or Volunteer Service. One year of experience refers to full-time work; part-time work is considered on a prorated basis.
-To ensure full credit for your work experience, please indicate dates of employment by month/year, and indicate number of hours worked per week, on your resume.","Internal Revenue Service
3.5","Austin, TX",Federal Agencies,Government
Data Scientist,"Job Title: Data Scientist

Location: Austin, Texas

Required Security Clearance: Top Secret or above

Required Education: Desired not required: BA/BS or MA/MS in a technical field such as mathematics, engineering, or computer science (6 years of work experience may be substituted for a Bachelor's degree)

Description:

The Mid-Level Data Scientist are responsible for analyzing, interpreting, and extracting data using IT techniques to support decision-making. This role works with customers to understand changing requirements and recommends solutions based on quantitative analysis. Responsibilities include working independently and collaboratively on a team to develop data models and solutions. This role compiles and reviews data, often disparate and inconsistent, to address complex intelligence issues or problems for the customers. This role requires constructing and performing complex statistical, mathematical, and data analysis independently or in partnership with other data scientists or analysts. This role provides recommendations for the development of tools and applications that improve process effectiveness and efficiency.

Experience and Qualifications:

• Experience supporting complex data science and analytic projects

• Experience/knowledge of computer science concepts including programming, statistics, data architecture, and data analytics

• Experience with quantitative and qualitative content analytics

• Excellent reading comprehension skills

• Detail-oriented with a proficiency for researching, analyzing, and prioritizing intelligence reports and cables

• Ability to work with IC tools and databases

• Strong problem-solving, analytic, and written and oral communication skills

• Excellent attention to detail and ability to accurately follow SOPs • Ability to work shift work/extended hours • Strong interpersonal skills and the ability to work well both independently and in a team environment

Preferred Skills and Education:

• Experience in modern machine learning, AI, biometrics, social network analysis, or geospatial analysis

• Experience/knowledge of link analysis tools (e.g. Palantir, i2 Analyst's Notebook)

• Experience with cloud architectures including AWS

• Experience with distributed computing and storage technologies

Working Conditions:

Work is typically based in a busy office environment and subject to frequent interruptions. Business work hours are normally set from Monday through Friday 8:00am to 5:00pm, however some extended or weekend hours may be required. Additional details on the precise hours will be informed to the candidate from the Program Manager/Hiring Manager.

Physical Requirements: Office work.

Background Screening/Check/Investigation: Successful Completion of a Background Screening/Check/Investigation will be required as a condition of hire.

Employment Type: Full-time

Benefits:

Federal Data Systems, LLC offers competitive compensation, a flexible benefits package, career development opportunities that reflect its commitment to creating a diverse and supportive workplace. Benefits include, not all inclusive – Medical, Vision & Dental Insurance, Flex-Spending Account, Paid Time-Off & Company Paid Holidays,401K, Short and Long-Term Disability, Personal Development & Learning Opportunities, Technical Training Assistance, and Tuition Reimbursement, etc

Other:

This employer participates in E-Verify and will provide the federal government with your Form I-9 information to confirm that you are authorized to work in the U.S.

Federal Data Systems, LLC (FEDDATA) is an Equal Opportunity/Affirmative Action Employer. That does not unlawfully discriminate in any of its programs or activities on the basis of race, color, religion, sex, age, sexual orientation, gender identity, national origin, disability, protected veteran status, or any other basis prohibited by applicable law.","Federal Data Systems
3.1","Austin, TX",IT Services,Information Technology
Data Analyst,"As the worlds number 1 job site, our mission is to help people get jobs. We need talented, passionate people working together to make this happen. We are looking to grow our teams with people who share our energy and enthusiasm for creating the best experience for job seekers.
We are a rapidly growing and focused product team building the most popular job site on the planet. Every month, over 250 million people count on Indeed to help them find jobs, make it easy to apply, research companies, and connect qualified candidates to their job openings. With product teams in Austin, Tokyo, Seattle, San Francisco, Singapore and Hyderabad, we are improving people's lives all around the world, one job at a time.

The base salary range below represents the low and high end of the Indeed salary range for this position. Actual salaries will vary and may be above or below the range based on various factors including but not limited to location, experience, and performance. The range listed is just one component of Indeed's total compensation package for employees. Other rewards may include quarterly bonuses, Long Term Incentive Plan units, an open Paid Time Off policy, and many region-specific benefits.
Austin Area Base Salary Range: 60,000 - 80,000 USD per year

We are building out a new business line at Indeed, focused on providing a frictionless talent agency experience for Job Seekers and workforce optimization for Clients. Keeping with the Indeed mission, this new business puts the Job Seeker first, utilizing software solutions to optimize the sourcing, screening, hiring, onboarding, and time management worker journey. The Recruiting and Support team is critical to recruiting Job Seekers and retaining Workers and Clients. We are looking for someone who is comfortable in a tech start up environment, effective building and managing a large team, rolls with change, and leverages data to make recommendations.

Your role.

In this role youll work on defining, measuring and scaling the success of our product and our internal teams. Youll partner with product, engineering, sales, and leadership to create analysis this drives our business forward. You will work closely with product to define requirements and guide our data analysis strategy.

As a Data Analyst, you will:
Understand your stakeholders objectives, the metrics that are the most important to them, and how they measure their performance.
Turn business requirements into technical requirements
Find and understand the correct data sources for a given analysis
Identify, design, and implement internal process improvements including automating manual processes and optimizing data delivery
Shape how our team manipulates and visualizes data
Advocate and strategize ways for our Sales and service groups to move faster and more efficiently
Requirements:
2+ years working in Strategy & Operations, Analytics, Engineering and/or Consulting
Excellent oral and written communication skills, and comfort presenting to everyone from entry-level employees to senior leaders
Effective communicator who is able to explain technical concepts in a simple way to non-technical audiences
Knowledge of ETL and data warehouse concepts and processes
Experience building and delivering proof of concepts. Strive for simplicity.
2+ Years of SQL. Must have the ability to write complex, highly-optimized queries across large volumes of data
1+ years of solid Python programming skills to create pipelines to cleanse and manipulate data
What we'd love to see (but isn't required):
Previous experience working with Sales data
Experience in a fast paced, rapidly evolving startup environment with the ability to work under pressure and consistently revise approaches in response to new demand
Indeed provides a variety of benefits that help us focus on our mission of helping people get jobs.

View our bounty of perks: http://indeedhi.re/IndeedBenefits

View Indeed's Applicant Privacy Terms: https://www.indeed.com/legal/applicant-privacy","Indeed
3.7","Austin, TX",Internet,Information Technology
Data Scientist,"Who is Moxie?


Moxie is a company on a mission to change the way e-Commerce is done. We are passionate about ensuring a great experience for our customers and their customers. Moxie integrates the power of email, chat, and real-time collaboration with a mature, robust, and multi-channel customer engagement platform, comprehensive analytics, and a fully integrated, system-wide knowledgebase.

More than 600 of the worlds leading brands rely on Moxie to engage with their constantly connected customers resulting in increased revenue, conversion, and total customer value. With top-tier, industry leading leadership, and a strong vision of the future, we are looking to recruit ambitious talent to join our team and truly make an impact. We provide an environment that encourages an entrepreneurial spirit, innovative ideas, and personal growth through the delivery of cutting edge digital and mobile technology.

Your Contribution

In this position, you will be leveraging the latest advancements in NLP and our existing corpus of millions of textual data to develop a pipeline for extracting key insights for our customers. Key problems include information extraction of semi-structured text, text segmentation, entity classification, etc. You will help prototype novel methods and productionize promising methods. You will collaborate with other team members, product managers, and engineers of other projects to add value to Moxies product offering.

Your Skills and Experience

· 2+ years of relevant professional experience and/or an advanced degree

· Knowledge of foundational techniques with NLP, such as text processing, document classification, sentiment analysis, etc.

· Experience in programming languages (Python, Java, etc.)

· Familiarity with NLP tools, such as NLTK, Gensim, SpaCy, and Word2Vec

· Working knowledge of statistics and probability (statistical inference, Bayesian statistics)

· Good written and spoken communication skills

Following Skills are a Plus

· Deep understanding of English grammar, syntax, semantics and human speech

· Data visualization and presentation of data-driven insights

· Experience with distributed computing (Hadoop/Spark)","NGENERA CORPORATION
2.2","Austin, TX",Computer Hardware & Software,Information Technology
Data Analyst,"Zynga is a leading developer of the world’s most popular social games that are played by people around the world every single day. To-date, more than 1 billion people have played our games across Web and mobile, including Words With Friends, FarmVille, Zynga Poker, Merge Dragons, Empires & Puzzles, Hit it Rich! Slots and CSR.

Zynga’s Data Science and Analytics team uses our outstanding and expansive data to deliver fundamental insights on who our audience is, how they engage with our games, and what are the best ways to personalize their in game experience. We strive for a better understanding of our players which translates into challenges and features that delight them.

Here’s where you would come in: A successful candidate will be passionate about using analytics and data science to impact revenue through customer-centric, data-driven initiatives. He/she will partner with other analytics/data science teams and studio leaders around the globe to identify and act on opportunities to increase engagement, retention, revenue, optimization, and improve the player experience for our customers.

Lastly, he/she will have strong technical analytical skills across a wide spectrum, including strong proficiency in scripting languages such as SQL, R and Python, telemetry definition and data modelling, data aggregation and manipulation, customer analytics, business intelligence, data visualization, and data science techniques.

Responsibilities:
Own objective evaluation of game health and all content/feature releases, through daily KPI reports, bi-weekly business health meetings, and feature/event readouts and analysis.
Engage with game leadership team to provide insights and guidance derived from quantitative study; influence and analytically validate product assumptions and roadmap.
Conduct partner relationships with leads of the Product Management, Design, Marketing, Advertising and Production organizations to understand the analytical requirements of the business.
Build KPI dashboards/reports that signal deviations from expected outcomes, empowering feature owners to run performance for the business.
Own experimentation efforts, including experimental design and analysis.
Manage game team’s data assets by defining telemetry events, architecting data models, and defining data quality governance.
Collaborate with software architects, database engineers, analysts, data scientists and game teams to drive key strategic initiatives for the improvement of the data and analytics infrastructure.
Required Skills and Experience:
B.S. or B.A. in Math, Statistics, Comp Sci, Engineering, or other quantitative field required; graduate degree preferred
3+ years of meaningful work experience in data science or analytics role in a product support capacity
Strong experience in SQL; Proficient in Python; Adept in at least one visualization tool such as Tableau.
Proven experience with some of the following: statistics, experimental design, machine learning, data mining, predictive modeling, deep learning
Experience in analyzing large datasets, preferably in a Hadoop or Spark environment, and deploying production ready systems at scale
Strong written and oral communication skills
Ability to work effectively in a fast-paced environment with changing priorities
Strong passion for gaming.
Zynga is an equal opportunity employer. We are proud of our broad community; we do not discriminate on the basis of race, sex, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, medical condition, disability, or any other class or characteristic protected by applicable law. We welcome job-seekers, players, employees, and partners from all backgrounds. Join us!

We will consider all qualified job-seekers with criminal histories in a manner consistent with applicable law.

Zynga is committed to providing reasonable accommodation to applicants with disabilities. If you need an accommodation during the interview process, please let us know.","Zynga
4.1","Austin, TX",Video Games,Media
Data Scientist,"About SubjectWell
SubjectWell is a venture-backed startup on an unstoppable mission to disrupt the antiquated $100 billion dollar clinical trial patient recruitment sector. Almost all clinical trials fall behind schedule, leaving patients unable to access the most promising treatments and pharmaceutical and biotech companies unable to quickly carry their innovations to market. SubjectWell was founded by two entrepreneurs on their third successful startup, to unlock the potential of a true marketplace for clinical trials. We leverage proven data science and performance marketing techniques to hit a hard reset to the massive patient recruitment challenge that sits at the critical nexus of speeding delivery of the best therapeutics to the world.

Here's your chance to really make a difference, both in your career and in the lives millions.

About the position
One of our core principles is a dedication to data-driven decision-making. The primary goal of this position is improve the process by which we match patients to clinical trials.

This successful candidate will perform the following:
Create and maintain insightful reporting for all business activities. Report to team on high-level summary statistics, key performance indicators, and trend/deviation estimates.
Deliver point-estimates and standard errors of causal effects of both firm decisions and external developments. Methods include field experiments (A/B testing), structural modeling, and econometric analysis.
Employ statistical, time-series, and structural models to provide forecasts of key business indicators. Forecasts are used for internal planning as well as guidance for external partners.
Provide recommendations to managers on optimal business decisions and strategy. Explore growth and effiiciency-enhancing opportunities, and deliver empirical and structural evidence to support improvements across all operations.
Qualifications and Skills
Graduate training in economics, or related field such as operations, statistics, finance, or quantitative marketing. Coursework in econometrics or advanced statistics required.
Working knowledge of SQL and relational databases
Fluency in Excel
Fluency in Python, R or another advanced data programming language
Strong skills in presentation and data visualization
Strong working knowledge of Tableau or other visualization platforms
Autonomous and self-motivated work ethic. Inclination to assume ownership of both short- and long-term projects.
Rockstar analytic and problem solving skills
Ability to extract meaningful business insights from data and identify the stories behind the patterns

Benefits
Full Medical, Dental, and Vision Benefits
401(k)
Company stock options
Paid time off
Paid holidays
Casual office
Flexible vacation",SubjectWell,"Austin, TX",-1,-1
Data Scientist,"Horne LLP is an industry leader in Accounting and Business Advisory Services and currently provides service from 13 locations across the US and Puerto Rico. Our Government Services practice is at the forefront of disaster recovery efforts nationwide with one of the most experienced and innovative teams anywhere.

The Data Scientist will be a technical role in leading data science projects, combining predictive analytics, data modeling, and machine learning. In this position, you will be responsible for building it, it’s attributes, and its parameters while modifying solutions to evolving business challenges

Requirements:
Required 4+ years of experience in relevant role
Bachelor’s degree in related field (mathematics, statistics, computer science, engineering or a related quantitative field)
Expertise and deep knowledge of typical data science techniques such as classification, regression and optimization
Experience/proficiency in statistical programming languages: R, SAS, SPSS, etc.· Experience/proficiency in one or more of the following scripting languages: Python, Perl, Java or Ruby
Experience/proficiency in relational databases such as: SQL, Oracle, Teradata
Understanding of:
BI tools (SAP business Intelligence, MicroStrategy, Tableau, QlikSense)
Big Data ecosystems& Distributed file systems / data frameworks (Apache Hadoop, AWS)
Machine learning tools/packages
Proficient level of MS Office (Word, Excel, Outlook, Powerpoint, Sharepoint, OneNote) and presentation tools
Responsibilities:
Independently and collaboratively explore, develop and deliver solutions to meet the business needs. Undertake data collection, processing and analysis.
Apply in-depth technical knowledge to create and implement customer centric solutions to complex business problems (ecosystem) across multiple areas.
Develop and apply algorithms. Analyze complex unstructured data sets to recommendations and implement solutions.
Build business intelligence system for the business integrating all and future platforms with multiple sources of data.
Independently convert business management questions into analyzable problems with solutions.
Horne LLP is an industry leader in Accounting and Business Advisory Services and currently provides service from 13 locations across the US and Puerto Rico. Our Government Services practice is at the forefront of disaster recovery efforts nationwide with one of the most experienced and innovative teams anywhere.","Horne LLP
3.1","Austin, TX",Accounting,Accounting & Legal
Machine Learning Engineer,"Who we are


Fueled by a fundamental belief that having access to financial services creates opportunity, PayPal (NASDAQ: PYPL) is committed to democratizing financial services and empowering people and businesses to join and thrive in the global economy. Our open digital payments platform gives PayPal’s 305 million active account holders the confidence to connect and transact in new and powerful ways, whether they are online, on a mobile device, in an app, or in person. Through a combination of technological innovation and strategic partnerships, PayPal creates better ways to manage and move money, and offers choice and flexibility when sending payments, paying or getting paid. Available in more than 200 markets around the world, the PayPal platform, including Braintree, Venmo and Xoom, enables consumers and merchants to receive money in more than 100 currencies, withdraw funds in 56 currencies and hold balances in their PayPal accounts in 25 currencies.

When applying for a job you are required to create an account, if you have already created an account - click Sign In.

Creating an account will allow you to follow the progress of your applications. Our system does have some requirements that will help us process your application, below are some guidelines for creation of your account:
Provide full legal First Name/Family Name – this is important for us to ensure our future hires have the right system set up.
Please Capitalize first letter of your First and Last Name.
Please avoid using fully capitalized text for your First and/or Last Name.
NOTE: If your name is hyphenated or has multiple capitalization, please use the same format as your government ID.
Job Description Summary:

PayPal customer success team is looking for a talented and highly motivated senior engineer for a technical domain that comprises of customer data analytics and ML/DL models development to support different business use cases

Job Description:

We are looking for a talented and highly motivated senior engineer for a technical domain that comprises of customer data analytics and ML/DL models development to support different business use cases
5+ Years of Experience Desired
Discovering, analyzing, structuring and mining data
Statistical hypotheses validation and model performance analysis
Developing neural network models supporting business use cases
Design and coordinate implementation of DL based solutions for production usage
Deep understanding of data mining algorithms and statistical methods
Experience in successfully applying machine learning to real-world problems
Strong knowledge of Deep Learning frameworks: Keras, Tensorflow, PyTorch, etc
Knowledge in python and packages for data analysis (scipy, numpy, pandas, matplotlib)
Proficient in one or more of programming languages Scala, Java, C++
Strong knowledge of extracting and processing data with RDBMS/NoSQL
Experience with one or more Container-ecosystem (Docker, Mesos, Kubernetes) will be a plus
Good communication skills and team player attitude
Experience in Natural Language Processing/Understanding using deep neural networks ( RNN (LSTM, GRU) / CNN) is a plus
Experience in working with GPU, profiling/low-level optimizations, Cuda/CuDNN is a plus
Experience with BigData ecosystem Hadoop, Hive, Spark/PySpark is a plus
Subsidiary:

PayPal

Travel Percent:

0

Primary Location:

Austin, Texas, United States of America

Additional Locations:

We're a purpose-driven company whose beliefs are the foundation for how we conduct business every day. We hold ourselves to our One Team Behaviors which demand that we hold the highest ethical standards, to empower an open and diverse workplace, and strive to treat everyone who is touched by our business with dignity and respect. Our employees challenge the status quo, ask questions, and find solutions. We want to break down barriers to financial empowerment. Join us as we change the way the world defines financial freedom.

PayPal provides equal employment opportunity (EEO) to all persons regardless of age, color, national origin, citizenship status, physical or mental disability, race, religion, creed, gender, sex, pregnancy, sexual orientation, gender identity and/or expression, genetic information, marital status, status with regard to public assistance, veteran status, or any other characteristic protected by federal, state or local law. In addition, PayPal will provide reasonable accommodations for qualified individuals with disabilities. If you are unable to submit an application because of incompatible assistive technology or a disability, please contact us at paypalglobaltalentacquisition@paypal.com.","PayPal
3.9","Austin, TX",Internet,Information Technology
Machine Learning Engineer,"ABOUT ENVIEW

Enview creates a digital twin of the world in 3D to protect people and critical infrastructure. We solve one of the hardest problems in machine perception: the application of AI to nation-scale, 3D point clouds to virtualize the world in 3D. The proliferation of 3D sensors like LiDAR is enabling for markets such as Energy, National Security, Autonomous Logistics & Vehicles, and Smart Cities. However, the unstructured 3D data from these sensors can't be processed by traditional computer vision methods, forcing these markets to be bottlenecked by slow, expensive, and unscalable manual services. Enview has built the world's most scalable AI platform to enable rapid, automated classification of 3D point clouds, which enables digital twinning of the world in 3D at unprecedented speed and scale.

RESEARCH AT ENVIEW

Advances in compute capacity combined with the proliferation of cost-efficient LiDAR sensors enables Enview's Research Team to pioneer ideas in the complex field of unstructured 3D point cloud classification. Our research drives Enview's ability to meet the needs of users in the field, who rely on our mapping data and insights about the environment to conduct important tasks in a fast-changing world.

We put a premium on innovation and curiosity, with the Research Team on the vanguard of new capability development. We work with the engineering team to transition our work into Enview's product pipeline with large-scale computing and advanced visualizations. The Research Team reports directly to the CTO and is engaged in collaborations with teams across the company.

THE ROLE

As a Machine Learning Engineer, your work will drive Enview's ability to extract geospatial insights from 3D point cloud data. Using your expertise you will help research and design algorithms and ML systems to tap into the cutting edge of 3D computer vision. In collaboration with the Engineering team, you will leverage your skills to build infrastructure for rapid prototyping of ML systems to support deployments to customers in the field.

YOU WILL:
Use machine learning to create reduced order models from complex, unstructured 3D point clouds
Design algorithms/ML systems capable of extracting geospatial insights from a variety of data sources
Build infrastructure for rapid training and testing of ML systems
Maintain insight into trends and advances in machine learning
Publish and present, formally and informally, on behalf of Enview
MINIMUM QUALIFICATIONS:
BS in engineering, computer science, or a related field
2+ years experience in 3D computer vision/machine learning OR 5+ years experience in 2D computer vision/machine learning (grad school counts!)
Background and expertise with object segmentation, classification, registration and general scene understanding
Mastery of Python and prior experience with GPU acceleration
Capability with deep learning frameworks (ie, TensorFlow, Keras, etc)
Excellent communication skills
Rigorous analytical thinking
Priority on team excellence
PREFERRED QUALIFICATIONS:
MS or PhD in engineering, computer science, or a related field
Prior experience with cloud computing, AWS preferred
Prior experience with GIS
PERKS
Opportunity to play a foundational role at a well-funded startup with major clients and revenue
Work with people like yourselftalented and thoughtful; passionate about solving challenging problems
Unlimited vacation policy (we're serious about this - do great work, have fun and live life)
Full medical/vision/dental + 401K
EXPORT CONTROL

Enview works with software and technology subject to U.S. export controls regulations. Under these regulations it may be necessary for Enview to obtain a U.S. government export license prior to releasing its software and technology to certain persons. Enview also complies with applicable U.S. sanctions laws and regulations, which can restrict Enview's ability to employ certain persons subject to U.S. sanctions.","Enview
5.0","Austin, TX",Computer Hardware & Software,Information Technology
Data Analyst,"HORNE is an industry leading provider of disaster recovery solutions for states, territories, and municipalities in the wake of natural and man-made disasters. We currently provide services from 13 locations across the US, Puerto Rico, and the US Virgin Islands. We are looking for a Data Analyst who will collaborate with program managers and our technology team to deliver world class reporting solutions that help us improve the delivery of federal assistance after a disaster. Your work will help our clients gain meaningful insight into their rebuilding efforts and provide actionable intelligence that helps communities recover faster. With guidance from senior team members, you will be responsible for designing and building data visualization tools in response to client needs, program management requests, and internal practice management needs.

Primary Duties& Responsibilities:
Design, develop, implement and maintain reporting solutions
Utilize reporting software (Power BI, Tableau, etc.) to automate and standardize report delivery tailored to the client’s needs
Anticipate program reporting needs and collaborate with our systems design team
Ensure data quality and integrity in databases
Work with program managers to identify team training needs or process improvements that will improve reporting reliability and accuracy
Create complex functions, scripts, stored procedures and triggers to support reporting development and maintenance
Evaluate existing reporting solutions, collaborate with program managers and partners, implement improvements
Troubleshoot reporting accuracy or completeness issues
Work with appropriate urgency and an attention to detail
Work with the team to deliver world-class work on time and within budget
Continuously enhance your skills and ultimately our capabilities through professional development, skills learning, and self-instruction
Work Complexity:
Custom development of reporting solutions for complex disaster recovery programs including housing recovery operations, infrastructure rebuilding programs, economic development programs, financial management and oversight programs, and monitoring programs
Install, configure, and integrate solutions into the customer environment
Work on multiple, small to large projects as a team member, or independently on small projects
Work within aggressive timelines to deliver accurate and impactful reporting solutions
Work may require limited travel
Qualifications and Requirements:
Bachelor’s degree in computer science or a related information technology field
Knowledge of MS SQL programming with ability to design and implement complex reporting solutions
Experience with SQL Server
Good understanding of data and schema standards and concepts
Critical thinking and problem-solving skills
Bonus:
Experience with Power BI or Tableau
Experience with data warehouse/ETL implementation and/or management
Experience with OnBase
Experience with low code development environments such as OutSystems or Appian
Experience with SSRS, Crystal Reports and/or Business Intelligence tools
Experience with cloud computing environments such as Azure, AWS or Google Cloud","Horne LLP
3.1","Austin, TX",Accounting,Accounting & Legal
Data Analyst,"The Data Analyst will be part of the Department of Family and Protective Services (DFPS) Office of Data and Systems Improvement (DSI). The position will act as an analyst in the Regional Systems Improvement Division. DSI works to build a preeminent system for protecting children and vulnerable adults from abuse, neglect and exploitation by partnering with DFPS leadership to continuously and proactively improve the agency's processes, practices, and functioning to ensure optimal outcomes for the people the agency serves.The DSI Team works with leadership to strategically use data to identify what parts of the system are working well and areas to target for improvement. The Team then works with the multiple divisions to explore the different aspects of a system (the people, policy, and processes) to find out why particular areas are performing well or need improvement. Working with leadership and, when appropriate, external stakeholders, the Team brainstorms what to do, helps implement plans, and tracks and reports on progress. Essential Job Functions:We're looking for someone who wants to dedicate their talents and abilities to serving and protecting the most vulnerable Texans. Someone who is excited to be a part of an established team of highly skilled, capable, and motivated individuals. We want someone who is intellectually curious, wanting to understand not just what is happening but why, and who's not afraid to think outside the box for innovative and new ways of doing things. We need someone who can engage a variety of people across the agency, building strong relationships and support for the work of our division. The specific job functions include:* Evaluate and conduct in-depth analyses of statewide systems and initiatives to proactively identify areas of strength and areas needing improvement.* When areas needing improvement are identified, support state office leadership in understanding root causes, crafting actionable plans and solutions, making needed adjustments and reporting on progress.* Create and provide strategic guidance on processes, tools and reports to assess quality casework, improve decision making and ensure client safety, including the use of predictive analytics to target high risk populations.* Organize and lead work groups, including internal and external stakeholders, and facilitate a collaborative approach to designing and implementing process, organizational, policy, training and other changes.* Explain data and analysis in a way that is understandable to those with limited data knowledge or experience. Knowledge Skills Abilities:* Ability to creatively problem solve, including accessing needed resources from multiple areas and sources and helping management think outside the box in developing solutions* Understanding of and demonstrated skill in project management - specifically being able to keep plans on track* An attitude of customer service with demonstrated experience in team-building and collaboration - helping management stay focused on outcomes to be achieved but being flexible and deferring to management with respect to how to best accomplish objectives* Knowledge of the child and adult welfare system generally - the purpose of child and adult welfare, how the system works along with governing policy and laws* Communication skills - the ability to communicate information orally and in writing in a way that is understandable for multiple different audiences, including taking complicated information and making it understandable* An ability to work with staff at all different levels* Data analysis skills - ability to understand and conduct basic data analysis* An understanding of and ability to apply process and systems improvement principles Registration or Licensure Requirements:None Initial Selection Criteria:Bachelor's degree (four years of applicable work experience can be substituted for the education criteria)Ability to travel (up to 40%)Experience organizing and leading workgroups and facilitating meetingsExperience communicating with individuals of differing levels of experience, knowledge, and authorityExperience implementing process, organizational, policy, and other systems level changeExperience in data analysis and use of Excel at a minimum.Experience with SQL and/or an analytics tool such as SAS, STATA, SPSS, R or Python preferred. Additional Information:None MOS Code:SB 389 Compliance: HHS Military Crosswalk (XLS).HHS agencies use E-Verify. You must bring your I-9 documentation with you on your first day of work.I-9 Form - Click here to download the I-9 form.In compliance with the Americans with Disabilities Act (ADA), HHS agencies will provide reasonable accommodation during the hiring and selection process for qualified individuals with a disability. If you need assistance completing the on-line application, contact the HHS Employee Service Center at 1-888-894-4747. If you are contacted for an interview and need accommodation to participate in the interview process, please notify the person scheduling the interview.","Texas Health & Human Services Commission
2.8","Austin, TX",State & Regional Agencies,Government
Data Analyst,"Job Description:

The client is currently implementing a Performance Management visualization portal pilot and in the planning stage of a client Performance Management and Data Analytics system with a goal to accomplish the following:
Development and publication of project management documents and deliverables in compliance with client Framework directives.
Conduct an in-house assessment of client data analytics and reporting needs.
Creation of statements of work that clearly define the services and deliverables required of a vendor in support of the implementation of the data and analytics solution.
Obtainment of matching federal funds for this initiative through the development of federally approved IAPD(s).
Design, development, and implementation of client performance portal using an agile methodology for all standard SDLC phases that include, but not limited to:
Validation of performance metric requirements.
Creation of EPICS/User Stories.
Creation and validation of dashboard and report mock-ups.
Automation of data acquisition from a variety of data sources.
Dashboard and report development.
Testing – integration, load and stress, and user.
Deployment/publication internally and externally.
Operations support and enhancement of the Performance Portal pilot.
Responsibilities:
Collaboration with the Chief Data Architect and the client Office of the Chief Technology Officer on technology and tool recommendations.
Implementation and configuration of developmental tools.
Coordination of infrastructure build-out and on-going support.
Collaboration with other members of the Data Analytics Support Team, key stakeholders, other agencies, and third-party vendors.
Participation in requirements and design sessions as a member of an agile sprint team.
Skills and Qualifications:

Required:
8 years of Strong analytical and problem-solving skills with experience architecting data analytics, performance management system, or data warehousing projects.
7 years of experience in defining integrative views of data drawn together from many data sources across the enterprise, including file extracts and different relational databases as sources.
7 years of experience in designing semantic data views to help visualization developers understand and access data using common business terms.
4 years of Strong dimensional modeling skills and proficiency in using data modeling tools such as Erwin.
4 years of demonstrated ability in engaging and communicating with stakeholders, across both business and technology functions
2 years of experience on an agile sprint team, preferably with prior experience as a member of a sprint team.
1 year of experience with JIRA software.
Preferred:
8 years of excellent oral and written communication skills.
7 years of experience in Risk management skills.
4 years of effectively manage multiple responsibilities, prioritize conflicting assignments, and switch quickly between assignments, as required.
3 years of prior experience in the Healthcare Industry.
2 years of prior experience with a client-agency.
2 years of experience with state-of-the-art software components for performance metrics data visualization or business intelligence environment.","CYNET SYSTEMS
4.0","Austin, TX",IT Services,Information Technology
Data Engineer,"We are looking for a teammate that is excited to take ownership of our data infrastructure and put us on a path where we are iterating quickly and using data to solve some of the biggest problems facing our industry. You will have a seat at the table in making technology decisions and in helping determine what and how we build things as opposed to just getting handed specifications to implement.

RunTitle is an Austin-based venture-backed software company innovating within the 100 year-old oil & gas title industry. We’re looking for someone who is eager to disrupt an extremely archaic industry, but also enjoys startup perks, happy hours, and afternoon ping pong showdowns. We’re a small but quickly growing organization, so every single person here has a mission critical impact on our business.

Responsibilities:

Take ownership and lead product development for our internal data processing pipeline
Perform analysis and generate models to improve our automated data extraction capabilities
Prototype, test and build models that will be adapted for use in our production data pipeline
Work closely with the engineering team to advise on system architecture and help guide engineering priorities
Build and lead a team of analysts and data scientists
Deepen our culture of data driven decision making

A little more about you:

18+ months of NLP, Data Science, ML professional work
Experience specifying and building clean and functional data pipelines
Comfort manipulating and analyzing complex, unstructured, data from various sources
Ability to communicate complex quantitative analysis and approaches clearly

Nice-to-have experience:

Named Entity Recognition
Dependency Parsing
Semantic Role Labeling
Probabilistic String Matching
Elasticsearch, Apache Spark

Perks:

Small team = opportunity for big impact
Compensation includes equity and competitive salary
Excellent company-sponsored benefits
Stocked kitchen including all of the Topo Chico your heart desires

An Equal Opportunity Employer","RunTitle
4.2","Austin, TX",Oil & Gas Exploration & Production,"Oil, Gas, Energy & Utilities"
Data Analyst,"PURPOSE AND SCOPE:

The Data Analyst is responsible for leading and contributing to the processes of report development, analysis and reconciliation. The Data Analyst is instrumental in cross-departmental reporting, communication, efficiency improvement, and risk identification. The Data Analyst must abide by all policies and processes to meet all state, regulatory, health/safety, and compliance guidelines.



PRINCIPAL DUTIES AND RESPONSIBILITIES:
Works on problems of moderate scope where analysis of situation or data requires a review of a variety of factors.
Exercises judgment within defined procedures and practices to determine appropriate action.
Primary source to validate and reconcile general reporting data throughout the organization
Identifies discrepancies, risk and root cause for remediation
Creates and maintains reporting in compliance with the organization’s policies (CMS and FHP).
Assists in preparing required materials for appropriate parties throughout the organization.
Abides by all policies, procedures, and work instructions for the reporting function of the Medicare Advantage (MA-PD) plan.
Ensures data integrity is maintained throughout the reporting lifecycle.
Improves efficiencies and service provided while reducing costs.
Assists with preparing files and materials for internal and external regulatory audits.
Implements reporting and reconciliation workflows and document processes.
Pulls ad-hoc reporting as needed
Automates manual reporting and analysis of business implications and trends
May provide assistance to junior level staff with general tasks that require a better understanding of functions, as directed by immediate supervisor.
May refer to senior level staff for assistance with higher level problems that may arise.
Escalates issues to supervisor/manager for resolution, as deemed necessary.
Review and comply with the Code of Business Conduct and all applicable company policies and procedures, local, state and federal laws and regulations.
Assists with various projects as assigned by direct supervisor.
Other duties as assigned.
Additional responsibilities may include focus on one or more departments or locations. See applicable addendum for department or location specific functions.
PHYSICAL DEMANDS AND WORKING CONDITIONS:
The physical demands and work environment characteristics described here are representative of those an employee encounters while performing the essential functions of this job. Reasonable accommodations may be made to enable individuals with disabilities to perform the essential functions.
EDUCATION:

Bachelor’s Degree required
EXPERIENCE AND REQUIRED SKILLS:
2 – 5 years’ related experience in reporting analytics.
Proficient with computers, Microsoft Office applications and Windows operating systems.
Process development/implementation experience preferred.
Medicare or Healthcare experience preferred.
Strong analytical and problem solving skills.
Strong attention to detail.
Excellent customer/interpersonal skills.
Excellent written and verbal communication skills.
Ability to communicate clearly and effectively with other associates and clients.
Organized and can function independent of immediate supervision.
Ability to lead projects preferred.
EO/AA Employer: Minorities/Females/Veterans/Disability/Sexual Orientation/Gender Identity

ADDENDUM:


Insurance/FHP focus:

SQL, SAS or other reporting database knowledge preferred
Fresenius Medical Care North America maintains a drug-free workplace in accordance with applicable federal and state laws.","NxStage
3.5","Austin, TX",Health Care Products Manufacturing,Manufacturing
Data Engineer,"Posted: Feb 6, 2020
Role Number:
200148400
At Apple, excellent ideas have a way of becoming extraordinary products, services, and customer experiences very quickly. Bring passion and dedication to your job and there's no telling what you could accomplish. Would you like to work in a fast-paced environment where your technical abilities will be challenged on a day-to-day basis? If so, Apple's Global Business Intelligence (GBI) team is seeking a hardworking Data Engineer to build high quality, scalable and resilient distributed systems that power apple's analytics platform and data pipelines.

Apple's Enterprise Data warehouse system cater to a wide variety of real-time, near real-time and batch analytical solutions. These solutions are integral part of business functions like Sales, Operations, Finance, AppleCare, Marketing and Internet services enabling business drivers to make critical decisions. We use a diverse technology stack such as Teradata, HANA, Vertica, Hadoop, Kafka, Spark, and Cassandra and beyond. Designing, Developing and scaling these Big Data technologies are a core part of our daily job. The team member will be able think outside of the box and should have passion for building analytics solutions to enable business in making time sensitive and critical decisions.
Key Qualifications
We would like for you to have In-depth understanding of data structures and algorithms
We are looking for experience in designing and building dimensional data models to improve accessibility, efficiency, and quality of data
Database development experience with Relational or MPP/distributed systems such as Oracle/Teradata/Vertica/Hadoop
We are seeking programming experience in building high quality software in Java, Python or Scala preferred
Experience in designing and developing ETL data pipelines. Should be proficient in writing Advanced SQLs, Expertise in performance tuning of SQLs
You will demonstrate excellent understanding of development processes and agile methodologies
Strong analytical and interpersonal skills
Enthusiastic, highly motivated and ability to learn quick
Experience with or advance courses on data science and machine learning is ideal
Work/project experience with Big Data and advanced programming languages is a plus
Experience developing Big Data/Hadoop applications using java, Spark, Hive, Oozie, Kafka, and Map Reduce is a huge plus
Description
You will build and design data structures on MPP platform like Teradata, Hadoop to provide efficient reporting and analytics capability.

Design and build highly scalable data pipelines using new generation tools and technologies like Spark, Kafka to induct data from various systems.

Translate complex business requirements into scalable technical solutions meeting data warehousing design standards.

Strong understanding of analytics needs and proactive-ness to build generic solutions to improve the efficiency.

Build dashboards using Self-Service tools like Tableau and perform data analysis to support business.

Collaborate with multiple multi-functional teams and work on solutions which has larger impact on Apple business.

We seek a self starter, forward-thinking person with strong leadership capabilities.

Ability to communicate effectively, both written and verbal, with technical and non-technical multi-functional teams.

You will interact with many other group’s internal team to lead and deliver elite products in an exciting rapidly changing environment.
Education & Experience
Bachelors Degree","Apple
4.1","Austin, TX",Computer Hardware & Software,Information Technology
Data Analyst,"PURPOSE AND SCOPE:

The Data Analyst is responsible for leading and contributing to the processes of report development, analysis and reconciliation. The Data Analyst is instrumental in cross-departmental reporting, communication, efficiency improvement, and risk identification. The Data Analyst must abide by all policies and processes to meet all state, regulatory, health/safety, and compliance guidelines.



PRINCIPAL DUTIES AND RESPONSIBILITIES:
Works on problems of moderate scope where analysis of situation or data requires a review of a variety of factors.
Exercises judgment within defined procedures and practices to determine appropriate action.
Primary source to validate and reconcile general reporting data throughout the organization
Identifies discrepancies, risk and root cause for remediation
Creates and maintains reporting in compliance with the organization’s policies (CMS and FHP).
Assists in preparing required materials for appropriate parties throughout the organization.
Abides by all policies, procedures, and work instructions for the reporting function of the Medicare Advantage (MA-PD) plan.
Ensures data integrity is maintained throughout the reporting lifecycle.
Improves efficiencies and service provided while reducing costs.
Assists with preparing files and materials for internal and external regulatory audits.
Implements reporting and reconciliation workflows and document processes.
Pulls ad-hoc reporting as needed
Automates manual reporting and analysis of business implications and trends
May provide assistance to junior level staff with general tasks that require a better understanding of functions, as directed by immediate supervisor.
May refer to senior level staff for assistance with higher level problems that may arise.
Escalates issues to supervisor/manager for resolution, as deemed necessary.
Review and comply with the Code of Business Conduct and all applicable company policies and procedures, local, state and federal laws and regulations.
Assists with various projects as assigned by direct supervisor.
Other duties as assigned.
Additional responsibilities may include focus on one or more departments or locations. See applicable addendum for department or location specific functions.
PHYSICAL DEMANDS AND WORKING CONDITIONS:
The physical demands and work environment characteristics described here are representative of those an employee encounters while performing the essential functions of this job. Reasonable accommodations may be made to enable individuals with disabilities to perform the essential functions.
EDUCATION:

Bachelor’s Degree required
EXPERIENCE AND REQUIRED SKILLS:
2 – 5 years’ related experience in reporting analytics.
Proficient with computers, Microsoft Office applications and Windows operating systems.
Process development/implementation experience preferred.
Medicare or Healthcare experience preferred.
Strong analytical and problem solving skills.
Strong attention to detail.
Excellent customer/interpersonal skills.
Excellent written and verbal communication skills.
Ability to communicate clearly and effectively with other associates and clients.
Organized and can function independent of immediate supervision.
Ability to lead projects preferred.
EO/AA Employer: Minorities/Females/Veterans/Disability/Sexual Orientation/Gender Identity

ADDENDUM:


Insurance/FHP focus:

SQL, SAS or other reporting database knowledge preferred
Fresenius Medical Care North America maintains a drug-free workplace in accordance with applicable federal and state laws.","Fresenius Medical Care
3.2","Austin, TX",Health Care Products Manufacturing,Manufacturing
Data Analyst,"The Data Analyst serves as a resource for business intelligence, performance and operational analysis for Central Health. Under general direction of the Analytics and Reporting Manager, the Data Analyst is responsible for organizing, analyzing and reporting on data from large clinical, financial and enrollment data sets. The Data Analyst will also assist in the design and development of data warehouses, performance dashboards and other systems that support the needs of an integrated network of physicians, safety net providers and hospitals to advance care that is patient centered and data driven.

Collect and document business requirements for reporting and analysis initiatives with customers.
Perform quantitative and/or qualitative data analysis and prepare results to share with internal and external customers.
Aid in design and development of data warehouse/data mart applications.
Interact with IT Team and Business Units to interpret dashboard requirement specifications and assist in the development and implementation of dashboards for the CCC.
Undertake complex data integration activities.
Utilize SQL or other advanced analytic tools to perform data extract and query functions.
Identify and troubleshoot data anomalies and irregularities.
Prepare written and oral reports that communicate necessary information to internal and external customers.
Produce and streamline as needed ongoing monthly, quarterly and annual reports in support of CCC.
Willingness to learn and work with Business Intelligence (BI) tools for extracting and compiling data.
Become a data subject matter expert (SME) and understand various sources and applications of CCC data.
Performs other duties as assigned.
KNOWLEDGE, SKILLS, AND ABILITIES
Use of statistics to solve problems and perform moderately complex data analysis.
Experience understanding and writing SQL queries in various environments.
Experience developing and troubleshooting programming code (e.g. SQL, SAS, STATA, R).
Demonstrated ability to manage and prioritize multiple projects with varying deadlines.
Compliance with data confidentiality and security procedures.
Perform complex operations in Microsoft Office Suite, with an emphasis on Excel and Access.
Ability to write and speak clearly, easily communicating complex ideas as indicated by audience.
Knowledge of healthcare, including medical claims coding, relationships between health plans, providers, and payers, a plus.

MINIMUM EDUCATION AND EXPERIENCE
Bachelor’s degree in related field required, Master’s degree preferred.
1-3 years of experience with data management and statistical analysis.
Proficiency in using SQL for database queries.
Experience in a health or healthcare field.
Experience using statistical analysis software such as SAS, R, or STATA is desirable but not required.
Any equivalent combination of education and/or experience may substitute.","Central Health
3.6","Austin, TX",Health Care Services & Hospitals,Health Care
Data Analyst,"Lightspeed Systems is looking for a passionate Data Analyst to transform our data into insights and insights into actions that could affect millions of K-12 students.

Using the latest tools and processes, Lightspeed Systems is able to maximize our technology offerings and deliver unparalleled service and support. The ideal candidate should be highly skilled in all aspects of data analytics, including storage and modeling, data mining, and storytelling with visualizations. Additionally, you should be committed to providing data in an ethical, sustainable, and self-service manner for continued innovation and growth by our various stakeholders.

ABOUT THE ROLE
Develop and maintain datastores by acquiring data from primary and secondary sources, writing scripts that will make our data evaluation process flexible and scalable
Define and implement data acquisition and integration logic, selecting appropriate combination of methods and tools within defined technology stack to ensure optimal scalability and performance
Proactively analyze data to answer key questions from stakeholders or out of self-initiated curiosity with an eye for what drives business performance, investigating and communicating areas for improvement in efficiency and productivity
Assist in interpreting and validating statistical models and A/B test results
Participate in strategic and tactical planning discussions - interface with business customers, gathering requirements and delivering complete self-service reporting solutions.
Work closely with project managers to understand and maintain focus on their analytical needs, including identifying critical metrics and KPIs, and deliver actionable insights to relevant decision-makers
Create and maintain rich interactive visualizations through data interpretation and analysis integrating various reporting components from multiple data sources
Applicants must be authorized to work for ANY employer in the US. We are unable to sponsor or take over sponsorship of employment Visa at this time.

ABOUT YOU
2+ years of relevant experience in a business analytics, business intelligence or comparable data engineering or data science role
Strong communication and interpersonal skills as you'll work cross-functionally across the organization (marketing, finance, sales, etc.you will work with every department)
Familiar with various supervised and unsupervised modeling techniques including but not limited to Decision Trees, Regressions, SVM, K-Means, Dimensionality Reduction, and others
A/B test experience preferred
Must be an analytical and creative thinker: wherever possible, you look to resolve questions through data and measurement
Strong attention to detail and accuracy you will be organizing and disseminating significant amounts of information on which business decisions will be made
You are skilled at being a storyteller with data
Online web analytics experience preferred but not required (measuring and tracking website behavior, interaction, pathing and fallout)
Desired Tools/Languages
SQL
Python, R, Perl, SAS, or other statistical packages/scripting languages
Experience with Cloud Environments and Tools (AWS, GCP, Azure)
Experience with traditional data stores (PostgreSQL, SQL Server, MySQL), NoSQL datastores (Cassandra, DynamoDB), and file system stores (HDFS, S3)
Experience with BI tools (Tableau, Looker, SiSense, etc)P
We require all qualified applicants, as part of the application process, to complete a set of assessments. We invite you to jump start your application for this role by completing our assessment (it will only take 7-10 minutes).

ABOUT US

Education is undergoing a technology revolution with new devices and tools being added to the classroom every day and IT departments are responsible for keeping all this technology managed, safe and working. That is where we come in! Lightspeed Systems, ed-tech provider and leader in K-12 device filtering for 20 years, partners with schools to make learning safe, managed and mobile. Learn more at www.lightspeedsystems.com.

We love our employees, and we show it. A sneak peek into our BENEFITS & PERKS include:
Health -- Medical, dental and vision insurance with healthy company contribution toward premiums.
Wellness -- Lightspeed kicks cash into your HSA if you participate our HDHP. Employees are provided an adjustable desk and onsite gyms at some offices. Healthy Holiday and PTO policy.
Retirement -- 401(k) matching up to 6%
Perks -- Fully stocked kitchen with snacks and beverages. Some lunches provided as well!","Lightspeed Systems
4.3","Austin, TX",Computer Hardware & Software,Information Technology
Data Engineer,"Data Engineer

ETL automation tools such as Informatica, Mulesoft, SSIS, Alooma, or Apache Airflow

Experience with traditional RDBMS solutions such as Microsoft SQL Server and Oracle

Experience with cloud-based platforms and tools

Familiarity with DevOps tools and practices such as Git, Jenkins, JIRA, Azure DevOps

Experience with integrating to both database systems and APIs

Experience with documenting technical requirements, designs and systems

Extensive experience building scalable and resilient data pipelines

Extensive experience writing SQL

Experience with a procedural, functional or object-oriented programming language such as Python, Java, Scala, R

Additionally, candidates should be able to perform at a high level in at least two of the following technology categories:
Big Data tools such as Apache Hadoop, Spark, and Hive including managed solutions such as Databricks, Amazon EMR, Azure HD Insight, and Google Cloud Dataproc
Cloud data storage solutions such as Amazon S3, Azure Blob Storage, or Google Cloud Storage
Data warehousing solutions such as Redshift, BigQuery, and Snowflake
Message broker solutions such as Kafka, Google Pub/Sub, Amazon Kinesis
Stream processing solutions such as Flume, Storm, Spark Streaming
NoSQL Databases such as HBase, Cassandra, Redis
Requirements

3-5+ years of experience in technology and/or consulting

Bachelor’s Degree in CS, MIS, CIS, or a comparable technical degree

US Citizen or GC Holder

Benefits

Sense Corp powers insight-driven organizations.

We turn data into actionable insights and transform organizations for the digital era.

Our people, culture, and how we engage with our clients are differentiators. Brilliant, Creative, Human, and Fun exemplify who we are. We are regularly recognized as a Best Place to Work by Austin, Houston, Dallas, and St. Louis Business Journals. With operations in Austin, Atlanta, Columbus, Dallas, Houston, San Antonio, and St. Louis we serve mid-market to Fortune 50 companies.

The Sense Corp Compass

We may be the only management consulting firm in the country where being brilliant isn’t enough to land you a job. Sense Corp people must be brilliant, creative, human, and fun all at once. In other words, we hire terrific, well-rounded people. It’s one reason clients love working with us. And it’s why we enjoy working with each other. We may not sound like typical consultants but that’s OK. We don’t think like them either.

Visit us at www.sensecorp.com.","Sense Corp
3.8","Austin, TX",Accounting,Accounting & Legal
Data Engineer,"Join SADA as a Data Engineer!

Your Mission

As a Data Engineer at SADA, you will work collaboratively with architects and other engineers to recommend, prototype, build and debug data infrastructures on Google Cloud Platform (GCP). You will have an opportunity to work on real-world data issues facing our customers today. Engagements vary from being purely consultative to requiring heavy hands-on work and cover a diverse array of domain areas, such as data migrations, data archival and disaster recovery, and big data analytics solutions requiring a combination of batch or streaming data pipelines, data lakes and data warehouses.

You will be recognized as an established contributor by your team. You will contribute design and implementation components for multiple projects. You will work mostly independently with limited oversight. You will also participate in client-facing discussions in areas of expertise.
Pathway to Success

#BeOneStepAhead: At SADA we are in the business of change. We are focused on leading-edge technology that is ever-evolving. We embrace change enthusiastically and encourage adaptability. This means that not only do our engineers understand that change is inevitable, but they embrace this change to continuously broaden their skills, preparing for future customer needs.

Your success comes from your enthusiasm, insight, and positive impact. You will be given direct feedback quarterly with respect to the scope and quality of your contributions, your ability to estimate accurately, customer feedback at the close of projects, your collaboration with your peers, and the consultative skill you demonstrate in customer interactions.

As you continue to execute successfully, we will build a personalized development plan together that leads you through the engineering or management growth tracks.

Expectations

Required Travel - 30% travel to customer sites, conferences, and other related events
Customer Facing - You will interact with customers on a regular basis, sometimes daily, other times weekly/bi-weekly. Common touchpoints occur when qualifying potential opportunities, at project kickoff, throughout the engagement as progress is communicated, and at project close. You can expect to interact with a range of customer stakeholders, including engineers, technical project managers, and executives.
Training - Ongoing with a first-week orientation at HQ followed by a 90-day onboarding schedule. Details of the timeline can be shared.

Job Requirements

Required Credentials:
Google Professional Data Engineer Certified or able to complete within the first 45 days of employment

Required Qualifications:
Expertise in at least one of the following domain areas:
Data warehouse modernization: building complete data warehouse solutions, including technical architectures, star/snowflake schema designs, infrastructure components, ETL/ELT pipelines, and reporting/analytic tools. Must have hands-on experience working with batch or streaming data processing software (such as Beam, Airflow, Hadoop, Spark, Hive).
Data migration: migrating data stores to reliable and scalable cloud-based stores, including strategies for near zero-downtime.
Backup, restore & disaster recovery: building production-grade data backup and restore, and disaster recovery solutions. Up to petabytes in scale.
Experience writing software in one or more languages such as Python, Java, Scala, or Go
Experience building production-grade data solutions (relational and NoSQL)
Experience with systems monitoring/alerting, capacity planning and performance tuning
Experience in technical consulting or other customer-facing role

Useful Qualifications:
Experience working with Google Cloud data products (CloudSQL, Spanner, Cloud Storage, Pub/Sub, Dataflow, Dataproc, Bigtable, BigQuery, Dataprep, Composer, etc)
Experience with IoT architectures and building real-time data streaming pipelines
Applied experience operationalizing machine learning models on large datasets
Knowledge and understanding of industry trends and new technologies and ability to apply trends to architectural needs
Demonstrated leadership and self-direction -- a willingness to teach others and learn new techniques
Demonstrated skills in selecting the right statistical tools given a data analysis problem

About SADA

Values: We built our core values on themes that internally compel us to deliver our best to our partners, our customers and to each other. Ensuring a diverse and inclusive workplace where we learn from each other is core to SADA’s values. We welcome people of different backgrounds, experiences, abilities and perspectives. We are an equal opportunity employer.

Make them rave
Be data driven
Be one step ahead
Be a change agent
Do the right thing

Work with the best: SADA has been the largest partner in North America for GCP since 2016 and has been named the 2019 and 2018 Google Cloud Global Partner of the Year. SADA has also been awarded Best Place to Work by Inc. as well as LA Business Journal!

Benefits: Unlimited PTO, competitive and attractive compensation, performance-based bonuses, paid holidays, rich medical, dental, vision plans, life, short and long-term disability insurance, RRSP, professional development reimbursement program as well as Google Certified training programs.

Business Performance: SADA has been named to the INC 5000 Fastest-Growing Private Companies list for 12 years in a row garnering Honoree status. CRN has also named SADA on the Top 500 Global Solutions Providers for the past 5 years. The overall culture continues to evolve with engineering at its core: 3200+ projects completed, 3000+ customers served, 10K+ workloads and 25M+ users migrated to the cloud.","SADA
4.7","Austin, TX",IT Services,Information Technology
Data Engineer,"Pilytix brings Explainable Artificial Intelligence (XAI) to sales teams so they can be more effective and close more deals, faster. We use best-in-class tools to quickly deliver data-driven insights to all of our clients. Data Engineers will assist in the development of cutting-edge data pipelines to ingest, transform and archive data for our clients and to support our team of Data Scientists.

Responsibilities:
Author and monitor directed acyclic graphs (DAGs) in Apache Airflow to ingest and transform data
Build and maintain internal Python packages to streamline ingest processes and add connections for new types of data
Manage Kubernetes infrastructure and PostgreSQL databases on Google Cloud Platform
Work collaboratively with the development and data science teams to add new data-driven features to our software-as-a-service product
Participate in Agile / Kanban processes on a daily basis
Comply with change management policies and code reviews to ensure data integrity and system stability
Requirements
BS/MS in a STEM field and 2+ years of industry experience programming and working with data
Exceptional understanding of data architecture and software engineering best practices
2+ years experience with Python (Python 3 preferred)
2+ years experience with SQL (PostgreSQL preferred)
2+ years of experience with Docker
1+ years experience with cloud infrastructure (GCP preferred)
1+ years of server orchestration (Kubernetes preferred)
Experience using Apache Airflow or similar data pipeline systems
Experience using Git or other DVCS
Knowledge of Agile / Kanban processes
Entrepreneurial spirit and highly self-motivated
Job is based in Austin TX, but extraordinarily qualified remote candidates (willing to travel to Austin semi-regularly) may apply.

Benefits
Competitive base salary with ability to earn bonuses
Professional development and entrepreneurial opportunities
Paid time off
401(k)
Medical and dental plans","Pilytix, LLC
3.8","Austin, TX",-1,-1
Data Analyst,"Ref ID: 04160-9502602115Classification: Data Analyst

Compensation: $52.18 to $60.00 hourly

Robert Half Technology is looking for a Data Analyst to help our client in South Austin on an upcoming short term project.

Duties:
Collect and document business requirements for reporting and analysis initiatives with customers.
Perform quantitative and/or qualitative data analysis and prepare results to share with internal and external customers.
Aid in design and development of data warehouse/data mart applications.
Undertake complex data integration activities.
Utilize SQL or other advanced analytic tools to perform data extract and query functions.
Identify and troubleshoot data anomalies and irregularities.
Prepare written and oral reports that communicate necessary information to internal and external customers.
Willingness to learn and work with Business Intelligence (BI) tools for extracting and compiling data.
Become a data subject matter expert (SME) and understand various sources and applications of CCC data.
Performs other duties as assigned.
Job Requirements:
Use of statistics to solve problems and perform moderately complex data analysis. - Experience understanding and writing SQL queries in various environments. - Experience developing and troubleshooting programming code (e.g. SQL, SAS, STATA, R). - Demonstrated ability to manage and prioritize multiple projects with varying deadlines. - Compliance with data confidentiality and security procedures. - Perform complex operations in Microsoft Office Suite, with an emphasis on Excel and Access. - Ability to write and speak clearly, easily communicating complex ideas as indicated by audience. - Knowledge of healthcare, including medical claims coding, relationships between health plans, providers, and payers, a plus. MINIMUM EDUCATION AND EXPERIENCE - Bachelors degree in related field required, Masters degree preferred. - 1-3 years of experience with data management and statistical analysis. - Proficiency in using SQL for database queries. - Experience in a health or healthcare field. - Experience using statistical analysis software such as SAS, R, or STATA is desirable but not required. - Any equivalent combination of education and/or experience may substitute Apply today if interested.
Robert Half Technology matches IT professionals with some of the best companies on a temporary, project or full-time basis. From roles in software and applications to IT infrastructure and operations, we provide you unparalleled access to exciting career opportunities. Our personalized approach, innovative matching technology and global network with local market expertise help you find the technology jobs that match your skills and priorities fast. By working with us, you have access to challenging opportunities, competitive compensation and benefits, and training to enhance your skill sets.

From philanthropy to environmental stewardship to employee programs, Robert Half is proud to have an active role in the communities in which we live and work. Our company has appeared on FORTUNEs Most Admired Companies list every year since 1998.

Download our mobile app to take your job search on the go!

Contact your local Robert Half Technology office at 888.490.4429 or visit www.roberthalf.com/jobs/technology to apply for this job now or find out more about other job opportunities.

All applicants applying for U.S. job openings must be authorized to work in the United States. All applicants applying for Canadian job openings must be authorized to work in Canada.

© 2020 Robert Half Technology. An Equal Opportunity Employer M/F/Disability/Veterans.

By clicking 'Apply Now' you are agreeing to Robert Half Terms of Use.","Robert Half
3.5","Austin, TX",Staffing & Outsourcing,Business Services
Data Engineer,"Position Title Data Engineer Location Austin, TX Position Type Full-time Permanent Role Job Description Open-source data warehousing(DWH), Python, java, google cloud, Apache Airflow design and architecture of data pipelines Should be able to articulate design challenges, performance considerations CICD SQL abilities. Complex SQL is used in BigData or DWH","Atos Syntel Inc.
3.5","Austin, TX",IT Services,Information Technology
Data Analyst,"Job Description
Data Analyst Responsibilities:
Interpreting data, analyzing results using statistical techniques
Developing and implementing data analyses, data collection systems and other strategies that optimize statistical efficiency and quality
Acquiring data from primary or secondary data sources and maintaining databases
We are looking for a passionate certified Data Analyst. The successful candidate will turn data into information, information into insight and insight into business decisions.

Data Analyst Job Duties

Data analyst responsibilities include conducting full lifecycle analysis to include requirements, activities and design. Data analysts will develop analysis and reporting capabilities. They will also monitor performance and quality control plans to identify improvements.",Cyclex Systems,"Austin, TX",-1,-1
Data Engineer,"Since our founding in 2009, weve relentlessly worked toward a vision of a future powered by Phunware. We spend our days obsessing over how best to design, build, launch, promote and support branded apps that engage, compel and delight the worlds most discerning audiences. For over a decade, weve helped Fortune 5000 businesses throughout the mobile app lifecycle with data-backed decisions at every step.

Everything You Need to Succeed on Mobile Transforming Digital Human Experience

Phunware, Inc. (NASDAQ: PHUN), is the pioneer of Multiscreen-as-a-Service (MaaS), an award-winning, fully integrated enterprise cloud platform for mobile that provides companies the products, solutions, data, and services necessary to engage, manage and monetize their mobile application portfolios and audiences globally at scale. Phunwares Software Development Kits (SDKs) include location-based services, mobile engagement, content management, messaging, advertising, loyalty (PhunCoin & Phun) and analytics, as well as a mobile application framework of pre-integrated iOS and Android software modules for building in-house or channel-based mobile application and vertical solutions. Phunware helps the worlds most respected brands create category-defining mobile experiences, with more than one billion active devices touching its platform each month.

If you share our passion for innovative mobile app experiences and dream of a world empowered by seamless, one-to-one interactions, we want to hear from you. Get in touch with us todayour Phamily always has room for one more!

Job Summary:

Phunware is seeking a Data Engineer with hands-on experience creating, deploying and optimizing large-scale data systems.

The ideal candidate will bring strong technical skills and be proactive, responsive and very comfortable dealing with ambiguity. He or she will also bring good experience with Big Data systems/technologies and have a strong track record of deployment, maintenance, and optimization of production code.

The ideal candidate is someone who combines an understanding of business processes with knowledge of both client and server-side technical requirements in mobile software projects. They will put the customer first, quickly build strong relationships, learn rapidly, and enjoy autonomy and problem-solving. They must be a gifted leader with a genuine passion for working with high-performance teams, extraordinarily organized., and have a strong work ethic. Additionally, the position may require travel both domestically and internationally.

What Youll Do:
Create robust, high-volume production systems/architectures, and develop prototypes quickly
Work with development teams to design maintenance and support strategies
Create optimized workflows using relevant technologies (Spark, Elastic Search, Kafka, Oozie, Hadoop)
Create architectural workflows, diagrams, and specification documents to help define platform features/functionality
Perform experiments and analyze results to improve the performance and quality of algorithms
Work with product management and executive stakeholders to take detailed requirements and implement them using Agile Test Driven techniques
Work in an organized team-oriented environment with shared responsibilities
What Youll Bring:
Bachelors Degree or higher in Computer Science or Computer Engineering; Masters Degree preferred
Have previously worked in Big Data technologies and deployed in production environment
Strong experience in building highly scalable, available and responsive systems using open-source software tools and technologies
5-10 years of professional software development
5-8 years strong Java development experience
Good experience with REST API frameworks
Strong SQL skills
1+ years of professional software development experience with some of the big data technologies including: Spark, Map Reduce, Hive, HBase, Hadoop, Kafka, Impala, Cassandra
Experience in Elastic Search is highly desirable
Some experience with one or more of the following will be an added advantage: statistical analysis, machine learning, natural language processing, predictive modeling
Domain experience in one or more of the following:
Outstanding skills for interacting with people
Responsible, organized and hardworking with excellent communication skills
Must be living in the Irvine, CA or Austin, TX area or be able to immediately relocate
Desirable:
NoSQL or similar DB design/implementation experience with large number of records (i.e. 1 Billion+)
Experience with information retrieval, network programming and/or developing large software systems
Experience with cloud delivery platforms, ideally Amazon
Experience doing Test Driven Development (TDD), Continuous Integration (CI) and test automation
Open-source software contributions
Track record of success in a start-up or high-growth environment
Compensation and Benefits:
Fun, casual, fast-paced work environment filled with talented colleagues
Flexible paid time off
Competitive salary
Restricted Stock Units
Full range of benefits, including 401(k), medical, dental and vision coverage
Candidates for this position must be authorized to work in the United States and not require work authorization sponsorship by our company for this position now or in the future.","Phunware, Inc
3.2","Austin, TX",Computer Hardware & Software,Information Technology
Data Engineer,"Be a part of what sets Amazon apart from everyone else! Join the power behind Prime.


Supply Chain Optimization Technologies (SCOT) creates the science and technology to drive Amazon's supply chain. SCOT builds software systems to make the most products available to the most people for delivery as quickly as possible. The SCOT Austin teams focus on improving the promises we make to Amazon customers, defining what is available with 2-day Prime shipping, optimizing fulfillment costs, consolidating multiple orders into a single shipment, predicting future supply and demand, and creating the execution plan for our global fulfillment network. To accomplish these goals we build simulation and experimentation systems at scale and leverage cutting-edge technologies across Operations Research, Software Engineering, Machine Learning, Forecasting, and Linear Programming.
Watch this short video for more on SCOT: http://bit.ly/amazon-scot

Amazon is seeking a truly innovative Data Engineer to join the FastTrack Data Engineering Team.

As an Amazon Data Engineer you will be working in one of the world's largest and most complex data warehouse environments. We maintain one of the largest data marts in Amazon as well as work on Business Intelligence reporting and dashboarding solutions that are used by thousands of users world-wide.


Our team is responsible for mission critical analytic reports and metrics that are viewed at the highest levels in the organization. We are also working on newer tools that help users discover data using visualization and Big Data technologies. You should have deep expertise in the design, creation, management, and business use of significantly large datasets. You should have excellent business and communication skills to be able to work with business owners to develop and define key business questions, and to build data sets that answer those questions. You should be expert at designing, implementing, and operating stable, scalable, low cost solutions to flow data from production systems into the data warehouse and into end-user facing applications. You should be able to work with business customers in a fast paced environment understanding the business requirements and implementing reporting solutions. Above all you should be passionate about working with huge data sets and someone who loves to bring datasets together to answer business questions and drive change.
This opportunity is perfect for highly motivated and talented data engineers who want to apply and grow their technical depth and breadth while defining and driving key aspects of the customer experience on Amazon.com.

Amazon is an Equal Opportunity-Affirmative Action Employer Minority / Female / Disability / Veteran / Gender Identity / Sexual Orientation.

Basic Qualifications


· Degree in Computer Science or related field
· 4+ years professional experience in database development, handling large data sets using SQL and databases in a business environment
· Must be proficient with Oracle/SQL Server/ Redshift/Tera data
· Familiar with ETL and DW processes
· Prior experience with Scala, Python or Java
· Strong troubleshooting and problem solving skills



Preferred Qualifications

· Previous experience with Linux
· Experience with multiple database platforms
· Familiar with computer science fundamentals including object-oriented design, data structures, algorithm design, problem solving, and complex analysis

Amazon is an Equal Opportunity-Affirmative Action Employer Minority / Female / Disability / Veteran / Gender Identity / Sexual Orientation.

We believe passionately that employing a diverse workforce is central to our success and we make recruiting decisions based on your experience and skills. We welcome applications from all members of society irrespective of age, gender, disability, sexual orientation, race, religion or belief.","Amazon
3.9","Austin, TX",Internet,Information Technology
Software Engineer,"The Zebra is expanding our engineering team and we’re seeking a Software Engineer to join our Data Team.

The Data Team is a unique mix of skill sets and disciplines, drawing from data science, engineering, product, and analytics. We built our own data pipeline and machine learning infrastructure, and have a strong focus on experimentation. We strive for a balance of enabling and empowering other teams through data, while also looking for opportunities to create value ourselves. Our team values autonomy, ownership and innovation. As an Engineer, you will have an impact on our architectural direction, work on challenging projects and mentor team members as we grow.
WHAT YOU'LL DO:
Supporting and enabling other teams with data
Work on a cross-functional team of engineers, data scientists, and data analysts and collaborate with other teams and stakeholders. We don’t work in isolation.
Take ownership in the data products we build, and care about their health.
REQUIREMENTS / QUALIFICATIONS:
3+ years of programming language experience (We mostly use Python, but also consider Ruby, Java, C++, C#, Go)
Experience with data pipeline aspects (ETL, schema design)
Willingness to learn and pivot when different technologies are introduced
EXPERIENCE THAT WILL IMPRESS THE HECK OUT OF US:
Experience with Snowflake or/and Kafka
Knowledge around K8s & AWS
Experience with microservice architecture
BENEFITS + PERKS:
Competitive Compensation & Stock Option Offering
Health, Dental, Vision & Disability Coverages
HSA offering + employer contribution
Unlimited PTO + flexibility to enjoy it
Paid Parental Leave Program
Commuter Benefits (up to $100/month)
Wellness perk ($100/month)
Learning & Development Stipends
Onsite Full Service Barista
Wednesday Catered Lunch + Fully Stocked Fridges
Opportunity to join Employee Resource Groups (ERGs) or drive our diversity & inclusion stance by creating your own
Join a team that truly lives their values, and values their lives (outside of the office. Cliche, we know… but we really mean it)

ABOUT THE ZEBRA:

The Zebra is the most comprehensive online car insurance comparison platform in the U.S. Since 2012, the company has brought transparency and simplicity to car insurance shopping — “car insurance in black and white.” The Zebra compares over 200 car insurance companies, and with its real-time, side-by-side quote comparison tool, drivers can easily and quickly find the coverage, service level, and pricing to suit their unique needs.

Headquartered in Austin, Texas, The Zebra has garnered the attention and investment of some of the nation’s top venture capitalists, and the company’s success has been profiled in publications like Inc., Time, Forbes, and TechCrunch. Austin Business Journal named The Zebra a Best Place to Work in 2015, 2016, 2017, and 2018. Austin American-Statesman also awarded The Zebra as a Top Workplace in 2016, 2017 and 2018.

The Zebra is aiming to grow our fantastic team to add to our dynamic culture and continue building on our success. Working at The Zebra means never being bored, always being challenged, and supporting one another. We’re a happy, hardworking group, and we’re eager to add “new stripes” who share those values.

The Zebra is an equal opportunity employer and “at will” company.

As part of our dedication to maintaining an inclusive and diverse workforce, The Zebra provides equal employment opportunities (EEO) to all employees and applicants for employment without regard to race, color, religion, sex, national origin, age, disability or genetics. In addition to federal law requirements, The Zebra complies with applicable state and local laws governing nondiscrimination in employment. This policy applies to all terms and conditions of employment, including recruiting, hiring, placement, promotion, termination, layoff, recall, transfer, leaves of absence, compensation and training.

The Zebra expressly prohibits any form of workplace harassment based on race, color, religion, gender, sexual orientation, gender identity or expression, national origin, age, genetic information, disability, or veteran status. Improper interference with the ability of The Zebra's employees to perform their job duties may result in discipline up to and including discharge.

**No external recruiters or agents, please.**","The Zebra
3.9","Austin, TX",Insurance Agencies & Brokerages,Insurance
Data Engineer,"Tachyon Technologies is a Digital Transformation consulting firm that partners with businesses to implement customer-focused business transformation. Tachyon Technologies understand what it takes for a consulting partner to be effective and strives to deliver a meaningful solution that exceeds its clients' expectations

Â

Title: Data Engineer/Software Engineer

Location: Austin, TX

Â

Key Qualifications:

Â

Â Strong programming skills in Java, knowledge of Scala is a plus

Â Experience with Big Data applications that use Spark, Hive, Kafka, Hadoop, and Oozie

Â Knowledge of build and test tools such as Maven, Gradle, SBT, and JUnit

Â Good understanding of relational and NoSQL databases

Â Experience writing and optimizing SQL queries

Â Experience in developing ETL data pipelines

Â Strong communication skills

Â Passion for excellence and commitment to continuous learning

Â

Tachyon's full-time employees receive complete and competitive benefits. We offer a collaborative work environment, competitive compensation, generous work/life opportunities, and an outstanding benefits package that includes paid time off plus holidays. In addition, all colleagues are eligible for a number of rewards and recognition programs. Encouraging a healthy work/life balance and providing our colleagues great benefits are just part of what makes Tachyon a great place to work.

A Disclaimer: The above statement is not a complete job description. The Client retains the discretion to add or change the duties of the position at any time","Tachyon Technologies
4.4","Austin, TX",IT Services,Information Technology
Data Analyst,"Title: Data Analyst with Alteryx experience

Location: AUSTIN TX 78749

Duration: 12+ months with extension possible

Job Description:
Skills: Talend, SSIS, ETL solution using Alteryx jobs to perform all business rules
Bachelors' degree in Engineering or Science or equivalent graduates with at least 7-8 years of overall experience
5 years of experience developing BI Solutions using tools like SSIS, Alteryx, etc.
Automation of Alteryx workflow using scheduler
Thank You,

Shibu Singha

Manager - Service Delivery

Avacend, Inc.

3155 North Point Pkwy Bldg. G

Suite 130, Alpharetta GA 30005

Phone: 770-702-0134

Shibu.S@avacend.com

Required Skills

Required Experience

Job Location
Austin, US-TX","Avacend, Inc.
2.5","Austin, TX",Staffing & Outsourcing,Business Services
Data Analyst,"Job Description
Job description
Interpret data, analyze results using statistical techniques and provide ongoing reports
Develop and implement databases, data collection systems, data analytics and other strategies that optimize statistical efficiency and quality
Acquire data from primary or secondary data sources and maintain databases/data systems
Identify, analyze, and interpret trends or patterns in complex data sets
Filter and “clean” data by reviewing computer reports, printouts, and performance indicators to locate and correct code problems
Work with management to prioritize business and information needs
Locate and define new process improvement opportunities
Requirements
Proven work experience as a data analyst or business data analyst
Technical expertise regarding data models, database design development, data mining and segmentation techniques
Strong knowledge of and experience with reporting packages (Business Objects etc), databases (SQL etc), programming (XML, Javascript, or ETL frameworks)
Knowledge of statistics and experience using statistical packages for analyzing datasets (Excel, SPSS, SAS etc)
Strong analytical skills with the ability to collect, organize, analyze, and disseminate significant amounts of information with attention to detail and accuracy
Adept at queries, report writing and presenting findings
Master's in Computer Science or Engineering Management or Project Management or Information Systems/Technology (Preferred)
Powered by JazzHR

GVn6W9liB2","Staffigo Technical Services, LLC
5.0","Austin, TX",IT Services,Information Technology
Data Engineer,"Job Description
Treehouse Technology Group is changing the way individuals interact with the data they generate on a daily basis. We are looking for hard-working, game-changing people who are able to take big technical ideas and market them to non-technical people. We are looking for big thinkers and doers that constantly push to the next level. Joining Treehouse Technology Group means being part of a team that is redefining data analytics and business intelligence software. Redefining an industry is hard work and it takes focused, dedicated team players. Come get in the game.

As a Data Engineer, you will work with stakeholders and the internal development team to guide technical development of enterprise data solutions. The Data Engineer is a combination of a business and technical customer facing role that will be accountable for the end-to-end customer data architecture, development, deployment and support. The Data Engineer will be responsible for working with stakeholders to identify opportunities to leverage data to drive business value. In addition, you will be responsible for mining and analyzing data to drive efficiency and optimization, develop custom data models and algorithms, and develop processes and tools to monitor production systems and data accuracy.

The ideal candidate will have experience in customer facing and development management roles and have led successful technical and economic value discussions with senior customer executives, driving decisions and implementation.

Requirements:
Austin, TX
Minimum 5 years related experience
AWS and\or Azure experience architecting solutions in Cloud Environments
Agile software development experience
Data background either in Analytics, Warehousing, Data Integration\API Dev, Visualization, etc
Technical Background
Can be one of following or multiple:
Data Engineer
Integration Engineer using SSIS, Talend, Pentaho
Data Warehousing
Data Modeling
Big Data technologies
Map/Reduce, Hadoop, Hive, Spark, Elasticsearch, etc
SQL Server, MySQL, Aurora primary experience (Oracle, Postgres, MongoDB secondary experience)
Data Scientist
Experience creating and using advanced machine learning algorithms and statistics: regression, simulation, scenario analysis, modeling, clustering, decision trees, neural networks, etc.
Knowledge and experience in statistical and data mining techniques: GLM/Regression, Random Forest, Boosting, Trees, text mining, social network analysis, etc.
TensorFlow, Kubernetes
R, SQL, Python – Pandas, Scikit, Numpy
Data Visualization
SQL Server, MySQL, Aurora primary experience (Oracle, Postgres, MongoDB secondary experience)
Map/Reduce, Hadoop, Hive, Spark, etc
InsightOut™ by Treehouse Technology Group is a data visualization platform that turns disparate, raw data into actionable business intelligence. It features a powerful method to integrate internal, proprietary data and third-party data into a common platform that will transform analytics into insights. Our user-friendly and visual-first focus enables all users and abilities to work with and create value from data and enable complex client reporting. Not just for internal analysis anymore, InsightOut™ provides industry leading capabilities to our clients by providing them a platform to share raw data, visualizations and insights discovery with external clients and stakeholders as necessary. Additionally, no other business intelligence tool uses real-time animation to show time-series data trends with the ability to customize that data on the fly.

We offer competitive compensation, company-sponsored premium benefits, full medical premiums covered, optional dental, vacation/holidays, etc. This can be a fully remote or work-from-home position, but those based in Austin have the option to work in an office. Treehouse Technology Group is an equal opportunity employer. We consider all qualified applicants of diverse background and hire without regard to race, color, gender identity, religion, national origin, ancestry, citizenship, physical abilities, age, sexual orientation, veteran status, or any other characteristic protected by law.
Company Description
InsightOutTM by Treehouse Technology Group is a data visualization platform that turns disparate, raw data into actionable business intelligence. It features a powerful method to integrate internal, proprietary data and third-party data into a common platform that will transform analytics into insights. Our user-friendly and visual-first focus enables all users and abilities to work with and create value from data and enable complex client reporting. Not just for internal analysis anymore, InsightOutTM provides industry-leading capabilities to our clients by providing them a platform to share raw data, visualizations and insights discovery with external clients and stakeholders as necessary. Additionally, no other business intelligence tool uses real-time animation to show time-series data trends with the ability to customize that data on the fly.
Accordingly, we perform vendor analysis and technical development based on industry best practices. When an off-the-shelf solution does not meet the needs of our partners, custom application development is necessary to bridge the gap between best-in-breed (specialized) and ERP solutions (general).



TTG prides itself on our ability to solve complex business problems with custom-tailored solutions that support the ever-changing business environment of our partners. We focus on business value first, aligning the strategy and direction of our partners with their specific technical needs, before providing a technology roadmap to implement the mutually established vision. By working closely with our partners and obtaining feedback along the way, we guarantee a positive experience that yields fruitful results.","Treehouse Technology Group, LLC
4.9","Austin, TX",IT Services,Information Technology
Data Engineer,"LMI is currently seeking a data engineer within LMI’s Advanced Analytics service line to support the design and implementation of business critical data management & engineering solutions.
This position is located in Austin, TX

The ideal candidate will have direct, applied experience with one or more of the following areas:
- Develop data structures and systems to support the generation of business insights
- Knowledge and experience in overall ETL processes
- Maintain data infrastructure and develop scripts for regular processes
- Define, design, and develop data flow diagrams, data dictionaries, and logical and physical models
- Define data requirements, document data elements, and capture and maintain metadeta
- Identify and clean incomplete, incorrect, inaccurate or irrelevant data
- Identify new opportunities to use data to improve business performance
- Communicate and present data by developing reports using Tableau or Business Intelligence tools
- Adhere to compliance and audit requirements for data storage, architecture, cybersecurity, etc.

Bachelor’s degree in a quantitative field (e.g., engineering, statistics, mathematics, information technology, etc.) is preferred.
Master's degree is desired.
Must have at least 3 years of experience, preferably with a federal government customer.
Experience with big data tools: Hadoop, Spark, Kafka
Experience with relational SQL and NoSQL databases: Postgres, Cassandra, MongoDB
Experience with data governance tools: Collibra, Immuta
Experience with AWS cloud services: EC2, EMR, RDS, Redshift
Experience with object-oriented/object function scripting languages: Python, Java, C++, Scala
Must possess strong written and verbal communication skills.
Secret or Top Secret clearance is preferred.

LMI is an Equal Opportunity Employer-all qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, or national origin.","LMI
4.0","Austin, TX",Consulting,Business Services
Data Engineer,"About the Role
We’re hiring an experienced Data Engineer to join our team and help lead the build-out of our data integration and pipeline processes and tools. You'll be a key contributor on a small distributed team working to build a data pipeline that serves the entire business, from internal employees to external stakeholders like our service providers. Making data-driven decisions is in our company culture -- your work will directly unlock this ability for the whole business.
Spruce is a remote-friendly company headquartered in Austin.
What You Get To Do
Drive the build out of a data pipeline and data warehousing solution
Work with platform and consumer engineers to determine best practices on data modeling, data streaming, and automation
Build systems that serve every team within Spruce as well as external stakeholders
Contribute to the heart of a multi-sided marketplace that is sustainably growing through these crazy times
Who You Are
Bachelor’s degree in Computer Science, Applied Mathematics, Operations Research, Statistics, or similar.
2+ years of experience as a Data Engineer or a similar role (scientist, analyst, etc.)
Direct experience with SQL, data modeling, data warehousing, and ELT pipelines
4+ years of experience in software development, data engineering, data science, business intelligence, or related field
Nice To Haves
Experience architecting distributed systems for data extraction, ingestion, and processing
Snowflake/Looker experience
Contribution to open source projects or the data community at large (data.world, Kaggle, etc.)
Who We Are
Spruce is a venture-backed company that provides Lifestyle Services to residents, such as housekeeping, pet care, laundry, dry cleaning, and more. For $15 or less, residents can have their clean clothes folded, their dishes washed, their bed sheets changed, or their bathroom cleaned. Spruce was founded in 2016 and has scaled rapidly. The Company is currently working with 13 of the top 15 apartment managers in Texas, including Greystar, Lincoln, and Alliance.
Spruce is an equal opportunity employer. In accordance with applicable law, we prohibit discrimination and harassment against employees, applicants for employment, individuals providing services in the workplace pursuant to a contract, unpaid interns and volunteers based on their actual or perceived: race, religious creed, color, national origin, ancestry, physical or mental disability, medical condition, genetic information, marital status, sex, gender, age, sexual orientation, Civil Air Patrol status, military and veteran status and any other consideration protected by federal, state or local law.
Job Type: Full-time
Pay: $95,000.00 - $120,000.00 per year
Benefits:
401(k)
Dental Insurance
Health Insurance
Life Insurance
Vision Insurance
Schedule:
Monday to Friday
Experience:
Data Engineering: 2 years (Preferred)
Work authorization:
United States (Required)
Visa Sponsorship Potentially Available:
No: Not providing sponsorship for this job
Company's website:
https://getspruce.com
Company's Facebook page:
https://www.facebook.com/SpruceCrew
Benefit Conditions:
Only full-time employees eligible
Work Remotely:
Temporarily due to COVID-19","Spruce Services, Inc","Austin, TX",Building & Personnel Services,Business Services
Data Engineer,"Integrated Technology Strategies is a provider of information technology consulting. Digital transformation, improving business performance, developing strategies and enhancing value is at the core of what we are.

Integrated Technology Strategies is looking to hire a Data Engineer to be a part of our Consulting team. You will participate and effectively contribute to the design, development, and implementation of complex applications, often using new technologies. You will provide technical expertise and systems design for individual initiatives.

Education & Experience:
Bachelor’s degree in engineering or a bachelor’s degree in technology from a recognized university
Candidate should have recent work experience with US-based customers
Minimum 5 years of relevant experience is required
Technical Skill Requirements:
4+ years of data engineer experience with large data lake platforms, ideally google or hadoop.
Familiarity with cloud, specifically GCP.
Experience utilizing tools like Spark and understand how to move data, build code-based data pipelines, data transformation, etc.
Development experience with Python and/or Go-lang
Plus: Hotspots and composure experience- how to break queries out—Saves time, performance, and money.
Retail/E-commerce industry would be a plus.
Experience with very large (multi-petabyte size) data lakes.
Experience with Unix (Shell, Scripting) is very helpful.
Development experience with building APIs – ex: REST, etc.—Python and/or Go-Lang
Experience with BigQuery and Composer.
Operational Experience managing a large data lake
Experience with code-based pipelines (ex Spark). Some exposure to Java, Scala, and/or Python is a plus","Integrated Technology Strategies, Inc.","Austin, TX","Health, Beauty, & Fitness",Consumer Services
Statistician,"The Department of Statistics and Data Sciences at The University of Texas at Austin is seeking applicants for three open-rank faculty positions to begin in Fall 2020.

The successful candidates will be expected to teach undergraduate and graduate statistics and data science courses, have an active research program, supervise graduate students, collaborate with other faculty, and be involved in service to the university and the profession.

The Department of Statistics and Data Sciences currently has 16 tenured and tenure-track faculty in statistics, biostatistics, and machine learning whose associative affiliations encompass biology, business, computer science, medicine, population health, engineering, and mathematics. The department is growing rapidly into a globally recognized center of excellence for research and education in statistical methodology, applied statistics, computationally-intensive statistical methods, and machine learning. The department sits amid one of the most intellectually vibrant universities in the country, with abundant opportunities for interdisciplinary research within the College of Natural Sciences and across the LBJ School of Public Affairs, the McCombs School of Business, Dell Medical School, the Oden Institute for Computational Engineering and Sciences, and many other research entities across the campus. A partnership with the Texas Advanced Computing Center (TACC) provides access to world-class computing resources. The department is dedicated to the goal of building a culturally diverse and pluralistic faculty and staff committed to teaching and working in a multicultural and diverse environment. We are therefore interested in candidates who will contribute to such diversity and equal opportunity in higher education through their teaching, research, and service.

More information about the department is here.

Full consideration will be given to applicants with research interests in any area of statistical applications, theory, or methods and in the emerging field of data science. The minimum qualification is a doctoral degree; strong applicants whose primary degree is not in statistics, machine learning, data science or a related area will also be considered, as long as their research exhibits independence and excellence in one of these areas. Candidates for tenured positions are expected to have an internationally-recognized research program and to have demonstrated a strong commitment to excellence in teaching, mentoring, and service.

All applicants should submit a cover letter, a CV, and a statement of research interests, and should arrange for three letters of support to be provided under separate cover. Applicants should not submit any supplemental material. However, applicants' CVs should include links to a web site (or sites) where all papers and software packages listed on the CV can be downloaded.

Applications will continue to be accepted until the position is filled, but the review of applications will begin on or around November 1, 2019.

Background check will be conducted on applicants selected for the positions.

Questions about the search process should be directed to Professor Peter Mueller (statjobs@austin.utexas.edu), SDS Faculty Search Committee Chair.","University of Texas at Austin
4.3","Austin, TX",Colleges & Universities,Education
Data Engineer,"Position Data Engineer We are seeking a Data Engineer with strong data analysis skills performing data profiling, quality checks, writing SQL and Python scripts for data movement ie ETL. This position is a consulting position with our client. The best candidate will be someone that can understand data issues, perform profiling and analysis using SQL and stored procedures.This is mostly a back end data position but does require some interaction with business users. Most of the work will be performed remotely. Qualifications Minimum six (6) years experience writing SQL code preferable SQL Server or MySQL. Knowledge with Python is required. Ability to work with business users and management to understand the business need for data exploration, data quality and profiling. Experience working with relational databases, data modeling and writing ETL scripts to move data from source systems to an Enterprise Datawarehouse. Understanding of Data Warehousing concepts and experience in creating data warehouse schemas with Kimball methodology. Knowledge working with data in the cloud (AWS) desired. Solid understanding of Software Development Lifecycle (SDLC) and versionsource control disciplines. Be able to work effectively in an Agile Project Development team Must be able to define functional and technical docs based on data availability, quality and profiling on source data systems. The ability to work effectively within a team environment Understand complex logic and solve data issues by coming up with sound technical solutions. Soft Skills The ability to work effectively with minimal direction and supervision. To think creativity and come up with solutions that improve process and efficiencies. Ability to understand existing process and requirements. Understand complex logic and solve data issues by coming up with sound technical solutions. Must have solid written and oral communication skills. Can prepare and maintain technical documentation. Education Bachelors Degree in Computer Science, Finance or Data Analytics preferred. SQL andor Python related certifications preferred Work references will be requested. Must be authorized to work in the U.S.","EtiVenture, Inc.
4.8","Austin, TX",Consulting,Business Services
Data Engineer,"You…

As a Data Engineer you will work with the application and data science teams to support the development of custom data solutions.

Us…

We were founded as a fresh alternative in the Government Consulting Community and are dedicated to the belief that results are a product of analytical thinking, agile design principles and that solutions are built in collaboration with, not for, our customers. This mantra drives us to succeed and act as true partners in advancing our client’s missions.

Program Mission…

The project you will be working on is an existing cloud-based information technology infrastructure to host mission systems, applications, services, and data. While the current environment exists as an enterprise enabling platform, the end state of the environment is to enable Army leaders at every echelon to make fully informed, data driven decisions, based on authoritative and/or production data sources. Our approach is to transform legacy applications to be cloud native and reside on a Platform as a Service (PaaS). Additionally, modernize current applications by breaking them down into loosely coupled micro-services, and leveraging a continuous integration / continuous delivery pipeline to enable an agile DevOps Strategy.

What we'd like to see...
Capable of supporting rapid iterations of feature engineering with the development of coding solutions to enrich existing data sets.
Experience with traditional, modern, and cloud native database solutions.
Support the database design, development, implementation, information storage and retrieval, data flow and analysis activities.
Translate a set of requirements and data into a usable database schema by creating or recreating ad hoc queries, scripts and macros, updates existing queries, creates new ones to manipulate data into a master file.
Support development of databases, database parser software, database loading software, and database structures that fit into the overall architecture of the system under development.
Current IAT I Certification (A+ CE, Network+, CCNA, SSCP).
Desired Skills:
Works with considerable freedom to make decisions on the techniques and approaches to be used.
Prepares recommendations for system improvement for management and user consideration.
Years of Experience: 3 years of experience or more

Education: Bachelor’s Degree in Computer Science, Information Systems, or other closely related discipline

Clearance: Active Secret Security Clearance Required","Octo Consulting Group
3.9","Austin, TX",Consulting,Business Services
Data Engineer,"WorldQuant develops and deploys systematic financial strategies across a variety of asset classes and global markets. We seek to produce high-quality trading signals (Alphas) through our proprietary research platform to employ trading strategies focused on exploiting market inefficiencies. Our teams work collaboratively to drive the production of Alphas and financial strategies the foundation of a sustainable, global trading platform.

Technologists at WorldQuant research, design, code, test and deploy projects while working collaboratively with researchers and portfolio managers. Our environment is relaxed yet intellectually intense. Our teams are lean and agile, which means rapid prototyping of products with immediate user feedback. We seek people who think in code, aspire to solve undiscovered computer science challenges and are motivated by being around like-minded people. In fact, of the 600 employees globally, approximately 500 of them code on a daily basis.

WorldQuants success is built on a culture that pairs academic sensibility with accountability for results. Employees are encouraged to think openly about problems, balancing intellectualism and practicality. Great ideas come from anyone, anywhere. Employees are encouraged to challenge conventional thinking and possess a mindset of continuous improvement. Thats a key ingredient in remaining a leader in any industry. Our goal is to hire the best and the brightest engineers. We value intellectual horsepower first and foremost, and people who demonstrate an exceptional talent. There is no roadmap to future success, so we need people who can help us create it. Our collective intelligence will drive us there.

The Role:

Design and implement software to facilitate data integration with trading and simulating systems
Adopt new technologies to improve existing frameworks of data flow and monitoring
Implement and maintain software that interface with external vendors to bring in new data sets
Implement the rules and procedures that ensure integrity in data sets
Provide second level support to production support team regarding market data issues
Collect and analyze statistics on market data applications and devise approaches to improve the relevant processes
Design and implement systems that track and manage data availability, access and usage
What Youll Bring:

Degree in a quantitative or technical discipline from a top university and strong academic scores
Interest in applying technology to real situations, comfortable working in a fast-paced environment, detail-oriented and capable of performing tasks under pressure
Demonstrated experience with C++ or other object oriented languages
Experience with scripting languages such as Perl, Python, and shell scripting; Interface with database (such as MySQL)
Possess strong trouble shooting and problem solving skills
Ability to work independently and as member of a team
Strong verbal and written communication skills
Have experience working under a Linux environment, familiar with Vim or Emacs for editing files under the command line
Copyright © 2020 WorldQuant, LLC. All Rights Reserved. WorldQuant is an equal opportunity employer and does not discriminate in hiring on the basis of race, color, creed, religion, sex, sexual orientation or preference, age, marital status, citizenship, national origin, disability, military status, genetic predisposition or carrier status, or any other protected characteristic as established by applicable law.","WorldQuant
4.0","Austin, TX",Investment Banking & Asset Management,Finance
Data Engineer,"At BGDS, our vision is to untap the economic welfare potential of technology through entrepreneurship. In order to fully realize our vision, we have committed ourselves the mission to provide transparency, openness, collaboration, ease-of-use and insights to technology startup financing so that entrepreneurship thrives globally and founders can develop life-changing technologies.

Job Overview

BGDS is looking for a savvy Data Engineer to join our growing team of data and analytics experts.

As a Data Engineer, you will be responsible for expanding and optimizing our data and data pipeline architecture, as well as optimizing data flow and collection for many external sources and professional users. The ideal candidate is an experienced data pipeline builder and data wrangler who enjoys optimizing data systems and building them from the ground up.

You will support our software developers, database architects, data analysts and data scientists on data initiatives and will ensure optimal data delivery architecture is consistent throughout ongoing needs. They must be self-directed and comfortable supporting the data needs of multiple users, systems, and products.

The ideal candidate will be excited by the prospect of optimizing or even re-designing our company’s data architecture to support our next generation of products and data initiatives. We’re in the process of revolutionizing startup financing, and we’re hoping you’ll be part of that experience.

Responsibilities and Duties

Help to design and implement the data repository architecture and a large-scale processing system for BGDS product.

Help to identify, design, and implement processes improvements: optimizing data gathering, data quality, data consolidation, and data delivery. Re-designing infrastructure for greater scalability and stability, etc.

Recommend and sometimes implement ways to improve data reliability, efficiency, and quality.

Help to build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using SQL and NoSQL ‘big data’ technologies.

Help to create data tools for analytics and data scientist team members that assist them in building and optimizing our product into an innovative industry leader.

Help to keep our data separated and secure across national boundaries through multiple data centers and regions, respecting the data privacy regulation (GDPR and similar).

Work with data and analytics experts to strive for greater functionality in our data systems.

Our approach to supervision is very adaptive, which is to say that we are happy to accommodate a variety of personal styles. We are searching for someone who is an independent contributor, but you will also get the support you need when you need it.

Qualification and Experience

Ability to work in our Austin office 5 days per week
A bachelor’s or higher degree in Computer Science, Physics, Statistics, Informatics, Information Systems or another quantitative field.
3+ years of work experience in software design and development
3+ years in data engineering
Advanced working SQL and CQL knowledge and experience working with relational databases and Cassandra, query authoring (SQL, CQL, KSQL, SparkSQL) as well as working familiarity with a variety of databases.
Experience building and optimizing ‘big data’ data pipelines, architectures and data sets.
Discover opportunities for data acquisition.
Experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement.
Strong analytic skills related to working with unstructured datasets.
Build processes supporting data transformation, data structures, metadata, dependency and work- load management.
A successful history of manipulating, processing and extracting value from large disconnected datasets.
Working knowledge of message queuing, stream processing, and highly scalable ‘big data’ data stores.
Strong project management and organizational skills.
Experience supporting and working with cross-functional teams in a dynamic environment.
Experience with big data tools: Spark, Kafka, etc.
Experience with relational SQL and NoSQL databases, including Postgres and Cassandra.
Experience with data processing engines: Apache Beam, Dataflow, etc.
Experience with data pipeline and workflow management tools: Azkaban, Luigi, Airflow, Python Fireworks, etc.
Experience with GCP cloud services: Compute, Kubernetes, Cloud Functions, BigQuery, Dataproc,
Experience with stream-processing systems: Storm, Spark-Streaming, etc.
Experience with object-oriented/object development languages: Python, Java, C++, Scala, etc.
Start-up experience is ideal

Salary based on experience - $100K +",BuildGroup Data Services,"Austin, TX",-1,-1
Data Engineer,"OverviewOBXtek Inc. is an established, award-winning business providing information technology and professional management services to the federal government. Our corporate growth has coincided with our investment in our employees as well as in outreach to our civilian and military community.ResponsibilitiesOBXtek is recruiting for a Data Engineer for the Army Forces Command Data & Decision Sciences Division (AFC DDSD) in Austin, TX. In this AFC, uses the Modernization Application & Data Environment (MADE) in a managed service provider style model to enable subordinate elements throughout AFC to access commercial cloud services. AFC DDSD has primary responsibility for the provisioning and operating the shared common services, maintaining approved desired state configurations for Infrastructure as a Service (IaaS) deployments, operating and maintaining a central data warehouse capability, and maintaining the Risk Management Framework (RMF) documentation for the commons services and environmental level accreditation in a manner that maximizes inheritance.The Data Engineer will:* Work with application and data science teams to support development of custom data solutions.* Support rapid iterations of feature engineering with the development of coding solutions to enrich existing data sets.* Support the database design, development, implementation, information storage and retrieval, data flow and analysis activities.* Translate a set of requirements and data into a usable database schema by creating or recreating ad hoc queries, scripts and macros, updates existing queries, creates new ones to manipulate data into a master file.* Support development of databases, database parser software, database loading software, and database structures that fit into the overall architecture of the system under development.Potential CONUS Travel of 25%QualificationsActive Secret ClearanceRequires a Bachelor's degree in Computer Science, Information Systems, Engineering, or other Scientific/Technical discipline* Experience with traditional, modern, and cloud native database solutions.* 3 years of related data engineering work experience.* Must meet IAT-I requirements as specified in DoD 8570.01-M; which includes A+ CE, CCNA-Security, Network + CE, SSCP.Company InformationHeadquartered in McLean, Virginia and founded in 2009, OBXtek is a fast-growing leader in the government contracting field. Our mission is Our PeopleOur Reputation. Our people are trained professionals who enhance our customers' knowledge and innovation using technology, collaboration, and education.We offer a robust suite of benefits including comprehensive medical, dental and vision plans, Flexible Spending Accounts, matching 401K, paid time off, tuition reimbursement plans and much more.As a prime contractor for 93% of our current work, OBXtek pairs lessons learned across disciplines with industry standard quality practices such as CMMI-Dev Level III, ITIL, 6Sigma, PMI, and ISO. Our rapid growth has been recognized by INC500, the Washington Business Journal, and Washington Technology magazine.OBXtek is an Equal Opportunity Employer and does not discriminate based on race, color, religion, sex, age, national origin, gender identity, disability, veteran status, sexual orientation or any other classification protected by federal, state or local law.","OBXtek
3.4","Austin, TX",IT Services,Information Technology
Data Engineer,"Job Description
Hi Professionals,

hope you are doing good,

Position 1

Role : Data Engineer (Architect/Lead level)

Location : Dallas, TX

Type : Contract to Hire (6+ Months contract)

Position 2

Role :Data Engineer (Developer/Consultant level)

Location : Dallas, TX

Type : Contract to Hire (6+ Months contract)

Job Description:

Essential Skills:

• Strong experience in chatbots and natural language processing (NLP).

• Good understanding of training classical Machine learning algorithms along with an understanding of choosing the right evaluation metric.

• Ability to use pretrained models and fine tune them if required.

• Experience with REST APIs and other web services.

• Perform keyword and topic extraction from chat logs.

• Solid knowledge of training and tuning topic modelling algorithms like LDA and NMF.

• Strong written communication skills.

• Ability to learn the latest technologies.

• Good problem-solving ability.

Nice to have skills:

• Experience in working with any AI/NLP platform (DialogFlow/ Alexa/ Converse.ai/ Amazon Lex etc.) for building chatbots Experience with any one of the technology (JavaScript, Node.js or Python).

• Understanding of conversational UI, voiced based processing (text to speech, speech to text) and voice apps built on Amazon Alexa or Google Home is a plus.

• Experience in Test Driven Development & Agile methodologies.

• Hands on experience of using frameworks like nltk and spacy.

• Experience with configuring, support and integrating various software systems, API’s, etc.

Thanks & Regards

Jayaraman | Infowaygroup.com | US IT Recruiter,

jayaraman@infowaygroup.com

Cell: +1 (315) 288-8461

Info Way Solutions LLC | 46520 Fremont Blvd, Suite 614 | Fremont, CA –94538.

Powered by JazzHR

lPDVJAPJcL","InfoWay Solutions LLC
2.6","Austin, TX",Internet,Information Technology
Data Engineer,"We're looking for a Data Engineer to join Procore's Information Technology Engineering team to help evolve our data-driven culture and become a world-class data organization. In this role, you'll help us gain a data advantage by leveraging our data assets and designing the foundation for which our advantage is constructed.

As a successful Data Engineer, you have a strong background in cloud infrastructure, particularly AWS and Google Cloud Platform. You strive to excel at everything you do while being able to prioritize between the must-haves and nice-to-haves. If you're intrinsically motivated and ready to roll up your sleeves and dive in—we'd love to hear from you!

This position will report into our Director, IT Engineering and has the option to be based in our Austin, TX offices located at the heart of downtown. We're looking for candidates to join us immediately.

What you'll do:
Create ETL (Extract, Transform & Load) pipelines to deliver sanctioned data to stakeholders, while maintaining high accuracy and reliability
Tune and monitor data infrastructure Performance to support a growing organization
Brainstorm data product ideas and partner closely with Data Scientists, Product Management and Operations teams to develop, test, deploy, and operate high-quality software
Develop data infrastructure that ingests and transform data from different sources and customers at scale.
Partner end-to-end with Business Managers, Product Managers, and Data Scientists to understand customer requirements and design prototypes and bring ideas to production
Work with internal business leaders to ingest data to enrich their data modeling and work products.
Participate in conversations with teams about business-impacting topics and brainstorm innovative ways to transform data into information and knowledge that drives revenue and reduces cost
What we are looking for:
BS or MS in Computer Science or equivalent
5+ years of data warehousing or data engineering experience with a distinguished track record on technically demanding projects
Deep knowledge of SQL databases (preferably PostgreSQL)
Comfort working with cloud-managed data warehouse technologies (Amazon Redshift, Google BigQuery, Snowflake)
Strong experience working with Python, particularly for ETL or Data Science related tasks
Experience working in a data lake architecture, separating compute from storage
Passion for creating new products and services, including being comfortable with the ambiguity associated with designing new products
Experience working with REST APIs to ingest and enrich data sets
Experience with Apache Airflow for workflow management is preferred
Comfort using Hadoop related technologies(Spark, Hive, Presto, etc.) is preferred
Data Science/Machine Learning background is preferred
Familiarity with the construction industry is preferred
About Us
Procore Technologies is building the software that builds the world. We provide cloud-based construction management software that helps clients more efficiently build skyscrapers, hospitals, housing complexes, and more. Our headquarters is located on the bluffs above the Pacific Ocean in Carpinteria, CA, with growing offices worldwide. Check us out on Glassdoor to see what others are saying about working at Procore!

We are an equal opportunity employer and welcome builders of all backgrounds. We thrive in a diverse, dynamic and inclusive environment. We do not tolerate discrimination against employees on the basis of age, color, disability, gender, gender identity or expression, marital status, national origin, political affiliation, race, religion, sexual orientation, veteran status, or any other classification protected by law.

Perks & Benefits
You are a person with dreams, goals, and ambitions—both personally and professionally. That's why we believe in providing benefits that not only match our Procore values (Openness, Optimism, and Ownership) but enhance the lives of our team members. Here are just a few of our benefit offerings: competitive health care plans, unlimited paid time off (Procore Values Time), employee enrichment and development programs, and volunteer days.","Procore Technologies
4.2","Austin, TX",Computer Hardware & Software,Information Technology
Data Engineer,"Horn Solutions is looking for a Senior Data Engineer to expand the data architectures and data services that drive its solutions. Be energized at a place that will allow you the flexibility to create, and customize your ideas utilizing cool technologies. You'll enjoy the flexible hours and unlimited vacation policy. We have excellent benefits, competitive salary, and a loaded kitchen to keep your tummy happy. Our ideal candidate 8+ years experience in Data Engineering In-depth knowledge in architecturing distributed systems Creating reliable data pipelines, data services involving queuing and stream processes Combining data sources and architecting data stores Collaborating with data science teams and building the right solutions for them Experience tuning databases for fast analysis and creating table schemas Building and redesigning services ETL data using big data and cloud based technologies Experience creating script to pull information from the main app database into the analytics database Expert in relational and NoSQL databases and distributed system (Google BigQuery, Postgres) Other great skillsexperience Presto, Hive, Spark SQL,Git, Unix, Python, Apache Airflow, Rstudio, R, Kuber. Container, Dockers, Hadoop, Cassandra, Jupyter, AWS, Azure, G. cloud HSITDice LI-KS1","Horn Solutions Inc.
4.2","Austin, TX",Consulting,Business Services
Data Engineer,"Our Story

The National Research Center for College and University Admissions™ (NRCCUA®), now a part of ACT®, is a membership organization that links colleges and universities to the nation’s largest college and career planning program for students seeking post-secondary guidance. In addition, members can receive exclusive access to Encoura™ Data Lab—an educational data science, analytics, and research platform. Since 1972, ACT | NRCCUA has been a leading provider of data, technology, and programs servicing public and private colleges and universities to enhance their marketing and recruiting efforts.

Over the years, ACT | NRCCUA has continued to evolve its offering to represent the link between students and higher education institutions. As part of that evolution, ACT | NRCCUA acquired Eduventures—the leading research and advisory firm focused exclusively on higher education. We are now able to provide forward-looking and actionable research based on proprietary market data, as well as advisory services that support both strategic and operational decision-making. All Eduventures Research is now available in the Encoura Data Lab platform.

The Senior Database Engineer is a hands-on technical position for a senior-level professional. The role involves an advanced, experienced skill set to design, develop and implement database objects, procedures and processes using the SQL Server platform to support business objectives throughout the organization.
You'll be working as part of an Agile team, developing the systems that power our business. This is a hands-on role, working with other engineers, writing code, testing, and deploying the finished apps and libraries.
Responsibilities and Deliverables
In partnership with your co-workers, design and develop database infrastructure (tables and views) to support a complex and rapidly changing data environment.
Create working, maintainable, and fast Python scripts and stored procedures using best practices and current organizational standards to support data-driven applications, both internal and client-facing.
Use indexing and other techniques to optimize new and existing objects and processes.
Develop processes for the ETL of data throughout the entire organization.
Generate data to support reporting (ad-hoc and standardized).
Follow and help develop database team standards and methodologies; use source control and build management procedures to ensure stable development, staging and production database environments.
Enhance, refactor, and continuously improve the database schemas and related code.
Communicate effectively with technical and non-technical people.
Solve business needs with short-term deliverables, while constantly improving and moving towards long-term architectural goals.
Generate new ideas, never say or think ""that's not my job.""
Be proactive in keeping your skills fresh
Qualifications and Experience
5+ years of T-SQL development experience in SQL Server.
3+ years of experience developing ETL processes with SQL Server Integration Services, Pentaho, or other tools. Bonus points for having developed ETL processes with Python and AWS.
2+ years of experience in development with Python 3.
1+ years of experience developing on AWS and Linux.
Mastery of advanced database design methodologies and experience with database modeling tools, dimensional modeling and statistical analysis
Clear understanding of SQL Server best practices for development of stored procedures, views, tables, security objects, indexes, etc.
Experience with any of the following is a plus: Postgres, SQL Server Reporting Services, MongoDB, Redis, Exasol
An appreciation for pragmatism and simplicity in code.
A strong code and architecture design sensibility.
Customized mathematical skills as determined by the requirements of the job
NRCCUA is an Equal Employment Opportunity (EEO) employer. It is the policy of the Company to provide equal employment opportunities to all qualified applicants without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, age, protected veteran or disabled status, or genetic information. All applicants must be eligible to work in the U.S.

NRCCUA endeavors to make reasonable accommodations for applicants with disabilities and disabled veterans pursuant to applicable federal and state law. If you are an individual with a disability and require a reasonable accommodation to complete any part of the application process or are limited in the ability and need an alternative method for applying, please contact the People Team.

To review our privacy policy, please click this link: https://encoura.org/privacy-policy/","NRCCUA
4.2","Austin, TX",Education Training Services,Education
Data Engineer,"Client is looking for people who can build solutions to write data pipelines and design storage solutions to stage the data that can be used by their data scientist community that resides in their individual business lines. It is important to present data engineers who have experience preparing data sets for AI solutions. Candidates would need to have 10 years of experience or higher. Herersquos the technology stack - Greenplum, Hadoop (for their Data Lake) and Teradata (for their Datawarehouse). Spark is used for Data transformations. Experience with MongoDB and any type of Graph databases(Neo4j, Amazon Neptune, Cassandra) is a plus.","Dutech Systems Inc
4.9","Round Rock, TX",IT Services,Information Technology
Data Engineer,"Overview


ProSphere is seeking an experienced Data Engineer to assist in strategizing, designing, continually improving and operating an existing Department of Army Government client’s cloud-based information technology infrastructure to host mission systems, applications, services, and data. This is full-time position that can be located in Austin, TX, National Capital (DC) Region, Redstone, AL, Detroit, MI, Natick, MA, Orlando, FL along with the possibility of telework options. Veterans are encouraged to apply.

Responsibilities


• Works with application and data science teams to support development of custom data solutions. • Capable of supporting rapid iterations of feature engineering with the development of coding solutions to enrich existing data sets. • Experience with traditional, modern, and cloud native database solutions. • Support the database design, development, implementation, information storage and retrieval, data flow and analysis activities. • Translate a set of requirements and data into a usable database schema by creating or recreating ad hoc queries, scripts and macros, updates existing queries, creates new ones to manipulate data into a master file. • Support development of databases, database parser software, database loading software, and database structures that fit into the overall architecture of the system under development.

Qualifications


• Requires a Bachelor’s degree in Computer Science, Information Systems, Engineering, or other Scientific/Technical discipline and • 3 years of related data engineering work experience. • Must meet IAT-I requirements as specified in DoD 8570.01-M (A+ CE, CCNA-Security, CND, Network+ CE, SSCP)• U.S. Citizenship (Government Requirement)• Must have an active Secret Clearance

Qualifications Highly Desired• U.S. Army or Army Future Command experience • Former Military

Knowledge/Skills/Abilities• Well organized• Superior attention to detail• Exceptional multi-tasking skills• Demonstrated and verifiable ability to recruit, develop, support, and maintain high performing teams

Physical Demands


• Ability to sit in an office environment for long periods of time • Typical office environment. Ability to sit and stand for extended periods of time; ability to lift 5-20 lbs

ProSphere offers full-time employees a comprehensive and competitive benefits package including paid vacation, sick leave, holidays, health insurance, life insurance, military leave, training, tuition reimbursement, a wellness program, short- and long-term disability, 401(k) retirement plan with company matches/immediate vesting, commuter benefits, and more.It is ProSphere’s policy to promote equal employment opportunities. All personnel decisions, including, but not limited to, recruiting, hiring, training, promotion, compensation, benefits and termination, are made without regard to race, creed, color, religion, national origin, sex, age, marital status, sexual orientation, gender identity, citizenship status, veteran status, disability or any other characteristic protected by applicable federal, state or local law.","Pro-Sphere Tek
3.3","Austin, TX",Enterprise Software & Network Solutions,Information Technology
Software Engineer,"As the worlds number 1 job site, our mission is to help people get jobs. We need talented, passionate people working together to make this happen. We are looking to grow our teams with people who share our energy and enthusiasm for creating the best experience for job seekers.
We are a rapidly growing and highly capable engineering team building the most popular job site on the planet. Every month, over 250 million people count on us to help them find jobs, publish their resumes, process their job applications, and connect them to qualified candidates for their job openings. With engineering hubs in Seattle, San Francisco, Austin, Tokyo and Hyderabad, we are improving people's lives all around the world, one job at a time.

The base salary range below represents the low and high end of the Indeed salary range for this position. Actual salaries will vary and may be above or below the range based on various factors including but not limited to location, experience, and performance. The range listed is just one component of Indeed's total compensation package for employees. Other rewards include quarterly bonuses, Long Term Incentive Plan units, an open Paid Time Off policy, and many region-specific benefits.

Austin Base Salary Range:

Software Engineer I: 90,000 - 112,000 USD per year

Software Engineer II: 116,000 - 142,000 USD per year

Senior Software Engineer: 116,000 - 142,000 USD per year

Staff Software Engineer 3: 138,000 - 174,000 USD per year

Principal Software Engineer: 172,000 - 218,000 USD per year

Technical Fellow: 199,000 - 261,000 USD per year

If you are an engineer who's passionate about building innovative products that scale to tens of millions of page views a day, Indeed is looking for you. Indeed offers smart developers like you a complex development ecosystem with short release cycles. Every week sees the new release of multiple products that meet the growing needs of millions of jobseekers worldwide.

As a Senior or Staff Software Engineer at Indeed, you will be responsible for designing, developing, and maintaining APIs for estimating job outcomes and setting ad budgets for small to medium businesses. You will design and implement pipelines that create datasets to train and evaluate learning models and work closely with the data scientists developing these models.

Indeeds SMB sponsored jobs product serves millions of users in helping them achieve their hiring goals. As part of a small collaborative team of engineers, data scientists, and product managers, you will develop new, scalable, low latency, fault-tolerant backend services. You will provide guidance on product and technical direction and own operational excellence of your deployed services.
Requirements
5+ years experience programming with at least one of the following languages: Java or Python
5+ years of experience with developing backend APIs in a data-driven environment
5+ years of experience building applications using at least one of the following web application technologies: HTML, CSS, or Javascript
5+ years of experience with databases such as: My SQL, Mongo, or a similar program
BS in Computer Science/Engineering or other technical related degrees.
Experience mentoring junior engineers
Experience conducting and leading code reviews
Significant experience with large scale, high-performance systems
Experience impacting a product or project in a tangible, positive manner

Indeed provides a variety of benefits that help us focus on our mission of helping people get jobs.

View our bounty of perks: http://indeedhi.re/IndeedBenefits

View Indeed's Applicant Privacy Terms: https://www.indeed.com/legal/applicant-privacy","Indeed
3.7","Austin, TX",Internet,Information Technology
Software Engineer,"Location: PICKLE RESEARCH CAMPUS

Job Posting Title:

Sonar Systems Software Engineering Scientist

----

Hiring Department:

Applied Research Laboratories

----

Position Open To:

All Applicants

----

Weekly Scheduled Hours:

40

----

FLSA Status:

Exempt

----

Earliest Start Date:

Immediately

----

Position Duration:

Expected to Continue

----

Location:

PICKLE RESEARCH CAMPUS

----

Job Description:

Research and development of software applications for sonar and underwater acoustics including algorithm design, implementation, verification, and performance analysis.

----

Job Details:

Responsibilities
Design, implementation, testing and integration of real-time and data analysis software applications to support the development of high-frequency tactical sonar systems
Documentation and presentation of work performed
Other related functions as assigned.
Required Qualifications

Bachelors degree in Computer Science, Computer Engineering, Electrical Engineering, or other related field. Three years of professional experience developing software in the C++ programming language targeting a Linux environment. Strong analytical and problem solving capability. Expert understanding of object-oriented programming concepts, data structures/design patterns/algorithm performance analysis. Applicant must have a dynamic skill set, willing to work with new technologies, be highly organized and capable of planning and coordinating multiple tasks and managing their time. The position will require attention to detail, effective problem solving skills and excellent judgment. Ability to work independently with sensitive and confidential information, maintain a professional demeanor, work as a team member without daily supervision and effectively communicate with diverse groups of clients. Able to work under pressure and accept supervision.

US Citizen: Applicant selected will be subject to a government security investigation and must meet eligibility requirements for access to classified information at the level appropriate to the project requirements of the position.

Preferred Qualifications

At least 5 years of professional experience programming in the C++ programming language (or 3+ years with Masters degree). Demonstrated technical proficiency in developing multi-threaded, multi-process, multi-machine computational software applications in a Linux environment. Experience with open-source build tools and procedures. Experience utilizing common application debugging and performance profiling tools. Understanding of common network protocols such as TCP/IP. Expertise with interpreted scripting languages such as Python or Bash. Knowledge of database concepts and/or familiarity with SQL. Familiarity with geospatial analysis and GIS concepts. Fundamental knowledge of electric circuit theory. Exposure to radar or underwater acoustic theory and common digital signal processing techniques. Cumulative GPA of 3.0.

General Notes

An agency designated by the federal government handles the investigation as to the requirement for eligibility for access to classified information. Factors considered during this investigation include but are not limited to allegiance to the United States, foreign influence, foreign preference, criminal conduct, security violations, drug involvement, the likelihood of continuation of such conduct, etc.

Please mark ""yes"" on the application question that asks if additional materials are required. Failure to attach all additional materials listed below may result in a delay in application processing.

Salary Range

$82,000-$129,996+/negotiable depending on qualifications

Working Conditions
Standard office conditions
Repetitive use of a keyboard at a workstation
Use of manual dexterity
Some weekend, evening and holiday work
Possible interstate/intrastate travel
Required Materials
Resume/CV
3 work references with their contact information; at least one reference should be from a supervisor
Letter of interest
Unofficial transcripts
Important for applicants who are NOT current university employees or contingent workers: You will be prompted to submit your resume the first time you apply, then you will be provided an option to upload a new Resume for subsequent applications. Any additional Required Materials (letter of interest, references, etc.) will be uploaded in the Application Questions section; you will be able to multi-select additional files. Before submitting your online job application, ensure that ALL Required Materials have been uploaded. Once your job application has been submitted, you cannot make changes.

Important for Current university employees and contingent workers: As a current university employee or contingent worker, you MUST apply within Workday by searching for Find UT Jobs. If you are a current University employee, log-in to Workday, navigate to your Worker Profile, click the Career link in the left hand navigation menu and then update the sections in your Professional Profile before you apply. This information will be pulled in to your application. The application is one page and you will be prompted to upload your resume. In addition, you must respond to the application questions presented to upload any additional Required Materials (letter of interest, references, etc.) that were noted above.

----

Employment Eligibility:

Regular staff who have been employed in their current position for the last six continuous months are eligible for openings being recruited for through University-Wide or Open Recruiting, to include both promotional opportunities and lateral transfers. Staff who are promotion/transfer eligible may apply for positions without supervisor approval.

----

Retirement Plan Eligibility:

The retirement plan for this position is Teacher Retirement System of Texas (TRS), subject to the position being at least 20 hours per week and at least 135 days in length.

----

Background Checks:

A criminal history background check will be required for finalist(s) under consideration for this position.

----

Equal Opportunity Employer:

The University of Texas at Austin, as an equal opportunity/affirmative action employer, complies with all applicable federal and state laws regarding nondiscrimination and affirmative action. The University is committed to a policy of equal opportunity for all persons and does not discriminate on the basis of race, color, national origin, age, marital status, sex, sexual orientation, gender identity, gender expression, disability, religion, or veteran status in employment, educational programs and activities, and admissions.

----

Pay Transparency:

The University of Texas at Austin will not discharge or in any other manner discriminate against employees or applicants because they have inquired about, discussed, or disclosed their own pay or the pay of another employee or applicant. However, employees who have access to the compensation information of other employees or applicants as a part of their essential job functions cannot disclose the pay of other employees or applicants to individuals who do not otherwise have access to compensation information, unless the disclosure is (a) in response to a formal complaint or charge, (b) in furtherance of an investigation, proceeding, hearing, or action, including an investigation conducted by the employer, or (c) consistent with the contractors legal duty to furnish information.

----

Employment Eligibility Verification:

If hired, you will be required to complete the federal Employment Eligibility Verification I-9 form. You will be required to present acceptable and original documents to prove your identity and authorization to work in the United States. Documents need to be presented no later than the third day of employment. Failure to do so will result in loss of employment at the university.

----

E-Verify:

The University of Texas at Austin use E-Verify to check the work authorization of all new hires effective May 2015. The universitys company ID number for purposes of E-Verify is 854197. For more information about E-Verify, please see the following:
E-Verify Poster (English) [PDF]
E-Verify Poster (Spanish) [PDF]
Right To Work Poster (English) [PDF]
Right To Work Poster (Spanish) [PDF]
----

Compliance:

Employees may be required to report violations of law under Title IX and the Jeanne Clery Disclosure of Campus Security Policy and Crime Statistics Act (Clery Act). If this position is identified a Campus Security Authority (Clery Act), you will be notified and provided resources for reporting. Responsible employees under Title IX are defined and outlined in HOP-3031.

The Clery Act requires all prospective employees be notified of the availability of the Annual Security and Fire Safety report. You may access the 2019 report here or obtain a copy at University Compliance Services, 1616 Guadalupe, Suite UTA 2.206, Austin, TX 78701.","The University of Texas at Austin
4.3","Austin, TX",Colleges & Universities,Education
Data Engineer,"Data Engineer - Austin, TX - $120,000-$130,000Job Description:

The Data Engineer will be responsible for supporting the development of a data factory pipeline within a cloud environment. The Data Engineer will work closely with Software Engineers, DevOps, and Data Analysts. They must be comfortable working both independently and as part of the larger data factory team in a complex, fluid environment.

Requirements:

• Data Factory Experience
• Data Pipeline experience
• CI/CD experience
• ETL
• Big Data experience
• SQL
• Cloud Services
• Java or Scala

Day-to-day responsibilities:

• Responsibilities for Data Engineer Develop and maintain optimal data pipeline architecture - including development related to data acquisition and monitoring, data quality, integration, normalization, and analytics development.
• Adhere to good code practices within an agile environment with a DevOps approach to development and implementation.
• Develop/design appropriate orchestration and structures supporting data transformation, metadata, code dependency and workload management.

In order to fast-track your opportunity, please reach out to me ASAP to talk more about this role! The company is looking to fill the position soon and it will not be on the market long. Please note, this is a permanent role. Candidates for this position must be either US citizens or Green Card holders; Visa sponsorship is not provided. My contact information can be found below.

Email: e.riley@nigelfrank.com

LinkedIn: https://www.linkedin.com/in/emma-riley-72028917a/

Job Requirements:
Azure, SQL, ETL, Data",Nigel Frank International US,"Austin, TX",-1,-1
Data Engineer,"Location: Round Rock, TX
Duration: 9 Months

Looking for local candidates only.

Project: Modeling Environment
The Modeling Environment Project objective is to integrate the process, tools, and platform used by our data scientists in the Digital Marketing R&D Lab for purposes of:
Data Acquisition (Hadoop, Spark, SQL, GreenPlum etc.)
Data Engineering & Preparation
Modeling & Machine learning
Source & Version Control
Microservice-enablement of models & delivery in Pivotal Cloud Foundry
Lab Operations (logging, SRs, uptime, dependency management)
Must Have (skillsets Data engineer with CS background. BS required Master’s degree ideal):
All data scientists are:
Using the same general tools (while different languages)
Expert in applied Python and R
Knowledge in Java, JavaScript
Can easily share, reuse and operationalize the predictive models & results
Have shared repositories, version control and security features
Assumptions/Considerations: (like to have):
Collaborate with the Data Science lab on tools and technologies
Experienced with Big data sets Structured and Unstructured

Regards,
Vikas
Vikasy@apninc.com","APN Software Services Inc.
4.1","Round Rock, TX",Computer Hardware & Software,Information Technology
Data Scientist,"Job Description
Job Title: Sr. Data Scientist

Location: Jacksonville,FL.

Type: Full Time

Responsibilities:
Build Predictive modeling ecosystems for real-time consumption
Design and develop advanced Machine Learning algorithms to rapidly build analytics apps and operationalize them into production
Deliver innovative solutions driven by exploratory data analysis from complex and high-dimensional data sets.
Develop Analytics applications using R/Python/Spark with Regression, SVM, and Neural Networks techniques
Apply knowledge of statistics, data modeling, and advanced mathematics to recognize patterns, identify opportunities, pose business questions, and make valuable discoveries.
Work with support teams in resolving operational & performance issues
Work in a Big Data environment with Hadoop, Spark, Hive
Education:

Bachelor’s, Masters or Doctorate in Computer Science, Information Systems and related Engineering disciplines",Springhead Technologies,"Jacksonville, FL",-1,-1
Data Scientist,"The Business

GradTests.com is a leading provider of practice psychometric tests to graduates, students and young professionals.

The Role

A data science all rounder role. The core purpose of the role is to build models to improve the product, the customer experience and ultimately the business. We're looking for someone with a nice blend of technical skills, and softer skills like business acumen, decision making and communication skills.

You'll do things like:
Conceive, devise, create, implement and fine tune data science models to solve a range of business problems, from customer churn through to
Set up, run and analyse A/B experiments for the website and email marketing campaigns
Help devise and layout a high quality infrastructure, upon which future data science can flourish
Help up skill other analytical team members into advanced data science techniques
Produce ad hoc analyses
And let's be honest, a whole load of data wrangling!
Skills and experience

Non negotiables:
SQL
Python or R
Data science models (K-means, random Forrest, neural nets etc.)
Strong foundational knowledge in stats and maths
Experience in actually productionising models and exposing to real customers
Business acumen
Strong communication skills, both written and verbal
Nice to haves:
Experience in working with developers, especially on experimentation
Some kind of cloud based experience (AWS preferred)
Some basic knowledge of source control with Git
Our application process consists of some online testing with Alooba, video call interview and then a case study. We expect the process to take about 10 business days end to end.

Job Types: Full-time, Contract

Salary: $120,000.00 /year

Experience:
Analytics: 1 year (Preferred)
Work Remotely:
Yes",GradTests (gradtests.com),"Jacksonville, FL",-1,-1
Statistician,"The U.S. Department of the Treasury has a distinguished history dating back to the founding of our nation. As the steward of U.S. economic and financial systems, Treasury is a major and influential leader in today's global economy. We have over 100,000 employees across the country and around the world. Come Join the Department of the Treasury and Invest in Tomorrow.
See Other Information for Locations
Positions are to be filled in the Large Business & International (LB&I), Data Solutions division.
Eight (8) positions are to be filled in any of the following locations:
Birmingham, AL
Fayetteville, AR
Little Rock, AR
Phoenix, AZ
El Monte, CA
Glendale, CA
Laguna Niguel, CA
Los Angeles, CA
Long Beach, CA
Oakland, CA
Sacramento, CA
San Diego, CA
San Francisco, CA
San Jose, CA
Santa Ana, CA
Lakewood, CO
Hartford, CT
New Haven, CT
Norwalk, CT
Washington, DC
Newark, DE
Miami, FL
Ft. Myers, FL
Jacksonville, FL
Maitland, FL
Plantation, FL
Tampa, FL
West Palm Beach, FL
Atlanta, GA
Honolulu, HI
Des Moines, IA
Chicago, IL
Downers Grove, IL
Schiller Park, IL
Springfield, IL
Indianapolis, IN
Wichita, KS
Louisville, KY
New Orleans, LA
Boston, MA
Brockton, MA
Stoneham, MA
Southborough, MA
Baltimore, MD
Lanham-Seabrook, MD
Rockville, MD
Ann Arbor, MI
Clinton Township, MI
Detroit, MI
Farmington Hills, MI
Flint, MI
Grand Rapids, MI
Pontiac, MI
Bloomington, MN
Chesterfield, MO
Lee's Summit, MO
Charlotte, NC
Greensboro, NC
Raleigh, NC
Omaha, NE
Edison, NJ
Iselin, NJ
Mountainside, NJ
Paterson, NJ
Las Vegas, NV
Albany, NY
Bethpage, NY
Buffalo, NY
New York, NY
Rochester, NY
Cincinnati, OH
Columbus, OH
Independence, OH
Oklahoma City, OK
Tulsa, OK
Portland, OR
Philadelphia, PA
Pittsburgh, PA
King Of Prussia, PA
Guaynabo, PR
Warwick, RI
Franklin, TN
Memphis, TN
Nashville, TN
Austin, TX
Farmers Branch, TX
Fort Worth, TX
Houston, TX
San Antonio, TX
Ogden, UT
Salt Lake City, UT
Norfolk, VA
Richmond, VA
Vienna, VA
Seattle, WA
Milwaukee, WI
Waukesha, WI
Kearneysville, WV
Martinsburg, WV
WHAT DOES A DATA SCIENTIST DO? The Data Scientist utilizes advanced analytical, statistical, and computer programming skills to develop data- driven solutions to difficult business challenges. As a data scientist, you are responsible for conducting data-centric projects to provide insight and informed decisions for mission- oriented programs of the Internal Revenue Service (IRS), which may impact multiple program segments, divisions, the Service, or segments of the taxpayer population. This is accomplished by utilizing a wide range of technical competencies such as statistics and machine learning, coding languages, data wrangling, and reporting and visualization techniques. The Data Scientist may lead team or cross functional projects, and will apply critical thinking, problem solving and ability to communicate complex analysis to advance the use of data-driven decision making in IRS operations.

WHAT IS THE LARGE BUSINESS AND INTERNATIONAL (LB&I) DIVISION OF THE INTERNAL REVENUE SERVICE? The Large Business and International (LB&I) business unit provides service and enforcement activities to support tax compliance of businesses and related entities with assets of $10 million or more, as well as small U.S. businesses engaged in international, U.S. citizens abroad, and foreign persons and businesses with a U.S. tax requirement.
As a Data Scientist, you will:
Serve as a technical expert with responsibility for the initiation, planning, implementation, controlling, modifying and executing of all or part of an entire project, including such tasks as formulation of workload estimates for program segments, specification of the methodology to be used, preparation of appropriate specifications and procedures, and review of computer systems specifications and materials and instructions needed for assuring the adequacy of the project’s design and objectives.
Explore novel methods of retrieving data and develop innovative recommendations to management and senior leadership as a means for making data driven decisions such as modification of processes and policies. Review, evaluate, validate, and document the results of the findings.
Assist the supervisor in determining the scope, goals and schedules for future programs in the Office. Collaborate with business or technology partners to understand business needs, identify opportunities, and develop and implement analytical solutions.
Identify and assess relevant data sources’ validity and reliability to meet project needs. Collate, clean, transform, analyze, and integrate structured and unstructured data from various sources in preparation for analysis.
Apply statistical methods and concepts including data mining, statistical theory and research procedures to test hypotheses using structured and unstructured data. Develop data product solutions to improve customer experiences, anomaly detection, and business outcomes. Develop proofs of concept or demonstrations to evaluate feasibility of project solutions and recommend visualization strategies.
Document project work and review deliverables for validity, reliability and timeliness. Communicate analytic solutions to technical and non-technical stakeholders, including during executive- level and/or cross-agency meetings, in a clear and effective manner using oral and written communications.
Maintain knowledge of state-of-the-art innovations in data science from both academic and industry sources and identify opportunities for implementation. Engage in general professional development to improve knowledge of IRS processes/programs.
Apply computer based mathematical/statistical techniques using software. Lead or participate in statistical projects or studies in survey sampling (design and estimation), modeling, or statistical research. Apply knowledge of programming/coding language (i.e., SQL, SAS, SPSS, RStudio) to develop scripts or applications.
Act as a troubleshooter in resolving bottlenecks at any step in a project by identifying and proposing solutions; this may include coordination with other project team members or stakeholders to mitigate issues.

WHERE CAN I FIND OUT MORE ABOUT OTHER IRS CAREERS? If you want to find out more about IRS careers, visit us on the web at www.jobs.irs.gov
#LI-POST
You must meet the following requirements by the closing date of this announcement
BASIC QUALIFICATION REQUIREMENTS:

GS-1530 Statistician All Grades:
You must have a Bachelor's degree that included 15 semester hours in statistics (or in mathematics and statistics, provided at least 6 semester hours were in statistics), and 9 additional semester hours in one or more of the following: physical or biological sciences, medicine, education, or engineering; or in the social sciences including demography, history, economics, social welfare, geography, international relations, social or cultural anthropology, health sociology, political science, public administration, psychology, etc. Credit toward meeting statistical course requirements should be given for courses in which 50 percent of the course content appears to be statistical methods, e.g., courses that included studies in research methods in psychology or economics such as tests and measurements or business cycles, or courses in methods of processing mass statistical data such as tabulating methods or electronic data processing. OR
Combination of education and experience -- courses as shown above, plus appropriate experience or additional education. The experience should have included a full range of professional statistical work such as (a) sampling, (b) collecting, computing, and analyzing statistical data, and (c) applying statistical techniques such as measurement of central tendency, dispersion, skewness, sampling error, simple and multiple correlation, analysis of variance, and tests of significance.
GS-13 LEVEL: You must have one year of specialized experience at a level of difficulty and responsibility equivalent to the GS-12 grade level in the Federal service. Specialized experience for this position includes all of the following:
Experience applying project management principles on a data science project
Experience planning and executing a variety of data science and/or analytics projects.
Experience using data mining process models (such as CRISP-DM, SEMMA, etc.,) to design and execute data science project.
Experience preparing and analyzing structured and unstructured datasets to explorations and evaluating data science centric models.
Experience working with multiple data types and formats as a part of a data science project.
Experience applying a range of analytic approaches, including (but not limited to) machine learning, text analytics, and natural language processing; graph theory, link analysis and optimization models; complex adaptive systems; and/or deep learning neural networks that are part of the exploration.
Experience coding in various programming languages (such as R, Python, SQL, or JAVA) to conduct various phases of data science projects.
Experience creating and querying different datastores and architectures (such as Sybase, Oracle, and open-source databases) to work with various types of data as part of the data science project.
Experience using tools for data visualization (graphs, tables, charts, etc.,) and end-user business intelligence.
-The experience may have been gained in the public sector, private sector or Volunteer Service. One year of experience refers to full-time work; part-time work is considered on a prorated basis.
-To ensure full credit for your work experience, please indicate dates of employment by month/year, and indicate number of hours worked per week, on your resume.","Internal Revenue Service
3.5","Jacksonville, FL",Federal Agencies,Government
Data Analyst,"Title Data Analyst Location Tampa, FL Job Type Minimum 6 Month Contract About CSI Tech CSI Tech is a different kind of IT talent company. We do our homework to match the right people, with the right skills, to every client challenge. Whether you're an organization with an immediate IT staffing need or an IT professional searching for the ideal opportunity, CSI Tech is the solution you've been looking for. We do IT talent right. We are seeking a Sr. Data Analyst who meets the below qualifications Required Experience Must have experience with SAS and SQL Must be able to pull data, run queries, modify queries andor basic SQL skills Must be highly analytical Must have experience analyzing complex data sets Must be able to work in a fast-paced environment Work Experience Healthcare experience is required (preferably on the payor side) Expenses reimbursement, according to your contract Consultant Care Program POSITION SUMMARY Primary point of contact for interface between data users and IS teams. Reviews programming requests and work with business users and technical staff to identify, gather, analyze, and document data requirements. Conduct analysis of business and user data needs, documenting requirements, create source to target mappings and revising existing logic, as necessary. Perform analysis of data needs for users and cross reference to data sources in IT systems. Responsible for the analysis, design, development, testing, and documentation of information management systems. Drives defining and maintaining development standards and development best practices. TechnicalFunctional Competencies Database used is Oracle and SQL","CSI Tech Inc.
3.0","Jacksonville, FL",Staffing & Outsourcing,Business Services
Data Engineer,"About The Energy Authority
The Energy Authority is a public power-owned, nonprofit corporation with offices in Jacksonville, Florida and Bellevue (Seattle), Washington. TEA provides public power utilities with access to advanced resources and technology systems so they can respond competitively in the changing energy markets. Through partnership with TEA, utilities benefit from an experienced organization that is singularly focused on deriving the maximum value of their assets from the market.

About the TEAm
The Connected Analytics team works directly with utility clients and portfolio managers to innovate and deliver on relevant analytic solutions for network asset management, customer analytics, demand forecasting and optimized predictive maintenance. The team consists of analysts and researchers with expertise in data architecture, machine learning, artificial intelligence, mathematics, software engineering, and computer science. With our focus on Data to Insight, Insight to Action, Connected Analytics works collaboratively within the Strategic Innovations business unit and across the whole of The Energy Authority team.

About the Job
Data Engineers, on the Connected Analytics team, work with large complex data sets to assemble and integrate them into a standardized platform using ETL tools and based on Microsoft Azure and SQL. The Data Engineer role is responsible for setting up and managing the ETL data pipeline and working with utility clients to ensure that the data acquisition process meets their immediate and future data analytics requirements. The Data Engineer will report to the Senior Data Architect and will collaborate with the Data Scientists and Research Scientists on the Connected Analytics team to understand and optimize the data inputs to statistical and machine learning models. The Data Engineer will present findings to both the internal team and external clients using effective visualization tools (e.g. Power Bi).

Essential Duties and/or Responsibilities include the following. Other duties may be assigned.
• Develop data pipelines using SQL, Python, and R
• Work with clients to setup data acquisition processes
• Test, Monitor, and Address issues with data pipeline processes
• Work with Data Scientists and Data Architects to build data structures to support Machine Learning models
• Collaborate with Data Scientists to understand the data needs of Statistical and Machine Learning Models
• Develop Visualizations to provide actionable insight to team members and clients

Education and/or Experience
• Bachelors degree in Computer Science, Software Engineering, Data Engineering, Mathematics or related discipline or 3-5 years relevant experience
• Proficient with SQL development, developing ETL pipelines, and building Data Structures
• Proficient with data scripting languages such as R, Python, and Scala (other ETL pipeline tools)
• Experience with Power BI or equivalent data visualization tool
• Experience with Big Data Spark development
• Experience with DataBricks
• Experience working in a Microsoft Azure Environment
• Experience working on a team project and meet deliverable milestones independently with minimal oversight
• Ability to learn new technologies quickly and test/implement them using an iterative approach
• Experience working in a team environment
• Excellent communication skills demonstrated by experience in communicating with clients and internal staff to understand and document requirements, and present project results

Core Competencies Required
Critical thinking
Communication
Accuracy
Commitment to continuous learning
Programming
Technical design
Project-related work
Issue management

Values Required
Customer Focus
Integrity
Teamwork
Ownership
Excellence","Energy Authority
4.3","Jacksonville, FL",Energy,"Oil, Gas, Energy & Utilities"
Data Analyst,"We are working with a client in Jacksonville, FL who is looking to add a mid-level Data Analyst to their growing team. Salary will be between $60-70k depending on previous experience and qualifications with the following requirements. Please apply directly if interested.
Create datasets for analysis.
Ability to plan, research, and analyze
Applying database skills including T-SQL, procedures, indexing and query tuning
Contribute to technical architectural planning, data modeling, process flow documentation and the design and development of innovative solutions
Working with both technical staff and business partners to translate requirements into technical implementations
Maintaining technical and user documentation
Manage datasets and perform data cleaning, including identifying potential problems with study data and collaborating with research team to resolve issues","Green Key Resources
4.5","Jacksonville, FL",Staffing & Outsourcing,Business Services
Data Analyst,"Job Description
Job description

• Interpret data, analyze results using statistical techniques and provide ongoing reports

• Develop and implement databases, data collection systems, data analytics and other strategies that optimize statistical efficiency and quality

• Acquire data from primary or secondary data sources and maintain databases/data systems

• Identify, analyze, and interpret trends or patterns in complex data sets

• Filter and “clean” data by reviewing computer reports, printouts, and performance indicators to locate and correct code problems

• Work with management to prioritize business and information needs

• Locate and define new process improvement opportunities

Requirements

• Proven work experience as a data analyst or business data analyst

• Technical expertise regarding data models, database design development, data mining and segmentation techniques

• Strong knowledge of and experience with reporting packages (Business Objects etc), databases (SQL etc), programming (XML, Javascript, or ETL frameworks)

• Knowledge of statistics and experience using statistical packages for analyzing datasets (Excel, SPSS, SAS etc)

• Strong analytical skills with the ability to collect, organize, analyze, and disseminate significant amounts of information with attention to detail and accuracy

• Adept at queries, report writing and presenting findings

• Master's in Computer Science or Engineering Management or Project Management or Information Systems/Technology (Preferred)

Powered by JazzHR

lBDnkQw1Lg","Staffigo Technical Services, LLC
5.0","Jacksonville, FL",IT Services,Information Technology
Data Analyst,"Experience:5 Years of SQL Server experience
Experience with Power BI, or similar reporting packages
Verbal and written communication skills
Experience managing data in various formats
Adept at queries, report writing, and presenting findings
Ability to collaborate effectively and work as part of a team
Experiecne with data modeling and warehousing","SNI Technology
3.5","Jacksonville, FL",Staffing & Outsourcing,Business Services
Data Engineer,"Title Data Engineer Location Jacksonville, FL Duration 3 months Compensation 40.00 - 45.00 per hour Work Requirements , GC Holders or Authorized to Work in the US Overview TekPartners has some of the most sought after Information Technology positions available. As a reputable company in the IT staffing industry, you can trust us to place you in the right position. We currently have an opportunity for a Data Engineer in Jacksonville, FL Qualifications Engineer with light analytical background. Enables the core infrastructure needed by the Business Analysts and Data Scientists to perform analytics. Partners with the enterprise IT to fill the data and tool gaps. Ability to work in a fast paced environment and adapt to changing requirements. Strong troubleshooting skills, able to debug production code with limited guidance. Self-starter, able to work with limited supervision and see tasks through to completion. Proficiency to create and support database technical environments. Excellent customer service skills that build high levels of customer satisfaction for internal and external customers. Excellent verbal and written communication skills to technical and non-technical audiences of various levels in the organization (e.g., executive, management, individual contributors). Willingly shares relevant technical andor industry knowledge and expertise to other resources. Excellent decision-making, problem-solving, team, and time management skills. Is resourceful and proactive in gathering information and sharing ideas. Ability to estimate work effort for project sub-plans or small projects and ensure the project is successfully completed. 3-5 years' experience with MS SQL. 2 years SSIS experience. Responsibilities Ability to build, update, and scale large datasets. Write queries to automate production tasks. Responsible for health and hygiene of non-IT managed data. Consume business requirements and develops the data, database specifications, tables and element attributes to support. Models databases and develops tables, stored procedures, views, and other database objects. Maintains database dictionaries, monitors overall database standards and procedures, and integrates systems through database design. Works closely with other developers to integrate databases with other applications. May provide leadership andor guidance to other technical professionals. Performs other related duties as assigned. Our benefits package includes Comprehensive Medical Benefits Competitive Pay, 401K Retirement Plan And Much More About TekPartners TekPartners is one of the fastest growing private staffing firms in the United States. We are a premier provider of highly qualified IT talent, Workforce Solutions and Business Intelligence Solutions to many enterprise organizations across the nation. As experts in the industry, our team continues to match proven talent to the right job opportunity every day. TekPartners is an Equal Opportunity Employer.","TekPartners
4.3","Jacksonville, FL",Staffing & Outsourcing,Business Services
Data Engineer,"The Data Engineer will support the design and development of data workflows, ETL-like processes, SQL queries, and Visualizations of various clinical and non-clinical databases in the Clearsense Data Ecosystem. They must also demonstrate advanced analytical skills, technical and business knowledge and have a strong understanding of how to leverage industry standard tools and methods to solve problems.

The Data Engineer will work closely with Software Engineers by providing data mapping and wrangling expertise and Data Scientists by helping to determine and provide data sets needed for analysis. They often wrestle with problems associated with database integration and messy, unstructured data sets. Their ultimate aim is to provide clean, usable data to whomever may require it.

Responsibilities:
• Research opportunities for data acquisition and new uses for existing data
• Develop data set processes for data modeling, mining and production
• Employ a variety of languages and tools (e.g. scripting languages) to merge data together
• Recommend ways to improve data reliability, efficiency and quality
• Define and Develop Clearsense Data Governance Policies
• Aggregate and analyze various data sets to provide actionable insight
• Develop reports, dashboards, and tools for business-users
• Perform detailed analysis of Customer data sources
• Write complex SQL queries across multiple data sources

Qualifications:
• Must have 5+ years within a data management role performing implementation, integration and/or technical development, with a heavy focus on SQL and relational databases
• A nice to have is prior use of Data Governance tools and processes
• A nice to have background would involve knowledge and experience with healthcare data exchange platforms and data aggregation tools and healthcare interoperability and messaging standards, including but not limited to HL7 2.x, HL7 3.x, HL7 FHIR, IHE integration profiles
• A nice to have background would be an understanding of general medical terminology and healthcare clinical code sets such as LOINC, CPT, ICD, RxNorm, etc.
• A nice to have background would be a demonstrated advanced knowledge in Healthcare data, HL7 scripting and two or more programming languages, Healthcare operations, process improvement, and application of technology to improve patient outcomes.
• A nice to have background would be as a highly skilled and proficient knowledge of and experience with build tools of the electronic medical record, and other clinical systems.
• Self-starter, self-motivated, high level of initiative within a fast-paced, constantly evolving data management environment
• Result focused, ability to solve complex problems and resolve conflicts in a timely manner
• Ability to travel to Customer sites (up to 10%)

REQUIRED:
Bachelors degree in Data Informatics, Computer Science, Business or related field.

Must have experience:
• SQL, scripting languages, ETL tools and Data workflow tools","Clearsense, LLC
3.8","Jacksonville, FL",Enterprise Software & Network Solutions,Information Technology
Data Engineer,"The Business

GradTests.com is a leading provider of practice psychometric tests to graduates, students and young professionals.

The Role

The core purpose of the role is to make high quality, high availability, accurate data available for our data analysts and data scientists to do their analysis, derive their insights and build their models. You are the Scotty Pippin to the Michael Jordans. You are the Xavi to the Messis.

You'll do things like:
Ensure our data warehouse is well structured, running smoothly and efficiently for all business intelligence
Set up and maintain various data pipelines used for customer analytics, marketing analytics and product analytics
Skills and experience

Non negotiables:
SQL
Python
Strong knowledge of traditional relational databases - we don't mind which
Some experience with cloud technologies - again we don't mind if it's AWS, GCP or Azure
Experience in any streaming technology
Great experience in using third party APIs at scale
Some web scraping experience
An obsession with data quality
Strong communication skills
Nice to haves:
Experience in working with analysts
Any basic knowledge of advanced analytics techniques
Experience in a visualisation tool like Tableau
Job Types: Full-time, Contract

Salary: $100,000.00 /year

Work Remotely:
Yes",GradTests (gradtests.com.au),"Jacksonville, FL",-1,-1
Data Analyst,"Lutheran Services Florida (LSF) envisions a world where children are safe, families are strong and communities are vibrant. Since 1982, Lutheran Services Florida has been providing and sharing solutions to protect Florida’s most vulnerable. Today, we are one of the largest nonprofits in Florida touching 1 in 50 Floridians with a wide range of services, including:
early childhood education
refugee and immigration
mental health and substance abuse
juvenile justice
child welfare
LSF is looking for a talentedData Analystwho wants to make an impact in the lives of children and families.

Purpose& Impact

The Data Analyst conducts full data life cycle from data capture, maintenance, synthesis, usage, publication, archival through purging. Data Analyst develop and support reporting capabilities.

A Day in The Life of a Data Analyst
Pull and integrate data from disparate sources
Support and maintain databases or data collections systems.
Evaluate and preprocess raw information
Filter and“clean” data by reviewing back-up data and reports
Interpret data, analyze results using statistical techniques and present findings.
Build and maintain reports
Interface with internal customers and business partners on issues with data systems, process or procedures
Responds proactively to data issues and escalates appropriately
Coordinate with Project Coordinator(s) for any program or project-specific functions and assignments
Supports reporting and data analytics; Deliver accurate, complete and timely submissions of all required reports, performance measures or benchmarks, trends and analyses.
Deliver exceptional customer services to external and internal clients, business partners or stakeholders
Other tasks and duties as assigned
Physical Requirements

Energy, persistence and stamina sufficient for functioning as part of a team in a fast-paced office environment

Qualifications

Required/Preferred Education and Experience
Bachelor’s degree in Computer Science, Information Management, Mathematics, Statistics or Industrial Engineering or Equivalent work experience
1-3 years proven working experience as a data analyst
Preferably working experience with Behavioral healthcare operations and systems.
Competencies (Skills/Knowledge& Abilities)

Knowledge of data models, database design development, data mining and segmentation techniques

Knowledge of statistics and experience using statistical packages for analyzing datasets (Excel, SPSS, etc. ).

Strong knowledge of and experience with reporting packages (SSRS, Crystal, etc.), databases (SQL, etc.), programming (XML, Javascript, or ETL frameworks)

Strong analytical skills with the ability to collect, organize, analyze, and disseminate significant amounts of information with attention to detail and accuracy.

Adept at queries, report writing and presenting findings

Why Work With LSF?

Ability to Make an Impact in Multiple Areas

LSF offers several programs, spanning across a wide range of populations in need. This gives our team members an opportunity to learn and potentially work in programs outside of their direct area.Either way, members of the LSF family will play a part in transforming the lives of those in need.

Community

A career at LSF means working and learning alongside talented professionals in a dynamic and inclusive environment. The values of our organization–OPEN-MINDED, COMPASSIONATE,GENEROUS, VISIONARY andHONESTY– drives each one of us.

People working at Lutheran Services Florida treat each other like family. Whether you work on the front lines or work in an office, you share a common bond that is felt throughout the organization.

Growth Opportunities

Because of the variety of programs we offer throughout Florida, team members have the option to explore areas of interest in other programs or grow within their existing program/department.

Amazing benefits packageincluding:
Medical, dental and vision
Teledoc (24/7 access to doctors via phone and video)
Employee Assistance Program (EAP)
Long-term disability
Employer paid life insurance (1X salary), AD&D
Health and dependent care FSA
12 paid holidays + 1 floating holiday
Generous PTO policy
403(b) Retirement plan with 3% discretionary employer match
Tuition reimbursement
LifeMart employee discount program (savings on everything from computers to car rentals)
Additional voluntary benefits:
Short-term disability
Group life insurance
Accident, critical illness/Cancer and hospital policy
Legal Shield coverage
Lutheran Family Services embraces diversity, equity and inclusion in all business practices. LSF is proud to be an equal opportunity employer.","Lutheran Services Florida
3.3","Jacksonville, FL",Religious Organizations,Non-Profit
Statistician,"The U.S. Department of the Treasury has a distinguished history dating back to the founding of our nation. As the steward of U.S. economic and financial systems, Treasury is a major and influential leader in today's global economy. We have over 100,000 employees across the country and around the world. Come Join the Department of the Treasury and Invest in Tomorrow.
See Other Information for Locations
Positions are to be filled in the Large Business & International (LB&I), Data Solutions division.
Eight (8) positions are to be filled in any of the following locations:
Birmingham, AL
Fayetteville, AR
Little Rock, AR
Phoenix, AZ
El Monte, CA
Glendale, CA
Laguna Niguel, CA
Los Angeles, CA
Long Beach, CA
Oakland, CA
Sacramento, CA
San Diego, CA
San Francisco, CA
San Jose, CA
Santa Ana, CA
Lakewood, CO
Hartford, CT
New Haven, CT
Norwalk, CT
Washington, DC
Newark, DE
Miami, FL
Ft. Myers, FL
Jacksonville, FL
Maitland, FL
Plantation, FL
Tampa, FL
West Palm Beach, FL
Atlanta, GA
Honolulu, HI
Des Moines, IA
Chicago, IL
Downers Grove, IL
Schiller Park, IL
Springfield, IL
Indianapolis, IN
Wichita, KS
Louisville, KY
New Orleans, LA
Boston, MA
Brockton, MA
Stoneham, MA
Southborough, MA
Baltimore, MD
Lanham-Seabrook, MD
Rockville, MD
Ann Arbor, MI
Clinton Township, MI
Detroit, MI
Farmington Hills, MI
Flint, MI
Grand Rapids, MI
Pontiac, MI
Bloomington, MN
Chesterfield, MO
Lee's Summit, MO
Charlotte, NC
Greensboro, NC
Raleigh, NC
Omaha, NE
Edison, NJ
Iselin, NJ
Mountainside, NJ
Paterson, NJ
Las Vegas, NV
Albany, NY
Bethpage, NY
Buffalo, NY
New York, NY
Rochester, NY
Cincinnati, OH
Columbus, OH
Independence, OH
Oklahoma City, OK
Tulsa, OK
Portland, OR
Philadelphia, PA
Pittsburgh, PA
King Of Prussia, PA
Guaynabo, PR
Warwick, RI
Franklin, TN
Memphis, TN
Nashville, TN
Austin, TX
Farmers Branch, TX
Fort Worth, TX
Houston, TX
San Antonio, TX
Ogden, UT
Salt Lake City, UT
Norfolk, VA
Richmond, VA
Vienna, VA
Seattle, WA
Milwaukee, WI
Waukesha, WI
Kearneysville, WV
Martinsburg, WV
WHAT DOES A DATA SCIENTIST DO? The Data Scientist utilizes advanced analytical, statistical, and computer programming skills to develop data- driven solutions to difficult business challenges. As a data scientist, you are responsible for conducting data-centric projects to provide insight and informed decisions for mission- oriented programs of the Internal Revenue Service (IRS), which may impact multiple program segments, divisions, the Service, or segments of the taxpayer population. This is accomplished by utilizing a wide range of technical competencies such as statistics and machine learning, coding languages, data wrangling, and reporting and visualization techniques. The Data Scientist may lead team or cross functional projects, and will apply critical thinking, problem solving and ability to communicate complex analysis to advance the use of data-driven decision making in IRS operations.

WHAT IS THE LARGE BUSINESS AND INTERNATIONAL (LB&I) DIVISION OF THE INTERNAL REVENUE SERVICE? The Large Business and International (LB&I) business unit provides service and enforcement activities to support tax compliance of businesses and related entities with assets of $10 million or more, as well as small U.S. businesses engaged in international, U.S. citizens abroad, and foreign persons and businesses with a U.S. tax requirement.
As a Data Scientist, you will:
Serve as a technical expert with responsibility for the initiation, planning, implementation, controlling, modifying and executing of all or part of an entire project, including such tasks as formulation of workload estimates for program segments, specification of the methodology to be used, preparation of appropriate specifications and procedures, and review of computer systems specifications and materials and instructions needed for assuring the adequacy of the project’s design and objectives.
Explore novel methods of retrieving data and develop innovative recommendations to management and senior leadership as a means for making data driven decisions such as modification of processes and policies. Review, evaluate, validate, and document the results of the findings.
Assist the supervisor in determining the scope, goals and schedules for future programs in the Office. Collaborate with business or technology partners to understand business needs, identify opportunities, and develop and implement analytical solutions.
Identify and assess relevant data sources’ validity and reliability to meet project needs. Collate, clean, transform, analyze, and integrate structured and unstructured data from various sources in preparation for analysis.
Apply statistical methods and concepts including data mining, statistical theory and research procedures to test hypotheses using structured and unstructured data. Develop data product solutions to improve customer experiences, anomaly detection, and business outcomes. Develop proofs of concept or demonstrations to evaluate feasibility of project solutions and recommend visualization strategies.
Document project work and review deliverables for validity, reliability and timeliness. Communicate analytic solutions to technical and non-technical stakeholders, including during executive- level and/or cross-agency meetings, in a clear and effective manner using oral and written communications.
Maintain knowledge of state-of-the-art innovations in data science from both academic and industry sources and identify opportunities for implementation. Engage in general professional development to improve knowledge of IRS processes/programs.
Apply computer based mathematical/statistical techniques using software. Lead or participate in statistical projects or studies in survey sampling (design and estimation), modeling, or statistical research. Apply knowledge of programming/coding language (i.e., SQL, SAS, SPSS, RStudio) to develop scripts or applications.
Act as a troubleshooter in resolving bottlenecks at any step in a project by identifying and proposing solutions; this may include coordination with other project team members or stakeholders to mitigate issues.

WHERE CAN I FIND OUT MORE ABOUT OTHER IRS CAREERS? If you want to find out more about IRS careers, visit us on the web at www.jobs.irs.gov
#LI-POST
You must meet the following requirements by the closing date of this announcement
BASIC QUALIFICATION REQUIREMENTS:

GS-1530 Statistician All Grades:
You must have a Bachelor's degree that included 15 semester hours in statistics (or in mathematics and statistics, provided at least 6 semester hours were in statistics), and 9 additional semester hours in one or more of the following: physical or biological sciences, medicine, education, or engineering; or in the social sciences including demography, history, economics, social welfare, geography, international relations, social or cultural anthropology, health sociology, political science, public administration, psychology, etc. Credit toward meeting statistical course requirements should be given for courses in which 50 percent of the course content appears to be statistical methods, e.g., courses that included studies in research methods in psychology or economics such as tests and measurements or business cycles, or courses in methods of processing mass statistical data such as tabulating methods or electronic data processing. OR
Combination of education and experience -- courses as shown above, plus appropriate experience or additional education. The experience should have included a full range of professional statistical work such as (a) sampling, (b) collecting, computing, and analyzing statistical data, and (c) applying statistical techniques such as measurement of central tendency, dispersion, skewness, sampling error, simple and multiple correlation, analysis of variance, and tests of significance.
GS-13 LEVEL: You must have one year of specialized experience at a level of difficulty and responsibility equivalent to the GS-12 grade level in the Federal service. Specialized experience for this position includes all of the following:
Experience applying project management principles on a data science project
Experience planning and executing a variety of data science and/or analytics projects.
Experience using data mining process models (such as CRISP-DM, SEMMA, etc.,) to design and execute data science project.
Experience preparing and analyzing structured and unstructured datasets to explorations and evaluating data science centric models.
Experience working with multiple data types and formats as a part of a data science project.
Experience applying a range of analytic approaches, including (but not limited to) machine learning, text analytics, and natural language processing; graph theory, link analysis and optimization models; complex adaptive systems; and/or deep learning neural networks that are part of the exploration.
Experience coding in various programming languages (such as R, Python, SQL, or JAVA) to conduct various phases of data science projects.
Experience creating and querying different datastores and architectures (such as Sybase, Oracle, and open-source databases) to work with various types of data as part of the data science project.
Experience using tools for data visualization (graphs, tables, charts, etc.,) and end-user business intelligence.
-The experience may have been gained in the public sector, private sector or Volunteer Service. One year of experience refers to full-time work; part-time work is considered on a prorated basis.
-To ensure full credit for your work experience, please indicate dates of employment by month/year, and indicate number of hours worked per week, on your resume.","Internal Revenue Service
3.5","Fort Worth, TX",Federal Agencies,Government
Data Scientist,"Job Description
The Data Scientist

This individual will work with the newly formed Data Science team for the company. That means you’ll be instrumental in making a big impact.

This team is responsible for providing analytical support, performing market analysis, identifying market trends, and telling stories with data.

Share your brilliance!

For this Data Science role, we are especially looking for a few particular traits: They must have a combination, but not having all is fine and not a deal breaker, the more the better odds.

- Looking for Big Data Engineers that well versed with big data tech like Spark, Kafka, Streams, SQL/NSQL database modeling.

Responsibilities:
Working with Data Science team on both internal and external data sets.
Collaborate and work closely with cross-functional business partners to identify gaps and structure problems.
Use large data sets of structured and un-structured data to Client insights.
Work in a fast-paced, dynamic environment to deliver results while meeting deadlines.
Promoting process improvement using machine learning techniques.
Design data visualizations to communicate complex ideas to various leadership teams.
Qualifications:
MS or PhD in Mathematics, Statistics, Computer Science, Engineering or other quantitative disciplines. Complete understanding of and expertise with various machine learning packages.
Experience applying machine learning to real-world problems.
Experience in feature engineering methods such as PCA, ANOVA and multivariate analysis. Comprehension of modeling techniques such as classification and regression.
Good understanding of various statistical methods, not limited to hypothesis testing, resampling, and Bayesian inference.
Fluent in R, Python (including Numpy, Pandas and Scikit-learn).
Experience in different distributed systems, such as Hadoop or Spark Proficient in SQL.
Ability to communicate complex quantitative analysis in a clear, precise, and actionable manner.

Company Description
Helping Your Business Thrive With Human Capital Solutions

www.ateroz.com","Ateroz
5.0","Irving, TX",Staffing & Outsourcing,Business Services
Data Scientist,"Objective:

The Data Scientist will be a technical role in leading data science projects, combining predictive analytics, data modeling, and machine learning. You’ll have a strong business acumen to assist in decision-making for complex business problems across the digital platform. You aren’t just reporting the data – you’ll be the key role in building it, it’s attributes, and its parameters while tailoring solutions to emerging business challenges.
Profile:
Required 4+ years of experience in relevant role (data/ decision science role, preferably in e-commerce and/or omni-channel)
Bachelor’s degree in related field (mathematics, statistics, computer science, engineering or a related quantitative field)
Expertise and deep knowledge of typical data science techniques such as classification, regression and optimization
Experience/proficiency in statistical programming languages: R, SAS, SPSS, etc.· Experience/proficiency in one or more of the following scripting languages: Python, Perl, Java or Ruby
Experience/proficiency in relational databases such as: SQL, Oracle, Teradata
Familiarity with:
BI tools (SAP business Intelligence, MicroStrategy, Tableau, QlikSense)
Big Data ecosystems & Distributed file systems / data frameworks (Apache Hadoop, AWS)
Machine learning tools/packages
Proficient level of MS Office (Word, Excel, Outlook, Powerpoint, Sharepoint, OneNote) and presentation tools
Duties:
Independently and collaboratively explore, develop and deliver solutions to meet the business needs. Undertake data collection, processing and analysis.
Apply in-depth technical knowledge to create and implement customer centric solutions to complex business problems (ecosystem) across multiple areas.
Develop and apply algorithms. Analyze complex unstructured data sets to recommendations and implement solutions.
Build business intelligence system for the business integrating all and future platforms with multiple sources of data.
Independently convert business management questions into analyzable problems with solutions.
Skills:
Analytical mind with a business acumen (customer centricity)
Attentive to details – very detail oriented
Strong portfolio of design projects
A strong working knowledge of product UX design and creative processes
Job Type: Full-time

This Job Is Ideal for Someone Who Is:
Detail-oriented -- would rather focus on the details of work than the bigger picture
Autonomous/Independent -- enjoys working with little direction
Schedule::
Monday to Friday","Rotoplas USA
4.0","Fort Worth, TX",-1,-1
Data Engineer,"Responsibilities Data Extraction, Transformation, Loading are main responsibilities considering enterprise data management for Data Lakes and Data Warehouses. Build Azure Data Factory Pipelines. Implement Azure Cloud Data Warehouses. Work with the Application Development team to Implement Data Strategies, Build Data Flows and Develop Conceptual Data Models. Required skills Experience Experience in Building Data Applications using Azure Data Factory Experience running ETLELT Projects from end to end, understanding required Experience in Azure Data Bricks with Python, Spark mandatory Strong SQL Skills Good Understanding of Azure SQL Data WarehouseDB Excellent in Data Analytical Skills Strong understanding of Data Integration (Validation and Cleaning), familiarity with Complex Data Structures Good to know Data Visualization tool Power BI",Headway Tek Inc,"Fort Worth, TX",-1,-1
Data Analyst,"Data AnalystFort Worth, TXData Analyst Fort Worth, TX

Outstanding opportunity for a Data Analyst to work with the Intelligent Automation team RPA, NLP, AI and Advanced Analytics, to provide specialization in Advanced Analytics to extract insight from information by iterating rapidly to summarize and visualize large data sets. You will be working closely with business SMEs, operations research and will be learning / leveraging AI tools & techniques. You will assist in efforts to create analytical solutions for client initiatives. Youll be responsible for data exploration, discovery, and presentation of gathered insight from data. You will be responsible for visualizing and communicating insight extracted from data to stakeholders at various levels across the company. You will construct, test, maintain and architect supporting datasets.

This position requires Hands on & expert experience with enterprise data visualization tools like Tableau and / or Power BI leveraging Azure AI platform tools like Databricks & Auto ML, etc. Proven ability to work independently on big projects is essential. Ability to facilitate conversations with business SMEs to understand the problem, rapidly iterate proposed solutions and clearly present new findings/ solutions is required. Lead-level experience providing technical & functional guidance is a must. Experience with relational database management system development also a required. Must be able to build analytics solution including data exploration, extraction, cleaning, transformation, testing and implementation. Solid analysis and problem-solving skills and superior interpersonal skills with the ability to work with several stakeholders across multiple organizations is required. Must be open to learn new tools and technologies and able to adapt to fast-paced working environment. Preferred Experience includes: Project leadership experience leading collaborative efforts; Masters Degree in Management Information Systems, Computer Science or equivalent; and, ability to write code in python, java and R.

Desired Skills: Data Analytics, Enterprise Reporting, Tableau, Power BI, RDBMS, Azure AI, Databricks, Auto ML, Python, Java, R

**Local candidates preferred**",Thinkfind Corporation,"Fort Worth, TX",IT Services,Information Technology
Data Engineer,"DATA ENGINEER

Job Description

Simpli.fi is hiring talented and experienced software engineers to join its Data Engineering team.

At Simpli.fi, you will have the opportunity to truly work with Big Data. We have roughly 100 Terabytes of data in our data warehouse and nearly 1 Petabyte in our Hadoop cluster. We handle over 70 billion messages a day funneled through Kafka topics. We integrate with a real time system that processes nearly 3 million queries per second on over 60,000 active campaigns. The Data Engineering team is responsible for moving and transforming massive datasets into valuable and insightful information.

Our Data Engineering team works very closely with all aspects of operational data, both internal and external. We are hiring Data Engineers with the Software Engineering capabilities to not only build data pipelines that efficiently transform and move data across systems, but also to build the next generation of data tools that will enable us to take full advantage of this data. In this role, your work will broadly influence the company's clients and internal analysts.

A career at Simpli.fi offers countless ways to make an impact in a fast-growing organization. This is a full-time position based in our office in Fort Worth, Texas.

Â

Responsibilities
Build data expertise and own data quality for the transfer pipelines that you build to transform and move data to our voluminous Data Warehouse (Flume, Kafka, Spark Streaming, Hadoop, Vertica)
Architect, build and launch new data models that provide intuitive analytics to our customers (Vertica/Star Schema, Looker analytics)
Design and develop new systems and tools to enable clients to optimize and track advertising campaigns (Vertica, Looker, Spark)
Use your expert skills across a number of platforms and tools such as Python, Ruby, SQL, Linux shell scripting, Git, and Chef
Work across multiple teams in high visibility roles and own the solution end-to-end
Provide support for our existing production systems. We use Datadog and PagerDuty for monitoring and alerting.
Requirements
Proficiency building and supporting applications on Linux topology.
Familiarity with OO and FP methodologies and philosophies.
Moderate experience in Big Data ecosystem (Hadoop, Spark, Kafka, etc.)
Proficiency in Ruby or Python development.
Familiarity with column-oriented Big Data systems such as Vertica or Cassandra.
Familiarity with profiling and tuning a SQL execution plan
Familiarity with the JVM. Scala is a definite plus.
Excellent communication skills including the ability to identify and communicate data driven insights.
BS or MS degree in Computer Science, Software Engineering, or a related technical field. We will consider equivalent experience in the industry.","Tek Leaders
3.5","Fort Worth, TX",IT Services,Information Technology
Data Engineer,"Hi, Hope you are doing well Please let me know if would be interested for the below position and share your updated resume to cmartinamvotech.com Job Title Data Engineer Location Fort Worth, TX Mode Direct Hire Remote till Covid ends. Job Description Specifically, the Data Engineer has a passion for data, and creatively leverages expertise with data tools and programming languages to assess, transform, organize, optimize, and exploit systems and platform data. Further, you will be responsible for generating representative data sets for demonstrations, technology evaluation, systems development, and data science initiatives. You will be expected to help automate processes, and articulate methods to gain data management efficiencies, as well implementing and adopting of Data Engineering Best Practices to include mentoring projects and team members toward success. Senior skill level 4+ years of data engineering, schema design, dimensional data modeling, and or data management experience Proficient with data management tools, such as Python, SQL, Java, and use of Git Demonstrated experience with extracting, cleaning, managing, optimizing, and exploiting large and very complex data sets Experience with best practices for compute, storage, and transfer optimization in processing large volumes of data Active SECRET security clearance is required. Preferred Experience with graph databases and event sourcing models Familiarity with machine learning, artificial intelligence, and or geospatial data analysis Strong interpersonal skills combined with ability to multi-task and maintain flexibility and creativity in a variety of situations Notes Candidates must have strong experience in SQL, Python and Data Modeling Must have secret clearance Warehousing would be preferred Thanks Regards Chris Martin cmartinamvotech.com","Amvotech Solutions, Inc
5.0","Fort Worth, TX",IT Services,Information Technology
Data Analyst,"The contractor serves as a Records and Data Management Specialist providing information and records management services including a variety of program assistance duties as assigned, or as required, to include:* Develops and maintains the electronic records for design and construction projects* Establishes effective controls over the creation, organization, maintenance, use and disposition of records in coordination with the Bureau Records Coordinator;* Ensures permanently valuable information is preserved and all other record information is retained, reviewed and disposed of systematically according to Department policies and procedures;* Reviews records systems and records management practices and coordinates with the Bureau Records Coordinator to ensure information and records management processes and programs are in full compliance with applicable laws and regulations and ensures that managers and staff","Ho Chunk
2.8","Arlington, TX",Convenience Stores & Truck Stops,"Restaurants, Bars & Food Services"
Data Analyst,"What you'll do
Data Analyst
Strong SQL ad Data Savvy.
Mortgage exp is mandatory

Location Coppell TX

BR - $55/hr.

What you bring

While others say it, we do it: we care. We have great people and we do great work. Just as importantly, we have great relationships with an impressive clientele. Over 1,000 talented, diverse, and career-minded professionals are carving out their role and experiencing a good mix of challenges and opportunities and we're rooting for them along the way, every day. For more, click: https://www.mindteck.com/career/life-at-mindteck.html
Mindteck is an Equal Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, religion, color, national origin, sex, sexual orientation, gender identity, age, status as a protected veteran, status as a qualified individual with a disability, or any other trait protected by law.","Mindteck
3.3","Coppell, TX",IT Services,Information Technology
Data Engineer,"The Data Engineer joins a team of engineers, subject matter experts, and data scientists to jointly provide experienced, high-quality Information Technology (IT) engineering solutions. The Data Engineer will work with our clients on their hardest challenges – advancing and enhancing systems supporting the defense of our nation and its partners. Your efforts will be integral to the success of these initiatives. As an NT Concepts team member, you will be expected to be solutions-oriented, innovative, collaborative and agile. Performing as part of, or in support of a SCRUM team, you will be expected to thrive in organized chaos and immediately adopt agile team self-organizing methods and techniques.

Specifically, the Data Engineer has a passion for data, and creatively leverages expertise with data tools and programming languages to assess, transform, organize, optimize, and exploit systems and platform data. Further, you will be responsible for generating representative data sets for demonstrations, technology evaluation, systems development, and data science initiatives. You will be expected to help automate processes, and articulate methods to gain data management efficiencies, as well implementing and adopting of Data Engineering Best Practices to include mentoring projects and team members toward success.

Senior skill level
4+ years of data engineering, schema design, dimensional data modeling, and / or data management experience
Proficient with data management tools, such as Python, SQL, Java, and use of Git
Demonstrated experience with extracting, cleaning, managing, optimizing, and exploiting large and very complex data sets
Experience with best practices for compute, storage, and transfer optimization in processing large volumes of data
Active SECRET security clearance is required.
Preferred:
Experience with graph databases and event sourcing models
Familiarity with machine learning, artificial intelligence, and / or geospatial data analysis
Strong interpersonal skills combined with ability to multi-task and maintain flexibility and creativity in a variety of situations
#CJ
#JT","NT Concepts
3.3","Fort Worth, TX",IT Services,Information Technology
Data Scientist,"Upstart is a leading AI lending platform partnering with banks to expand access to affordable credit. Forbes recently ranked Upstart #12 on its list of ""most promising AI companies in America."" Inc. Magazine also recognized Upstart as one of the Best Workplaces for 2020.

By leveraging Upstart's AI platform, Upstart-powered banks can have higher approval rates and lower loss rates, while simultaneously delivering the exceptional digital-first lending experience their customers demand. Upstart's patent-pending platform is the first to receive a no-action letter from the Consumer Financial Protection Bureau related to fair lending. Upstart is based in San Mateo, California and Columbus, Ohio.

Most Upstarters join us because they connect with our mission of enabling access to effortless credit based on true risk. If you are energized by the impact you can make at Upstart, we'd love to hear from you!

The Team

Data Scientists with Upstart have a direct impact on our company's success. Our data science team consists of full-stack generalists as well as specialists in statistical modeling or machine learning as well as Machine Learning Engineers.

Because our challenges are so new, Data Scientists at Upstart need strong creative problem-solving skills and the technical background to implement solutions. Our research environment affords team members the opportunity to utilize a variety of statistical and machine learning methods with the freedom and encouragement to pursue alternative approaches to solving problems. Whether developing new products or identifying novel approaches to core models, we are continuously seeking the next big ideas to move our business forward.

The Role

As a Data Scientist, you'll have ownership across a breadth of data science projects working end-to-end from building proof-of-concepts to productionalizing models. You'll also have an opportunity to work alongside a talented team that values curiosity, humility, drive and teamwork.

What we're looking for:
Strong academic credentials with a M.S. in statistics, mathematics, computer science or a related quantitative field of study with a preference for a PhD
Comfort with programming (ideally in Python and R)
Rigorous quantitative background
Predictive modeling experience is preferred
Enthusiasm for and alignment with Upstart's mission and values
Strong sense of intellectual curiosity balanced with humility
Numerically-savvy with ability to operate at a speedy pace
What you'll love:
Competitive compensation (base + bonus & equity)
Comprehensive medical, dental, and vision coverage
Personal development and technology & ergonomic budgets
Life insurance and disability benefits
Clubs and Activities (game nights, Fitstarters, Superwomen, book club, investing club, money discussions, photography club and basketball teams)
Generous vacation policy
401(k) retirement plan
Catered lunches + snacks & drinks
Upstart is a proud Equal Opportunity Employer. We are dedicated to ensuring that underrepresented classes receive better access to affordable credit, and are just as committed to embracing diversity and inclusion in our hiring practices. We celebrate all cultures, backgrounds, perspectives, and experiences, and know that we can only become better together.","Upstart
4.2","Columbus, OH",Lending,Finance
Machine Learning Engineer,"Upstart is a leading AI lending platform partnering with banks to expand access to affordable credit. Forbes recently ranked Upstart #12 on its list of ""most promising AI companies in America."" Inc. Magazine also recognized Upstart as one of the Best Workplaces for 2020.

By leveraging Upstart's AI platform, Upstart-powered banks can have higher approval rates and lower loss rates, while simultaneously delivering the exceptional digital-first lending experience their customers demand. Upstart's patent-pending platform is the first to receive a no-action letter from the Consumer Financial Protection Bureau related to fair lending. Upstart is based in San Mateo, California and Columbus, Ohio.

Most Upstarters join us because they connect with our mission of enabling access to effortless credit based on true risk. If you are energized by the impact you can make at Upstart, we'd love to hear from you!

The Team

Upstart's data science team has a direct impact on our company's success. Our data science team consists of full-stack generalists as well as specialists in statistical modeling or machine learning as well as machine learning engineers.

Because our challenges are so new, members of our data science team need strong creative problem-solving skills and the technical background to implement solutions. Our research environment affords team members the opportunity to utilize a variety of statistical and machine learning methods with the freedom and encouragement to pursue alternative approaches to solving problems. Whether developing new products or identifying novel approaches to core models, we are continuously seeking the next big ideas to move our business forward.

The Role

As a Machine Learning Engineer with Upstart, you'll enjoy a fast-paced environment with a focus on productionalizing, deploying and training machine learning models. You'll also have an opportunity to work alongside a talented team that values curiosity, humility, drive and teamwork.

What we're looking for:
2+ years of professional experience as a data scientist or software engineer
Experience productionalizing, deploying, and training machine learning models (we use Python and sklearn, but experience in any language is valuable)
Interest in helping other data scientists improve code quality in addition to conducting independent analyses
Experience optimizing models for memory and speed
Knowledge of machine learning and statistics or a strong desire to learn
BS in computer science, mathematics, statistics or related area of study with advanced degree(s) preferred
What you'll love:
Competitive compensation (base + bonus & equity)
Comprehensive medical, dental, and vision coverage
Personal development and technology & ergonomic budgets
Life insurance and disability benefits
Clubs and Activities (game nights, Fitstarters, Superwomen, book club, investing club, money discussions, photography club and basketball teams)
Generous vacation policy
401(k) retirement plan
Catered lunches + snacks & drinks
Upstart is a proud Equal Opportunity Employer. We are dedicated to ensuring that underrepresented classes receive better access to affordable credit, and are just as committed to embracing diversity and inclusion in our hiring practices. We celebrate all cultures, backgrounds, perspectives, and experiences, and know that we can only become better together.","Upstart
4.2","Columbus, OH",Lending,Finance
Data Scientist,"Battelle is guided by a founding mission. We invest our knowledge, talents and resources, helping our customers achieve their most important goals. We apply scientific rigor and creativity, succeeding where others may fail, and we invest in our communities, making the world better for generations to come. All of us share a common purpose: to solve the greatest challenges of today and tomorrow.

Our 22,000 employees work at the forefront of scientific innovation to tackle critical challenges in security, human health, manufacturing, energy and environmental management. Battelle’s work is grounded in the belief that science, technology and a passion for excellence can make industries more competitive and the world a better place.

Battelle is seeking a Data Scientist. There are multiple positions under this posting located in Columbus, Ohio, and Dayton, Ohio. Work will support Wright-Patterson AFB in Dayton, Ohio. This position is contingent on award of contract and candidates are expected to start within 30 days of contract award.
JOB SUMMARY
The selected candidate(s) will serve as a member of a team of highly qualified and motivated individuals supporting timely and mission-critical effort related to Publicly Available Information/Open Source (PAI/OS) data on foreign developments in current and future weapons systems, subsystems, and technologies impacting air, space, and cyberspace, missiles, and other new initiatives. The candidate will work with a team of cleared linguists, scientists, intelligence analysts, engineers, and other relevant subject matter experts for collection, organization, and analysis. The position will be responsible for leading the development and maintenance of data processing and analysis solutions, which will aid in parsing and formatting large data sets, advanced searching and collection, natural language processing (NLP), triaging, and language translation for Scientific & Technical (S&T) open-source information. This will include direct collaboration with team members to maximize collection and interpretation efforts for a wide variety of data aligned with mission requirements. The candidate will also be responsible for data visualization, web scraping technologies, digital libraries and databases, appropriate algorithms, and similar tasks in support of the project. S/he will provide direct input to finished products in the form of visualizations, datasets, and recommendations for further collection and analysis, among other duties.
MAJOR RESPONSIBILITIES
Leads data science solutions for digital library development, human language translations, optical character recognition, and technical analysis of foreign language materials and technologies.
Leads the development of data science solutions to integrate, ingest, reformat, and transform PAI data.
Catalogs and scans translated material to identify data of interest based on specific requests.
Develops and maintains data collection solutions for PAI/OS information, including web scrapers and technologies for sensitive searching.
Works with a multi-disciplinary team to leverage data science and NLP tools to collect, organize, and analyze diverse science and technology information from multiple sources.
Uses data visualization techniques to provide insights on large data sets and input to finished reports.
Leads building and maintaining of databases in support of analyst and subject matter expert use.
Uses NLP tools to support language translation and science and technology assessments.
Must be able to oversee teams and lead tasking to deliver outcomes on time and effectively as part of a team in a joint working environment.
THE FOLLOWING IS REQUIRED
Must be a US Citizen with an active TS/SCI clearance
Bachelor’s Degree in mathematics, statistics, computer science, or similar technical field.
At least 5-10 years of experience as a data scientist, statistician, applied mathematician, or equivalent to fulfill the job requirements.
Proficiency with a high-level programming language, i.e. Python, R, Perl.
Experience working in U.S. national security, e.g. intelligence community, military, joint operations, or related government contracting.
THE FOLLOWING IS DESIRED
Master’s degree in the above areas.
Experience with shell scripting (bash, ksh, or equivalent).
More than 10 years of experience as a data scientist, statistician, applied mathematician, or equivalent to fulfill the job requirements.
Experience using NLP tools to collect, assemble, interpret, translate, and analyze open-source data, such as scientific publications, social media, and databases, and synthesizing knowledge into actionable intelligence.
Experience using NLP tools to support assessments and technical reporting on technologies and scientific topics, i.e. technology readiness levels (TRL) and critical technology elements (CTE).
Subject matter expertise in and support of U.S. air- and space-related programs and technologies.
LEGAL DISCLAIMER
The above statements are intended to describe the nature and level of work being performed by people assigned to this job. They are not intended to be an exhaustive list of all responsibilities, activities, and skills required of staff members. No statement herein is intended to imply any authorities to commit Battelle unless special written permission is granted by Battelle’s Legal Department.

BENEFITS

Battelle’s competitive benefits program includes comprehensive medical and dental care, matching 401K, paid time off, flexible spending accounts, disability coverage, and other benefits that help provide financial protection for you and your family.

Battelle provides employment and opportunities for advancement, compensation, training, and growth according to individual merit, without regard to race, color, religion, sex (including pregnancy), national origin, sexual orientation, gender identity, marital status, age, genetic information, disability, veteran-status, or any other characteristic protected under applicable Federal, state, or local law. Our goal is for each staff member to have the opportunity to grow to the limits of their abilities and to achieve personal and organizational objectives. We will support positive programs for equal treatment of all staff and full utilization of all qualified employees at all levels within Battelle.

For more information about our other openings, please visit www.battelle.org/careers","Battelle
3.1","Columbus, OH",Research & Development,Business Services
Data Analyst,"Olive is healthcare’s first intelligent digital workforce and has been successfully deployed at numerous healthcare systems across the country. Olive helps streamline and automate the most high-volume, repetitive tasks so healthcare professionals can concentrate on their patients and solving healthcare’s most challenging problems. Olive’s promise to her customers is that she finds out where she can make an impact, onboards quickly, shows up to work everyday, does her job extremely well, and gets smarter over time.Omega is Olive’s digital workforce operations center dedicated to ensuring that Olive keeps her promise, by providing support, analysis, communications, and continual improvements to all live customer bots.The Data Analyst at Olive is part of Omega’s rapidly growing Omega Analysis team. With Olive being deployed across the country, the Data Analyst will work cross-functionally to help make Olive more efficient and elevate customer insights to internal stakeholders. The Data Analyst will perform data manipulation and in-depth analysis of complex health care data to produce analysis on customer quality, utilization and outcomes. The ideal candidate is inquisitive, creative, self-driven and flexible with the ability to work within a dynamic high-growth startup environment.

Requirements
Bachelor’s degree in Mathematics, Economics, Computer Science, Statistics, or equivalent professional experience
0-3 years of professional experience in data analysis, data management and manipulation, report writing, and/or database design
Technical expertise regarding data modeling, database development, data mining and segmentation techniques
Strong working knowledge of databases (Amazon Redshift and Athena), and querying languages (SQL)
Experience building data visualizations using tools like Tableau or similar
Ability to analyze large data sets and collect insights in a fast-paced, agile environment
Experience with predictive analysis and statistical methods
Previous experience with analytical programing languages (Python, R) and related data manipulation packages (Pandas, Numpy, dplyr, tidyr) is a plus","Olive
3.5","Columbus, OH",Enterprise Software & Network Solutions,Information Technology
Data Scientist,"Job Description
One of our clients is currently seeking a Data Scientist ***ONLY FOR US CITIZENS***

Responsibilities
Responsible for the end-to-end architecture of the Data Science and Natural Language Processing (NLP) solution, including its assembly and integration into the client’s IT architecture.
Responsible for the management and mitigation of technical risks, ensuring that the solution services can be realistically delivered by the underlying technology components.
The ideal candidate should be experienced in architecting highly scalable end-to-end data science platforms.
Required Skills
Experience working with senior decision-makers
Strong communication/interpersonal skills
Proven analytical background
Advanced Excel skills","Dash Technologies Inc
3.8","Columbus, OH",-1,-1
Data Scientist,"Job Description
CAS uses unparalleled scientific content, specialized technology and unmatched human expertise to help R&D organizations across Commercial, Government and Academic sectors create groundbreaking innovations that benefit the world. As the Scientific Information Solutions Division of the American Chemical Society, CAS manages the largest curated reservoir of scientific knowledge, and for 111 years, has helped innovators mine, assess and apply that information to keep businesses thriving. The CAS team is global, diverse, endlessly curious and strives to make actionable scientific insights accessible to innovators worldwide.

CAS is currently seeking a Data Scientist. This position will be located in our headquarters in Columbus, Ohio.

Data scientists are passionate about data and applying analytical methods while simultaneously understanding the business context in order to arrive at a solution. Data scientists add business value by leveraging vast quantities of data and building accurate mathematical models. Data scientists are skilled in putting well-defined parameters around potentially ambiguous problems, evaluating success based on business-important criteria, and applying modern artificial intelligence and machine learning techniques to large datasets to solve complex business problems.

Duties:
Develop, plan, and execute analytical projects as an individual contributor and in teams
Synthesize analytical findings for consumption by senior business executives
Participate in multiple, assigned research projects with minimal supervision and within time and budget constraints
Organize data from many different types of sources and at significantly varying scales for subsequent analysis
Critically evaluate data for quality measures such as completeness, accuracy, and applicability, applying understanding of relevant research area nomenclature
Solve unusual problems using a combination of appropriate statistics, machine learning, and computational methods
Create technical reports and presentations, describing results with visualization in a manner that the client can understand
Present research results to clients and participate in scientific conferences, peer review panels, and increase company visibility through publications
Perform other duties as assigned
Qualifications:
Master's Degree in Statistics, Economics, Applied Mathematics, Operations Research, Physics, Data Science fields and 0-2 years’ experience OR Bachelor's with 2-5 years’ experience.
Experience across a broad range of modern data science and analytics tools (e.g., SQL, Hive, Hadoop, Spark, Python, R)
Experienced with data cleansing, reconciliation, conversion, and validation
Expert knowledge in quantitative methods for business and advanced data science
Proven track record of various artificial intelligence and machine learning techniques to create models that drive significant business results
Demonstrated analytical, multi-tasking, problem solving, organizational, and planning skills
Ability to interpret reports, analyze trends and provide insights
Strong written and verbal communication skills. Demonstrated ability to communicate complicated statistical analytical concepts to business stakeholders in a simplified, comprehendible manner.
Trusted advisor and thought leader on data and analytical techniques
Collaborative team player: Selfless, places team above self. Embraces feedback and shares knowledge with team.
Establish and manage relationships with clients and internal partners
Plan and carry out appropriate professional self-development activities
Ability to travel as required
Desired, but not required:
PhD in Statistics, Economics, Applied Mathematics, Operations Research, Physics, Data Science fields
Experience with Natural Language Processing
Knowledge and experience in chemistry, drug discovery/development, or medical related industry
Conducting analyses using cloud platforms
Experience delivering analytics in a consulting role
CAS offers a competitive salary and comprehensive benefits package, including a generous vacation plan, medical, dental, vision insurance plans, and employee savings and retirement plans. Candidates for this position must be authorized to work in the United States and not require work authorization sponsorship by our company for this position now or in the future. EEO/Minority/Female/Disabled/Veteran.
Company Description
CAS uses intuitive technology, unparalleled scientific content and unmatched human expertise to help companies create groundbreaking innovations that benefit the world. As the scientific information solutions division of the American Chemical Society, CAS manages the largest curated reservoir of scientific knowledge, and for 111 years, has helped innovators mine, assess and apply that information to keep businesses thriving. The CAS team is global, diverse, endlessly curious and strives to make scientific insights accessible to innovators worldwide.","CAS
3.1","Columbus, OH",Enterprise Software & Network Solutions,Information Technology
Data Scientist,"Job Description:

· Working closely with the technology and learning teams, theData Scientist will be responsible for the following:

· Creating infrastructure for thedelivery team; Maintain a working knowledge of data mining and visualizationbest practices; Work in coordination with the team for better and quickresults;

· Being able to develop or program databases; Having theability to query databases and perform statistical analysis; Analyze the dataavailable and provide the relevant output;

· Collaborate with engineering colleagues to define the datamodeling goals for designated project areas;

· Having a good understanding of design and architectureprinciples; Understand the importance of the system development and help ingetting it implemented;

· Have good time management skills and should be able to meetthe expected deliverables;

· Being able to create examples, prototypes, demonstrations tohelp management better understand the work;

· Capacity to motivate and train junior scientists and offercounsel to peers. Being able to work autonomously;

Basic Qualifications:

Passion, commitment, resourcefulness, and a drive to continuelearning are essential prerequisites. For this role, were also looking for someonewho meets the following criteria:

· PhD/ Master's Degree in Statistics,Mathematics, Computer Science, or equivalent; 5+ years of data science/miningexperience;

· Excellent knowledge of at least twocoding languages, e.g. Python, Java, Scala, R Language, SQL, ETL Tools, Perland Pig;

· Should have worked on different toolslike Java, SQL, Python, etc.; Good experience with SQL, Linux shell scripts,Perl, and AWK;

· Domain knowledge in at least twoindustries; Minimum five years of experience in customer-facing activities;

· Overall knowledge of BusinessIntelligence; in particular, data modeling, ETL, and reporting tools;

· Extensive hands-on experience workingwith very large data sets, including statistical analyses, data visualization,data mining, and data cleansing/transformation;","Kognetics
3.6","Gahanna, OH",-1,-1
Data Analyst,"Job Description
Ultrasonic Crack Detection (UCD) – Data Analyst

The ROSEN Group operates in more than 100 countries and employs over 3,000 people. ROSEN
USA, based in Houston, TX seeks to employ an In-Line Inspection – Ultrasonic Crack Detection
(UCD) Data Analyst. This position is located at our Columbus, OH office.

Responsibilities:
Through the performance of daily tasks, and in cooperation with other department process
functions, execute all aspects of the UCD Data Analysis process per ROSEN policies and
procedures.
Receive pipeline In-line inspection data from ROSEN Sub-processes, check for quality and
quantity using ROSEN proprietary software, procedures, and specifications.
Perform basic data processing and compile Line Information File.
Analyze and interpret UCD signal data to identify both references and anomalies.
Perform In-Line Inspection data correlation.
Requirements

Qualifications or Skills:
A two - year degree in a technical discipline or equivalent work experience in a related area is
preferred.
A minimum high school education or GED is required.
Satisfactory completion of the required training and experience as required by ANSI/ASNT
ILI-PQ-2005 per applicable technology.
Intermediate Microsoft Office skills, particularly Microsoft Word and Excel.
Excellent interpersonal skills – ability to work well within a team environment.
Excellent troubleshooting skills.
Strong communication skills – both written and verbal.
Strong analytical and interpretive skills.
Detail oriented/organizational skills required.
Ability to grasp new concepts quickly and easily.
Our Offer

ROSEN USA offers an exceptional working environment, salary commensurate with experience and an incredible benefits package.
Company Description
ROSEN is a leading privately owned company serving the oil and gas industry with inspection, integrity, and rehabilitation products and services. For over 35 years, ROSEN has provided the industry with advanced inspection solutions to ensure safe and economical operation of a wide range of assets and facilities. The ROSEN Group operates in more than 120 countries and employs over 3,000 people.

ROSEN is an extended team of people with a passion for technology and innovation. Our claim “empowered by technology” is the key to our sophisticated and highly innovative products and services to the oil and gas and other engineering industries. The focus of all our research efforts and high tech solutions is on a safe operation of assets and therefore provide protection for both people and the environment.","ROSEN USA
3.6","Columbus, OH",Oil & Gas Services,"Oil, Gas, Energy & Utilities"
Data Scientist,"Title: Data Science

Location: COLUMBUS OH 43215

Duration: 11+ months with extension possible

Basic Qualifications
MS. in a quantitative field such as Computer Science, Statistics, or Mathematics
4 years of hands on working with data , 2+ years of predictive modeling, machine learning and data science experience
2 / 2 + years of hands on R Coding involving focused on DS packages –
Proficiency in statistical and other tools/languages - R, S-plus, SAS, STATA, Python, Java, Scala


Preferred Skills:
Coding experience with R/ SAS/ open source programming platforms


Thank You,

Shibu Singha

Assistant Manager - Recruitment

Avacend, Inc.

3155 North Point Pkwy Bldg. G

Suite 100, Alpharetta GA 30005

Shibu.S@avacend.com

Required Skills

Data Science, Predictive Modeling, Scala,
R, S-plus, SAS, STATA, Python, Java, Scala
Reliability models, Markov Models, Stochastic models, Bayesian Modeling, Classification Models, Cluster Analysis, Neural Network, Non-parametric Methods, Multivariate Statistics
Required Experience

Job Location
Columbus, US-OH","Avacend, Inc.
2.5","Columbus, OH",Staffing & Outsourcing,Business Services
Statistician,"The U.S. Department of the Treasury has a distinguished history dating back to the founding of our nation. As the steward of U.S. economic and financial systems, Treasury is a major and influential leader in today's global economy. We have over 100,000 employees across the country and around the world. Come Join the Department of the Treasury and Invest in Tomorrow.
See Other Information for Locations
Positions are to be filled in the Large Business & International (LB&I), Data Solutions division.
Eight (8) positions are to be filled in any of the following locations:
Birmingham, AL
Fayetteville, AR
Little Rock, AR
Phoenix, AZ
El Monte, CA
Glendale, CA
Laguna Niguel, CA
Los Angeles, CA
Long Beach, CA
Oakland, CA
Sacramento, CA
San Diego, CA
San Francisco, CA
San Jose, CA
Santa Ana, CA
Lakewood, CO
Hartford, CT
New Haven, CT
Norwalk, CT
Washington, DC
Newark, DE
Miami, FL
Ft. Myers, FL
Jacksonville, FL
Maitland, FL
Plantation, FL
Tampa, FL
West Palm Beach, FL
Atlanta, GA
Honolulu, HI
Des Moines, IA
Chicago, IL
Downers Grove, IL
Schiller Park, IL
Springfield, IL
Indianapolis, IN
Wichita, KS
Louisville, KY
New Orleans, LA
Boston, MA
Brockton, MA
Stoneham, MA
Southborough, MA
Baltimore, MD
Lanham-Seabrook, MD
Rockville, MD
Ann Arbor, MI
Clinton Township, MI
Detroit, MI
Farmington Hills, MI
Flint, MI
Grand Rapids, MI
Pontiac, MI
Bloomington, MN
Chesterfield, MO
Lee's Summit, MO
Charlotte, NC
Greensboro, NC
Raleigh, NC
Omaha, NE
Edison, NJ
Iselin, NJ
Mountainside, NJ
Paterson, NJ
Las Vegas, NV
Albany, NY
Bethpage, NY
Buffalo, NY
New York, NY
Rochester, NY
Cincinnati, OH
Columbus, OH
Independence, OH
Oklahoma City, OK
Tulsa, OK
Portland, OR
Philadelphia, PA
Pittsburgh, PA
King Of Prussia, PA
Guaynabo, PR
Warwick, RI
Franklin, TN
Memphis, TN
Nashville, TN
Austin, TX
Farmers Branch, TX
Fort Worth, TX
Houston, TX
San Antonio, TX
Ogden, UT
Salt Lake City, UT
Norfolk, VA
Richmond, VA
Vienna, VA
Seattle, WA
Milwaukee, WI
Waukesha, WI
Kearneysville, WV
Martinsburg, WV
WHAT DOES A DATA SCIENTIST DO? The Data Scientist utilizes advanced analytical, statistical, and computer programming skills to develop data- driven solutions to difficult business challenges. As a data scientist, you are responsible for conducting data-centric projects to provide insight and informed decisions for mission- oriented programs of the Internal Revenue Service (IRS), which may impact multiple program segments, divisions, the Service, or segments of the taxpayer population. This is accomplished by utilizing a wide range of technical competencies such as statistics and machine learning, coding languages, data wrangling, and reporting and visualization techniques. The Data Scientist may lead team or cross functional projects, and will apply critical thinking, problem solving and ability to communicate complex analysis to advance the use of data-driven decision making in IRS operations.

WHAT IS THE LARGE BUSINESS AND INTERNATIONAL (LB&I) DIVISION OF THE INTERNAL REVENUE SERVICE? The Large Business and International (LB&I) business unit provides service and enforcement activities to support tax compliance of businesses and related entities with assets of $10 million or more, as well as small U.S. businesses engaged in international, U.S. citizens abroad, and foreign persons and businesses with a U.S. tax requirement.
As a Data Scientist, you will:
Serve as a technical expert with responsibility for the initiation, planning, implementation, controlling, modifying and executing of all or part of an entire project, including such tasks as formulation of workload estimates for program segments, specification of the methodology to be used, preparation of appropriate specifications and procedures, and review of computer systems specifications and materials and instructions needed for assuring the adequacy of the project’s design and objectives.
Explore novel methods of retrieving data and develop innovative recommendations to management and senior leadership as a means for making data driven decisions such as modification of processes and policies. Review, evaluate, validate, and document the results of the findings.
Assist the supervisor in determining the scope, goals and schedules for future programs in the Office. Collaborate with business or technology partners to understand business needs, identify opportunities, and develop and implement analytical solutions.
Identify and assess relevant data sources’ validity and reliability to meet project needs. Collate, clean, transform, analyze, and integrate structured and unstructured data from various sources in preparation for analysis.
Apply statistical methods and concepts including data mining, statistical theory and research procedures to test hypotheses using structured and unstructured data. Develop data product solutions to improve customer experiences, anomaly detection, and business outcomes. Develop proofs of concept or demonstrations to evaluate feasibility of project solutions and recommend visualization strategies.
Document project work and review deliverables for validity, reliability and timeliness. Communicate analytic solutions to technical and non-technical stakeholders, including during executive- level and/or cross-agency meetings, in a clear and effective manner using oral and written communications.
Maintain knowledge of state-of-the-art innovations in data science from both academic and industry sources and identify opportunities for implementation. Engage in general professional development to improve knowledge of IRS processes/programs.
Apply computer based mathematical/statistical techniques using software. Lead or participate in statistical projects or studies in survey sampling (design and estimation), modeling, or statistical research. Apply knowledge of programming/coding language (i.e., SQL, SAS, SPSS, RStudio) to develop scripts or applications.
Act as a troubleshooter in resolving bottlenecks at any step in a project by identifying and proposing solutions; this may include coordination with other project team members or stakeholders to mitigate issues.

WHERE CAN I FIND OUT MORE ABOUT OTHER IRS CAREERS? If you want to find out more about IRS careers, visit us on the web at www.jobs.irs.gov
#LI-POST
You must meet the following requirements by the closing date of this announcement
BASIC QUALIFICATION REQUIREMENTS:

GS-1530 Statistician All Grades:
You must have a Bachelor's degree that included 15 semester hours in statistics (or in mathematics and statistics, provided at least 6 semester hours were in statistics), and 9 additional semester hours in one or more of the following: physical or biological sciences, medicine, education, or engineering; or in the social sciences including demography, history, economics, social welfare, geography, international relations, social or cultural anthropology, health sociology, political science, public administration, psychology, etc. Credit toward meeting statistical course requirements should be given for courses in which 50 percent of the course content appears to be statistical methods, e.g., courses that included studies in research methods in psychology or economics such as tests and measurements or business cycles, or courses in methods of processing mass statistical data such as tabulating methods or electronic data processing. OR
Combination of education and experience -- courses as shown above, plus appropriate experience or additional education. The experience should have included a full range of professional statistical work such as (a) sampling, (b) collecting, computing, and analyzing statistical data, and (c) applying statistical techniques such as measurement of central tendency, dispersion, skewness, sampling error, simple and multiple correlation, analysis of variance, and tests of significance.
GS-13 LEVEL: You must have one year of specialized experience at a level of difficulty and responsibility equivalent to the GS-12 grade level in the Federal service. Specialized experience for this position includes all of the following:
Experience applying project management principles on a data science project
Experience planning and executing a variety of data science and/or analytics projects.
Experience using data mining process models (such as CRISP-DM, SEMMA, etc.,) to design and execute data science project.
Experience preparing and analyzing structured and unstructured datasets to explorations and evaluating data science centric models.
Experience working with multiple data types and formats as a part of a data science project.
Experience applying a range of analytic approaches, including (but not limited to) machine learning, text analytics, and natural language processing; graph theory, link analysis and optimization models; complex adaptive systems; and/or deep learning neural networks that are part of the exploration.
Experience coding in various programming languages (such as R, Python, SQL, or JAVA) to conduct various phases of data science projects.
Experience creating and querying different datastores and architectures (such as Sybase, Oracle, and open-source databases) to work with various types of data as part of the data science project.
Experience using tools for data visualization (graphs, tables, charts, etc.,) and end-user business intelligence.
-The experience may have been gained in the public sector, private sector or Volunteer Service. One year of experience refers to full-time work; part-time work is considered on a prorated basis.
-To ensure full credit for your work experience, please indicate dates of employment by month/year, and indicate number of hours worked per week, on your resume.","Internal Revenue Service
3.5","Columbus, OH",Federal Agencies,Government
Data Analyst,"The Paragon Group is a Columbus, Ohio based Information Technology firm delivering high quality, cost effective resources to a progressive clientele. Founded in 1998, The Paragon Group has a full time staff of highly skilled, motivated professionals. The Paragon Group provides staff augmentation, temp-to-perm placements, permanent placements, and consulting services both locally and nationally. We are a full time employer and offer a full benefits package. We are currently looking for a Data Analyst for a contract to hire position here in Columbus, OH.

Job Description:
Data quality analyst familiar with ServiceNow, who will be required to work within the IT Asset and Configuration Management team and will be specifically focused on data quality review and data cleanup
Discovery scans will be applied to the production environment which will capture and categorize assets within the existing structure database; These discovery schedules will capture and create new hardware and software models, and create the related hardware and software assets
Candidate will be responsible for reviewing the data quality of these new assets, ensuring appropriate categorization, and that the new assets contain required data to ensure appropriate production support
Candidate will work with support teams to capture lifecycle status and end of life/support dates in support of Technical Debt reporting and be responsible for additional data quality clean-up initiatives including potential duplicate assets, misconfigured assets, and retirement of related assets is in scope for this position
Job Requirements
Contract to Hire position *no C2C*
Must have experience with data analysis and data quality
Experience with ServiceNow (or similar product) preferred
Must have excellent communication and documentation skills
Experience with IT Asset Management preferred","The Paragon Group
2.9","Columbus, OH",Banks & Credit Unions,Finance
Machine Learning Engineer,"At Path we work to develop state-of-the-art artificial intelligence, machine learning, computer vision, and sensors systems to make industrial robots intelligent. We create world transforming technology, like our first robotic welding system, allowing hardware to do much more, with much less human input.

We are looking for a machine learning engineer who is eager to find novel solutions and methods to solve challenging problems. You will report to the CTO and will join a team of dedicated, supportive, and enthusiastic people to help create the future of manufacturing.

What You'll Do
Design and apply machine learning algorithms for improving robotic intelligence.
Create and apply new approaches to solve computer vision problems in image and 3D data domains, signal processing, reinforcement learning, offline and online motor control and path planning.
Develop new machine learning algorithms to improve rate of learning, generalizability, variable reduction, increase run-times, or improve applicability to different modalities of data.
Run machine learning test and experiments, and perform statistical analysis
Collaborate with software and hardware teams to build data and model pipelines
Stay up-to-date with new research and novel findings in machine learning
Who You Are
You have 3+ years of experience working with machine learning algorithms
You have an advanced degree in in computer science, mathematics, or related discipline involving computer vision, machine learning or artificial intelligence
You have 2+ publications with a focus on computer vision, deep reinforcement learning, or related
You have research experience that may include deep learning, computer vision, reinforcement or active learning
You understand Tensorflow, Theano, or Caffe and GPU-based computation in general
You have proficiency in Python or C/C++
You have experience with common image or vision processing libraries (OpenCV or PCL)
You are excited by the opportunity to be a part of a venture-backed startup early on, where your work will have an immediate and direct impact
You are passionate about what you do and enjoy working in a collaborative environment
You like the idea of working at a tech first company with all the perks that go with that- free lunch, unlimited time off, team events, and great benefits
At Path Robotics we love coming to work to solve interesting and tough challenges but also because our ideas are welcomed and valued. We encourage unique thinking and are dedicated to creating a diverse and inclusive environment. All qualified applicants will receive consideration for employment without regard to race, color, religion, gender, gender identity or expression, sexual orientation, national origin, genetics, disability, age, or veteran status.","Path Robotics
4.5","Columbus, OH",Industrial Manufacturing,Manufacturing
Data Analyst,"Data Analyst
If you are a Data Analyst with experience, please read on!

Job Title: Data Analyst
Job Locations: Remote with HQ in Redwood City, CA
Job Type: $45-$50/hr
Requirements:
1.) 3+ years experience creating dashboards in Business Intelligence (BI) tools (i.e. Tableau)
2.) Experience writing code in Python, R or similar language
3.) Bachelor's Degree
4.) Experience writing SQL Queries, and Excel Formulas
What You Will Be Doing
As a member of our team, you will be writing code that is readable in flat files, and processing data in several different ways and you will responsible for summarizing data results into files, charts, and graphs.
What You Need for this Position
Requirements:
1.) 3+ years experience creating dashboards in Business Intelligence (BI) tools (i.e. Tableau)
2.) Experience writing code in Python, R or similar language
3.) Bachelor's Degree
4.) Experience writing SQL Queries, and Excel Formulas

Preferred Skills:
1.) Salesforce experience
2.) Healthcare/Health Plan Analytics experience
What's In It for You
- Competitive Compensation $40 - $50/hr
- Benefits (Medical, Dental)
- PTO
So, if you are a Data Analyst with experience, please apply today!
-
Applicants must be authorized to work in the U.S.


CyberCoders, Inc is proud to be an Equal Opportunity Employer

All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, disability, protected veteran status, or any other characteristic protected by law.

Your Right to Work In compliance with federal law, all persons hired will be required to verify identity and eligibility to work in the United States and to complete the required employment eligibility verification document form upon hire.","CyberCoders
4.2","Columbus, OH",Staffing & Outsourcing,Business Services
Data Analyst,"Hello,

Hope you are doing great.

Data Analyst(4681)

Columbus, OH

18 months

W2 Position

Required Skills and Experience:

4-6 yearsâ experience

Bachelorâs degree in computer science, management information science, or related field

Data Profiling

Data Analysis

Data Mapping

Strong SQL

Source-Target Data Mapping

ETL Knowledge

Detail-Oriented/Critical Thinker

Preferred Skills and Experience:

Informatica IDQ

Information Analyzer

IBM Data Architect

Insurance domain knowledge

Keywords: Data Profiling, Data Analysis, Data Mapping, SQL, Source Target Data Mapping, ETL Knowledge

Please fill the details for submission

1. Full legal name:

2. Last 4 digits of social security number:

3. Date of birth:

4. Phone #:

5. Visa Status:

6. Email address:

7. Rate:

8. Skype Id:

9. Current Location:

10. LinkedIn :

11. Have you worked for Nationwide/Unicon in the last 6 months ?

12. Full education details, including school name, type of degree, concentration of study, year of graduation

a. Masters:Â

b. Branch/Stream:

c. university:

d. year of passed:

e. location:

Â

f.ÂBachelors:

g. Branch/Stream:

h. university:

i.Âyear of passed:

j.Âlocation:

1. Are you still currently employed?

2. Why are you leaving your current position?

3. Based on your Visa status will you require ANY DSIG sponsorship or associated costs within the first 18 months of assignment?

If yes, what sponsorship would be requested and when is it needed by?

4. Are you able to relocate for the position?

a. How much notice would you need to relocate

b. Can you start within 2 weeks of the offer

4. What is the rate at your current position or most recent position?

5. If offered an interview â how quickly can you attend â is 2 daysâ notice enough?

Regards,

<b>Naveen A<b>Data Systems Integration Group Inc,
485 Metro Place South, Suite 101

Dublin, OH 43017
Email : naveen@dsiginc.com

Phone : 614-344-4600 x 114
Fax : 1866.421.8583

This email has been checked for viruses by Avast antivirus software.
www.avast.com </p>","Data Systems Integration Group Inc
2.8","Columbus, OH",Accounting,Accounting & Legal
Machine Learning Engineer,"Tiger Analytics is an advanced analytics consulting firm. We are the trusted analytics partner for several Fortune 100 companies, enabling them to generate business value from data. Our consultants bring deep expertise in Data Science, Machine Learning and AI. Our business value and leadership has been recognized by various market research firms, including Forrester and Gartner.We are looking for a Machine Learning Engineers for our team. As part of this job, you will be responsible for:* Providing solutions for the deployment, execution, validation, monitoring, and improvement of data science solutions.* Creating high performance and scalable Machine Learning systems* Building reusable production data pipelines for machine learning models* Writing production quality code and libraries that can be packaged as containers, installed and deployed* Demonstrate up-to-date knowledge in software engineering practices and provides solutions for the development, implementation and scaling, execution, validation, monitoring, and improvement of data science solutions* Collaborate with Data Engineers and Data Scientist to build data and model pipelines and help in running machine learning tests and experiments* Manage the infrastructure and data pipelines needed to bring ML solution to production* Demonstrate end-to-end understanding of applications (including, but not limited to, the machine learning algorithms) being created and maintain scalable machine learning solutions in production* Abstracts complexity of production for machine learning through the use of containers* Troubleshoots production machine learning model issues, including recommendations for retrain, re-validate, and improvements.* 3-5 years of experience with Big Data Projects using multiple types of structured and unstructured data* Ability to work with a global team, playing a key role in communicating problem context to the remote teams* Excellent communication and team work skills* Bachelor's degree or higher in computer science or relatedAdditional Skills Required:* Technologies used would include Python (multiple versions), Spark, Hadoop, with an emphasis on good coding practices in a continuous integration context, model evaluation, and experimental design* Test driven development (prefer py.test / nose), experience with Cloud environments* Proficiency in statistical tools, relational databases & expertise in programming languages like Python/SQL is desired* Dockers & Kubernetes experience is preferred* Experience with AWS will be an added advantageSignificant career development opportunities exist as the company grows. The position offers a unique opportunity to be part of a small, challenging, and entrepreneurial environment, with a high degree of individual responsibility.","Tiger Analytics
4.6","Columbus, OH",Consulting,Business Services
Data Analyst,"Data Analyst

Required Skills:
Must have 1-3 years of experience in a professional data analysis
Knowledge of Microsoft Office and components, including Access
Experience creating schedules in Excel is required
Experience with relational databases, SQL, Crystal Reports.
Some familiarity with IT groups will be required
Analyze data using appropriate control and run charts
Must be strong with Math numerator and denominator
Must be comfortable in a fast-paced environment
Must be polished and able to present to Executives if needed
Must be driven and eager to learn
Must have a great attitude
Excellent written and verbal communication skills are ABSOLUTELY required
Must be accountable, this group is the top of their department and they must be able to trust you


Desired Skills:
Degree in HIM
Healthcare Data Analysis
Description of Role/Responsibilities:
We are looking for a Data Analyst to join an expanding team at one of the most well respected Health Care organizations in Columbus. Our client is seeking a Data Analyst in their Quality Improvement Services department. This position is responsible for reviewing and analyzing data that supports assigned projects in Quality Improvement Services; will maintain databases and sources of information for quality initiatives, accreditation efforts, regulatory mandates, contractual requirement and ad hoc requests; position coordinates data from various sources.
Find Us on Facebook!
Follow Us on Twitter!

Beacon Hill is an Equal Opportunity Employer that values the strength diversity brings to the workplace. Individuals with Disabilities and Protected Veterans are encouraged to apply.

Company Profile:

Beacon Hill Technologies, a premier National Information Technology Staffing Group, provides world class technology talent across all industries on a contract, direct (permanent), contract-to-direct and project basis. Beacon Hill Technologies' dedicated team of recruiting and staffing experts consistently delivers quality IT professionals to solve our customers' technical and business needs.

Beacon Hill Technologies covers a broad spectrum of IT positions, including Project Management and Business Analysis, Programming/Development, Database, Infrastructure, Quality Assurance, Production/Support and ERP roles.

Learn more about Beacon Hill Staffing Group and our specialty divisions, Beacon Hill Associates, Beacon Hill Financial, Beacon Hill HR, Beacon Hill Legal, Beacon Hill Pharma and Beacon Hill Technologies by visiting www.beaconhillstaffing.com.

We look forward to working with you.

Beacon Hill. Employing the Future","Beacon Hill Staffing Group
4.5","Columbus, OH",Staffing & Outsourcing,Business Services
Data Engineer,"About Beam

Beam Dental was founded in 2012 by three engineers who saw the opportunity to make dental services more accessible using technology. The Beam Brush, which launched the company, was one of the earliest examples of the ‘Internet of Things’, where everyday objects can enable incredible new understanding and capability. Today, Beam Dental has parlayed its industry passion into the fastest growing provider of dental insurance in the US, with a mission to offer businesses best in class dental coverage and close the gap on the over 100 million Americans who don’t have dental insurance today.

Joining Beam Dental Means

• Working for a complex and dynamic business, simultaneously operating across insurance, CPG manufacturing, IOT, and dental services
• Being challenged to improve every day by a diverse and diversely skilled team
• Engaging in an active, intense, and fun work environment
• Being a decision maker and ‘owner’ of your subject matter
• Joining in our mission to forever change the way people access dental services
• Being a person of high character, high EQ, and amazing talent

The Role

Beam is looking for a data engineer to join our Data Management team. In this role, you will be working cross-functionally with business domain experts, analytics, and engineering teams to design and implement our Data Lakehouse model (Data Lake + Data Warehouse). You will design, implement and scale data pipelines that transform data into actionable information that enables decision making. You will drive initiatives to formalize data governance and quality assurance. You will have a significant part in building a solid data foundation for a data-driven company.

What You Will Bring

You're an engineer with a passion for data and information. You possess a strong knowledge of both data modeling and engineering. You're confident with cloud technologies and infrastructure like AWS. You're comfortable working independently while collaborating across various business and technical teams to deliver scalable solutions. You are unafraid to tackle the unfamiliar and bring clarity to complex concepts.
What You Will Do
Ingest multiple internal and external systems into our data lake using batch and streaming concepts.
Build and scale data warehouse systems that support complex analysis across the business.
Design, build, and own data pipelines that deliver information that drives the business forward.
Work with business domain experts to transform business processes into data models that are understandable and used across the company.
Partner with data analysts and engineering teams to build foundational data sets that are trusted, well understood, and aligned with business strategy in order to enable self-service through BI tools.
Work with analytics and business teams to build predictive analytics solutions using machine learning.
Serve as a primary data expertise resource who will help drive decisions on tooling, testing, and process to improve data quality.
Define and manage SLAs for data sets that support production services.
Implement an Incident Response Framework to handle situations that disrupt data availability to the business.
What Skills Will Help You Be Successful
3+ years of experience working as engineer with cloud data architecture (AWS) in an Agile, TDD environment
Strong knowledge of data modeling methods and approaches (partitioning, star and snowflake, dimensional modeling) as well as how to scale those models over time
Recent accomplishments working with object, relational, and columnar data stores such as Redshift
Experience working with Python, Java, or other data-oriented programming languages
An understanding of containerization technologies and orchestration tools
Experience with workflow orchestration tools such as Airflow and running it on Kubernetes
Exceptional communication and critical thinking skills
Experience working in a healthcare technology environment is a plus
Visa sponsorship or transfer not available for this position.
---------------------------------------
Beam believes a diverse and inclusive environment is key to building a great company and a great product. We are committed to creating an environment that is welcoming for people of all backgrounds, and encourage everyone to apply. Beam is an Equal Opportunity Employer and does not discriminate on the basis of race, color, gender, sexual orientation, gender identity or expression, religion, disability, national origin, protected veteran status, age, or any other status protected by applicable national, federal, state, or local law.","Beam Dental
4.9","Columbus, OH",Insurance Carriers,Insurance
Machine Learning Engineer,"Job Description
We are seeking an upper-mid-level to senior Machine Learning Engineer/Developer to join our team on an intelligent Machine Learning developer tools software project. You should have a history of working within an Agile product delivery team, strong understanding and practice of coding standards, knowledge of the intricacies of common ML frameworks and languages, cloud-based data management products, and excellent problem-solving skills. Must be a US Citizen.

What you would be doing:

Design generative adversarial networks for generating synthetic data

Work closely with a team of AI experts to solve problems in computer vision, data visualization, and user computer interaction

Python and/or C/C++ using deep learning toolkits such as PyTorch, TensorFlow, Keras, and/or Caffee

Evaluate the learning rate and stability of the networks in order to improve the network design

Stay informed about the latest developments in artificial neural network research and utilize state-of-the-art technology as it emerges

What you need to have:

M.S./Ph.D. in relevant field or equivalent experience

In-depth knowledge of common deep learning frameworks such as PyTorch, TensorFlow, or Keras

Proven experience solving problems using deep neural networks

Solid understanding of computer vision fundamentals

Strong programming skills and demonstrable experience in Python and C++

Broad understanding of Machine Learning across multiple domains, algorithms, and applications

Use of good programming practices including writing, testing, and documenting robust and maintainable code

Proficiency with computer vision toolkits such as OpenVX is a plus

Experience with Agile software development methodology is a plus","Cognitive Recruiting Solutions, LLC","Columbus, OH",-1,-1
Data Analyst,"Job Description
Job description

• Interpret data, analyze results using statistical techniques and provide ongoing reports

• Develop and implement databases, data collection systems, data analytics and other strategies that optimize statistical efficiency and quality

• Acquire data from primary or secondary data sources and maintain databases/data systems

• Identify, analyze, and interpret trends or patterns in complex data sets

• Filter and “clean” data by reviewing computer reports, printouts, and performance indicators to locate and correct code problems

• Work with management to prioritize business and information needs

• Locate and define new process improvement opportunities

Requirements

• Proven work experience as a data analyst or business data analyst

• Technical expertise regarding data models, database design development, data mining and segmentation techniques

• Strong knowledge of and experience with reporting packages (Business Objects etc), databases (SQL etc), programming (XML, Javascript, or ETL frameworks)

• Knowledge of statistics and experience using statistical packages for analyzing datasets (Excel, SPSS, SAS etc)

• Strong analytical skills with the ability to collect, organize, analyze, and disseminate significant amounts of information with attention to detail and accuracy

• Adept at queries, report writing and presenting findings

• Master's in Computer Science or Engineering Management or Project Management or Information Systems/Technology (Preferred)

Powered by JazzHR

EwmRECs19V","Staffigo Technical Services, LLC
5.0","Columbus, OH",IT Services,Information Technology
Data Analyst,"We are currently accepting resumes for a Data Analyst in Columbus, OH .Required Skills and Experience:
Bachelors degree in computer science, management information science, or related field
4-6 years experience
Data Analyst with Power BI skill sets preferably with Modeling, Profiling and Mapping experience.
UNICON International, Inc. is an Equal Opportunity Employer.

If you are interested in working for an organization where honesty, integrity and quality are among the core principles then click apply today!

Keywords: Data analyst, Power BI

Job Requirements:

• Ensure data accuracy and data integrity
• Acquire data from primary or secondary data sources and maintain databases/data systems
• Extracting data from the database
•","UNICON International, Inc
4.5","Columbus, OH",-1,-1
Data Engineer,"Helping patients, pathologists and physicians work together to accelerate and optimize treatment
Deep Lens, Inc, through our next-generation AI technology and cloud-based solutions, is driven to increase cancer cure rates and minimize the side effects of treatment for patients globally.
We value everyone’s unique background and support a work-life balance to bring solutions to market that have a positive impact on health professionals and those individuals impacted by cancer.
Job Description:
The Technology team at Deep Lens, Inc. is seeking an experienced Data Engineer to support the new and ongoing development of our platform. The hire will be responsible for building and maintaining our data and data pipeline architecture. The ideal candidate is an experienced data pipeline builder and data wrangler who enjoys optimizing data systems and building them from the ground up. The Data Engineer will support our engineers, data analysts, and product team on data initiatives and will ensure data delivery architecture is consistent throughout ongoing projects. They must be self-directed and comfortable supporting the data needs of multiple teams, systems, and products. Knowledge of healthcare and healthcare data is beneficial.
Key Roles & Responsibilities
Responsible for the design, development, and maintenance of mission-critical healthcare data pipelines
Responsible for the design, development, and maintenance of healthcare data lake
Perform data analysis required to troubleshoot data-related issues and assist in the resolution of data issues
Represent the global development team during business design sessions and architecture reviews to ensure delivery aligns with expectations.
Participate in code reviews and support QA initiatives to ensure high-quality delivery
Create clear and concise documentation for implemented software and processes
Skills Required
Experience with relational database technologies (MySQL, PostgreSQL, MSSQL, etc)
Experience with big data technologies (Hadoop, Drill, Spark, etc)
Experience in programming and object-oriented design (Python, Java, etc)
Strong analytic and design skills, including the ability to understand business requirements and translate them into efficient and effective technical designs that work well within large-scale, well-structured enterprise environments
Strong communication with the ability to interface directly with clients and analysts to ensure technical requirements and delivery align with expectations
Experience with Agile Software Development methodologies
Ability to work in a fast-paced environment and handle multiple priorities or tasks
Experience with healthcare data and data formats (e.g. HL7, FHIR) is a plus
Job Type
Full-time
Experience
BS or MS degree in Computer Science or a related technical field
5+ years of Data Engineer (or equivalent) experience
Job Type: Full-time
Benefits:
Flexible Schedule
Health Insurance
Paid Time Off
Schedule:
Monday to Friday
COVID-19 considerations:
Our team is working remotely which has been an easy transition as we offer a flexible work environment generally.
Experience:
Data Engineering: 5 years (Required)
Object Oriented Design: 2 years (Required)
Big Data Technologies (Hadoop, Spark, Drill): 1 year (Required)
Education:
Bachelor's (Required)
Additional Compensation:
Other forms
Work Location:
One location
Visa Sponsorship Potentially Available:
No: Not providing sponsorship for this job
This Company Describes Its Culture as:
Detail-oriented -- quality and precision-focused
Innovative -- innovative and risk-taking
Company's website:
https://www.deeplens.ai/
Company's Facebook page:
https://www.facebook.com/deeplensai/
Work Remotely:
Temporarily due to COVID-19",Deep Lens,"Columbus, OH",-1,-1
Data Engineer,"At Finite State, our mission is to protect the devices that power our modern lives by illuminating the vulnerabilities and threats within their complex software supply chains. We do this by leveraging massive data analysis to provide transparency to device manufacturers and their customers - enabling them to understand and mitigate their risks before they are compromised. We are seeking a Data Engineer with special interest in firmware analysis. If you are a self-starter who enjoys working in a fast-paced, collaborative environment, then we want to talk to you!

Primary responsibilities for this position include:
● Manage the ingestion, flow, and processing of firmware and network data through our analytics pipeline.
● Collecting data from third party API’s and other data sources.
● Developing new data models to support a wide variety of data types and use cases.
● Developing customer facing and internal REST and GraphQL API interfaces to the full data set.
● Solving challenging big data management problems.

Candidates at a minimum must have significant experience with the following:
● Experience with large scale, complex, and fast moving data sets
● Experience with Stream based data pipelines preferably leveraging Kafka
● AWS Cloud Batch, Lambda, Glue, ECS
● NoSQL and SQL database technologies
● Django Development
● Python Development
● Source control (Github)

It’s preferred (but not required) that candidate have familiarity and experience with:
● Kubernetes and Docker orchestration
● Apache Calcite
● PostgreSQL
● Pilosa and Molecula
● CI/CD tooling
● Python Alembic
● Python Graphene and GraphQL
● PySpark
● ElasticSearch
● Enterprise SaaS Development
● Apache Airflow

About Finite State
Built on two decades of cybersecurity experience serving the Fortune 50 and the U.S. Intelligence Community, our team of experts understands the hidden risks in today’s enterprise networks, where IoT vulnerabilities are quickly becoming the entry point of choice for cyber attacks.

Finite State gives cyber defenders a tactical advantage by identifying the devices running on the network and proactively analyzing firmware buried inside the IoT devices for hidden vulnerabilities. We have a sense of duty to protect the critical infrastructure we rely on including medical devices, power grids and telecommunication networks. We were founded in 2017 in Columbus, Ohio.

At Finite State, we are dedicated to hiring a diverse workforce and are proud to be an equal opportunity employer. We offer competitive salary, equity, full benefits (medical, dental, vision, disability and life-insurance), 401k plan and unlimited PTO, because we believe it is important to unplug and recharge.

Come help us solve one of the biggest problems in cyber security!","Finite State
5.0","Columbus, OH",Security Services,Business Services
Data Engineer,"Job Description:

· Pythondevelopers who can confidently work unassisted and deliver high qualitysolutions:

· Strongprogramming experience in- Python

· Strongbackground in data structures, algorithm complexities and object-orientedprogramming in- Python, with knowledge of at least one- Python- web framework(Django).

· Stronghands-on experience as an individual contributor in Conceptualize.

· Designand Develop new features in the product Experience with NoSQL technologies.

· Handson experience with Cassandra and Redis is good to have.

Basic Qualifications:

· Passion,commitment, resourcefulness, and a drive to continue learning are essentialprerequisites. For this role, were also looking for someone who meets thefollowing criteria:

· B. Tech/PhD/ Master's Degree inStatistics, Mathematics, Computer Science, or equivalent; 5+ years of datascience mining experience;","Kognetics
3.6","Gahanna, OH",-1,-1
Data Engineer,"Greetings,

Job Title- Data Engineer ( Netezza & OBIEE )

Location- Columbus OH

Duration -6 months with visibility for extension

Need a Sr.Data Engineer of whom has strong experience in OBIEE/ Netezza/PDA and of whom has been a Tech Lead for driving requirements through to development for a data warehouse solution

Must have Skills- Netezza, OBIEE, DWH, Data Modeling

Good to have- DataStage, Hadoop.

Warm Regards,

Rahul

R3 Technology Inc.,

324 Courtyard Drive, Suite A

Hillsborough, New Jersey,Â08844

Direct:7328373458

Website: www.r3tek.com

Â",R3 Tek,"Columbus, OH",-1,-1
Data Engineer,"It's fun to work in a company where people truly BELIEVE in what they're doing!


We're committed to bringing passion and customer focus to the business.



Summary & Key Responsibilities




This role on the Enterprise Data team will support our Data Engineering initiatives, including the development of our “Data Lake” architecture. This role is primarily project based, but also may provide support and maintenance to applications in production.

Key Responsibilities:
Build distributed, scalable, and reliable data pipelines that ingest and process data at scale and in real-time
Create metrics and apply business logic using Spark, Scala, R, Python, and/or Java
Model, design, develop, code, test, debug, document and deploy an application to production through standard processes
Harmonize, transform, and move data from a raw format to consumable, curated views
Analyze, design, develop, and test applications
Contribute to the maturation of Data Engineering practices, which may include providing training and mentoring to others
Perform Data Designer activities to transform raw data to meaningful datasets and extracts, such as business logic design, source-to-target mappings, data sourcing strategy, and transformation rules.
Apply strong Data Governance principles, standards, and frameworks to promote data consistency and quality while effectively managing and protecting the integrity of corporate data.
Minimum Experience/Education:
Bachelor’s degree in Computer Science, Computer Engineering, Programming, Management Information Systems, or related field. Insurance industry experience is a plus.
Minimum of five years of prior data engineer experience.
Strong hands-on experience in Spark, Scala, R, Python, and/or Java.
Programming experience with the Hadoop ecosystem of applications and functional understanding of distributed data processing systems architecture (Data Lake / Big Data /Hadoop/ Spark / HIVE, etc).
Amazon Big Data ecosystem (EMR, Kinesis, Aurora) experience is a plus.
Extensive knowledge of source system data, such as Guidewire PolicyCenter, is a plus.
Communication and Collaboration Skills:

Written: Must be able to convey key messages in technical terms and business terms. Must be able to create technical documentation, such as specifications, design documents, and testing documents.
Oral: Ability to collaborate and communicate with a wide range of partners, including IT and business, across all levels of the organization. Must actively manage expectations with stakeholders.

Problem Solving:
Must understand the business need and develop technical solutions to meet those needs. Innovation, creativity, and critical problem-solving skills are required to be successful in this role. Solutions need to be comprehensive, flexible for future changes and delivered with a high degree of quality.



State Auto offers a competitive salary, an annual bonus program, an excellent benefits program including medical, dental, vision and prescription insurance coverage, life insurance, matching 401(k) plan, flexible spending accounts, tuition assistance, and a stock purchase plan.

State Auto is committed to the principle of equal employment opportunity for all associates and applicants and to providing associates with a work environment that is free from discrimination and harassment. All employment decisions (hiring, placement, promotion, termination, layoff, recall, transfer, leaves of absence, compensation, training and work assignments) are based on business needs, job requirements and individual qualifications without regard to race, color, religion, gender, sex, sexual orientation, gender identity, national origin, age, disability, genetic information, marital status, citizenship status, military status, or status as a covered veteran in accordance with applicable federal, state and local laws. State Auto will not tolerate discrimination or harassment based on any of these characteristics.

State Auto is a smoke-free work environment. We utilize drug screening and background checks as conditions of employment. For all exempt positions, we also obtain motor vehicle reports (MVR s).

State Auto will not accept candidates from third-party recruiters without a signed agreement with State Auto.

Full Time / Part Time




Full time
Worker Sub-Type




Regular

If you like wild growth and working with happy, enthusiastic over-achievers, you'll enjoy your career with us!","State Auto Insurance Companies
3.9","Columbus, OH",Insurance Carriers,Insurance
Software Engineer,"As a member of our Software Engineering Group, we look first and foremost for people who are passionate around solving business problems through innovation and engineering practices. You'll be required to apply your depth of knowledge and expertise to all aspects of the software development lifecycle, as well as partner continuously with your many stakeholders on a daily basis to stay focused on common goals. We embrace a culture of experimentation and constantly strive for improvement and learning. You'll work in a collaborative, trusting, thought-provoking environment-one that encourages diversity of thought and creative solutions that are in the best interests of our customers globally.

This role requires a wide variety of strengths and capabilities, including:
BS/BA degree or equivalent experience
Advanced knowledge of application, data, and infrastructure architecture disciplines
Understanding of architecture and design across all systems
Working proficiency in developmental toolsets
Knowledge of industry-wide technology trends and best practices
Ability to work in large, collaborative teams to achieve organizational goals
Passionate about building an innovative culture
Proficiency in one or more modern programming languages
Understanding of software skills such as business analysis, development, maintenance, and software improvement
Experience with; Scala/ Sqoop / Spark / Unix / Hadoop /large data sets
JPMorgan Chase & Co., one of the oldest financial institutions, offers innovative financial solutions to millions of consumers, small businesses and many of the world's most prominent corporate, institutional and government clients under the J.P. Morgan and Chase brands. Our history spans over 200 years and today we are a leader in investment banking, consumer and small business banking, commercial banking, financial transaction processing and asset management.

We recognize that our people are our strength and the diverse talents they bring to our global workforce are directly linked to our success. We are an equal opportunity employer and place a high value on diversity and inclusion at our company. We do not discriminate on the basis of any protected attribute, including race, religion, color, national origin, gender, sexual orientation, gender identity, gender expression, age, marital or veteran status, pregnancy or disability, or any other basis protected under applicable law. In accordance with applicable law, we make reasonable accommodations for applicants' and employees' religious practices and beliefs, as well as any mental health or physical disability needs.

Equal Opportunity Employer/Disability/Veterans","JPMorgan Chase Bank, N.A.
3.9","Columbus, OH",Investment Banking & Asset Management,Finance
Data Engineer,"Data Engineer ColumbusCincinnati, OH Our industry leading client is searching for an experienced Data Engineer to design, develop and implement scalable data analytics solutions in the Columbus, OH area. This Data Engineering team is creating a next generation Data Science platform to automate the movement of financial data and provide real time analytics. The Data Engineer will work on an Agile Big Data team to deliver enriched data analytics solutions for unstructured data. Experience working with data flow tools (NiFi Kafka) and data transformation and pipelining experience is desired. Rate 60.00hr - 80.00hr C2C or W2 + Health, Dental, Vision, 401k matching Duration 12 months+ Contract to Hire Requirements for the Data Engineer 3-5+ Years experience creating Data solutions using Python, Spark, Kafka, SQL etc. Strong Python Development experience Ability to implement data warehousing solutions that can take large volumes of structured and unstructured data and rapidly generate meaningful reports andor support ongoing analytical needs. Must have strong ELT ETL Background Experience in identifying and documenting data integration issues, challenges such as duplicate data, non-conformed data, and unclean data including both internal and external data sources. Agile Software Development Experience Experience with Data Transformation, Spark streaming, and PySpark development is highly desired. For immediate consideration, please send updated MS Word Resume to kkareliseliassen.com Keywords Python, Hadoop, Cloudera, Hortonworks, Hive, Spark, Kafka, Nifi, Pig, Scala, PySpark, NumPy, SciPy, SparkML, Agile","Eliassen Group
4.2","Columbus, OH",Staffing & Outsourcing,Business Services
Data Engineer,"RESPONSIBILITIES:

Kforce has a client in search a Data Engineer in Columbus, OH.

Data Wrangler:
Key Tasks:
With full competence, implements data and analytic capabilities, practices, processes, standards, and procedures to align strategy with stakeholder needs and current levels of data and analytic maturity; May analyze trends and patterns in structured and unstructured data in support of business problem solving
Work may include the management and manipulation of complex high volume data from a variety of sources, leading analysis for multiple business units, synthesis of analytic results, development and implementation of techniques and procedures for one or more areas of data and analytics including audits, data analytics, data mapping, modeling, data and analytic requirements, data architecture, and statistical analysis; Support complex projects and undertake moderate projects requiring specialized technical skills; Support data-intensive programs, projects, and/or domains to align enterprise data and analytic policies, standards, and strategies
REQUIREMENTS:
Familiar with all data capabilities
Expert in data acquisition, data wrangling, and data visualization
Experience with SQL, Data Warehouses, Data Marts, and Databases
Experience with data tools such as Tableau, PowerBI, Informatica, Paxata, Denodo, AI/ML, and AWS, is crucial
Ability to interface effectively with business partners and propose and implement complex data solutions
Kforce is an Equal Opportunity/Affirmative Action Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, pregnancy, sexual orientation, gender identity, national origin, age, protected veteran status, or disability status.","Kforce
4.1","Columbus, OH",Staffing & Outsourcing,Business Services
Software Engineer,"As a member of our Software Engineering Group, we look first and foremost for people who are passionate around solving business problems through innovation and engineering practices. You'll be required to apply your depth of knowledge and expertise to all aspects of the software development lifecycle, as well as partner continuously with your many stakeholders on a daily basis to stay focused on common goals. We embrace a culture of experimentation and constantly strive for improvement and learning. You'll work in a collaborative, trusting, thought-provoking environment-one that encourages diversity of thought and creative solutions that are in the best interests of our customers globally.

This role requires a wide variety of strengths and capabilities, including:
BS/BA degree or equivalent experience
Advanced knowledge of application, data, and infrastructure architecture disciplines
Understanding of architecture and design across all systems
Working proficiency in developmental toolsets
Knowledge of industry-wide technology trends and best practices
Ability to work in large, collaborative teams to achieve organizational goals
Passionate about building an innovative culture
Proficiency in one or more modern programming languages
Understanding of software skills such as business analysis, development, maintenance, and software improvement
Expertise with: Java / Hive/ Kafka / API's / Spring Boot / Cloud Foundary / Avro
JPMorgan Chase & Co., one of the oldest financial institutions, offers innovative financial solutions to millions of consumers, small businesses and many of the world's most prominent corporate, institutional and government clients under the J.P. Morgan and Chase brands. Our history spans over 200 years and today we are a leader in investment banking, consumer and small business banking, commercial banking, financial transaction processing and asset management.

We recognize that our people are our strength and the diverse talents they bring to our global workforce are directly linked to our success. We are an equal opportunity employer and place a high value on diversity and inclusion at our company. We do not discriminate on the basis of any protected attribute, including race, religion, color, national origin, gender, sexual orientation, gender identity, gender expression, age, marital or veteran status, pregnancy or disability, or any other basis protected under applicable law. In accordance with applicable law, we make reasonable accommodations for applicants' and employees' religious practices and beliefs, as well as any mental health or physical disability needs.

Equal Opportunity Employer/Disability/Veterans","JPMorgan Chase Bank, N.A.
3.9","Columbus, OH",Investment Banking & Asset Management,Finance
